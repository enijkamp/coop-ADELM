[Warning: Setting the 'MW_NVCC_PATH' environment variable to '/usr/local/cuda-8.0/bin/nvcc'] 
[> In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('vl_compilenn>activate_nvcc', '/home/enijkamp/Dropbox/coop ADELM/matconvnet-1.0-beta16-gpu/matlab/vl_compilenn.m', 600)" style="font-weight:bold">vl_compilenn>activate_nvcc</a> (<a href="matlab: opentoline('/home/enijkamp/Dropbox/coop ADELM/matconvnet-1.0-beta16-gpu/matlab/vl_compilenn.m',600,0)">line 600</a>)
  In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('vl_compilenn', '/home/enijkamp/Dropbox/coop ADELM/matconvnet-1.0-beta16-gpu/matlab/vl_compilenn.m', 253)" style="font-weight:bold">vl_compilenn</a> (<a href="matlab: opentoline('/home/enijkamp/Dropbox/coop ADELM/matconvnet-1.0-beta16-gpu/matlab/vl_compilenn.m',253,0)">line 253</a>)
  In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('Setup', '/home/enijkamp/Dropbox/coop ADELM/training/coop_net_vanilla_escher/Setup.m', 11)" style="font-weight:bold">Setup</a> (<a href="matlab: opentoline('/home/enijkamp/Dropbox/coop ADELM/training/coop_net_vanilla_escher/Setup.m',11,0)">line 11</a>)
  In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('experiment_learn_escher_31_titan', '/home/enijkamp/Dropbox/coop ADELM/training/coop_net_vanilla_escher/experiment_learn_escher_31_titan.m', 12)" style="font-weight:bold">experiment_learn_escher_31_titan</a> (<a href="matlab: opentoline('/home/enijkamp/Dropbox/coop ADELM/training/coop_net_vanilla_escher/experiment_learn_escher_31_titan.m',12,0)">line 12</a>)] 
[Warning: NVCC not found in the command line path or the one found does not matches '/usr/local/cuda-8.0/bin/nvcc'.] 
[> In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('vl_compilenn>activate_nvcc', '/home/enijkamp/Dropbox/coop ADELM/matconvnet-1.0-beta16-gpu/matlab/vl_compilenn.m', 609)" style="font-weight:bold">vl_compilenn>activate_nvcc</a> (<a href="matlab: opentoline('/home/enijkamp/Dropbox/coop ADELM/matconvnet-1.0-beta16-gpu/matlab/vl_compilenn.m',609,0)">line 609</a>)
  In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('vl_compilenn', '/home/enijkamp/Dropbox/coop ADELM/matconvnet-1.0-beta16-gpu/matlab/vl_compilenn.m', 253)" style="font-weight:bold">vl_compilenn</a> (<a href="matlab: opentoline('/home/enijkamp/Dropbox/coop ADELM/matconvnet-1.0-beta16-gpu/matlab/vl_compilenn.m',253,0)">line 253</a>)
  In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('Setup', '/home/enijkamp/Dropbox/coop ADELM/training/coop_net_vanilla_escher/Setup.m', 11)" style="font-weight:bold">Setup</a> (<a href="matlab: opentoline('/home/enijkamp/Dropbox/coop ADELM/training/coop_net_vanilla_escher/Setup.m',11,0)">line 11</a>)
  In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('experiment_learn_escher_31_titan', '/home/enijkamp/Dropbox/coop ADELM/training/coop_net_vanilla_escher/experiment_learn_escher_31_titan.m', 12)" style="font-weight:bold">experiment_learn_escher_31_titan</a> (<a href="matlab: opentoline('/home/enijkamp/Dropbox/coop ADELM/training/coop_net_vanilla_escher/experiment_learn_escher_31_titan.m',12,0)">line 12</a>)] 
Location of NVCC (/usr/local/cuda-8.0/bin) added to your command search PATH.
vl_compilenn:	CUDA: MEX config file: '/home/enijkamp/Dropbox/coop ADELM/matconvnet-1.0-beta16-gpu/matlab/src/config/mex_CUDA_glnxa64.xml'
Building with 'g++'.
MEX completed successfully.
Building with 'g++'.
MEX completed successfully.
Building with 'g++'.
MEX completed successfully.
Building with 'g++'.
MEX completed successfully.
Building with 'g++'.
MEX completed successfully.
Building with 'g++'.
MEX completed successfully.
Building with 'g++'.
MEX completed successfully.
Building with 'g++'.
In file included from /home/enijkamp/Dropbox/coop ADELM/matconvnet-1.0-beta16-gpu/matlab/src/bits/impl/imread_libjpeg.cpp:14:0:
/home/enijkamp/Dropbox/coop ADELM/matconvnet-1.0-beta16-gpu/matlab/src/bits/impl/imread_helpers.hpp:35:2: warning: #warning "SSSE3 instruction set not enabled. Using slower image conversion routines." [-Wcpp]
 #warning "SSSE3 instruction set not enabled. Using slower image conversion routines."
  ^

MEX completed successfully.
/home/enijkamp/Dropbox/coop ADELM/matconvnet-1.0-beta16-gpu/matlab/src/bits/impl/tinythread.h(654): warning: extra ";" ignored

/home/enijkamp/Dropbox/coop ADELM/matconvnet-1.0-beta16-gpu/matlab/src/bits/impl/tinythread.h(654): warning: extra ";" ignored

Building with 'gcc'.
MEX completed successfully.
Building with 'gcc'.
MEX completed successfully.
Building with 'gcc'.
MEX completed successfully.
Building with 'gcc'.
MEX completed successfully.
Building with 'gcc'.
MEX completed successfully.
Building with 'gcc'.
MEX completed successfully.
  <a href="matlab:helpPopup parallel.gpu.CUDADevice" style="font-weight:bold">CUDADevice</a> with properties:

                      Name: 'TITAN X (Pascal)'
                     Index: 1
         ComputeCapability: '6.1'
            SupportsDouble: 1
             DriverVersion: 9
            ToolkitVersion: 8
        MaxThreadsPerBlock: 1024
          MaxShmemPerBlock: 49152
        MaxThreadBlockSize: [1024 1024 64]
               MaxGridSize: [2.1475e+09 65535 65535]
                 SIMDWidth: 32
               TotalMemory: 1.2774e+10
           AvailableMemory: 1.2118e+10
       MultiprocessorCount: 28
              ClockRateKHz: 1531000
               ComputeMode: 'Default'
      GPUOverlapsTransfers: 1
    KernelExecutionTimeout: 1
          CanMapHostMemory: 1
           DeviceSupported: 1
            DeviceSelected: 1

384.90
/usr/local/MATLAB/R2017a/sys/opengl/lib/glnxa64:/usr/local/MATLAB/R2017a/sys/os/glnxa64:/usr/local/MATLAB/R2017a/bin/glnxa64:/usr/local/MATLAB/R2017a/extern/lib/glnxa64:/usr/local/MATLAB/R2017a/runtime/glnxa64:/usr/local/MATLAB/R2017a/sys/java/jre/glnxa64/jre/lib/amd64/native_threads:/usr/local/MATLAB/R2017a/sys/java/jre/glnxa64/jre/lib/amd64/server:/home/enijkamp/cudnn-3.0/lib64:
### 1/1 ###
Learning category: escher
read and process images 1 / 1000
read and process images 2 / 1000
read and process images 3 / 1000
read and process images 4 / 1000
read and process images 5 / 1000
read and process images 6 / 1000
read and process images 7 / 1000
read and process images 8 / 1000
read and process images 9 / 1000
read and process images 10 / 1000
read and process images 11 / 1000
read and process images 12 / 1000
read and process images 13 / 1000
read and process images 14 / 1000
read and process images 15 / 1000
read and process images 16 / 1000
read and process images 17 / 1000
read and process images 18 / 1000
read and process images 19 / 1000
read and process images 20 / 1000
read and process images 21 / 1000
read and process images 22 / 1000
read and process images 23 / 1000
read and process images 24 / 1000
read and process images 25 / 1000
read and process images 26 / 1000
read and process images 27 / 1000
read and process images 28 / 1000
read and process images 29 / 1000
read and process images 30 / 1000
read and process images 31 / 1000
read and process images 32 / 1000
read and process images 33 / 1000
read and process images 34 / 1000
read and process images 35 / 1000
read and process images 36 / 1000
read and process images 37 / 1000
read and process images 38 / 1000
read and process images 39 / 1000
read and process images 40 / 1000
read and process images 41 / 1000
read and process images 42 / 1000
read and process images 43 / 1000
read and process images 44 / 1000
read and process images 45 / 1000
read and process images 46 / 1000
read and process images 47 / 1000
read and process images 48 / 1000
read and process images 49 / 1000
read and process images 50 / 1000
read and process images 51 / 1000
read and process images 52 / 1000
read and process images 53 / 1000
read and process images 54 / 1000
read and process images 55 / 1000
read and process images 56 / 1000
read and process images 57 / 1000
read and process images 58 / 1000
read and process images 59 / 1000
read and process images 60 / 1000
read and process images 61 / 1000
read and process images 62 / 1000
read and process images 63 / 1000
read and process images 64 / 1000
read and process images 65 / 1000
read and process images 66 / 1000
read and process images 67 / 1000
read and process images 68 / 1000
read and process images 69 / 1000
read and process images 70 / 1000
read and process images 71 / 1000
read and process images 72 / 1000
read and process images 73 / 1000
read and process images 74 / 1000
read and process images 75 / 1000
read and process images 76 / 1000
read and process images 77 / 1000
read and process images 78 / 1000
read and process images 79 / 1000
read and process images 80 / 1000
read and process images 81 / 1000
read and process images 82 / 1000
read and process images 83 / 1000
read and process images 84 / 1000
read and process images 85 / 1000
read and process images 86 / 1000
read and process images 87 / 1000
read and process images 88 / 1000
read and process images 89 / 1000
read and process images 90 / 1000
read and process images 91 / 1000
read and process images 92 / 1000
read and process images 93 / 1000
read and process images 94 / 1000
read and process images 95 / 1000
read and process images 96 / 1000
read and process images 97 / 1000
read and process images 98 / 1000
read and process images 99 / 1000
read and process images 100 / 1000
read and process images 101 / 1000
read and process images 102 / 1000
read and process images 103 / 1000
read and process images 104 / 1000
read and process images 105 / 1000
read and process images 106 / 1000
read and process images 107 / 1000
read and process images 108 / 1000
read and process images 109 / 1000
read and process images 110 / 1000
read and process images 111 / 1000
read and process images 112 / 1000
read and process images 113 / 1000
read and process images 114 / 1000
read and process images 115 / 1000
read and process images 116 / 1000
read and process images 117 / 1000
read and process images 118 / 1000
read and process images 119 / 1000
read and process images 120 / 1000
read and process images 121 / 1000
read and process images 122 / 1000
read and process images 123 / 1000
read and process images 124 / 1000
read and process images 125 / 1000
read and process images 126 / 1000
read and process images 127 / 1000
read and process images 128 / 1000
read and process images 129 / 1000
read and process images 130 / 1000
read and process images 131 / 1000
read and process images 132 / 1000
read and process images 133 / 1000
read and process images 134 / 1000
read and process images 135 / 1000
read and process images 136 / 1000
read and process images 137 / 1000
read and process images 138 / 1000
read and process images 139 / 1000
read and process images 140 / 1000
read and process images 141 / 1000
read and process images 142 / 1000
read and process images 143 / 1000
read and process images 144 / 1000
read and process images 145 / 1000
read and process images 146 / 1000
read and process images 147 / 1000
read and process images 148 / 1000
read and process images 149 / 1000
read and process images 150 / 1000
read and process images 151 / 1000
read and process images 152 / 1000
read and process images 153 / 1000
read and process images 154 / 1000
read and process images 155 / 1000
read and process images 156 / 1000
read and process images 157 / 1000
read and process images 158 / 1000
read and process images 159 / 1000
read and process images 160 / 1000
read and process images 161 / 1000
read and process images 162 / 1000
read and process images 163 / 1000
read and process images 164 / 1000
read and process images 165 / 1000
read and process images 166 / 1000
read and process images 167 / 1000
read and process images 168 / 1000
read and process images 169 / 1000
read and process images 170 / 1000
read and process images 171 / 1000
read and process images 172 / 1000
read and process images 173 / 1000
read and process images 174 / 1000
read and process images 175 / 1000
read and process images 176 / 1000
read and process images 177 / 1000
read and process images 178 / 1000
read and process images 179 / 1000
read and process images 180 / 1000
read and process images 181 / 1000
read and process images 182 / 1000
read and process images 183 / 1000
read and process images 184 / 1000
read and process images 185 / 1000
read and process images 186 / 1000
read and process images 187 / 1000
read and process images 188 / 1000
read and process images 189 / 1000
read and process images 190 / 1000
read and process images 191 / 1000
read and process images 192 / 1000
read and process images 193 / 1000
read and process images 194 / 1000
read and process images 195 / 1000
read and process images 196 / 1000
read and process images 197 / 1000
read and process images 198 / 1000
read and process images 199 / 1000
read and process images 200 / 1000
read and process images 201 / 1000
read and process images 202 / 1000
read and process images 203 / 1000
read and process images 204 / 1000
read and process images 205 / 1000
read and process images 206 / 1000
read and process images 207 / 1000
read and process images 208 / 1000
read and process images 209 / 1000
read and process images 210 / 1000
read and process images 211 / 1000
read and process images 212 / 1000
read and process images 213 / 1000
read and process images 214 / 1000
read and process images 215 / 1000
read and process images 216 / 1000
read and process images 217 / 1000
read and process images 218 / 1000
read and process images 219 / 1000
read and process images 220 / 1000
read and process images 221 / 1000
read and process images 222 / 1000
read and process images 223 / 1000
read and process images 224 / 1000
read and process images 225 / 1000
read and process images 226 / 1000
read and process images 227 / 1000
read and process images 228 / 1000
read and process images 229 / 1000
read and process images 230 / 1000
read and process images 231 / 1000
read and process images 232 / 1000
read and process images 233 / 1000
read and process images 234 / 1000
read and process images 235 / 1000
read and process images 236 / 1000
read and process images 237 / 1000
read and process images 238 / 1000
read and process images 239 / 1000
read and process images 240 / 1000
read and process images 241 / 1000
read and process images 242 / 1000
read and process images 243 / 1000
read and process images 244 / 1000
read and process images 245 / 1000
read and process images 246 / 1000
read and process images 247 / 1000
read and process images 248 / 1000
read and process images 249 / 1000
read and process images 250 / 1000
read and process images 251 / 1000
read and process images 252 / 1000
read and process images 253 / 1000
read and process images 254 / 1000
read and process images 255 / 1000
read and process images 256 / 1000
read and process images 257 / 1000
read and process images 258 / 1000
read and process images 259 / 1000
read and process images 260 / 1000
read and process images 261 / 1000
read and process images 262 / 1000
read and process images 263 / 1000
read and process images 264 / 1000
read and process images 265 / 1000
read and process images 266 / 1000
read and process images 267 / 1000
read and process images 268 / 1000
read and process images 269 / 1000
read and process images 270 / 1000
read and process images 271 / 1000
read and process images 272 / 1000
read and process images 273 / 1000
read and process images 274 / 1000
read and process images 275 / 1000
read and process images 276 / 1000
read and process images 277 / 1000
read and process images 278 / 1000
read and process images 279 / 1000
read and process images 280 / 1000
read and process images 281 / 1000
read and process images 282 / 1000
read and process images 283 / 1000
read and process images 284 / 1000
read and process images 285 / 1000
read and process images 286 / 1000
read and process images 287 / 1000
read and process images 288 / 1000
read and process images 289 / 1000
read and process images 290 / 1000
read and process images 291 / 1000
read and process images 292 / 1000
read and process images 293 / 1000
read and process images 294 / 1000
read and process images 295 / 1000
read and process images 296 / 1000
read and process images 297 / 1000
read and process images 298 / 1000
read and process images 299 / 1000
read and process images 300 / 1000
read and process images 301 / 1000
read and process images 302 / 1000
read and process images 303 / 1000
read and process images 304 / 1000
read and process images 305 / 1000
read and process images 306 / 1000
read and process images 307 / 1000
read and process images 308 / 1000
read and process images 309 / 1000
read and process images 310 / 1000
read and process images 311 / 1000
read and process images 312 / 1000
read and process images 313 / 1000
read and process images 314 / 1000
read and process images 315 / 1000
read and process images 316 / 1000
read and process images 317 / 1000
read and process images 318 / 1000
read and process images 319 / 1000
read and process images 320 / 1000
read and process images 321 / 1000
read and process images 322 / 1000
read and process images 323 / 1000
read and process images 324 / 1000
read and process images 325 / 1000
read and process images 326 / 1000
read and process images 327 / 1000
read and process images 328 / 1000
read and process images 329 / 1000
read and process images 330 / 1000
read and process images 331 / 1000
read and process images 332 / 1000
read and process images 333 / 1000
read and process images 334 / 1000
read and process images 335 / 1000
read and process images 336 / 1000
read and process images 337 / 1000
read and process images 338 / 1000
read and process images 339 / 1000
read and process images 340 / 1000
read and process images 341 / 1000
read and process images 342 / 1000
read and process images 343 / 1000
read and process images 344 / 1000
read and process images 345 / 1000
read and process images 346 / 1000
read and process images 347 / 1000
read and process images 348 / 1000
read and process images 349 / 1000
read and process images 350 / 1000
read and process images 351 / 1000
read and process images 352 / 1000
read and process images 353 / 1000
read and process images 354 / 1000
read and process images 355 / 1000
read and process images 356 / 1000
read and process images 357 / 1000
read and process images 358 / 1000
read and process images 359 / 1000
read and process images 360 / 1000
read and process images 361 / 1000
read and process images 362 / 1000
read and process images 363 / 1000
read and process images 364 / 1000
read and process images 365 / 1000
read and process images 366 / 1000
read and process images 367 / 1000
read and process images 368 / 1000
read and process images 369 / 1000
read and process images 370 / 1000
read and process images 371 / 1000
read and process images 372 / 1000
read and process images 373 / 1000
read and process images 374 / 1000
read and process images 375 / 1000
read and process images 376 / 1000
read and process images 377 / 1000
read and process images 378 / 1000
read and process images 379 / 1000
read and process images 380 / 1000
read and process images 381 / 1000
read and process images 382 / 1000
read and process images 383 / 1000
read and process images 384 / 1000
read and process images 385 / 1000
read and process images 386 / 1000
read and process images 387 / 1000
read and process images 388 / 1000
read and process images 389 / 1000
read and process images 390 / 1000
read and process images 391 / 1000
read and process images 392 / 1000
read and process images 393 / 1000
read and process images 394 / 1000
read and process images 395 / 1000
read and process images 396 / 1000
read and process images 397 / 1000
read and process images 398 / 1000
read and process images 399 / 1000
read and process images 400 / 1000
read and process images 401 / 1000
read and process images 402 / 1000
read and process images 403 / 1000
read and process images 404 / 1000
read and process images 405 / 1000
read and process images 406 / 1000
read and process images 407 / 1000
read and process images 408 / 1000
read and process images 409 / 1000
read and process images 410 / 1000
read and process images 411 / 1000
read and process images 412 / 1000
read and process images 413 / 1000
read and process images 414 / 1000
read and process images 415 / 1000
read and process images 416 / 1000
read and process images 417 / 1000
read and process images 418 / 1000
read and process images 419 / 1000
read and process images 420 / 1000
read and process images 421 / 1000
read and process images 422 / 1000
read and process images 423 / 1000
read and process images 424 / 1000
read and process images 425 / 1000
read and process images 426 / 1000
read and process images 427 / 1000
read and process images 428 / 1000
read and process images 429 / 1000
read and process images 430 / 1000
read and process images 431 / 1000
read and process images 432 / 1000
read and process images 433 / 1000
read and process images 434 / 1000
read and process images 435 / 1000
read and process images 436 / 1000
read and process images 437 / 1000
read and process images 438 / 1000
read and process images 439 / 1000
read and process images 440 / 1000
read and process images 441 / 1000
read and process images 442 / 1000
read and process images 443 / 1000
read and process images 444 / 1000
read and process images 445 / 1000
read and process images 446 / 1000
read and process images 447 / 1000
read and process images 448 / 1000
read and process images 449 / 1000
read and process images 450 / 1000
read and process images 451 / 1000
read and process images 452 / 1000
read and process images 453 / 1000
read and process images 454 / 1000
read and process images 455 / 1000
read and process images 456 / 1000
read and process images 457 / 1000
read and process images 458 / 1000
read and process images 459 / 1000
read and process images 460 / 1000
read and process images 461 / 1000
read and process images 462 / 1000
read and process images 463 / 1000
read and process images 464 / 1000
read and process images 465 / 1000
read and process images 466 / 1000
read and process images 467 / 1000
read and process images 468 / 1000
read and process images 469 / 1000
read and process images 470 / 1000
read and process images 471 / 1000
read and process images 472 / 1000
read and process images 473 / 1000
read and process images 474 / 1000
read and process images 475 / 1000
read and process images 476 / 1000
read and process images 477 / 1000
read and process images 478 / 1000
read and process images 479 / 1000
read and process images 480 / 1000
read and process images 481 / 1000
read and process images 482 / 1000
read and process images 483 / 1000
read and process images 484 / 1000
read and process images 485 / 1000
read and process images 486 / 1000
read and process images 487 / 1000
read and process images 488 / 1000
read and process images 489 / 1000
read and process images 490 / 1000
read and process images 491 / 1000
read and process images 492 / 1000
read and process images 493 / 1000
read and process images 494 / 1000
read and process images 495 / 1000
read and process images 496 / 1000
read and process images 497 / 1000
read and process images 498 / 1000
read and process images 499 / 1000
read and process images 500 / 1000
read and process images 501 / 1000
read and process images 502 / 1000
read and process images 503 / 1000
read and process images 504 / 1000
read and process images 505 / 1000
read and process images 506 / 1000
read and process images 507 / 1000
read and process images 508 / 1000
read and process images 509 / 1000
read and process images 510 / 1000
read and process images 511 / 1000
read and process images 512 / 1000
read and process images 513 / 1000
read and process images 514 / 1000
read and process images 515 / 1000
read and process images 516 / 1000
read and process images 517 / 1000
read and process images 518 / 1000
read and process images 519 / 1000
read and process images 520 / 1000
read and process images 521 / 1000
read and process images 522 / 1000
read and process images 523 / 1000
read and process images 524 / 1000
read and process images 525 / 1000
read and process images 526 / 1000
read and process images 527 / 1000
read and process images 528 / 1000
read and process images 529 / 1000
read and process images 530 / 1000
read and process images 531 / 1000
read and process images 532 / 1000
read and process images 533 / 1000
read and process images 534 / 1000
read and process images 535 / 1000
read and process images 536 / 1000
read and process images 537 / 1000
read and process images 538 / 1000
read and process images 539 / 1000
read and process images 540 / 1000
read and process images 541 / 1000
read and process images 542 / 1000
read and process images 543 / 1000
read and process images 544 / 1000
read and process images 545 / 1000
read and process images 546 / 1000
read and process images 547 / 1000
read and process images 548 / 1000
read and process images 549 / 1000
read and process images 550 / 1000
read and process images 551 / 1000
read and process images 552 / 1000
read and process images 553 / 1000
read and process images 554 / 1000
read and process images 555 / 1000
read and process images 556 / 1000
read and process images 557 / 1000
read and process images 558 / 1000
read and process images 559 / 1000
read and process images 560 / 1000
read and process images 561 / 1000
read and process images 562 / 1000
read and process images 563 / 1000
read and process images 564 / 1000
read and process images 565 / 1000
read and process images 566 / 1000
read and process images 567 / 1000
read and process images 568 / 1000
read and process images 569 / 1000
read and process images 570 / 1000
read and process images 571 / 1000
read and process images 572 / 1000
read and process images 573 / 1000
read and process images 574 / 1000
read and process images 575 / 1000
read and process images 576 / 1000
read and process images 577 / 1000
read and process images 578 / 1000
read and process images 579 / 1000
read and process images 580 / 1000
read and process images 581 / 1000
read and process images 582 / 1000
read and process images 583 / 1000
read and process images 584 / 1000
read and process images 585 / 1000
read and process images 586 / 1000
read and process images 587 / 1000
read and process images 588 / 1000
read and process images 589 / 1000
read and process images 590 / 1000
read and process images 591 / 1000
read and process images 592 / 1000
read and process images 593 / 1000
read and process images 594 / 1000
read and process images 595 / 1000
read and process images 596 / 1000
read and process images 597 / 1000
read and process images 598 / 1000
read and process images 599 / 1000
read and process images 600 / 1000
read and process images 601 / 1000
read and process images 602 / 1000
read and process images 603 / 1000
read and process images 604 / 1000
read and process images 605 / 1000
read and process images 606 / 1000
read and process images 607 / 1000
read and process images 608 / 1000
read and process images 609 / 1000
read and process images 610 / 1000
read and process images 611 / 1000
read and process images 612 / 1000
read and process images 613 / 1000
read and process images 614 / 1000
read and process images 615 / 1000
read and process images 616 / 1000
read and process images 617 / 1000
read and process images 618 / 1000
read and process images 619 / 1000
read and process images 620 / 1000
read and process images 621 / 1000
read and process images 622 / 1000
read and process images 623 / 1000
read and process images 624 / 1000
read and process images 625 / 1000
read and process images 626 / 1000
read and process images 627 / 1000
read and process images 628 / 1000
read and process images 629 / 1000
read and process images 630 / 1000
read and process images 631 / 1000
read and process images 632 / 1000
read and process images 633 / 1000
read and process images 634 / 1000
read and process images 635 / 1000
read and process images 636 / 1000
read and process images 637 / 1000
read and process images 638 / 1000
read and process images 639 / 1000
read and process images 640 / 1000
read and process images 641 / 1000
read and process images 642 / 1000
read and process images 643 / 1000
read and process images 644 / 1000
read and process images 645 / 1000
read and process images 646 / 1000
read and process images 647 / 1000
read and process images 648 / 1000
read and process images 649 / 1000
read and process images 650 / 1000
read and process images 651 / 1000
read and process images 652 / 1000
read and process images 653 / 1000
read and process images 654 / 1000
read and process images 655 / 1000
read and process images 656 / 1000
read and process images 657 / 1000
read and process images 658 / 1000
read and process images 659 / 1000
read and process images 660 / 1000
read and process images 661 / 1000
read and process images 662 / 1000
read and process images 663 / 1000
read and process images 664 / 1000
read and process images 665 / 1000
read and process images 666 / 1000
read and process images 667 / 1000
read and process images 668 / 1000
read and process images 669 / 1000
read and process images 670 / 1000
read and process images 671 / 1000
read and process images 672 / 1000
read and process images 673 / 1000
read and process images 674 / 1000
read and process images 675 / 1000
read and process images 676 / 1000
read and process images 677 / 1000
read and process images 678 / 1000
read and process images 679 / 1000
read and process images 680 / 1000
read and process images 681 / 1000
read and process images 682 / 1000
read and process images 683 / 1000
read and process images 684 / 1000
read and process images 685 / 1000
read and process images 686 / 1000
read and process images 687 / 1000
read and process images 688 / 1000
read and process images 689 / 1000
read and process images 690 / 1000
read and process images 691 / 1000
read and process images 692 / 1000
read and process images 693 / 1000
read and process images 694 / 1000
read and process images 695 / 1000
read and process images 696 / 1000
read and process images 697 / 1000
read and process images 698 / 1000
read and process images 699 / 1000
read and process images 700 / 1000
read and process images 701 / 1000
read and process images 702 / 1000
read and process images 703 / 1000
read and process images 704 / 1000
read and process images 705 / 1000
read and process images 706 / 1000
read and process images 707 / 1000
read and process images 708 / 1000
read and process images 709 / 1000
read and process images 710 / 1000
read and process images 711 / 1000
read and process images 712 / 1000
read and process images 713 / 1000
read and process images 714 / 1000
read and process images 715 / 1000
read and process images 716 / 1000
read and process images 717 / 1000
read and process images 718 / 1000
read and process images 719 / 1000
read and process images 720 / 1000
read and process images 721 / 1000
read and process images 722 / 1000
read and process images 723 / 1000
read and process images 724 / 1000
read and process images 725 / 1000
read and process images 726 / 1000
read and process images 727 / 1000
read and process images 728 / 1000
read and process images 729 / 1000
read and process images 730 / 1000
read and process images 731 / 1000
read and process images 732 / 1000
read and process images 733 / 1000
read and process images 734 / 1000
read and process images 735 / 1000
read and process images 736 / 1000
read and process images 737 / 1000
read and process images 738 / 1000
read and process images 739 / 1000
read and process images 740 / 1000
read and process images 741 / 1000
read and process images 742 / 1000
read and process images 743 / 1000
read and process images 744 / 1000
read and process images 745 / 1000
read and process images 746 / 1000
read and process images 747 / 1000
read and process images 748 / 1000
read and process images 749 / 1000
read and process images 750 / 1000
read and process images 751 / 1000
read and process images 752 / 1000
read and process images 753 / 1000
read and process images 754 / 1000
read and process images 755 / 1000
read and process images 756 / 1000
read and process images 757 / 1000
read and process images 758 / 1000
read and process images 759 / 1000
read and process images 760 / 1000
read and process images 761 / 1000
read and process images 762 / 1000
read and process images 763 / 1000
read and process images 764 / 1000
read and process images 765 / 1000
read and process images 766 / 1000
read and process images 767 / 1000
read and process images 768 / 1000
read and process images 769 / 1000
read and process images 770 / 1000
read and process images 771 / 1000
read and process images 772 / 1000
read and process images 773 / 1000
read and process images 774 / 1000
read and process images 775 / 1000
read and process images 776 / 1000
read and process images 777 / 1000
read and process images 778 / 1000
read and process images 779 / 1000
read and process images 780 / 1000
read and process images 781 / 1000
read and process images 782 / 1000
read and process images 783 / 1000
read and process images 784 / 1000
read and process images 785 / 1000
read and process images 786 / 1000
read and process images 787 / 1000
read and process images 788 / 1000
read and process images 789 / 1000
read and process images 790 / 1000
read and process images 791 / 1000
read and process images 792 / 1000
read and process images 793 / 1000
read and process images 794 / 1000
read and process images 795 / 1000
read and process images 796 / 1000
read and process images 797 / 1000
read and process images 798 / 1000
read and process images 799 / 1000
read and process images 800 / 1000
read and process images 801 / 1000
read and process images 802 / 1000
read and process images 803 / 1000
read and process images 804 / 1000
read and process images 805 / 1000
read and process images 806 / 1000
read and process images 807 / 1000
read and process images 808 / 1000
read and process images 809 / 1000
read and process images 810 / 1000
read and process images 811 / 1000
read and process images 812 / 1000
read and process images 813 / 1000
read and process images 814 / 1000
read and process images 815 / 1000
read and process images 816 / 1000
read and process images 817 / 1000
read and process images 818 / 1000
read and process images 819 / 1000
read and process images 820 / 1000
read and process images 821 / 1000
read and process images 822 / 1000
read and process images 823 / 1000
read and process images 824 / 1000
read and process images 825 / 1000
read and process images 826 / 1000
read and process images 827 / 1000
read and process images 828 / 1000
read and process images 829 / 1000
read and process images 830 / 1000
read and process images 831 / 1000
read and process images 832 / 1000
read and process images 833 / 1000
read and process images 834 / 1000
read and process images 835 / 1000
read and process images 836 / 1000
read and process images 837 / 1000
read and process images 838 / 1000
read and process images 839 / 1000
read and process images 840 / 1000
read and process images 841 / 1000
read and process images 842 / 1000
read and process images 843 / 1000
read and process images 844 / 1000
read and process images 845 / 1000
read and process images 846 / 1000
read and process images 847 / 1000
read and process images 848 / 1000
read and process images 849 / 1000
read and process images 850 / 1000
read and process images 851 / 1000
read and process images 852 / 1000
read and process images 853 / 1000
read and process images 854 / 1000
read and process images 855 / 1000
read and process images 856 / 1000
read and process images 857 / 1000
read and process images 858 / 1000
read and process images 859 / 1000
read and process images 860 / 1000
read and process images 861 / 1000
read and process images 862 / 1000
read and process images 863 / 1000
read and process images 864 / 1000
read and process images 865 / 1000
read and process images 866 / 1000
read and process images 867 / 1000
read and process images 868 / 1000
read and process images 869 / 1000
read and process images 870 / 1000
read and process images 871 / 1000
read and process images 872 / 1000
read and process images 873 / 1000
read and process images 874 / 1000
read and process images 875 / 1000
read and process images 876 / 1000
read and process images 877 / 1000
read and process images 878 / 1000
read and process images 879 / 1000
read and process images 880 / 1000
read and process images 881 / 1000
read and process images 882 / 1000
read and process images 883 / 1000
read and process images 884 / 1000
read and process images 885 / 1000
read and process images 886 / 1000
read and process images 887 / 1000
read and process images 888 / 1000
read and process images 889 / 1000
read and process images 890 / 1000
read and process images 891 / 1000
read and process images 892 / 1000
read and process images 893 / 1000
read and process images 894 / 1000
read and process images 895 / 1000
read and process images 896 / 1000
read and process images 897 / 1000
read and process images 898 / 1000
read and process images 899 / 1000
read and process images 900 / 1000
read and process images 901 / 1000
read and process images 902 / 1000
read and process images 903 / 1000
read and process images 904 / 1000
read and process images 905 / 1000
read and process images 906 / 1000
read and process images 907 / 1000
read and process images 908 / 1000
read and process images 909 / 1000
read and process images 910 / 1000
read and process images 911 / 1000
read and process images 912 / 1000
read and process images 913 / 1000
read and process images 914 / 1000
read and process images 915 / 1000
read and process images 916 / 1000
read and process images 917 / 1000
read and process images 918 / 1000
read and process images 919 / 1000
read and process images 920 / 1000
read and process images 921 / 1000
read and process images 922 / 1000
read and process images 923 / 1000
read and process images 924 / 1000
read and process images 925 / 1000
read and process images 926 / 1000
read and process images 927 / 1000
read and process images 928 / 1000
read and process images 929 / 1000
read and process images 930 / 1000
read and process images 931 / 1000
read and process images 932 / 1000
read and process images 933 / 1000
read and process images 934 / 1000
read and process images 935 / 1000
read and process images 936 / 1000
read and process images 937 / 1000
read and process images 938 / 1000
read and process images 939 / 1000
read and process images 940 / 1000
read and process images 941 / 1000
read and process images 942 / 1000
read and process images 943 / 1000
read and process images 944 / 1000
read and process images 945 / 1000
read and process images 946 / 1000
read and process images 947 / 1000
read and process images 948 / 1000
read and process images 949 / 1000
read and process images 950 / 1000
read and process images 951 / 1000
read and process images 952 / 1000
read and process images 953 / 1000
read and process images 954 / 1000
read and process images 955 / 1000
read and process images 956 / 1000
read and process images 957 / 1000
read and process images 958 / 1000
read and process images 959 / 1000
read and process images 960 / 1000
read and process images 961 / 1000
read and process images 962 / 1000
read and process images 963 / 1000
read and process images 964 / 1000
read and process images 965 / 1000
read and process images 966 / 1000
read and process images 967 / 1000
read and process images 968 / 1000
read and process images 969 / 1000
read and process images 970 / 1000
read and process images 971 / 1000
read and process images 972 / 1000
read and process images 973 / 1000
read and process images 974 / 1000
read and process images 975 / 1000
read and process images 976 / 1000
read and process images 977 / 1000
read and process images 978 / 1000
read and process images 979 / 1000
read and process images 980 / 1000
read and process images 981 / 1000
read and process images 982 / 1000
read and process images 983 / 1000
read and process images 984 / 1000
read and process images 985 / 1000
read and process images 986 / 1000
read and process images 987 / 1000
read and process images 988 / 1000
read and process images 989 / 1000
read and process images 990 / 1000
read and process images 991 / 1000
read and process images 992 / 1000
read and process images 993 / 1000
read and process images 994 / 1000
read and process images 995 / 1000
read and process images 996 / 1000
read and process images 997 / 1000
read and process images 998 / 1000
read and process images 999 / 1000
read and process images 1000 / 1000

ans = 

  <a href="matlab:helpPopup parallel.gpu.CUDADevice" style="font-weight:bold">CUDADevice</a> with properties:

                      Name: 'TITAN X (Pascal)'
                     Index: 1
         ComputeCapability: '6.1'
            SupportsDouble: 1
             DriverVersion: 9
            ToolkitVersion: 8
        MaxThreadsPerBlock: 1024
          MaxShmemPerBlock: 49152
        MaxThreadBlockSize: [1024 1024 64]
               MaxGridSize: [2.1475e+09 65535 65535]
                 SIMDWidth: 32
               TotalMemory: 1.2774e+10
           AvailableMemory: 1.2156e+10
       MultiprocessorCount: 28
              ClockRateKHz: 1531000
               ComputeMode: 'Default'
      GPUOverlapsTransfers: 1
    KernelExecutionTimeout: 1
          CanMapHostMemory: 1
           DeviceSupported: 1
            DeviceSelected: 1

Iteration 1 / 200
training: epoch 01: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 0.011120, min gradient is -0.000783, learning rate is 0.080000
Net1: layer conv2:max response is , min response is .
max gradient is 0.000020, min gradient is -0.000025, learning rate is 0.080000
Net1: layer conv1:max response is , min response is .
max gradient is 0.000011, min gradient is -0.000010, learning rate is 0.080000
Net2: layer bn51:max response is 0.999998, min response is -0.999991.
max gradient is -7.891015, min gradient is -8.000000, learning rate is 0.001000
Net2: layer deconv3:max response is 6.866060, min response is -6.152231.
max gradient is 7.538596, min gradient is -8.000000, learning rate is 0.000500
Net2: layer bn50:max response is 7.358142, min response is -1.408137.
max gradient is 0.686588, min gradient is -8.000000, learning rate is 0.001000
Net2: layer deconv2:max response is , min response is .
max gradient is 7.989993, min gradient is -7.672693, learning rate is 0.000500
Net2: layer bn49:max response is 3.538815, min response is -0.694145.
max gradient is 1.216789, min gradient is -2.308660, learning rate is 0.001000
Net2: layer deconv1:max response is , min response is .
max gradient is 7.495629, min gradient is -8.000000, learning rate is 0.000500
max inferred z is 4.05, min inferred z is -4.17, and std is 1.00
 4.74 s (21.1 data/s) [100/100]
training: epoch 01: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 0.082211, min gradient is -0.107901, learning rate is 0.080000
Net1: layer conv2:max response is , min response is .
max gradient is 0.000145, min gradient is -0.000236, learning rate is 0.080000
Net1: layer conv1:max response is , min response is .
max gradient is 0.000168, min gradient is -0.000189, learning rate is 0.080000
Net2: layer bn51:max response is 0.999998, min response is -0.999962.
max gradient is -7.205890, min gradient is -8.000000, learning rate is 0.001000
Net2: layer deconv3:max response is 6.845210, min response is -5.441856.
max gradient is 8.000000, min gradient is -5.890881, learning rate is 0.000500
Net2: layer bn50:max response is 7.836409, min response is -1.487330.
max gradient is 6.287024, min gradient is -8.000000, learning rate is 0.001000
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.725630, learning rate is 0.000500
Net2: layer bn49:max response is 3.675682, min response is -0.739087.
max gradient is 2.556736, min gradient is -1.747211, learning rate is 0.001000
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.814609, learning rate is 0.000500
max inferred z is 4.18, min inferred z is -3.60, and std is 1.00
 4.00 s (25.0 data/s) [100/100]
training: epoch 01: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 0.083944, min gradient is -0.000683, learning rate is 0.080000
Net1: layer conv2:max response is , min response is .
max gradient is 0.000257, min gradient is -0.000162, learning rate is 0.080000
Net1: layer conv1:max response is , min response is .
max gradient is 0.000112, min gradient is -0.000126, learning rate is 0.080000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.427151, min gradient is -8.000001, learning rate is 0.001000
Net2: layer deconv3:max response is 15.649179, min response is -11.211101.
max gradient is 8.000000, min gradient is -7.620587, learning rate is 0.000500
Net2: layer bn50:max response is 9.315053, min response is -1.553513.
max gradient is 8.000000, min gradient is -6.949780, learning rate is 0.001000
Net2: layer deconv2:max response is , min response is .
max gradient is 3.508348, min gradient is -3.910667, learning rate is 0.000500
Net2: layer bn49:max response is 4.142406, min response is -0.823558.
max gradient is 2.110533, min gradient is -1.400667, learning rate is 0.001000
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.798566, learning rate is 0.000500
max inferred z is 4.24, min inferred z is -3.56, and std is 1.00
 3.97 s (25.2 data/s) [100/100]
training: epoch 01: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 0.087559, min gradient is -0.074365, learning rate is 0.080000
Net1: layer conv2:max response is , min response is .
max gradient is 0.000628, min gradient is -0.000070, learning rate is 0.080000
Net1: layer conv1:max response is , min response is .
max gradient is 0.000359, min gradient is -0.000445, learning rate is 0.080000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.250994, min gradient is -8.000000, learning rate is 0.001000
Net2: layer deconv3:max response is 28.905918, min response is -24.302883.
max gradient is 7.344061, min gradient is -8.000000, learning rate is 0.000500
Net2: layer bn50:max response is 15.918290, min response is -2.332393.
max gradient is 5.489558, min gradient is -4.820628, learning rate is 0.001000
Net2: layer deconv2:max response is , min response is .
max gradient is 2.121774, min gradient is -1.806515, learning rate is 0.000500
Net2: layer bn49:max response is 5.107516, min response is -1.008658.
max gradient is 1.467721, min gradient is -1.153834, learning rate is 0.001000
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.173324, learning rate is 0.000500
max inferred z is 3.89, min inferred z is -3.93, and std is 1.00
 4.00 s (25.0 data/s) [100/100]
training: epoch 01: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 0.081604, min gradient is -0.050617, learning rate is 0.080000
Net1: layer conv2:max response is , min response is .
max gradient is 0.001038, min gradient is -0.000105, learning rate is 0.080000
Net1: layer conv1:max response is , min response is .
max gradient is 0.000628, min gradient is -0.000684, learning rate is 0.080000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -4.970721, min gradient is -8.000000, learning rate is 0.001000
Net2: layer deconv3:max response is 37.479839, min response is -30.500990.
max gradient is 8.000000, min gradient is -7.605293, learning rate is 0.000500
Net2: layer bn50:max response is 19.184359, min response is -3.158560.
max gradient is 4.498230, min gradient is -4.764830, learning rate is 0.001000
Net2: layer deconv2:max response is , min response is .
max gradient is 1.111728, min gradient is -0.813855, learning rate is 0.000500
Net2: layer bn49:max response is 6.080436, min response is -1.070952.
max gradient is 0.828063, min gradient is -0.451099, learning rate is 0.001000
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.030392, learning rate is 0.000500
max inferred z is 3.94, min inferred z is -3.93, and std is 1.00
 3.99 s (25.1 data/s) [100/100]
training: epoch 01: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 0.090538, min gradient is -0.040831, learning rate is 0.080000
Net1: layer conv2:max response is , min response is .
max gradient is 0.001568, min gradient is -0.000053, learning rate is 0.080000
Net1: layer conv1:max response is , min response is .
max gradient is 0.000889, min gradient is -0.001152, learning rate is 0.080000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.360934, min gradient is -8.000000, learning rate is 0.001000
Net2: layer deconv3:max response is 42.569256, min response is -36.276703.
max gradient is 8.000000, min gradient is -7.870778, learning rate is 0.000500
Net2: layer bn50:max response is 24.955093, min response is -3.634043.
max gradient is 4.582410, min gradient is -4.340198, learning rate is 0.001000
Net2: layer deconv2:max response is , min response is .
max gradient is 0.663060, min gradient is -0.716042, learning rate is 0.000500
Net2: layer bn49:max response is 6.315547, min response is -1.339708.
max gradient is 0.636819, min gradient is -0.399003, learning rate is 0.001000
Net2: layer deconv1:max response is , min response is .
max gradient is 6.708757, min gradient is -4.922520, learning rate is 0.000500
max inferred z is 3.85, min inferred z is -4.19, and std is 1.00
 4.00 s (25.0 data/s) [100/100]
training: epoch 01: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 0.100256, min gradient is -0.036320, learning rate is 0.080000
Net1: layer conv2:max response is , min response is .
max gradient is 0.002322, min gradient is -0.000103, learning rate is 0.080000
Net1: layer conv1:max response is , min response is .
max gradient is 0.001358, min gradient is -0.001599, learning rate is 0.080000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.621994, min gradient is -8.000000, learning rate is 0.001000
Net2: layer deconv3:max response is 43.183044, min response is -36.271084.
max gradient is 7.831304, min gradient is -8.000000, learning rate is 0.000500
Net2: layer bn50:max response is 27.054806, min response is -3.877076.
max gradient is 3.324298, min gradient is -3.193913, learning rate is 0.001000
Net2: layer deconv2:max response is , min response is .
max gradient is 0.442032, min gradient is -0.396467, learning rate is 0.000500
Net2: layer bn49:max response is 6.910513, min response is -1.432788.
max gradient is 0.398618, min gradient is -0.308229, learning rate is 0.001000
Net2: layer deconv1:max response is , min response is .
max gradient is 4.704492, min gradient is -3.533219, learning rate is 0.000500
max inferred z is 4.04, min inferred z is -3.87, and std is 1.00
 4.04 s (24.7 data/s) [100/100]
training: epoch 01: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 0.125741, min gradient is -0.027983, learning rate is 0.080000
Net1: layer conv2:max response is , min response is .
max gradient is 0.003133, min gradient is -0.000044, learning rate is 0.080000
Net1: layer conv1:max response is , min response is .
max gradient is 0.001974, min gradient is -0.002390, learning rate is 0.080000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.738930, min gradient is -8.000000, learning rate is 0.001000
Net2: layer deconv3:max response is 49.687176, min response is -40.201691.
max gradient is 8.000000, min gradient is -7.592513, learning rate is 0.000500
Net2: layer bn50:max response is 31.038761, min response is -4.810237.
max gradient is 2.471351, min gradient is -1.922855, learning rate is 0.001000
Net2: layer deconv2:max response is , min response is .
max gradient is 0.368268, min gradient is -0.412742, learning rate is 0.000500
Net2: layer bn49:max response is 7.705454, min response is -1.623231.
max gradient is 0.324175, min gradient is -0.226097, learning rate is 0.001000
Net2: layer deconv1:max response is , min response is .
max gradient is 3.855952, min gradient is -3.191837, learning rate is 0.000500
max inferred z is 3.83, min inferred z is -4.18, and std is 1.00
 4.02 s (24.9 data/s) [100/100]
training: epoch 01: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 0.168082, min gradient is -0.03vl_compilenn:	CUDA: MEX config file: '/home/enijkamp/Dropbox/coop ADELM/matconvnet-1.0-beta16-gpu/matlab/src/config/mex_CUDA_glnxa64.xml'
Building with 'g++'.
MEX completed successfully.
Building with 'g++'.
MEX completed successfully.
Building with 'g++'.
MEX completed successfully.
Building with 'g++'.
MEX completed successfully.
Building with 'g++'.
MEX completed successfully.
Building with 'g++'.
MEX completed successfully.
Building with 'g++'.
MEX completed successfully.
Building with 'g++'.
In file included from /home/enijkamp/Dropbox/coop ADELM/matconvnet-1.0-beta16-gpu/matlab/src/bits/impl/imread_libjpeg.cpp:14:0:
/home/enijkamp/Dropbox/coop ADELM/matconvnet-1.0-beta16-gpu/matlab/src/bits/impl/imread_helpers.hpp:35:2: warning: #warning "SSSE3 instruction set not enabled. Using slower image conversion routines." [-Wcpp]
 #warning "SSSE3 instruction set not enabled. Using slower image conversion routines."
  ^

MEX completed successfully.
/home/enijkamp/Dropbox/coop ADELM/matconvnet-1.0-beta16-gpu/matlab/src/bits/impl/tinythread.h(654): warning: extra ";" ignored

/home/enijkamp/Dropbox/coop ADELM/matconvnet-1.0-beta16-gpu/matlab/src/bits/impl/tinythread.h(654): warning: extra ";" ignored

Building with 'gcc'.
MEX completed successfully.
Building with 'gcc'.
MEX completed successfully.
Building with 'gcc'.
MEX completed successfully.
Building with 'gcc'.
MEX completed successfully.
Building with 'gcc'.
MEX completed successfully.
Building with 'gcc'.
MEX completed successfully.
  <a href="matlab:helpPopup parallel.gpu.CUDADevice" style="font-weight:bold">CUDADevice</a> with properties:

                      Name: 'TITAN X (Pascal)'
                     Index: 1
         ComputeCapability: '6.1'
            SupportsDouble: 1
             DriverVersion: 9
            ToolkitVersion: 8
        MaxThreadsPerBlock: 1024
          MaxShmemPerBlock: 49152
        MaxThreadBlockSize: [1024 1024 64]
               MaxGridSize: [2.1475e+09 65535 65535]
                 SIMDWidth: 32
               TotalMemory: 1.2774e+10
           AvailableMemory: 1.2121e+10
       MultiprocessorCount: 28
              ClockRateKHz: 1531000
               ComputeMode: 'Default'
      GPUOverlapsTransfers: 1
    KernelExecutionTimeout: 1
          CanMapHostMemory: 1
           DeviceSupported: 1
            DeviceSelected: 1

384.90
/usr/local/MATLAB/R2017a/sys/opengl/lib/glnxa64:/usr/local/MATLAB/R2017a/sys/os/glnxa64:/usr/local/MATLAB/R2017a/bin/glnxa64:/usr/local/MATLAB/R2017a/extern/lib/glnxa64:/usr/local/MATLAB/R2017a/runtime/glnxa64:/usr/local/MATLAB/R2017a/sys/java/jre/glnxa64/jre/lib/amd64/native_threads:/usr/local/MATLAB/R2017a/sys/java/jre/glnxa64/jre/lib/amd64/server:/home/enijkamp/cudnn-3.0/lib64:
### 1/1 ###
Learning category: escher
read and process images 1 / 1000
read and process images 2 / 1000
read and process images 3 / 1000
read and process images 4 / 1000
read and process images 5 / 1000
read and process images 6 / 1000
read and process images 7 / 1000
read and process images 8 / 1000
read and process images 9 / 1000
read and process images 10 / 1000
read and process images 11 / 1000
read and process images 12 / 1000
read and process images 13 / 1000
read and process images 14 / 1000
read and process images 15 / 1000
read and process images 16 / 1000
read and process images 17 / 1000
read and process images 18 / 1000
read and process images 19 / 1000
read and process images 20 / 1000
read and process images 21 / 1000
read and process images 22 / 1000
read and process images 23 / 1000
read and process images 24 / 1000
read and process images 25 / 1000
read and process images 26 / 1000
read and process images 27 / 1000
read and process images 28 / 1000
read and process images 29 / 1000
read and process images 30 / 1000
read and process images 31 / 1000
read and process images 32 / 1000
read and process images 33 / 1000
read and process images 34 / 1000
read and process images 35 / 1000
read and process images 36 / 1000
read and process images 37 / 1000
read and process images 38 / 1000
read and process images 39 / 1000
read and process images 40 / 1000
read and process images 41 / 1000
read and process images 42 / 1000
read and process images 43 / 1000
read and process images 44 / 1000
read and process images 45 / 1000
read and process images 46 / 1000
read and process images 47 / 1000
read and process images 48 / 1000
read and process images 49 / 1000
read and process images 50 / 1000
read and process images 51 / 1000
read and process images 52 / 1000
read and process images 53 / 1000
read and process images 54 / 1000
read and process images 55 / 1000
read and process images 56 / 1000
read and process images 57 / 1000
read and process images 58 / 1000
read and process images 59 / 1000
read and process images 60 / 1000
read and process images 61 / 1000
read and process images 62 / 1000
read and process images 63 / 1000
read and process images 64 / 1000
read and process images 65 / 1000
read and process images 66 / 1000
read and process images 67 / 1000
read and process images 68 / 1000
read and process images 69 / 1000
read and process images 70 / 1000
read and process images 71 / 1000
read and process images 72 / 1000
read and process images 73 / 1000
read and process images 74 / 1000
read and process images 75 / 1000
read and process images 76 / 1000
read and process images 77 / 1000
read and process images 78 / 1000
read and process images 79 / 1000
read and process images 80 / 1000
read and process images 81 / 1000
read and process images 82 / 1000
read and process images 83 / 1000
read and process images 84 / 1000
read and process images 85 / 1000
read and process images 86 / 1000
read and process images 87 / 1000
read and process images 88 / 1000
read and process images 89 / 1000
read and process images 90 / 1000
read and process images 91 / 1000
read and process images 92 / 1000
read and process images 93 / 1000
read and process images 94 / 1000
read and process images 95 / 1000
read and process images 96 / 1000
read and process images 97 / 1000
read and process images 98 / 1000
read and process images 99 / 1000
read and process images 100 / 1000
read and process images 101 / 1000
read and process images 102 / 1000
read and process images 103 / 1000
read and process images 104 / 1000
read and process images 105 / 1000
read and process images 106 / 1000
read and process images 107 / 1000
read and process images 108 / 1000
read and process images 109 / 1000
read and process images 110 / 1000
read and process images 111 / 1000
read and process images 112 / 1000
read and process images 113 / 1000
read and process images 114 / 1000
read and process images 115 / 1000
read and process images 116 / 1000
read and process images 117 / 1000
read and process images 118 / 1000
read and process images 119 / 1000
read and process images 120 / 1000
read and process images 121 / 1000
read and process images 122 / 1000
read and process images 123 / 1000
read and process images 124 / 1000
read and process images 125 / 1000
read and process images 126 / 1000
read and process images 127 / 1000
read and process images 128 / 1000
read and process images 129 / 1000
read and process images 130 / 1000
read and process images 131 / 1000
read and process images 132 / 1000
read and process images 133 / 1000
read and process images 134 / 1000
read and process images 135 / 1000
read and process images 136 / 1000
read and process images 137 / 1000
read and process images 138 / 1000
read and process images 139 / 1000
read and process images 140 / 1000
read and process images 141 / 1000
read and process images 142 / 1000
read and process images 143 / 1000
read and process images 144 / 1000
read and process images 145 / 1000
read and process images 146 / 1000
read and process images 147 / 1000
read and process images 148 / 1000
read and process images 149 / 1000
read and process images 150 / 1000
read and process images 151 / 1000
read and process images 152 / 1000
read and process images 153 / 1000
read and process images 154 / 1000
read and process images 155 / 1000
read and process images 156 / 1000
read and process images 157 / 1000
read and process images 158 / 1000
read and process images 159 / 1000
read and process images 160 / 1000
read and process images 161 / 1000
read and process images 162 / 1000
read and process images 163 / 1000
read and process images 164 / 1000
read and process images 165 / 1000
read and process images 166 / 1000
read and process images 167 / 1000
read and process images 168 / 1000
read and process images 169 / 1000
read and process images 170 / 1000
read and process images 171 / 1000
read and process images 172 / 1000
read and process images 173 / 1000
read and process images 174 / 1000
read and process images 175 / 1000
read and process images 176 / 1000
read and process images 177 / 1000
read and process images 178 / 1000
read and process images 179 / 1000
read and process images 180 / 1000
read and process images 181 / 1000
read and process images 182 / 1000
read and process images 183 / 1000
read and process images 184 / 1000
read and process images 185 / 1000
read and process images 186 / 1000
read and process images 187 / 1000
read and process images 188 / 1000
read and process images 189 / 1000
read and process images 190 / 1000
read and process images 191 / 1000
read and process images 192 / 1000
read and process images 193 / 1000
read and process images 194 / 1000
read and process images 195 / 1000
read and process images 196 / 1000
read and process images 197 / 1000
read and process images 198 / 1000
read and process images 199 / 1000
read and process images 200 / 1000
read and process images 201 / 1000
read and process images 202 / 1000
read and process images 203 / 1000
read and process images 204 / 1000
read and process images 205 / 1000
read and process images 206 / 1000
read and process images 207 / 1000
read and process images 208 / 1000
read and process images 209 / 1000
read and process images 210 / 1000
read and process images 211 / 1000
read and process images 212 / 1000
read and process images 213 / 1000
read and process images 214 / 1000
read and process images 215 / 1000
read and process images 216 / 1000
read and process images 217 / 1000
read and process images 218 / 1000
read and process images 219 / 1000
read and process images 220 / 1000
read and process images 221 / 1000
read and process images 222 / 1000
read and process images 223 / 1000
read and process images 224 / 1000
read and process images 225 / 1000
read and process images 226 / 1000
read and process images 227 / 1000
read and process images 228 / 1000
read and process images 229 / 1000
read and process images 230 / 1000
read and process images 231 / 1000
read and process images 232 / 1000
read and process images 233 / 1000
read and process images 234 / 1000
read and process images 235 / 1000
read and process images 236 / 1000
read and process images 237 / 1000
read and process images 238 / 1000
read and process images 239 / 1000
read and process images 240 / 1000
read and process images 241 / 1000
read and process images 242 / 1000
read and process images 243 / 1000
read and process images 244 / 1000
read and process images 245 / 1000
read and process images 246 / 1000
read and process images 247 / 1000
read and process images 248 / 1000
read and process images 249 / 1000
read and process images 250 / 1000
read and process images 251 / 1000
read and process images 252 / 1000
read and process images 253 / 1000
read and process images 254 / 1000
read and process images 255 / 1000
read and process images 256 / 1000
read and process images 257 / 1000
read and process images 258 / 1000
read and process images 259 / 1000
read and process images 260 / 1000
read and process images 261 / 1000
read and process images 262 / 1000
read and process images 263 / 1000
read and process images 264 / 1000
read and process images 265 / 1000
read and process images 266 / 1000
read and process images 267 / 1000
read and process images 268 / 1000
read and process images 269 / 1000
read and process images 270 / 1000
read and process images 271 / 1000
read and process images 272 / 1000
read and process images 273 / 1000
read and process images 274 / 1000
read and process images 275 / 1000
read and process images 276 / 1000
read and process images 277 / 1000
read and process images 278 / 1000
read and process images 279 / 1000
read and process images 280 / 1000
read and process images 281 / 1000
read and process images 282 / 1000
read and process images 283 / 1000
read and process images 284 / 1000
read and process images 285 / 1000
read and process images 286 / 1000
read and process images 287 / 1000
read and process images 288 / 1000
read and process images 289 / 1000
read and process images 290 / 1000
read and process images 291 / 1000
read and process images 292 / 1000
read and process images 293 / 1000
read and process images 294 / 1000
read and process images 295 / 1000
read and process images 296 / 1000
read and process images 297 / 1000
read and process images 298 / 1000
read and process images 299 / 1000
read and process images 300 / 1000
read and process images 301 / 1000
read and process images 302 / 1000
read and process images 303 / 1000
read and process images 304 / 1000
read and process images 305 / 1000
read and process images 306 / 1000
read and process images 307 / 1000
read and process images 308 / 1000
read and process images 309 / 1000
read and process images 310 / 1000
read and process images 311 / 1000
read and process images 312 / 1000
read and process images 313 / 1000
read and process images 314 / 1000
read and process images 315 / 1000
read and process images 316 / 1000
read and process images 317 / 1000
read and process images 318 / 1000
read and process images 319 / 1000
read and process images 320 / 1000
read and process images 321 / 1000
read and process images 322 / 1000
read and process images 323 / 1000
read and process images 324 / 1000
read and process images 325 / 1000
read and process images 326 / 1000
read and process images 327 / 1000
read and process images 328 / 1000
read and process images 329 / 1000
read and process images 330 / 1000
read and process images 331 / 1000
read and process images 332 / 1000
read and process images 333 / 1000
read and process images 334 / 1000
read and process images 335 / 1000
read and process images 336 / 1000
read and process images 337 / 1000
read and process images 338 / 1000
read and process images 339 / 1000
read and process images 340 / 1000
read and process images 341 / 1000
read and process images 342 / 1000
read and process images 343 / 1000
read and process images 344 / 1000
read and process images 345 / 1000
read and process images 346 / 1000
read and process images 347 / 1000
read and process images 348 / 1000
read and process images 349 / 1000
read and process images 350 / 1000
read and process images 351 / 1000
read and process images 352 / 1000
read and process images 353 / 1000
read and process images 354 / 1000
read and process images 355 / 1000
read and process images 356 / 1000
read and process images 357 / 1000
read and process images 358 / 1000
read and process images 359 / 1000
read and process images 360 / 1000
read and process images 361 / 1000
read and process images 362 / 1000
read and process images 363 / 1000
read and process images 364 / 1000
read and process images 365 / 1000
read and process images 366 / 1000
read and process images 367 / 1000
read and process images 368 / 1000
read and process images 369 / 1000
read and process images 370 / 1000
read and process images 371 / 1000
read and process images 372 / 1000
read and process images 373 / 1000
read and process images 374 / 1000
read and process images 375 / 1000
read and process images 376 / 1000
read and process images 377 / 1000
read and process images 378 / 1000
read and process images 379 / 1000
read and process images 380 / 1000
read and process images 381 / 1000
read and process images 382 / 1000
read and process images 383 / 1000
read and process images 384 / 1000
read and process images 385 / 1000
read and process images 386 / 1000
read and process images 387 / 1000
read and process images 388 / 1000
read and process images 389 / 1000
read and process images 390 / 1000
read and process images 391 / 1000
read and process images 392 / 1000
read and process images 393 / 1000
read and process images 394 / 1000
read and process images 395 / 1000
read and process images 396 / 1000
read and process images 397 / 1000
read and process images 398 / 1000
read and process images 399 / 1000
read and process images 400 / 1000
read and process images 401 / 1000
read and process images 402 / 1000
read and process images 403 / 1000
read and process images 404 / 1000
read and process images 405 / 1000
read and process images 406 / 1000
read and process images 407 / 1000
read and process images 408 / 1000
read and process images 409 / 1000
read and process images 410 / 1000
read and process images 411 / 1000
read and process images 412 / 1000
read and process images 413 / 1000
read and process images 414 / 1000
read and process images 415 / 1000
read and process images 416 / 1000
read and process images 417 / 1000
read and process images 418 / 1000
read and process images 419 / 1000
read and process images 420 / 1000
read and process images 421 / 1000
read and process images 422 / 1000
read and process images 423 / 1000
read and process images 424 / 1000
read and process images 425 / 1000
read and process images 426 / 1000
read and process images 427 / 1000
read and process images 428 / 1000
read and process images 429 / 1000
read and process images 430 / 1000
read and process images 431 / 1000
read and process images 432 / 1000
read and process images 433 / 1000
read and process images 434 / 1000
read and process images 435 / 1000
read and process images 436 / 1000
read and process images 437 / 1000
read and process images 438 / 1000
read and process images 439 / 1000
read and process images 440 / 1000
read and process images 441 / 1000
read and process images 442 / 1000
read and process images 443 / 1000
read and process images 444 / 1000
read and process images 445 / 1000
read and process images 446 / 1000
read and process images 447 / 1000
read and process images 448 / 1000
read and process images 449 / 1000
read and process images 450 / 1000
read and process images 451 / 1000
read and process images 452 / 1000
read and process images 453 / 1000
read and process images 454 / 1000
read and process images 455 / 1000
read and process images 456 / 1000
read and process images 457 / 1000
read and process images 458 / 1000
read and process images 459 / 1000
read and process images 460 / 1000
read and process images 461 / 1000
read and process images 462 / 1000
read and process images 463 / 1000
read and process images 464 / 1000
read and process images 465 / 1000
read and process images 466 / 1000
read and process images 467 / 1000
read and process images 468 / 1000
read and process images 469 / 1000
read and process images 470 / 1000
read and process images 471 / 1000
read and process images 472 / 1000
read and process images 473 / 1000
read and process images 474 / 1000
read and process images 475 / 1000
read and process images 476 / 1000
read and process images 477 / 1000
read and process images 478 / 1000
read and process images 479 / 1000
read and process images 480 / 1000
read and process images 481 / 1000
read and process images 482 / 1000
read and process images 483 / 1000
read and process images 484 / 1000
read and process images 485 / 1000
read and process images 486 / 1000
read and process images 487 / 1000
read and process images 488 / 1000
read and process images 489 / 1000
read and process images 490 / 1000
read and process images 491 / 1000
read and process images 492 / 1000
read and process images 493 / 1000
read and process images 494 / 1000
read and process images 495 / 1000
read and process images 496 / 1000
read and process images 497 / 1000
read and process images 498 / 1000
read and process images 499 / 1000
read and process images 500 / 1000
read and process images 501 / 1000
read and process images 502 / 1000
read and process images 503 / 1000
read and process images 504 / 1000
read and process images 505 / 1000
read and process images 506 / 1000
read and process images 507 / 1000
read and process images 508 / 1000
read and process images 509 / 1000
read and process images 510 / 1000
read and process images 511 / 1000
read and process images 512 / 1000
read and process images 513 / 1000
read and process images 514 / 1000
read and process images 515 / 1000
read and process images 516 / 1000
read and process images 517 / 1000
read and process images 518 / 1000
read and process images 519 / 1000
read and process images 520 / 1000
read and process images 521 / 1000
read and process images 522 / 1000
read and process images 523 / 1000
read and process images 524 / 1000
read and process images 525 / 1000
read and process images 526 / 1000
read and process images 527 / 1000
read and process images 528 / 1000
read and process images 529 / 1000
read and process images 530 / 1000
read and process images 531 / 1000
read and process images 532 / 1000
read and process images 533 / 1000
read and process images 534 / 1000
read and process images 535 / 1000
read and process images 536 / 1000
read and process images 537 / 1000
read and process images 538 / 1000
read and process images 539 / 1000
read and process images 540 / 1000
read and process images 541 / 1000
read and process images 542 / 1000
read and process images 543 / 1000
read and process images 544 / 1000
read and process images 545 / 1000
read and process images 546 / 1000
read and process images 547 / 1000
read and process images 548 / 1000
read and process images 549 / 1000
read and process images 550 / 1000
read and process images 551 / 1000
read and process images 552 / 1000
read and process images 553 / 1000
read and process images 554 / 1000
read and process images 555 / 1000
read and process images 556 / 1000
read and process images 557 / 1000
read and process images 558 / 1000
read and process images 559 / 1000
read and process images 560 / 1000
read and process images 561 / 1000
read and process images 562 / 1000
read and process images 563 / 1000
read and process images 564 / 1000
read and process images 565 / 1000
read and process images 566 / 1000
read and process images 567 / 1000
read and process images 568 / 1000
read and process images 569 / 1000
read and process images 570 / 1000
read and process images 571 / 1000
read and process images 572 / 1000
read and process images 573 / 1000
read and process images 574 / 1000
read and process images 575 / 1000
read and process images 576 / 1000
read and process images 577 / 1000
read and process images 578 / 1000
read and process images 579 / 1000
read and process images 580 / 1000
read and process images 581 / 1000
read and process images 582 / 1000
read and process images 583 / 1000
read and process images 584 / 1000
read and process images 585 / 1000
read and process images 586 / 1000
read and process images 587 / 1000
read and process images 588 / 1000
read and process images 589 / 1000
read and process images 590 / 1000
read and process images 591 / 1000
read and process images 592 / 1000
read and process images 593 / 1000
read and process images 594 / 1000
read and process images 595 / 1000
read and process images 596 / 1000
read and process images 597 / 1000
read and process images 598 / 1000
read and process images 599 / 1000
read and process images 600 / 1000
read and process images 601 / 1000
read and process images 602 / 1000
read and process images 603 / 1000
read and process images 604 / 1000
read and process images 605 / 1000
read and process images 606 / 1000
read and process images 607 / 1000
read and process images 608 / 1000
read and process images 609 / 1000
read and process images 610 / 1000
read and process images 611 / 1000
read and process images 612 / 1000
read and process images 613 / 1000
read and process images 614 / 1000
read and process images 615 / 1000
read and process images 616 / 1000
read and process images 617 / 1000
read and process images 618 / 1000
read and process images 619 / 1000
read and process images 620 / 1000
read and process images 621 / 1000
read and process images 622 / 1000
read and process images 623 / 1000
read and process images 624 / 1000
read and process images 625 / 1000
read and process images 626 / 1000
read and process images 627 / 1000
read and process images 628 / 1000
read and process images 629 / 1000
read and process images 630 / 1000
read and process images 631 / 1000
read and process images 632 / 1000
read and process images 633 / 1000
read and process images 634 / 1000
read and process images 635 / 1000
read and process images 636 / 1000
read and process images 637 / 1000
read and process images 638 / 1000
read and process images 639 / 1000
read and process images 640 / 1000
read and process images 641 / 1000
read and process images 642 / 1000
read and process images 643 / 1000
read and process images 644 / 1000
read and process images 645 / 1000
read and process images 646 / 1000
read and process images 647 / 1000
read and process images 648 / 1000
read and process images 649 / 1000
read and process images 650 / 1000
read and process images 651 / 1000
read and process images 652 / 1000
read and process images 653 / 1000
read and process images 654 / 1000
read and process images 655 / 1000
read and process images 656 / 1000
read and process images 657 / 1000
read and process images 658 / 1000
read and process images 659 / 1000
read and process images 660 / 1000
read and process images 661 / 1000
read and process images 662 / 1000
read and process images 663 / 1000
read and process images 664 / 1000
read and process images 665 / 1000
read and process images 666 / 1000
read and process images 667 / 1000
read and process images 668 / 1000
read and process images 669 / 1000
read and process images 670 / 1000
read and process images 671 / 1000
read and process images 672 / 1000
read and process images 673 / 1000
read and process images 674 / 1000
read and process images 675 / 1000
read and process images 676 / 1000
read and process images 677 / 1000
read and process images 678 / 1000
read and process images 679 / 1000
read and process images 680 / 1000
read and process images 681 / 1000
read and process images 682 / 1000
read and process images 683 / 1000
read and process images 684 / 1000
read and process images 685 / 1000
read and process images 686 / 1000
read and process images 687 / 1000
read and process images 688 / 1000
read and process images 689 / 1000
read and process images 690 / 1000
read and process images 691 / 1000
read and process images 692 / 1000
read and process images 693 / 1000
read and process images 694 / 1000
read and process images 695 / 1000
read and process images 696 / 1000
read and process images 697 / 1000
read and process images 698 / 1000
read and process images 699 / 1000
read and process images 700 / 1000
read and process images 701 / 1000
read and process images 702 / 1000
read and process images 703 / 1000
read and process images 704 / 1000
read and process images 705 / 1000
read and process images 706 / 1000
read and process images 707 / 1000
read and process images 708 / 1000
read and process images 709 / 1000
read and process images 710 / 1000
read and process images 711 / 1000
read and process images 712 / 1000
read and process images 713 / 1000
read and process images 714 / 1000
read and process images 715 / 1000
read and process images 716 / 1000
read and process images 717 / 1000
read and process images 718 / 1000
read and process images 719 / 1000
read and process images 720 / 1000
read and process images 721 / 1000
read and process images 722 / 1000
read and process images 723 / 1000
read and process images 724 / 1000
read and process images 725 / 1000
read and process images 726 / 1000
read and process images 727 / 1000
read and process images 728 / 1000
read and process images 729 / 1000
read and process images 730 / 1000
read and process images 731 / 1000
read and process images 732 / 1000
read and process images 733 / 1000
read and process images 734 / 1000
read and process images 735 / 1000
read and process images 736 / 1000
read and process images 737 / 1000
read and process images 738 / 1000
read and process images 739 / 1000
read and process images 740 / 1000
read and process images 741 / 1000
read and process images 742 / 1000
read and process images 743 / 1000
read and process images 744 / 1000
read and process images 745 / 1000
read and process images 746 / 1000
read and process images 747 / 1000
read and process images 748 / 1000
read and process images 749 / 1000
read and process images 750 / 1000
read and process images 751 / 1000
read and process images 752 / 1000
read and process images 753 / 1000
read and process images 754 / 1000
read and process images 755 / 1000
read and process images 756 / 1000
read and process images 757 / 1000
read and process images 758 / 1000
read and process images 759 / 1000
read and process images 760 / 1000
read and process images 761 / 1000
read and process images 762 / 1000
read and process images 763 / 1000
read and process images 764 / 1000
read and process images 765 / 1000
read and process images 766 / 1000
read and process images 767 / 1000
read and process images 768 / 1000
read and process images 769 / 1000
read and process images 770 / 1000
read and process images 771 / 1000
read and process images 772 / 1000
read and process images 773 / 1000
read and process images 774 / 1000
read and process images 775 / 1000
read and process images 776 / 1000
read and process images 777 / 1000
read and process images 778 / 1000
read and process images 779 / 1000
read and process images 780 / 1000
read and process images 781 / 1000
read and process images 782 / 1000
read and process images 783 / 1000
read and process images 784 / 1000
read and process images 785 / 1000
read and process images 786 / 1000
read and process images 787 / 1000
read and process images 788 / 1000
read and process images 789 / 1000
read and process images 790 / 1000
read and process images 791 / 1000
read and process images 792 / 1000
read and process images 793 / 1000
read and process images 794 / 1000
read and process images 795 / 1000
read and process images 796 / 1000
read and process images 797 / 1000
read and process images 798 / 1000
read and process images 799 / 1000
read and process images 800 / 1000
read and process images 801 / 1000
read and process images 802 / 1000
read and process images 803 / 1000
read and process images 804 / 1000
read and process images 805 / 1000
read and process images 806 / 1000
read and process images 807 / 1000
read and process images 808 / 1000
read and process images 809 / 1000
read and process images 810 / 1000
read and process images 811 / 1000
read and process images 812 / 1000
read and process images 813 / 1000
read and process images 814 / 1000
read and process images 815 / 1000
read and process images 816 / 1000
read and process images 817 / 1000
read and process images 818 / 1000
read and process images 819 / 1000
read and process images 820 / 1000
read and process images 821 / 1000
read and process images 822 / 1000
read and process images 823 / 1000
read and process images 824 / 1000
read and process images 825 / 1000
read and process images 826 / 1000
read and process images 827 / 1000
read and process images 828 / 1000
read and process images 829 / 1000
read and process images 830 / 1000
read and process images 831 / 1000
read and process images 832 / 1000
read and process images 833 / 1000
read and process images 834 / 1000
read and process images 835 / 1000
read and process images 836 / 1000
read and process images 837 / 1000
read and process images 838 / 1000
read and process images 839 / 1000
read and process images 840 / 1000
read and process images 841 / 1000
read and process images 842 / 1000
read and process images 843 / 1000
read and process images 844 / 1000
read and process images 845 / 1000
read and process images 846 / 1000
read and process images 847 / 1000
read and process images 848 / 1000
read and process images 849 / 1000
read and process images 850 / 1000
read and process images 851 / 1000
read and process images 852 / 1000
read and process images 853 / 1000
read and process images 854 / 1000
read and process images 855 / 1000
read and process images 856 / 1000
read and process images 857 / 1000
read and process images 858 / 1000
read and process images 859 / 1000
read and process images 860 / 1000
read and process images 861 / 1000
read and process images 862 / 1000
read and process images 863 / 1000
read and process images 864 / 1000
read and process images 865 / 1000
read and process images 866 / 1000
read and process images 867 / 1000
read and process images 868 / 1000
read and process images 869 / 1000
read and process images 870 / 1000
read and process images 871 / 1000
read and process images 872 / 1000
read and process images 873 / 1000
read and process images 874 / 1000
read and process images 875 / 1000
read and process images 876 / 1000
read and process images 877 / 1000
read and process images 878 / 1000
read and process images 879 / 1000
read and process images 880 / 1000
read and process images 881 / 1000
read and process images 882 / 1000
read and process images 883 / 1000
read and process images 884 / 1000
read and process images 885 / 1000
read and process images 886 / 1000
read and process images 887 / 1000
read and process images 888 / 1000
read and process images 889 / 1000
read and process images 890 / 1000
read and process images 891 / 1000
read and process images 892 / 1000
read and process images 893 / 1000
read and process images 894 / 1000
read and process images 895 / 1000
read and process images 896 / 1000
read and process images 897 / 1000
read and process images 898 / 1000
read and process images 899 / 1000
read and process images 900 / 1000
read and process images 901 / 1000
read and process images 902 / 1000
read and process images 903 / 1000
read and process images 904 / 1000
read and process images 905 / 1000
read and process images 906 / 1000
read and process images 907 / 1000
read and process images 908 / 1000
read and process images 909 / 1000
read and process images 910 / 1000
read and process images 911 / 1000
read and process images 912 / 1000
read and process images 913 / 1000
read and process images 914 / 1000
read and process images 915 / 1000
read and process images 916 / 1000
read and process images 917 / 1000
read and process images 918 / 1000
read and process images 919 / 1000
read and process images 920 / 1000
read and process images 921 / 1000
read and process images 922 / 1000
read and process images 923 / 1000
read and process images 924 / 1000
read and process images 925 / 1000
read and process images 926 / 1000
read and process images 927 / 1000
read and process images 928 / 1000
read and process images 929 / 1000
read and process images 930 / 1000
read and process images 931 / 1000
read and process images 932 / 1000
read and process images 933 / 1000
read and process images 934 / 1000
read and process images 935 / 1000
read and process images 936 / 1000
read and process images 937 / 1000
read and process images 938 / 1000
read and process images 939 / 1000
read and process images 940 / 1000
read and process images 941 / 1000
read and process images 942 / 1000
read and process images 943 / 1000
read and process images 944 / 1000
read and process images 945 / 1000
read and process images 946 / 1000
read and process images 947 / 1000
read and process images 948 / 1000
read and process images 949 / 1000
read and process images 950 / 1000
read and process images 951 / 1000
read and process images 952 / 1000
read and process images 953 / 1000
read and process images 954 / 1000
read and process images 955 / 1000
read and process images 956 / 1000
read and process images 957 / 1000
read and process images 958 / 1000
read and process images 959 / 1000
read and process images 960 / 1000
read and process images 961 / 1000
read and process images 962 / 1000
read and process images 963 / 1000
read and process images 964 / 1000
read and process images 965 / 1000
read and process images 966 / 1000
read and process images 967 / 1000
read and process images 968 / 1000
read and process images 969 / 1000
read and process images 970 / 1000
read and process images 971 / 1000
read and process images 972 / 1000
read and process images 973 / 1000
read and process images 974 / 1000
read and process images 975 / 1000
read and process images 976 / 1000
read and process images 977 / 1000
read and process images 978 / 1000
read and process images 979 / 1000
read and process images 980 / 1000
read and process images 981 / 1000
read and process images 982 / 1000
read and process images 983 / 1000
read and process images 984 / 1000
read and process images 985 / 1000
read and process images 986 / 1000
read and process images 987 / 1000
read and process images 988 / 1000
read and process images 989 / 1000
read and process images 990 / 1000
read and process images 991 / 1000
read and process images 992 / 1000
read and process images 993 / 1000
read and process images 994 / 1000
read and process images 995 / 1000
read and process images 996 / 1000
read and process images 997 / 1000
read and process images 998 / 1000
read and process images 999 / 1000
read and process images 1000 / 1000

ans = 

  <a href="matlab:helpPopup parallel.gpu.CUDADevice" style="font-weight:bold">CUDADevice</a> with properties:

                      Name: 'TITAN X (Pascal)'
                     Index: 1
         ComputeCapability: '6.1'
            SupportsDouble: 1
             DriverVersion: 9
            ToolkitVersion: 8
        MaxThreadsPerBlock: 1024
          MaxShmemPerBlock: 49152
        MaxThreadBlockSize: [1024 1024 64]
               MaxGridSize: [2.1475e+09 65535 65535]
                 SIMDWidth: 32
               TotalMemory: 1.2774e+10
           AvailableMemory: 1.2156e+10
       MultiprocessorCount: 28
              ClockRateKHz: 1531000
               ComputeMode: 'Default'
      GPUOverlapsTransfers: 1
    KernelExecutionTimeout: 1
          CanMapHostMemory: 1
           DeviceSupported: 1
            DeviceSelected: 1

Iteration 1 / 200
training: epoch 01: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 0.011120, min gradient is -0.000783, learning rate is 0.080000
Net1: layer conv2:max response is , min response is .
max gradient is 0.000020, min gradient is -0.000025, learning rate is 0.080000
Net1: layer conv1:max response is , min response is .
max gradient is 0.000011, min gradient is -0.000010, learning rate is 0.080000
Net2: layer bn51:max response is 0.999998, min response is -0.999991.
max gradient is -7.891015, min gradient is -8.000000, learning rate is 0.001000
Net2: layer deconv3:max response is 6.866060, min response is -6.152231.
max gradient is 7.538596, min gradient is -8.000000, learning rate is 0.000500
Net2: layer bn50:max response is 7.358142, min response is -1.408137.
max gradient is 0.686588, min gradient is -8.000000, learning rate is 0.001000
Net2: layer deconv2:max response is , min response is .
max gradient is 7.989993, min gradient is -7.672693, learning rate is 0.000500
Net2: layer bn49:max response is 3.538815, min response is -0.694145.
max gradient is 1.216789, min gradient is -2.308660, learning rate is 0.001000
Net2: layer deconv1:max response is , min response is .
max gradient is 7.495629, min gradient is -8.000000, learning rate is 0.000500
max inferred z is 4.05, min inferred z is -4.17, and std is 1.00
 4.79 s (20.9 data/s) [100/100]
training: epoch 01: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 0.082211, min gradient is -0.107901, learning rate is 0.080000
Net1: layer conv2:max response is , min response is .
max gradient is 0.000145, min gradient is -0.000236, learning rate is 0.080000
Net1: layer conv1:max response is , min response is .
max gradient is 0.000168, min gradient is -0.000189, learning rate is 0.080000
Net2: layer bn51:max response is 0.999998, min response is -0.999962.
max gradient is -7.205890, min gradient is -8.000000, learning rate is 0.001000
Net2: layer deconv3:max response is 6.845210, min response is -5.441856.
max gradient is 8.000000, min gradient is -5.890879, learning rate is 0.000500
Net2: layer bn50:max response is 7.836408, min response is -1.487330.
max gradient is 6.287024, min gradient is -8.000000, learning rate is 0.001000
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.725632, learning rate is 0.000500
Net2: layer bn49:max response is 3.675681, min response is -0.739087.
max gradient is 2.556731, min gradient is -1.747207, learning rate is 0.001000
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.814610, learning rate is 0.000500
max inferred z is 4.18, min inferred z is -3.60, and std is 1.00
 3.99 s (25.1 data/s) [100/100]
training: epoch 01: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 0.083944, min gradient is -0.000683, learning rate is 0.080000
Net1: layer conv2:max response is , min response is .
max gradient is 0.000257, min gradient is -0.000162, learning rate is 0.080000
Net1: layer conv1:max response is , min response is .
max gradient is 0.000112, min gradient is -0.000126, learning rate is 0.080000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.427149, min gradient is -8.000001, learning rate is 0.001000
Net2: layer deconv3:max response is 15.649178, min response is -11.211099.
max gradient is 8.000000, min gradient is -7.620591, learning rate is 0.000500
Net2: layer bn50:max response is 9.315055, min response is -1.553514.
max gradient is 8.000000, min gradient is -6.949783, learning rate is 0.001000
Net2: layer deconv2:max response is , min response is .
max gradient is 3.508353, min gradient is -3.910666, learning rate is 0.000500
Net2: layer bn49:max response is 4.142406, min response is -0.823558.
max gradient is 2.110524, min gradient is -1.400665, learning rate is 0.001000
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.798572, learning rate is 0.000500
max inferred z is 4.24, min inferred z is -3.56, and std is 1.00
 4.01 s (24.9 data/s) [100/100]
training: epoch 01: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 0.087558, min gradient is -0.074365, learning rate is 0.080000
Net1: layer conv2:max response is , min response is .
max gradient is 0.000628, min gradient is -0.000070, learning rate is 0.080000
Net1: layer conv1:max response is , min response is .
max gradient is 0.000359, min gradient is -0.000445, learning rate is 0.080000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.250994, min gradient is -8.000000, learning rate is 0.001000
Net2: layer deconv3:max response is 28.905935, min response is -24.302898.
max gradient is 7.344065, min gradient is -8.000000, learning rate is 0.000500
Net2: layer bn50:max response is 15.918301, min response is -2.332395.
max gradient is 5.489560, min gradient is -4.820632, learning rate is 0.001000
Net2: layer deconv2:max response is , min response is .
max gradient is 2.121769, min gradient is -1.806516, learning rate is 0.000500
Net2: layer bn49:max response is 5.107514, min response is -1.008658.
max gradient is 1.467719, min gradient is -1.153832, learning rate is 0.001000
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.173313, learning rate is 0.000500
max inferred z is 3.89, min inferred z is -3.93, and std is 1.00
 4.01 s (25.0 data/s) [100/100]
training: epoch 01: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 0.081604, min gradient is -0.050617, learning rate is 0.080000
Net1: layer conv2:max response is , min response is .
max gradient is 0.001038, min gradient is -0.000105, learning rate is 0.080000
Net1: layer conv1:max response is , min response is .
max gradient is 0.000628, min gradient is -0.000684, learning rate is 0.080000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -4.970725, min gradient is -8.000000, learning rate is 0.001000
Net2: layer deconv3:max response is 37.479858, min response is -30.501001.
max gradient is 8.000000, min gradient is -7.605321, learning rate is 0.000500
Net2: layer bn50:max response is 19.184368, min response is -3.158561.
max gradient is 4.498233, min gradient is -4.764833, learning rate is 0.001000
Net2: layer deconv2:max response is , min response is .
max gradient is 1.111727, min gradient is -0.813854, learning rate is 0.000500
Net2: layer bn49:max response is 6.080435, min response is -1.070952.
max gradient is 0.828064, min gradient is -0.451100, learning rate is 0.001000
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.030383, learning rate is 0.000500
max inferred z is 3.94, min inferred z is -3.93, and std is 1.00
 4.03 s (24.8 data/s) [100/100]
training: epoch 01: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 0.090538, min gradient is -0.040831, learning rate is 0.080000
Net1: layer conv2:max response is , min response is .
max gradient is 0.001568, min gradient is -0.000053, learning rate is 0.080000
Net1: layer conv1:max response is , min response is .
max gradient is 0.000889, min gradient is -0.001152, learning rate is 0.080000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.360922, min gradient is -8.000000, learning rate is 0.001000
Net2: layer deconv3:max response is 42.569271, min response is -36.276703.
max gradient is 8.000000, min gradient is -7.870767, learning rate is 0.000500
Net2: layer bn50:max response is 24.955097, min response is -3.634044.
max gradient is 4.582417, min gradient is -4.340199, learning rate is 0.001000
Net2: layer deconv2:max response is , min response is .
max gradient is 0.663062, min gradient is -0.716043, learning rate is 0.000500
Net2: layer bn49:max response is 6.315547, min response is -1.339708.
max gradient is 0.636824, min gradient is -0.399002, learning rate is 0.001000
Net2: layer deconv1:max response is , min response is .
max gradient is 6.708744, min gradient is -4.922525, learning rate is 0.000500
max inferred z is 3.85, min inferred z is -4.19, and std is 1.00
 4.06 s (24.6 data/s) [100/100]
training: epoch 01: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 0.100256, min gradient is -0.036320, learning rate is 0.080000
Net1: layer conv2:max response is , min response is .
max gradient is 0.002322, min gradient is -0.000103, learning rate is 0.080000
Net1: layer conv1:max response is , min response is .
max gradient is 0.001358, min gradient is -0.001599, learning rate is 0.080000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.621956, min gradient is -8.000000, learning rate is 0.001000
Net2: layer deconv3:max response is 43.183037, min response is -36.271091.
max gradient is 7.831305, min gradient is -8.000000, learning rate is 0.000500
Net2: layer bn50:max response is 27.054800, min response is -3.877076.
max gradient is 3.324239, min gradient is -3.193848, learning rate is 0.001000
Net2: layer deconv2:max response is , min response is .
max gradient is 0.442031, min gradient is -0.396470, learning rate is 0.000500
Net2: layer bn49:max response is 6.910519, min response is -1.432790.
max gradient is 0.398616, min gradient is -0.308234, learning rate is 0.001000
Net2: layer deconv1:max response is , min response is .
max gradient is 4.704507, min gradient is -3.533212, learning rate is 0.000500
max inferred z is 4.04, min inferred z is -3.87, and std is 1.00
 4.01 s (24.9 data/s) [100/100]
training: epoch 01: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 0.125741, min gradient is -0.027983, learning rate is 0.080000
Net1: layer conv2:max response is , min response is .
max gradient is 0.003133, min gradient is -0.000044, learning rate is 0.080000
Net1: layer conv1:max response is , min response is .
max gradient is 0.001974, min gradient is -0.002390, learning rate is 0.080000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.738885, min gradient is -8.000000, learning rate is 0.001000
Net2: layer deconv3:max response is 49.687202, min response is -40.201687.
max gradient is 8.000000, min gradient is -7.592469, learning rate is 0.000500
Net2: layer bn50:max response is 31.038769, min response is -4.810241.
max gradient is 2.471328, min gradient is -1.922841, learning rate is 0.001000
Net2: layer deconv2:max response is , min response is .
max gradient is 0.368271, min gradient is -0.412742, learning rate is 0.000500
Net2: layer bn49:max response is 7.705460, min response is -1.623231.
max gradient is 0.324174, min gradient is -0.226094, learning rate is 0.001000
Net2: layer deconv1:max response is , min response is .
max gradient is 3.855950, min gradient is -3.191832, learning rate is 0.000500
max inferred z is 3.83, min inferred z is -4.18, and std is 1.00
 4.05 s (24.7 data/s) [100/100]
training: epoch 01: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 0.168082, min gradient is -0.031883, learning rate is 0.080000
Net1: layer conv2:max response is , min response is .
max gradient is 0.004114, min gradient is -0.000047, learning rate is 0.080000
Net1: layer conv1:max response is , min response is .
max gradient is 0.002863, min gradient is -0.003340, learning rate is 0.080000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.572939, min gradient is -8.000000, learning rate is 0.001000
Net2: layer deconv3:max response is 46.919495, min response is -35.825287.
max gradient is 7.366398, min gradient is -8.000000, learning rate is 0.000500
Net2: layer bn50:max response is 28.634628, min response is -4.246875.
max gradient is 1.523162, min gradient is -1.996418, learning rate is 0.001000
Net2: layer deconv2:max response is , min response is .
max gradient is 0.314620, min gradient is -0.294147, learning rate is 0.000500
Net2: layer bn49:max response is 7.442834, min response is -1.634532.
max gradient is 0.231164, min gradient is -0.214536, learning rate is 0.001000
Net2: layer deconv1:max response is , min response is .
max gradient is 2.145969, min gradient is -2.884309, learning rate is 0.000500
max inferred z is 3.79, min inferred z is -3.85, and std is 1.00
 4.06 s (24.6 data/s) [100/100]
training: epoch 01: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 0.228480, min gradient is -0.024981, learning rate is 0.080000
Net1: layer conv2:max response is , min response is .
max gradient is 0.006073, min gradient is -0.000045, learning rate is 0.080000
Net1: layer conv1:max response is , min response is .
max gradient is 0.004188, min gradient is -0.005386, learning rate is 0.080000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.370795, min gradient is -8.000000, learning rate is 0.001000
Net2: layer deconv3:max response is 48.136425, min response is -35.782166.
max gradient is 8.000000, min gradient is -6.661072, learning rate is 0.000500
Net2: layer bn50:max response is 29.984116, min response is -4.611467.
max gradient is 2.265421, min gradient is -2.002912, learning rate is 0.001000
Net2: layer deconv2:max response is , min response is .
max gradient is 0.267076, min gradient is -0.286790, learning rate is 0.000500
Net2: layer bn49:max response is 7.195003, min response is -1.625536.
max gradient is 0.229247, min gradient is -0.192747, learning rate is 0.001000
Net2: layer deconv1:max response is , min response is .
max gradient is 2.458877, min gradient is -2.148497, learning rate is 0.000500
max inferred z is 3.71, min inferred z is -3.76, and std is 1.00
 4.05 s (24.7 data/s) [100/100]
Loss: 2.0951
Iteration 2 / 200
training: epoch 02: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 0.320735, min gradient is -0.021802, learning rate is 0.080000
Net1: layer conv2:max response is , min response is .
max gradient is 0.008434, min gradient is -0.000061, learning rate is 0.080000
Net1: layer conv1:max response is , min response is .
max gradient is 0.006537, min gradient is -0.008286, learning rate is 0.080000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.377849, min gradient is -8.000000, learning rate is 0.001000
Net2: layer deconv3:max response is 48.281353, min response is -34.946236.
max gradient is 6.656949, min gradient is -8.000000, learning rate is 0.000500
Net2: layer bn50:max response is 29.202911, min response is -4.355088.
max gradient is 1.278787, min gradient is -1.658975, learning rate is 0.001000
Net2: layer deconv2:max response is , min response is .
max gradient is 0.292931, min gradient is -0.308226, learning rate is 0.000500
Net2: layer bn49:max response is 6.995636, min response is -1.786210.
max gradient is 0.179969, min gradient is -0.169754, learning rate is 0.001000
Net2: layer deconv1:max response is , min response is .
max gradient is 2.089463, min gradient is -1.515545, learning rate is 0.000500
max inferred z is 3.86, min inferred z is -3.89, and std is 1.01
 4.06 s (24.6 data/s) [100/100]
training: epoch 02: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 0.519859, min gradient is -0.021922, learning rate is 0.080000
Net1: layer conv2:max response is , min response is .
max gradient is 0.013022, min gradient is -0.000062, learning rate is 0.080000
Net1: layer conv1:max response is , min response is .
max gradient is 0.010715, min gradient is -0.014388, learning rate is 0.080000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.362556, min gradient is -8.000000, learning rate is 0.001000
Net2: layer deconv3:max response is 46.404228, min response is -33.093002.
max gradient is 8.000000, min gradient is -7.959152, learning rate is 0.000500
Net2: layer bn50:max response is 28.517349, min response is -4.294855.
max gradient is 1.587384, min gradient is -1.478103, learning rate is 0.001000
Net2: layer deconv2:max response is , min response is .
max gradient is 0.253143, min gradient is -0.311634, learning rate is 0.000500
Net2: layer bn49:max response is 7.645205, min response is -1.719094.
max gradient is 0.197588, min gradient is -0.163913, learning rate is 0.001000
Net2: layer deconv1:max response is , min response is .
max gradient is 1.696006, min gradient is -1.719169, learning rate is 0.000500
max inferred z is 4.22, min inferred z is -4.51, and std is 1.01
 4.10 s (24.4 data/s) [100/100]
training: epoch 02: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 0.808356, min gradient is -0.018446, learning rate is 0.080000
Net1: layer conv2:max response is , min response is .
max gradient is 0.021140, min gradient is -0.000093, learning rate is 0.080000
Net1: layer conv1:max response is , min response is .
max gradient is 0.018859, min gradient is -0.026714, learning rate is 0.080000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.099147, min gradient is -8.000000, learning rate is 0.001000
Net2: layer deconv3:max response is 50.027119, min response is -34.558430.
max gradient is 7.827519, min gradient is -8.000000, learning rate is 0.000500
Net2: layer bn50:max response is 31.109915, min response is -4.685465.
max gradient is 1.357088, min gradient is -1.677230, learning rate is 0.001000
Net2: layer deconv2:max response is , min response is .
max gradient is 0.266726, min gradient is -0.292124, learning rate is 0.000500
Net2: layer bn49:max response is 7.803419, min response is -1.516265.
max gradient is 0.123748, min gradient is -0.169860, learning rate is 0.001000
Net2: layer deconv1:max response is , min response is .
max gradient is 1.888241, min gradient is -1.848141, learning rate is 0.000500
max inferred z is 4.81, min inferred z is -3.71, and std is 1.01
 4.10 s (24.4 data/s) [100/100]
training: epoch 02: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 1.544914, min gradient is -0.016801, learning rate is 0.080000
Net1: layer conv2:max response is , min response is .
max gradient is 0.043675, min gradient is -0.000095, learning rate is 0.080000
Net1: layer conv1:max response is , min response is .
max gradient is 0.036379, min gradient is -0.059902, learning rate is 0.080000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.456971, min gradient is -8.000000, learning rate is 0.001000
Net2: layer deconv3:max response is 43.584991, min response is -29.188335.
max gradient is 8.000000, min gradient is -7.598078, learning rate is 0.000500
Net2: layer bn50:max response is 27.038261, min response is -4.001631.
max gradient is 1.752998, min gradient is -1.599317, learning rate is 0.001000
Net2: layer deconv2:max response is , min response is .
max gradient is 0.234636, min gradient is -0.297605, learning rate is 0.000500
Net2: layer bn49:max response is 7.853323, min response is -1.824625.
max gradient is 0.106440, min gradient is -0.135250, learning rate is 0.001000
Net2: layer deconv1:max response is , min response is .
max gradient is 1.296286, min gradient is -1.158529, learning rate is 0.000500
max inferred z is 4.01, min inferred z is -4.12, and std is 1.01
 4.11 s (24.3 data/s) [100/100]
training: epoch 02: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.763507, min gradient is -0.018991, learning rate is 0.080000
Net1: layer conv2:max response is , min response is .
max gradient is 0.106181, min gradient is -0.000221, learning rate is 0.080000
Net1: layer conv1:max response is , min response is .
max gradient is 0.085297, min gradient is -0.146179, learning rate is 0.080000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.897136, min gradient is -8.000000, learning rate is 0.001000
Net2: layer deconv3:max response is 58.053856, min response is -38.900822.
max gradient is 8.000000, min gradient is -6.873412, learning rate is 0.000500
Net2: layer bn50:max response is 36.622265, min response is -5.279760.
max gradient is 1.335788, min gradient is -1.150361, learning rate is 0.001000
Net2: layer deconv2:max response is , min response is .
max gradient is 0.195068, min gradient is -0.263405, learning rate is 0.000500
Net2: layer bn49:max response is 9.943411, min response is -1.758298.
max gradient is 0.091935, min gradient is -0.142148, learning rate is 0.001000
Net2: layer deconv1:max response is , min response is .
max gradient is 1.247334, min gradient is -1.402543, learning rate is 0.000500
max inferred z is 3.88, min inferred z is -3.59, and std is 1.01
 4.11 s (24.3 data/s) [100/100]
training: epoch 02: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -0.011399, learning rate is 0.080000
Net1: layer conv2:max response is , min response is .
max gradient is 0.373728, min gradient is -0.000403, learning rate is 0.080000
Net1: layer conv1:max response is , min response is .
max gradient is 0.273501, min gradient is -0.524706, learning rate is 0.080000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.269154, min gradient is -8.000000, learning rate is 0.001000
Net2: layer deconv3:max response is 62.725815, min response is -42.491669.
max gradient is 8.000000, min gradient is -7.310617, learning rate is 0.000500
Net2: layer bn50:max response is 38.585220, min response is -5.662576.
max gradient is 0.682378, min gradient is -0.885053, learning rate is 0.001000
Net2: layer deconv2:max response is , min response is .
max gradient is 0.165579, min gradient is -0.164794, learning rate is 0.000500
Net2: layer bn49:max response is 10.020912, min response is -1.554806.
max gradient is 0.146967, min gradient is -0.149670, learning rate is 0.001000
Net2: layer deconv1:max response is , min response is .
max gradient is 1.168883, min gradient is -1.089104, learning rate is 0.000500
max inferred z is 4.16, min inferred z is -3.66, and std is 1.01
 4.14 s (24.2 data/s) [100/100]
training: epoch 02: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -0.002876, learning rate is 0.080000
Net1: layer conv2:max response is , min response is .
max gradient is 1.808912, min gradient is -0.000331, learning rate is 0.080000
Net1: layer conv1:max response is , min response is .
max gradient is 1.176364, min gradient is -2.550876, learning rate is 0.080000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -4.874732, min gradient is -8.000000, learning rate is 0.001000
Net2: layer deconv3:max response is 48.604385, min response is -33.305370.
max gradient is 8.000000, min gradient is -7.742883, learning rate is 0.000500
Net2: layer bn50:max response is 30.768970, min response is -4.681678.
max gradient is 0.969920, min gradient is -1.222636, learning rate is 0.001000
Net2: layer deconv2:max response is , min response is .
max gradient is 0.157905, min gradient is -0.213283, learning rate is 0.000500
Net2: layer bn49:max response is 8.179629, min response is -1.994383.
max gradient is 0.079417, min gradient is -0.137328, learning rate is 0.001000
Net2: layer deconv1:max response is , min response is .
max gradient is 0.800551, min gradient is -1.132145, learning rate is 0.000500
max inferred z is 4.03, min inferred z is -4.06, and std is 1.01
 4.09 s (24.5 data/s) [100/100]
training: epoch 02: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -0.000253, learning rate is 0.080000
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -0.000638, learning rate is 0.080000
Net1: layer conv1:max response is , min response is .
max gradient is 3.427049, min gradient is -8.000000, learning rate is 0.080000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -4.996085, min gradient is -8.000000, learning rate is 0.001000
Net2: layer deconv3:max response is 47.353691, min response is -32.334888.
max gradient is 4.099132, min gradient is -8.000000, learning rate is 0.000500
Net2: layer bn50:max response is 30.695753, min response is -4.514113.
max gradient is 1.178449, min gradient is -1.097026, learning rate is 0.001000
Net2: layer deconv2:max response is , min response is .
max gradient is 0.142528, min gradient is -0.205888, learning rate is 0.000500
Net2: layer bn49:max response is 8.546731, min response is -1.718034.
max gradient is 0.067951, min gradient is -0.103046, learning rate is 0.001000
Net2: layer deconv1:max response is , min response is .
max gradient is 1.000118, min gradient is -0.915129, learning rate is 0.000500
max inferred z is 4.37, min inferred z is -3.75, and std is 1.01
 4.10 s (24.4 data/s) [100/100]
training: epoch 02: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000001, min gradient is -0.000148, learning rate is 0.080000
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -0.001031, learning rate is 0.080000
Net1: layer conv1:max response is , min response is .
max gradient is 3.292514, min gradient is -8.000000, learning rate is 0.080000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.871316, learning rate is 0.001000
Net2: layer deconv3:max response is 56.612442, min response is -37.988953.
max gradient is 3.252625, min gradient is -8.000000, learning rate is 0.000500
Net2: layer bn50:max response is 36.628937, min response is -5.323860.
max gradient is 8.000000, min gradient is -6.895836, learning rate is 0.001000
Net2: layer deconv2:max response is , min response is .
max gradient is 2.343077, min gradient is -2.554389, learning rate is 0.000500
Net2: layer bn49:max response is 9.511938, min response is -1.788825.
max gradient is 0.706800, min gradient is -0.381635, learning rate is 0.001000
Net2: layer deconv1:max response is , min response is .
max gradient is 7.656229, min gradient is -6.104832, learning rate is 0.000500
max inferred z is 4.00, min inferred z is -4.22, and std is 1.01
 4.11 s (24.3 data/s) [100/100]
training: epoch 02: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -3.620555, learning rate is 0.080000
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -0.004906, learning rate is 0.080000
Net1: layer conv1:max response is , min response is .
max gradient is 3.026781, min gradient is -8.000000, learning rate is 0.080000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.020477, learning rate is 0.001000
Net2: layer deconv3:max response is 44.546562, min response is -30.904596.
max gradient is 5.566872, min gradient is -8.000000, learning rate is 0.000500
Net2: layer bn50:max response is 30.641878, min response is -4.825602.
max gradient is 8.000000, min gradient is -4.180195, learning rate is 0.001000
Net2: layer deconv2:max response is , min response is .
max gradient is 7.901842, min gradient is -8.000000, learning rate is 0.000500
Net2: layer bn49:max response is 7.978776, min response is -1.700279.
max gradient is 8.000000, min gradient is -5.671230, learning rate is 0.001000
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.881110, learning rate is 0.000500
max inferred z is 4.05, min inferred z is -3.71, and std is 1.01
 4.10 s (24.4 data/s) [100/100]
Loss: 2.1389
Iteration 3 / 200
training: epoch 03: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 2.368639, min gradient is -8.000000, learning rate is 0.075470
Net1: layer conv2:max response is , min response is .
max gradient is 0.009335, min gradient is -8.000000, learning rate is 0.075470
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -0.998021, learning rate is 0.075470
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.429729, learning rate is 0.000971
Net2: layer deconv3:max response is 44.664120, min response is -34.543209.
max gradient is 5.905100, min gradient is -8.000000, learning rate is 0.000486
Net2: layer bn50:max response is 39.412518, min response is -6.942723.
max gradient is 8.000000, min gradient is -3.662909, learning rate is 0.000971
Net2: layer deconv2:max response is , min response is .
max gradient is 7.604681, min gradient is -8.000000, learning rate is 0.000486
Net2: layer bn49:max response is 10.733039, min response is -1.865050.
max gradient is 8.000000, min gradient is -7.495813, learning rate is 0.000971
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.856913, learning rate is 0.000486
max inferred z is 4.84, min inferred z is -4.42, and std is 1.00
 4.10 s (24.4 data/s) [100/100]
training: epoch 03: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 1.593746, min gradient is -8.000000, learning rate is 0.075470
Net1: layer conv2:max response is , min response is .
max gradient is 0.008777, min gradient is -8.000000, learning rate is 0.075470
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -2.650853, learning rate is 0.075470
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.373233, learning rate is 0.000971
Net2: layer deconv3:max response is 29.733335, min response is -24.505058.
max gradient is 5.424338, min gradient is -8.000000, learning rate is 0.000486
Net2: layer bn50:max response is 33.207188, min response is -6.254498.
max gradient is 8.000000, min gradient is -2.985914, learning rate is 0.000971
Net2: layer deconv2:max response is , min response is .
max gradient is 6.579877, min gradient is -8.000000, learning rate is 0.000486
Net2: layer bn49:max response is 9.877745, min response is -1.658038.
max gradient is 8.000000, min gradient is -6.050149, learning rate is 0.000971
Net2: layer deconv1:max response is , min response is .
max gradient is 7.927758, min gradient is -8.000001, learning rate is 0.000486
max inferred z is 3.74, min inferred z is -4.17, and std is 1.00
 4.10 s (24.4 data/s) [100/100]
training: epoch 03: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 2.936801, min gradient is -8.000000, learning rate is 0.075470
Net1: layer conv2:max response is , min response is .
max gradient is 0.065305, min gradient is -8.000000, learning rate is 0.075470
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.682620, learning rate is 0.075470
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.331288, learning rate is 0.000971
Net2: layer deconv3:max response is 15.295775, min response is -14.642167.
max gradient is 3.452645, min gradient is -8.000000, learning rate is 0.000486
Net2: layer bn50:max response is 23.908663, min response is -4.375247.
max gradient is 8.000000, min gradient is -3.757498, learning rate is 0.000971
Net2: layer deconv2:max response is , min response is .
max gradient is 5.585925, min gradient is -8.000000, learning rate is 0.000486
Net2: layer bn49:max response is 7.985345, min response is -1.544127.
max gradient is 8.000000, min gradient is -5.880166, learning rate is 0.000971
Net2: layer deconv1:max response is , min response is .
max gradient is 5.149218, min gradient is -8.000000, learning rate is 0.000486
max inferred z is 4.13, min inferred z is -3.80, and std is 1.00
 4.10 s (24.4 data/s) [100/100]
training: epoch 03: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -3.625916, learning rate is 0.075470
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -1.363631, learning rate is 0.075470
Net1: layer conv1:max response is , min response is .
max gradient is 0.959082, min gradient is -8.000000, learning rate is 0.075470
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.172098, learning rate is 0.000971
Net2: layer deconv3:max response is 11.000939, min response is -14.208826.
max gradient is 3.606839, min gradient is -8.000000, learning rate is 0.000486
Net2: layer bn50:max response is 27.702959, min response is -4.915256.
max gradient is 8.000000, min gradient is -3.888250, learning rate is 0.000971
Net2: layer deconv2:max response is , min response is .
max gradient is 6.568542, min gradient is -8.000000, learning rate is 0.000486
Net2: layer bn49:max response is 8.172102, min response is -1.459937.
max gradient is 8.000000, min gradient is -3.745316, learning rate is 0.000971
Net2: layer deconv1:max response is , min response is .
max gradient is 6.225999, min gradient is -8.000000, learning rate is 0.000486
max inferred z is 3.93, min inferred z is -3.68, and std is 1.00
 4.11 s (24.3 data/s) [100/100]
training: epoch 03: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -3.357051, learning rate is 0.075470
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -0.003334, learning rate is 0.075470
Net1: layer conv1:max response is , min response is .
max gradient is 2.412677, min gradient is -8.000000, learning rate is 0.075470
Net2: layer bn51:max response is 0.999908, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.296436, learning rate is 0.000971
Net2: layer deconv3:max response is 4.992075, min response is -10.637840.
max gradient is 4.049868, min gradient is -8.000000, learning rate is 0.000486
Net2: layer bn50:max response is 21.659090, min response is -3.896352.
max gradient is 8.000000, min gradient is -3.022048, learning rate is 0.000971
Net2: layer deconv2:max response is , min response is .
max gradient is 4.610936, min gradient is -8.000000, learning rate is 0.000486
Net2: layer bn49:max response is 6.810150, min response is -1.511338.
max gradient is 8.000000, min gradient is -4.235825, learning rate is 0.000971
Net2: layer deconv1:max response is , min response is .
max gradient is 7.214943, min gradient is -8.000000, learning rate is 0.000486
max inferred z is 4.38, min inferred z is -4.08, and std is 1.00
 4.14 s (24.1 data/s) [100/100]
training: epoch 03: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.129004, min gradient is -8.000000, learning rate is 0.075470
Net1: layer conv2:max response is , min response is .
max gradient is 2.948773, min gradient is -8.000000, learning rate is 0.075470
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -0.993854, learning rate is 0.075470
Net2: layer bn51:max response is 0.999119, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.652182, learning rate is 0.000971
Net2: layer deconv3:max response is 3.863839, min response is -11.953966.
max gradient is 4.342186, min gradient is -8.000000, learning rate is 0.000486
Net2: layer bn50:max response is 21.778725, min response is -4.088242.
max gradient is 8.000000, min gradient is -2.230452, learning rate is 0.000971
Net2: layer deconv2:max response is , min response is .
max gradient is 7.561610, min gradient is -8.000000, learning rate is 0.000486
Net2: layer bn49:max response is 6.230313, min response is -1.354752.
max gradient is 8.000000, min gradient is -3.467598, learning rate is 0.000971
Net2: layer deconv1:max response is , min response is .
max gradient is 6.712240, min gradient is -8.000000, learning rate is 0.000486
max inferred z is 4.30, min inferred z is -4.37, and std is 1.00
 4.30 s (23.3 data/s) [100/100]
training: epoch 03: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.028706, learning rate is 0.075470
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.350283, learning rate is 0.075470
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -2.755249, learning rate is 0.075470
Net2: layer bn51:max response is 0.990380, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.753652, learning rate is 0.000971
Net2: layer deconv3:max response is 2.666116, min response is -9.175403.
max gradient is 4.029131, min gradient is -8.000000, learning rate is 0.000486
Net2: layer bn50:max response is 16.806440, min response is -3.246729.
max gradient is 8.000000, min gradient is -3.920764, learning rate is 0.000971
Net2: layer deconv2:max response is , min response is .
max gradient is 4.157827, min gradient is -8.000000, learning rate is 0.000486
Net2: layer bn49:max response is 5.916198, min response is -1.183983.
max gradient is 8.000000, min gradient is -7.234306, learning rate is 0.000971
Net2: layer deconv1:max response is , min response is .
max gradient is 4.715946, min gradient is -8.000000, learning rate is 0.000486
max inferred z is 3.78, min inferred z is -3.58, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
training: epoch 03: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -3.862719, learning rate is 0.075470
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -0.812540, learning rate is 0.075470
Net1: layer conv1:max response is , min response is .
max gradient is 5.394188, min gradient is -8.000000, learning rate is 0.075470
Net2: layer bn51:max response is 0.999696, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.077601, learning rate is 0.000971
Net2: layer deconv3:max response is 4.395575, min response is -9.991301.
max gradient is 5.434248, min gradient is -8.000000, learning rate is 0.000486
Net2: layer bn50:max response is 14.573190, min response is -3.052683.
max gradient is 8.000000, min gradient is -5.084240, learning rate is 0.000971
Net2: layer deconv2:max response is , min response is .
max gradient is 7.454264, min gradient is -8.000000, learning rate is 0.000486
Net2: layer bn49:max response is 6.349278, min response is -1.193643.
max gradient is 5.532890, min gradient is -8.000000, learning rate is 0.000971
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.736777, learning rate is 0.000486
max inferred z is 4.07, min inferred z is -4.75, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 03: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -3.757195, learning rate is 0.075470
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -2.821172, learning rate is 0.075470
Net1: layer conv1:max response is , min response is .
max gradient is 4.368919, min gradient is -8.000000, learning rate is 0.075470
Net2: layer bn51:max response is 0.999972, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.224479, learning rate is 0.000971
Net2: layer deconv3:max response is 5.579235, min response is -8.600696.
max gradient is 8.000000, min gradient is -5.510224, learning rate is 0.000486
Net2: layer bn50:max response is 14.896405, min response is -3.355604.
max gradient is 8.000000, min gradient is -4.513779, learning rate is 0.000971
Net2: layer deconv2:max response is , min response is .
max gradient is 7.119306, min gradient is -8.000000, learning rate is 0.000486
Net2: layer bn49:max response is 6.396865, min response is -1.257299.
max gradient is 6.982875, min gradient is -8.000000, learning rate is 0.000971
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.801805, learning rate is 0.000486
max inferred z is 3.72, min inferred z is -4.04, and std is 1.00
 4.21 s (23.7 data/s) [100/100]
training: epoch 03: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.717002, min gradient is -8.000000, learning rate is 0.075470
Net1: layer conv2:max response is , min response is .
max gradient is 4.022775, min gradient is -8.000000, learning rate is 0.075470
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -2.966365, learning rate is 0.075470
Net2: layer bn51:max response is 0.999993, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.582314, learning rate is 0.000971
Net2: layer deconv3:max response is 6.252438, min response is -8.983635.
max gradient is 8.000000, min gradient is -4.372947, learning rate is 0.000486
Net2: layer bn50:max response is 17.803083, min response is -4.117755.
max gradient is 8.000000, min gradient is -3.447773, learning rate is 0.000971
Net2: layer deconv2:max response is , min response is .
max gradient is 7.695023, min gradient is -8.000000, learning rate is 0.000486
Net2: layer bn49:max response is 6.970414, min response is -1.209626.
max gradient is 5.541318, min gradient is -8.000000, learning rate is 0.000971
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.440561, learning rate is 0.000486
max inferred z is 4.20, min inferred z is -4.48, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
Loss: 6.6881
Iteration 4 / 200
training: epoch 04: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 1.713184, min gradient is -8.000000, learning rate is 0.075470
Net1: layer conv2:max response is , min response is .
max gradient is 2.301656, min gradient is -8.000000, learning rate is 0.075470
Net1: layer conv1:max response is , min response is .
max gradient is 3.897613, min gradient is -8.000000, learning rate is 0.075470
Net2: layer bn51:max response is 0.999940, min response is -1.000000.
max gradient is 8.000001, min gradient is 6.975971, learning rate is 0.000971
Net2: layer deconv3:max response is 5.203379, min response is -9.553847.
max gradient is 8.000000, min gradient is -6.210035, learning rate is 0.000486
Net2: layer bn50:max response is 18.214197, min response is -4.012618.
max gradient is 8.000001, min gradient is -2.773610, learning rate is 0.000971
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.463234, learning rate is 0.000486
Net2: layer bn49:max response is 7.129107, min response is -1.181841.
max gradient is 8.000000, min gradient is -4.937439, learning rate is 0.000971
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.686312, learning rate is 0.000486
max inferred z is 4.06, min inferred z is -3.83, and std is 1.00
 4.21 s (23.8 data/s) [100/100]
training: epoch 04: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.912487, learning rate is 0.075470
Net1: layer conv2:max response is , min response is .
max gradient is 2.833826, min gradient is -8.000000, learning rate is 0.075470
Net1: layer conv1:max response is , min response is .
max gradient is 2.987170, min gradient is -8.000000, learning rate is 0.075470
Net2: layer bn51:max response is 0.999006, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.466611, learning rate is 0.000971
Net2: layer deconv3:max response is 3.803094, min response is -7.789468.
max gradient is 8.000000, min gradient is -7.329483, learning rate is 0.000486
Net2: layer bn50:max response is 15.101802, min response is -2.813252.
max gradient is 5.432947, min gradient is -8.000000, learning rate is 0.000971
Net2: layer deconv2:max response is , min response is .
max gradient is 4.289632, min gradient is -8.000000, learning rate is 0.000486
Net2: layer bn49:max response is 6.102334, min response is -1.088847.
max gradient is 8.000000, min gradient is -5.193160, learning rate is 0.000971
Net2: layer deconv1:max response is , min response is .
max gradient is 6.399513, min gradient is -8.000000, learning rate is 0.000486
max inferred z is 3.69, min inferred z is -4.08, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
training: epoch 04: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.408258, min gradient is -8.000000, learning rate is 0.075470
Net1: layer conv2:max response is , min response is .
max gradient is 2.034107, min gradient is -8.000000, learning rate is 0.075470
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -0.181435, learning rate is 0.075470
Net2: layer bn51:max response is 0.999147, min response is -0.999977.
max gradient is 8.000000, min gradient is 7.588933, learning rate is 0.000971
Net2: layer deconv3:max response is 3.879643, min response is -5.690253.
max gradient is 8.000000, min gradient is -6.712061, learning rate is 0.000486
Net2: layer bn50:max response is 15.599971, min response is -2.747130.
max gradient is 8.000001, min gradient is -3.873184, learning rate is 0.000971
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.371595, learning rate is 0.000486
Net2: layer bn49:max response is 5.169266, min response is -1.081704.
max gradient is 8.000000, min gradient is -3.714850, learning rate is 0.000971
Net2: layer deconv1:max response is , min response is .
max gradient is 6.791009, min gradient is -8.000000, learning rate is 0.000486
max inferred z is 4.23, min inferred z is -3.93, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 04: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.093699, learning rate is 0.075470
Net1: layer conv2:max response is , min response is .
max gradient is 4.262473, min gradient is -8.000000, learning rate is 0.075470
Net1: layer conv1:max response is , min response is .
max gradient is 6.204262, min gradient is -8.000000, learning rate is 0.075470
Net2: layer bn51:max response is 0.999919, min response is -0.999955.
max gradient is 8.000000, min gradient is 7.637912, learning rate is 0.000971
Net2: layer deconv3:max response is 5.057831, min response is -5.350794.
max gradient is 8.000000, min gradient is -4.669158, learning rate is 0.000486
Net2: layer bn50:max response is 16.416260, min response is -3.002137.
max gradient is 8.000000, min gradient is -3.814768, learning rate is 0.000971
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.531435, learning rate is 0.000486
Net2: layer bn49:max response is 6.343144, min response is -1.092326.
max gradient is 6.897187, min gradient is -8.000000, learning rate is 0.000971
Net2: layer deconv1:max response is , min response is .
max gradient is 6.382131, min gradient is -8.000000, learning rate is 0.000486
max inferred z is 4.30, min inferred z is -3.81, and std is 1.00
 4.18 s (23.9 data/s) [100/100]
training: epoch 04: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -3.803054, learning rate is 0.075470
Net1: layer conv2:max response is , min response is .
max gradient is 4.239482, min gradient is -8.000000, learning rate is 0.075470
Net1: layer conv1:max response is , min response is .
max gradient is 5.911856, min gradient is -8.000000, learning rate is 0.075470
Net2: layer bn51:max response is 0.999968, min response is -0.999989.
max gradient is 8.000000, min gradient is 7.602361, learning rate is 0.000971
Net2: layer deconv3:max response is 5.514715, min response is -6.077494.
max gradient is 8.000000, min gradient is -7.381055, learning rate is 0.000486
Net2: layer bn50:max response is 15.127153, min response is -2.455957.
max gradient is 8.000000, min gradient is -7.611929, learning rate is 0.000971
Net2: layer deconv2:max response is , min response is .
max gradient is 7.397510, min gradient is -8.000000, learning rate is 0.000486
Net2: layer bn49:max response is 6.227362, min response is -1.143171.
max gradient is 8.000000, min gradient is -3.270990, learning rate is 0.000971
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.669188, learning rate is 0.000486
max inferred z is 3.85, min inferred z is -3.93, and std is 1.00
 4.17 s (24.0 data/s) [100/100]
training: epoch 04: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.062786, learning rate is 0.075470
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.376997, learning rate is 0.075470
Net1: layer conv1:max response is , min response is .
max gradient is 4.254103, min gradient is -8.000000, learning rate is 0.075470
Net2: layer bn51:max response is 0.999998, min response is -0.999989.
max gradient is 8.000000, min gradient is 7.479779, learning rate is 0.000971
Net2: layer deconv3:max response is 6.966077, min response is -6.056982.
max gradient is 6.770989, min gradient is -8.000000, learning rate is 0.000486
Net2: layer bn50:max response is 17.655003, min response is -2.885493.
max gradient is 4.939924, min gradient is -8.000000, learning rate is 0.000971
Net2: layer deconv2:max response is , min response is .
max gradient is 6.644209, min gradient is -8.000000, learning rate is 0.000486
Net2: layer bn49:max response is 5.815627, min response is -1.237302.
max gradient is 8.000000, min gradient is -1.729074, learning rate is 0.000971
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.126620, learning rate is 0.000486
max inferred z is 3.85, min inferred z is -3.74, and std is 1.00
 4.30 s (23.2 data/s) [100/100]
training: epoch 04: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.681802, learning rate is 0.075470
Net1: layer conv2:max response is , min response is .
max gradient is 6.929618, min gradient is -8.000000, learning rate is 0.075470
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.095848, learning rate is 0.075470
Net2: layer bn51:max response is 0.999911, min response is -0.999904.
max gradient is 8.000000, min gradient is 7.210954, learning rate is 0.000971
Net2: layer deconv3:max response is 5.011809, min response is -4.969490.
max gradient is 5.982826, min gradient is -8.000000, learning rate is 0.000486
Net2: layer bn50:max response is 15.398101, min response is -2.754967.
max gradient is 5.829344, min gradient is -8.000000, learning rate is 0.000971
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.360806, learning rate is 0.000486
Net2: layer bn49:max response is 6.249866, min response is -1.199710.
max gradient is 8.000000, min gradient is -1.185424, learning rate is 0.000971
Net2: layer deconv1:max response is , min response is .
max gradient is 7.213655, min gradient is -8.000000, learning rate is 0.000486
max inferred z is 4.00, min inferred z is -4.11, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 04: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -3.487371, learning rate is 0.075470
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.185549, learning rate is 0.075470
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.488819, learning rate is 0.075470
Net2: layer bn51:max response is 0.999364, min response is -0.999747.
max gradient is 8.000000, min gradient is 6.913713, learning rate is 0.000971
Net2: layer deconv3:max response is 4.026850, min response is -4.487212.
max gradient is 8.000000, min gradient is -7.115555, learning rate is 0.000486
Net2: layer bn50:max response is 12.812708, min response is -2.593029.
max gradient is 8.000000, min gradient is -1.825820, learning rate is 0.000971
Net2: layer deconv2:max response is , min response is .
max gradient is 6.618157, min gradient is -8.000000, learning rate is 0.000486
Net2: layer bn49:max response is 6.244026, min response is -1.449833.
max gradient is 8.000000, min gradient is -2.117319, learning rate is 0.000971
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.317770, learning rate is 0.000486
max inferred z is 3.91, min inferred z is -4.30, and std is 1.00
 4.38 s (22.9 data/s) [100/100]
training: epoch 04: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -3.846635, learning rate is 0.075470
Net1: layer conv2:max response is , min response is .
max gradient is 7.850110, min gradient is -8.000000, learning rate is 0.075470
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.997924, learning rate is 0.075470
Net2: layer bn51:max response is 0.999798, min response is -0.999978.
max gradient is 8.000000, min gradient is 7.905509, learning rate is 0.000971
Net2: layer deconv3:max response is 4.599179, min response is -5.711385.
max gradient is 7.542850, min gradient is -8.000000, learning rate is 0.000486
Net2: layer bn50:max response is 13.593872, min response is -2.605346.
max gradient is 8.000000, min gradient is -1.644912, learning rate is 0.000971
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.365910, learning rate is 0.000486
Net2: layer bn49:max response is 6.830040, min response is -1.249399.
max gradient is 8.000000, min gradient is -5.159523, learning rate is 0.000971
Net2: layer deconv1:max response is , min response is .
max gradient is 5.357131, min gradient is -8.000000, learning rate is 0.000486
max inferred z is 4.05, min inferred z is -3.67, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 04: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.608763, min gradient is -8.000000, learning rate is 0.075470
Net1: layer conv2:max response is , min response is .
max gradient is 4.157238, min gradient is -8.000000, learning rate is 0.075470
Net1: layer conv1:max response is , min response is .
max gradient is 5.025228, min gradient is -8.000000, learning rate is 0.075470
Net2: layer bn51:max response is 0.999935, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.809794, learning rate is 0.000971
Net2: layer deconv3:max response is 5.165774, min response is -8.069901.
max gradient is 5.795162, min gradient is -8.000000, learning rate is 0.000486
Net2: layer bn50:max response is 14.433144, min response is -2.581752.
max gradient is 8.000000, min gradient is -2.443897, learning rate is 0.000971
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.403843, learning rate is 0.000486
Net2: layer bn49:max response is 7.182146, min response is -1.439479.
max gradient is 6.547660, min gradient is -8.000000, learning rate is 0.000971
Net2: layer deconv1:max response is , min response is .
max gradient is 4.090573, min gradient is -8.000000, learning rate is 0.000486
max inferred z is 3.47, min inferred z is -3.81, and std is 1.00
 4.32 s (23.2 data/s) [100/100]
Loss: 4.8798
Iteration 5 / 200
training: epoch 05: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.818200, min gradient is -8.000000, learning rate is 0.071196
Net1: layer conv2:max response is , min response is .
max gradient is 6.065338, min gradient is -8.000000, learning rate is 0.071196
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.901283, learning rate is 0.071196
Net2: layer bn51:max response is 0.999996, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.930032, learning rate is 0.000943
Net2: layer deconv3:max response is 6.514827, min response is -11.816453.
max gradient is 7.157021, min gradient is -8.000000, learning rate is 0.000472
Net2: layer bn50:max response is 17.199474, min response is -3.268360.
max gradient is 8.000000, min gradient is -7.240975, learning rate is 0.000943
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.853501, learning rate is 0.000472
Net2: layer bn49:max response is 7.148697, min response is -1.611241.
max gradient is 4.758123, min gradient is -8.000000, learning rate is 0.000943
Net2: layer deconv1:max response is , min response is .
max gradient is 6.594345, min gradient is -8.000000, learning rate is 0.000472
max inferred z is 4.17, min inferred z is -3.74, and std is 1.00
 4.18 s (23.9 data/s) [100/100]
training: epoch 05: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.539361, min gradient is -8.000000, learning rate is 0.071196
Net1: layer conv2:max response is , min response is .
max gradient is 6.954732, min gradient is -8.000000, learning rate is 0.071196
Net1: layer conv1:max response is , min response is .
max gradient is 6.269352, min gradient is -8.000000, learning rate is 0.071196
Net2: layer bn51:max response is 0.999946, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.946354, learning rate is 0.000943
Net2: layer deconv3:max response is 5.258992, min response is -9.573353.
max gradient is 7.923656, min gradient is -8.000000, learning rate is 0.000472
Net2: layer bn50:max response is 13.797343, min response is -2.604165.
max gradient is 4.420948, min gradient is -8.000000, learning rate is 0.000943
Net2: layer deconv2:max response is , min response is .
max gradient is 7.191247, min gradient is -8.000000, learning rate is 0.000472
Net2: layer bn49:max response is 6.401183, min response is -1.302826.
max gradient is 4.779822, min gradient is -8.000000, learning rate is 0.000943
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.768943, learning rate is 0.000472
max inferred z is 4.15, min inferred z is -3.89, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 05: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.602190, min gradient is -8.000000, learning rate is 0.071196
Net1: layer conv2:max response is , min response is .
max gradient is 6.739885, min gradient is -8.000000, learning rate is 0.071196
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.916569, learning rate is 0.071196
Net2: layer bn51:max response is 0.999987, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.897564, learning rate is 0.000943
Net2: layer deconv3:max response is 5.978320, min response is -10.167141.
max gradient is 8.000000, min gradient is -7.305949, learning rate is 0.000472
Net2: layer bn50:max response is 15.472754, min response is -2.667345.
max gradient is 8.000000, min gradient is -7.708513, learning rate is 0.000943
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.211207, learning rate is 0.000472
Net2: layer bn49:max response is 7.250369, min response is -1.513586.
max gradient is 8.000000, min gradient is -7.779537, learning rate is 0.000943
Net2: layer deconv1:max response is , min response is .
max gradient is 6.825516, min gradient is -8.000000, learning rate is 0.000472
max inferred z is 3.86, min inferred z is -4.35, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 05: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.516900, min gradient is -8.000000, learning rate is 0.071196
Net1: layer conv2:max response is , min response is .
max gradient is 5.651893, min gradient is -8.000000, learning rate is 0.071196
Net1: layer conv1:max response is , min response is .
max gradient is 7.551929, min gradient is -8.000000, learning rate is 0.071196
Net2: layer bn51:max response is 0.999969, min response is -0.999999.
max gradient is 8.000000, min gradient is 7.890171, learning rate is 0.000943
Net2: layer deconv3:max response is 5.545393, min response is -7.511714.
max gradient is 8.000000, min gradient is -5.970079, learning rate is 0.000472
Net2: layer bn50:max response is 13.928815, min response is -2.504871.
max gradient is 6.170688, min gradient is -8.000000, learning rate is 0.000943
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.024038, learning rate is 0.000472
Net2: layer bn49:max response is 8.323411, min response is -1.436276.
max gradient is 8.000000, min gradient is -4.919034, learning rate is 0.000943
Net2: layer deconv1:max response is , min response is .
max gradient is 7.642794, min gradient is -8.000000, learning rate is 0.000472
max inferred z is 3.72, min inferred z is -4.02, and std is 1.00
 4.19 s (23.9 data/s) [100/100]
training: epoch 05: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.822947, min gradient is -8.000001, learning rate is 0.071196
Net1: layer conv2:max response is , min response is .
max gradient is 5.297397, min gradient is -8.000000, learning rate is 0.071196
Net1: layer conv1:max response is , min response is .
max gradient is 7.455105, min gradient is -8.000000, learning rate is 0.071196
Net2: layer bn51:max response is 0.999994, min response is -0.999951.
max gradient is 8.000000, min gradient is 7.913624, learning rate is 0.000943
Net2: layer deconv3:max response is 6.340770, min response is -5.313035.
max gradient is 8.000000, min gradient is -6.103704, learning rate is 0.000472
Net2: layer bn50:max response is 13.852364, min response is -2.502335.
max gradient is 8.000000, min gradient is -6.054368, learning rate is 0.000943
Net2: layer deconv2:max response is , min response is .
max gradient is 7.417125, min gradient is -8.000000, learning rate is 0.000472
Net2: layer bn49:max response is 6.587437, min response is -1.449949.
max gradient is 8.000000, min gradient is -7.994873, learning rate is 0.000943
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.495454, learning rate is 0.000472
max inferred z is 4.20, min inferred z is -3.79, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
training: epoch 05: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.417287, min gradient is -8.000000, learning rate is 0.071196
Net1: layer conv2:max response is , min response is .
max gradient is 5.018826, min gradient is -8.000000, learning rate is 0.071196
Net1: layer conv1:max response is , min response is .
max gradient is 7.443548, min gradient is -8.000000, learning rate is 0.071196
Net2: layer bn51:max response is 0.999984, min response is -0.999945.
max gradient is 8.000000, min gradient is 7.860301, learning rate is 0.000943
Net2: layer deconv3:max response is 5.872148, min response is -5.246619.
max gradient is 8.000000, min gradient is -5.893949, learning rate is 0.000472
Net2: layer bn50:max response is 13.138771, min response is -2.409332.
max gradient is 8.000000, min gradient is -3.772349, learning rate is 0.000943
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.717957, learning rate is 0.000472
Net2: layer bn49:max response is 7.789099, min response is -1.308042.
max gradient is 4.621669, min gradient is -8.000000, learning rate is 0.000943
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.104305, learning rate is 0.000472
max inferred z is 4.82, min inferred z is -3.88, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 05: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.803173, learning rate is 0.071196
Net1: layer conv2:max response is , min response is .
max gradient is 4.931122, min gradient is -8.000000, learning rate is 0.071196
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.820752, learning rate is 0.071196
Net2: layer bn51:max response is 0.999982, min response is -0.999694.
max gradient is 8.000000, min gradient is 7.855885, learning rate is 0.000943
Net2: layer deconv3:max response is 5.802321, min response is -4.392442.
max gradient is 8.000000, min gradient is -5.428240, learning rate is 0.000472
Net2: layer bn50:max response is 15.113174, min response is -2.794060.
max gradient is 8.000000, min gradient is -2.527348, learning rate is 0.000943
Net2: layer deconv2:max response is , min response is .
max gradient is 7.283316, min gradient is -8.000000, learning rate is 0.000472
Net2: layer bn49:max response is 6.946572, min response is -1.503300.
max gradient is 4.311076, min gradient is -8.000000, learning rate is 0.000943
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.340271, learning rate is 0.000472
max inferred z is 4.11, min inferred z is -4.58, and std is 1.00
 4.22 s (23.7 data/s) [100/100]
training: epoch 05: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.452627, learning rate is 0.071196
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.948201, learning rate is 0.071196
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.126214, learning rate is 0.071196
Net2: layer bn51:max response is 0.999921, min response is -0.999957.
max gradient is 8.000000, min gradient is 7.878017, learning rate is 0.000943
Net2: layer deconv3:max response is 5.071575, min response is -5.368631.
max gradient is 8.000000, min gradient is -4.194993, learning rate is 0.000472
Net2: layer bn50:max response is 13.220764, min response is -2.719295.
max gradient is 8.000000, min gradient is -1.994916, learning rate is 0.000943
Net2: layer deconv2:max response is , min response is .
max gradient is 6.729984, min gradient is -8.000000, learning rate is 0.000472
Net2: layer bn49:max response is 7.417420, min response is -1.502742.
max gradient is 4.941315, min gradient is -8.000000, learning rate is 0.000943
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.488758, learning rate is 0.000472
max inferred z is 4.23, min inferred z is -4.24, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 05: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.607791, learning rate is 0.071196
Net1: layer conv2:max response is , min response is .
max gradient is 6.556701, min gradient is -8.000000, learning rate is 0.071196
Net1: layer conv1:max response is , min response is .
max gradient is 5.985764, min gradient is -8.000000, learning rate is 0.071196
Net2: layer bn51:max response is 0.999987, min response is -0.999779.
max gradient is 8.000000, min gradient is 7.913360, learning rate is 0.000943
Net2: layer deconv3:max response is 5.972497, min response is -4.554768.
max gradient is 8.000000, min gradient is -5.670007, learning rate is 0.000472
Net2: layer bn50:max response is 15.673121, min response is -3.352531.
max gradient is 8.000000, min gradient is -1.951331, learning rate is 0.000943
Net2: layer deconv2:max response is , min response is .
max gradient is 7.035163, min gradient is -8.000000, learning rate is 0.000472
Net2: layer bn49:max response is 6.561218, min response is -1.499388.
max gradient is 5.534900, min gradient is -8.000000, learning rate is 0.000943
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.287183, learning rate is 0.000472
max inferred z is 4.27, min inferred z is -3.87, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
training: epoch 05: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.733318, learning rate is 0.071196
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.982126, learning rate is 0.071196
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.522297, learning rate is 0.071196
Net2: layer bn51:max response is 0.999953, min response is -0.999947.
max gradient is 8.000000, min gradient is 7.864253, learning rate is 0.000943
Net2: layer deconv3:max response is 5.325068, min response is -5.266347.
max gradient is 8.000001, min gradient is -6.479257, learning rate is 0.000472
Net2: layer bn50:max response is 15.848265, min response is -2.865946.
max gradient is 8.000000, min gradient is -1.530149, learning rate is 0.000943
Net2: layer deconv2:max response is , min response is .
max gradient is 7.174969, min gradient is -8.000000, learning rate is 0.000472
Net2: layer bn49:max response is 6.825186, min response is -1.401367.
max gradient is 6.186154, min gradient is -8.000000, learning rate is 0.000943
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.313600, learning rate is 0.000472
max inferred z is 3.65, min inferred z is -3.93, and std is 1.00
 4.47 s (22.4 data/s) [100/100]
Loss: 4.1673
Iteration 6 / 200
training: epoch 06: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.159054, min gradient is -8.000000, learning rate is 0.071196
Net1: layer conv2:max response is , min response is .
max gradient is 7.548183, min gradient is -8.000000, learning rate is 0.071196
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.039212, learning rate is 0.071196
Net2: layer bn51:max response is 0.999999, min response is -0.999996.
max gradient is 8.000000, min gradient is 7.745847, learning rate is 0.000943
Net2: layer deconv3:max response is 7.100191, min response is -6.541299.
max gradient is 8.000000, min gradient is -7.087576, learning rate is 0.000472
Net2: layer bn50:max response is 19.469847, min response is -3.313335.
max gradient is 8.000000, min gradient is -1.067163, learning rate is 0.000943
Net2: layer deconv2:max response is , min response is .
max gradient is 7.678154, min gradient is -8.000000, learning rate is 0.000472
Net2: layer bn49:max response is 7.991108, min response is -1.923041.
max gradient is 8.000000, min gradient is -7.826357, learning rate is 0.000943
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.110878, learning rate is 0.000472
max inferred z is 3.95, min inferred z is -4.23, and std is 0.99
 4.22 s (23.7 data/s) [100/100]
training: epoch 06: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.483749, min gradient is -8.000000, learning rate is 0.071196
Net1: layer conv2:max response is , min response is .
max gradient is 7.628979, min gradient is -8.000000, learning rate is 0.071196
Net1: layer conv1:max response is , min response is .
max gradient is 3.812636, min gradient is -8.000000, learning rate is 0.071196
Net2: layer bn51:max response is 0.999996, min response is -0.999987.
max gradient is 8.000000, min gradient is 7.525220, learning rate is 0.000943
Net2: layer deconv3:max response is 6.530761, min response is -5.958318.
max gradient is 5.778874, min gradient is -8.000000, learning rate is 0.000472
Net2: layer bn50:max response is 18.931850, min response is -3.136091.
max gradient is 8.000000, min gradient is -1.544969, learning rate is 0.000943
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.729631, learning rate is 0.000472
Net2: layer bn49:max response is 6.698243, min response is -1.322097.
max gradient is 8.000000, min gradient is -5.750643, learning rate is 0.000943
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.818332, learning rate is 0.000472
max inferred z is 3.84, min inferred z is -3.66, and std is 0.99
 4.18 s (23.9 data/s) [100/100]
training: epoch 06: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.543214, min gradient is -8.000000, learning rate is 0.071196
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.031079, learning rate is 0.071196
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -2.980168, learning rate is 0.071196
Net2: layer bn51:max response is 1.000000, min response is -0.999978.
max gradient is 8.000000, min gradient is 6.427877, learning rate is 0.000943
Net2: layer deconv3:max response is 8.190322, min response is -5.713942.
max gradient is 4.855289, min gradient is -8.000000, learning rate is 0.000472
Net2: layer bn50:max response is 20.082523, min response is -3.477701.
max gradient is 8.000001, min gradient is -2.181823, learning rate is 0.000943
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.325498, learning rate is 0.000472
Net2: layer bn49:max response is 6.491007, min response is -1.485031.
max gradient is 7.986934, min gradient is -8.000000, learning rate is 0.000943
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.713895, learning rate is 0.000472
max inferred z is 4.15, min inferred z is -4.01, and std is 0.99
 4.25 s (23.5 data/s) [100/100]
training: epoch 06: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.777648, min gradient is -8.000000, learning rate is 0.071196
Net1: layer conv2:max response is , min response is .
max gradient is 4.890278, min gradient is -8.000000, learning rate is 0.071196
Net1: layer conv1:max response is , min response is .
max gradient is 7.789227, min gradient is -8.000000, learning rate is 0.071196
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.428427, learning rate is 0.000943
Net2: layer deconv3:max response is 8.550036, min response is -8.343515.
max gradient is 5.216512, min gradient is -8.000000, learning rate is 0.000472
Net2: layer bn50:max response is 20.058006, min response is -3.456879.
max gradient is 8.000000, min gradient is -3.646373, learning rate is 0.000943
Net2: layer deconv2:max response is , min response is .
max gradient is 6.395766, min gradient is -8.000000, learning rate is 0.000472
Net2: layer bn49:max response is 8.340302, min response is -1.785800.
max gradient is 4.932628, min gradient is -8.000000, learning rate is 0.000943
Net2: layer deconv1:max response is , min response is .
max gradient is 5.064506, min gradient is -8.000000, learning rate is 0.000472
max inferred z is 3.92, min inferred z is -4.16, and std is 0.99
 4.47 s (22.4 data/s) [100/100]
training: epoch 06: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.519590, min gradient is -8.000000, learning rate is 0.071196
Net1: layer conv2:max response is , min response is .
max gradient is 7.778914, min gradient is -8.000000, learning rate is 0.071196
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.144789, learning rate is 0.071196
Net2: layer bn51:max response is 0.999996, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.548611, learning rate is 0.000943
Net2: layer deconv3:max response is 6.588294, min response is -12.802532.
max gradient is 4.906867, min gradient is -8.000000, learning rate is 0.000472
Net2: layer bn50:max response is 16.618017, min response is -2.523293.
max gradient is 8.000000, min gradient is -5.324503, learning rate is 0.000943
Net2: layer deconv2:max response is , min response is .
max gradient is 3.732537, min gradient is -8.000000, learning rate is 0.000472
Net2: layer bn49:max response is 9.119638, min response is -1.566807.
max gradient is 4.245323, min gradient is -8.000000, learning rate is 0.000943
Net2: layer deconv1:max response is , min response is .
max gradient is 6.889386, min gradient is -8.000000, learning rate is 0.000472
max inferred z is 3.89, min inferred z is -4.25, and std is 0.99
 4.41 s (22.7 data/s) [100/100]
training: epoch 06: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.643407, min gradient is -8.000000, learning rate is 0.071196
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.736373, learning rate is 0.071196
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.589437, learning rate is 0.071196
Net2: layer bn51:max response is 0.999969, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.643818, learning rate is 0.000943
Net2: layer deconv3:max response is 5.543391, min response is -16.754955.
max gradient is 8.000000, min gradient is -6.398857, learning rate is 0.000472
Net2: layer bn50:max response is 17.558750, min response is -2.641989.
max gradient is 7.384503, min gradient is -8.000000, learning rate is 0.000943
Net2: layer deconv2:max response is , min response is .
max gradient is 2.675180, min gradient is -8.000000, learning rate is 0.000472
Net2: layer bn49:max response is 9.062300, min response is -1.477183.
max gradient is 8.000000, min gradient is -4.493517, learning rate is 0.000943
Net2: layer deconv1:max response is , min response is .
max gradient is 6.913106, min gradient is -8.000000, learning rate is 0.000472
max inferred z is 3.91, min inferred z is -4.20, and std is 0.99
 4.35 s (23.0 data/s) [100/100]
training: epoch 06: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.108135, min gradient is -8.000000, learning rate is 0.071196
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.954929, learning rate is 0.071196
Net1: layer conv1:max response is , min response is .
max gradient is 3.516259, min gradient is -8.000000, learning rate is 0.071196
Net2: layer bn51:max response is 0.999972, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.919145, learning rate is 0.000943
Net2: layer deconv3:max response is 5.589263, min response is -20.145391.
max gradient is 8.000000, min gradient is -6.926023, learning rate is 0.000472
Net2: layer bn50:max response is 19.143637, min response is -3.042205.
max gradient is 4.122262, min gradient is -8.000000, learning rate is 0.000943
Net2: layer deconv2:max response is , min response is .
max gradient is 4.897253, min gradient is -8.000000, learning rate is 0.000472
Net2: layer bn49:max response is 8.471357, min response is -1.514451.
max gradient is 8.000000, min gradient is -3.415462, learning rate is 0.000943
Net2: layer deconv1:max response is , min response is .
max gradient is 5.830760, min gradient is -8.000000, learning rate is 0.000472
max inferred z is 4.70, min inferred z is -4.02, and std is 0.99
 4.40 s (22.7 data/s) [100/100]
training: epoch 06: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.294957, learning rate is 0.071196
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.874797, learning rate is 0.071196
Net1: layer conv1:max response is , min response is .
max gradient is 3.756577, min gradient is -8.000000, learning rate is 0.071196
Net2: layer bn51:max response is 0.999993, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.690988, learning rate is 0.000943
Net2: layer deconv3:max response is 6.285930, min response is -24.635723.
max gradient is 7.632371, min gradient is -8.000000, learning rate is 0.000472
Net2: layer bn50:max response is 22.704342, min response is -3.881690.
max gradient is 5.424398, min gradient is -8.000000, learning rate is 0.000943
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.964120, learning rate is 0.000472
Net2: layer bn49:max response is 7.974219, min response is -1.574219.
max gradient is 8.000000, min gradient is -2.483548, learning rate is 0.000943
Net2: layer deconv1:max response is , min response is .
max gradient is 7.063373, min gradient is -8.000000, learning rate is 0.000472
max inferred z is 3.99, min inferred z is -4.17, and std is 0.99
 4.23 s (23.6 data/s) [100/100]
training: epoch 06: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.883805, learning rate is 0.071196
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.338131, learning rate is 0.071196
Net1: layer conv1:max response is , min response is .
max gradient is 3.907320, min gradient is -8.000000, learning rate is 0.071196
Net2: layer bn51:max response is 0.999992, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.731061, learning rate is 0.000943
Net2: layer deconv3:max response is 6.242090, min response is -20.705437.
max gradient is 5.877654, min gradient is -8.000000, learning rate is 0.000472
Net2: layer bn50:max response is 20.195648, min response is -3.369843.
max gradient is 5.024842, min gradient is -8.000000, learning rate is 0.000943
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.541173, learning rate is 0.000472
Net2: layer bn49:max response is 7.595019, min response is -1.930799.
max gradient is 8.000000, min gradient is -2.121422, learning rate is 0.000943
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.858005, learning rate is 0.000472
max inferred z is 4.38, min inferred z is -3.98, and std is 0.99
 4.21 s (23.7 data/s) [100/100]
training: epoch 06: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.947151, min gradient is -8.000000, learning rate is 0.071196
Net1: layer conv2:max response is , min response is .
max gradient is 5.138945, min gradient is -8.000000, learning rate is 0.071196
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -1.673114, learning rate is 0.071196
Net2: layer bn51:max response is 0.999964, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.473115, learning rate is 0.000943
Net2: layer deconv3:max response is 5.469088, min response is -21.711063.
max gradient is 4.524321, min gradient is -8.000000, learning rate is 0.000472
Net2: layer bn50:max response is 20.467619, min response is -3.349503.
max gradient is 4.516542, min gradient is -8.000000, learning rate is 0.000943
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.443608, learning rate is 0.000472
Net2: layer bn49:max response is 8.535272, min response is -1.564857.
max gradient is 8.000000, min gradient is -2.585562, learning rate is 0.000943
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.870666, learning rate is 0.000472
max inferred z is 3.87, min inferred z is -3.83, and std is 0.99
 4.37 s (22.9 data/s) [100/100]
Loss: 3.5001
Iteration 7 / 200
training: epoch 07: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 2.169276, min gradient is -8.000000, learning rate is 0.067165
Net1: layer conv2:max response is , min response is .
max gradient is 4.082222, min gradient is -8.000000, learning rate is 0.067165
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.085497, learning rate is 0.067165
Net2: layer bn51:max response is 0.999983, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.558287, learning rate is 0.000916
Net2: layer deconv3:max response is 5.828953, min response is -20.208616.
max gradient is 4.344014, min gradient is -8.000000, learning rate is 0.000458
Net2: layer bn50:max response is 19.720379, min response is -3.531081.
max gradient is 5.220417, min gradient is -8.000000, learning rate is 0.000916
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.799354, learning rate is 0.000458
Net2: layer bn49:max response is 6.569399, min response is -1.474136.
max gradient is 8.000000, min gradient is -2.906446, learning rate is 0.000916
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.472457, learning rate is 0.000458
max inferred z is 4.02, min inferred z is -3.89, and std is 0.99
 4.34 s (23.0 data/s) [100/100]
training: epoch 07: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.141422, min gradient is -8.000000, learning rate is 0.067165
Net1: layer conv2:max response is , min response is .
max gradient is 4.661530, min gradient is -8.000000, learning rate is 0.067165
Net1: layer conv1:max response is , min response is .
max gradient is 7.824119, min gradient is -8.000000, learning rate is 0.067165
Net2: layer bn51:max response is 0.999992, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.981775, learning rate is 0.000916
Net2: layer deconv3:max response is 6.222453, min response is -16.584921.
max gradient is 5.977623, min gradient is -8.000000, learning rate is 0.000458
Net2: layer bn50:max response is 19.090643, min response is -3.410358.
max gradient is 4.771921, min gradient is -8.000000, learning rate is 0.000916
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.053214, learning rate is 0.000458
Net2: layer bn49:max response is 6.768797, min response is -1.433532.
max gradient is 8.000000, min gradient is -2.902762, learning rate is 0.000916
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.965742, learning rate is 0.000458
max inferred z is 3.82, min inferred z is -3.97, and std is 0.99
 4.31 s (23.2 data/s) [100/100]
training: epoch 07: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.643129, min gradient is -8.000000, learning rate is 0.067165
Net1: layer conv2:max response is , min response is .
max gradient is 5.947415, min gradient is -8.000000, learning rate is 0.067165
Net1: layer conv1:max response is , min response is .
max gradient is 7.385590, min gradient is -8.000000, learning rate is 0.067165
Net2: layer bn51:max response is 0.999995, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.823792, learning rate is 0.000916
Net2: layer deconv3:max response is 6.496727, min response is -13.858798.
max gradient is 6.420886, min gradient is -8.000000, learning rate is 0.000458
Net2: layer bn50:max response is 19.483883, min response is -3.855689.
max gradient is 4.603873, min gradient is -8.000000, learning rate is 0.000916
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.130102, learning rate is 0.000458
Net2: layer bn49:max response is 6.586571, min response is -1.816744.
max gradient is 8.000000, min gradient is -2.860790, learning rate is 0.000916
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.527682, learning rate is 0.000458
max inferred z is 3.86, min inferred z is -3.68, and std is 0.99
 4.36 s (22.9 data/s) [100/100]
training: epoch 07: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -2.486655, learning rate is 0.067165
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.053439, learning rate is 0.067165
Net1: layer conv1:max response is , min response is .
max gradient is 7.447233, min gradient is -8.000000, learning rate is 0.067165
Net2: layer bn51:max response is 0.999989, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.832902, learning rate is 0.000916
Net2: layer deconv3:max response is 6.034465, min response is -11.655566.
max gradient is 8.000000, min gradient is -6.936635, learning rate is 0.000458
Net2: layer bn50:max response is 17.704941, min response is -3.333167.
max gradient is 7.672308, min gradient is -8.000000, learning rate is 0.000916
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.542466, learning rate is 0.000458
Net2: layer bn49:max response is 7.543495, min response is -1.415861.
max gradient is 8.000000, min gradient is -2.426797, learning rate is 0.000916
Net2: layer deconv1:max response is , min response is .
max gradient is 4.620998, min gradient is -8.000000, learning rate is 0.000458
max inferred z is 3.70, min inferred z is -4.04, and std is 0.99
 4.43 s (22.6 data/s) [100/100]
training: epoch 07: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.693181, min gradient is -8.000000, learning rate is 0.067165
Net1: layer conv2:max response is , min response is .
max gradient is 3.944219, min gradient is -8.000000, learning rate is 0.067165
Net1: layer conv1:max response is , min response is .
max gradient is 2.603418, min gradient is -8.000000, learning rate is 0.067165
Net2: layer bn51:max response is 0.999972, min response is -0.999999.
max gradient is 8.000000, min gradient is 7.824679, learning rate is 0.000916
Net2: layer deconv3:max response is 5.587099, min response is -7.173299.
max gradient is 8.000000, min gradient is -7.885847, learning rate is 0.000458
Net2: layer bn50:max response is 13.300403, min response is -2.642269.
max gradient is 8.000000, min gradient is -7.868011, learning rate is 0.000916
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.641528, learning rate is 0.000458
Net2: layer bn49:max response is 7.434481, min response is -1.377907.
max gradient is 8.000000, min gradient is -3.304469, learning rate is 0.000916
Net2: layer deconv1:max response is , min response is .
max gradient is 4.947704, min gradient is -8.000000, learning rate is 0.000458
max inferred z is 3.74, min inferred z is -4.09, and std is 0.99
 4.45 s (22.5 data/s) [100/100]
training: epoch 07: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.527511, min gradient is -8.000000, learning rate is 0.067165
Net1: layer conv2:max response is , min response is .
max gradient is 4.192021, min gradient is -8.000000, learning rate is 0.067165
Net1: layer conv1:max response is , min response is .
max gradient is 7.358052, min gradient is -8.000000, learning rate is 0.067165
Net2: layer bn51:max response is 0.999992, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.778762, learning rate is 0.000916
Net2: layer deconv3:max response is 6.233548, min response is -8.069895.
max gradient is 8.000000, min gradient is -6.819798, learning rate is 0.000458
Net2: layer bn50:max response is 15.958442, min response is -3.026190.
max gradient is 8.000000, min gradient is -2.701945, learning rate is 0.000916
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.919838, learning rate is 0.000458
Net2: layer bn49:max response is 7.662879, min response is -1.673710.
max gradient is 8.000000, min gradient is -3.678064, learning rate is 0.000916
Net2: layer deconv1:max response is , min response is .
max gradient is 4.363519, min gradient is -8.000000, learning rate is 0.000458
max inferred z is 3.79, min inferred z is -4.09, and std is 0.99
 4.31 s (23.2 data/s) [100/100]
training: epoch 07: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.786229, learning rate is 0.067165
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.072062, learning rate is 0.067165
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.965263, learning rate is 0.067165
Net2: layer bn51:max response is 0.999980, min response is -1.000000.
max gradient is -7.328952, min gradient is -8.000000, learning rate is 0.000916
Net2: layer deconv3:max response is 5.752401, min response is -8.550001.
max gradient is 8.000000, min gradient is -5.412060, learning rate is 0.000458
Net2: layer bn50:max response is 15.193025, min response is -2.673961.
max gradient is 8.000000, min gradient is -1.013130, learning rate is 0.000916
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000001, min gradient is -7.863006, learning rate is 0.000458
Net2: layer bn49:max response is 8.614015, min response is -1.716013.
max gradient is 8.000000, min gradient is -6.025201, learning rate is 0.000916
Net2: layer deconv1:max response is , min response is .
max gradient is 6.553059, min gradient is -8.000000, learning rate is 0.000458
max inferred z is 4.12, min inferred z is -4.35, and std is 0.99
 4.38 s (22.8 data/s) [100/100]
training: epoch 07: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.962182, learning rate is 0.067165
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.864020, learning rate is 0.067165
Net1: layer conv1:max response is , min response is .
max gradient is 2.852731, min gradient is -8.000000, learning rate is 0.067165
Net2: layer bn51:max response is 0.999995, min response is -0.999996.
max gradient is -5.394291, min gradient is -8.000000, learning rate is 0.000916
Net2: layer deconv3:max response is 6.427313, min response is -6.627982.
max gradient is 8.000000, min gradient is -6.806110, learning rate is 0.000458
Net2: layer bn50:max response is 11.505537, min response is -2.882291.
max gradient is 8.000000, min gradient is -0.841096, learning rate is 0.000916
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.528562, learning rate is 0.000458
Net2: layer bn49:max response is 8.120693, min response is -1.543697.
max gradient is 8.000000, min gradient is -6.615869, learning rate is 0.000916
Net2: layer deconv1:max response is , min response is .
max gradient is 3.610722, min gradient is -8.000000, learning rate is 0.000458
max inferred z is 4.56, min inferred z is -4.21, and std is 0.99
 4.36 s (22.9 data/s) [100/100]
training: epoch 07: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.700821, learning rate is 0.067165
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.704036, learning rate is 0.067165
Net1: layer conv1:max response is , min response is .
max gradient is 6.029016, min gradient is -8.000000, learning rate is 0.067165
Net2: layer bn51:max response is 0.999992, min response is -1.000000.
max gradient is 8.000000, min gradient is 0.333494, learning rate is 0.000916
Net2: layer deconv3:max response is 6.208379, min response is -8.915771.
max gradient is 8.000000, min gradient is -7.423284, learning rate is 0.000458
Net2: layer bn50:max response is 12.504484, min response is -2.440519.
max gradient is 8.000000, min gradient is -0.893781, learning rate is 0.000916
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.498612, learning rate is 0.000458
Net2: layer bn49:max response is 8.278451, min response is -1.764735.
max gradient is 7.842493, min gradient is -8.000000, learning rate is 0.000916
Net2: layer deconv1:max response is , min response is .
max gradient is 4.446977, min gradient is -8.000000, learning rate is 0.000458
max inferred z is 4.33, min inferred z is -4.06, and std is 0.99
 4.27 s (23.4 data/s) [100/100]
training: epoch 07: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.575408, min gradient is -8.000000, learning rate is 0.067165
Net1: layer conv2:max response is , min response is .
max gradient is 5.190212, min gradient is -8.000000, learning rate is 0.067165
Net1: layer conv1:max response is , min response is .
max gradient is 5.832707, min gradient is -8.000000, learning rate is 0.067165
Net2: layer bn51:max response is 0.999999, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.320895, learning rate is 0.000916
Net2: layer deconv3:max response is 7.093411, min response is -8.643465.
max gradient is 8.000000, min gradient is -7.701678, learning rate is 0.000458
Net2: layer bn50:max response is 13.697761, min response is -2.087226.
max gradient is 8.000000, min gradient is -1.171551, learning rate is 0.000916
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.114736, learning rate is 0.000458
Net2: layer bn49:max response is 9.032119, min response is -1.757078.
max gradient is 5.707846, min gradient is -8.000000, learning rate is 0.000916
Net2: layer deconv1:max response is , min response is .
max gradient is 3.511995, min gradient is -8.000000, learning rate is 0.000458
max inferred z is 4.10, min inferred z is -3.87, and std is 0.99
 4.29 s (23.3 data/s) [100/100]
Loss: 2.9984
Iteration 8 / 200
training: epoch 08: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.483853, min gradient is -8.000000, learning rate is 0.067165
Net1: layer conv2:max response is , min response is .
max gradient is 5.120591, min gradient is -8.000000, learning rate is 0.067165
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -2.632464, learning rate is 0.067165
Net2: layer bn51:max response is 0.999999, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.209905, learning rate is 0.000916
Net2: layer deconv3:max response is 7.175712, min response is -9.289852.
max gradient is 8.000000, min gradient is -7.970137, learning rate is 0.000458
Net2: layer bn50:max response is 13.455020, min response is -2.121775.
max gradient is 8.000000, min gradient is -1.532493, learning rate is 0.000916
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.729706, learning rate is 0.000458
Net2: layer bn49:max response is 6.879608, min response is -1.497269.
max gradient is 4.923643, min gradient is -8.000000, learning rate is 0.000916
Net2: layer deconv1:max response is , min response is .
max gradient is 3.556887, min gradient is -8.000000, learning rate is 0.000458
max inferred z is 3.99, min inferred z is -3.79, and std is 1.01
 4.21 s (23.7 data/s) [100/100]
training: epoch 08: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.673035, min gradient is -8.000000, learning rate is 0.067165
Net1: layer conv2:max response is , min response is .
max gradient is 4.453698, min gradient is -8.000000, learning rate is 0.067165
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.273585, learning rate is 0.067165
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.703131, learning rate is 0.000916
Net2: layer deconv3:max response is 8.427572, min response is -12.091339.
max gradient is 7.635208, min gradient is -8.000000, learning rate is 0.000458
Net2: layer bn50:max response is 14.366926, min response is -2.605276.
max gradient is 8.000000, min gradient is -2.308314, learning rate is 0.000916
Net2: layer deconv2:max response is , min response is .
max gradient is 6.400399, min gradient is -8.000000, learning rate is 0.000458
Net2: layer bn49:max response is 7.833837, min response is -1.512526.
max gradient is 4.352218, min gradient is -8.000000, learning rate is 0.000916
Net2: layer deconv1:max response is , min response is .
max gradient is 4.518384, min gradient is -8.000000, learning rate is 0.000458
max inferred z is 3.91, min inferred z is -4.17, and std is 1.01
 4.24 s (23.6 data/s) [100/100]
training: epoch 08: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.738106, min gradient is -8.000000, learning rate is 0.067165
Net1: layer conv2:max response is , min response is .
max gradient is 6.926264, min gradient is -8.000000, learning rate is 0.067165
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.699539, learning rate is 0.067165
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.844591, learning rate is 0.000916
Net2: layer deconv3:max response is 7.964122, min response is -14.172839.
max gradient is 7.196459, min gradient is -8.000000, learning rate is 0.000458
Net2: layer bn50:max response is 15.747270, min response is -2.468161.
max gradient is 8.000000, min gradient is -2.523042, learning rate is 0.000916
Net2: layer deconv2:max response is , min response is .
max gradient is 6.089776, min gradient is -8.000000, learning rate is 0.000458
Net2: layer bn49:max response is 7.365107, min response is -1.716769.
max gradient is 4.296388, min gradient is -8.000000, learning rate is 0.000916
Net2: layer deconv1:max response is , min response is .
max gradient is 6.105435, min gradient is -8.000000, learning rate is 0.000458
max inferred z is 4.50, min inferred z is -4.15, and std is 1.01
 4.34 s (23.1 data/s) [100/100]
training: epoch 08: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.957472, min gradient is -8.000000, learning rate is 0.067165
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.543416, learning rate is 0.067165
Net1: layer conv1:max response is , min response is .
max gradient is 3.955299, min gradient is -8.000000, learning rate is 0.067165
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.897920, learning rate is 0.000916
Net2: layer deconv3:max response is 7.931476, min response is -16.228487.
max gradient is 6.932748, min gradient is -8.000001, learning rate is 0.000458
Net2: layer bn50:max response is 13.304012, min response is -2.252705.
max gradient is 8.000000, min gradient is -2.634478, learning rate is 0.000916
Net2: layer deconv2:max response is , min response is .
max gradient is 5.100115, min gradient is -8.000000, learning rate is 0.000458
Net2: layer bn49:max response is 7.498735, min response is -1.752650.
max gradient is 5.288605, min gradient is -8.000000, learning rate is 0.000916
Net2: layer deconv1:max response is , min response is .
max gradient is 7.932048, min gradient is -8.000000, learning rate is 0.000458
max inferred z is 3.99, min inferred z is -3.88, and std is 1.01
 4.27 s (23.4 data/s) [100/100]
training: epoch 08: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.188165, learning rate is 0.067165
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.579649, learning rate is 0.067165
Net1: layer conv1:max response is , min response is .
max gradient is 5.925461, min gradient is -8.000000, learning rate is 0.067165
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.887917, learning rate is 0.000916
Net2: layer deconv3:max response is 8.752382, min response is -15.661242.
max gradient is 6.033852, min gradient is -8.000000, learning rate is 0.000458
Net2: layer bn50:max response is 13.735958, min response is -2.292219.
max gradient is 8.000000, min gradient is -4.652452, learning rate is 0.000916
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -3.548917, learning rate is 0.000458
Net2: layer bn49:max response is 7.925421, min response is -1.588604.
max gradient is 8.000000, min gradient is -7.572909, learning rate is 0.000916
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.104183, learning rate is 0.000458
max inferred z is 3.65, min inferred z is -4.06, and std is 1.01
 4.25 s (23.5 data/s) [100/100]
training: epoch 08: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.026854, learning rate is 0.067165
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.606936, learning rate is 0.067165
Net1: layer conv1:max response is , min response is .
max gradient is 7.170655, min gradient is -8.000000, learning rate is 0.067165
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.751973, learning rate is 0.000916
Net2: layer deconv3:max response is 8.200700, min response is -16.583052.
max gradient is 5.161881, min gradient is -8.000000, learning rate is 0.000458
Net2: layer bn50:max response is 13.330053, min response is -2.192523.
max gradient is 8.000000, min gradient is -6.808856, learning rate is 0.000916
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -3.611578, learning rate is 0.000458
Net2: layer bn49:max response is 7.447227, min response is -1.478561.
max gradient is 8.000000, min gradient is -5.981570, learning rate is 0.000916
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.688866, learning rate is 0.000458
max inferred z is 4.71, min inferred z is -4.01, and std is 1.01
 4.46 s (22.4 data/s) [100/100]
training: epoch 08: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.685093, learning rate is 0.067165
Net1: layer conv2:max response is , min response is .
max gradient is 5.768167, min gradient is -8.000000, learning rate is 0.067165
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.864897, learning rate is 0.067165
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.601984, learning rate is 0.000916
Net2: layer deconv3:max response is 7.746389, min response is -14.802156.
max gradient is 5.013501, min gradient is -8.000000, learning rate is 0.000458
Net2: layer bn50:max response is 13.125223, min response is -2.302602.
max gradient is 7.264448, min gradient is -8.000000, learning rate is 0.000916
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.493964, learning rate is 0.000458
Net2: layer bn49:max response is 7.705236, min response is -1.481771.
max gradient is 8.000000, min gradient is -6.633477, learning rate is 0.000916
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.822953, learning rate is 0.000458
max inferred z is 4.09, min inferred z is -4.30, and std is 1.01
 4.32 s (23.2 data/s) [100/100]
training: epoch 08: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.427993, learning rate is 0.067165
Net1: layer conv2:max response is , min response is .
max gradient is 7.417959, min gradient is -8.000000, learning rate is 0.067165
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -5.469473, learning rate is 0.067165
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.466943, learning rate is 0.000916
Net2: layer deconv3:max response is 8.030054, min response is -14.518379.
max gradient is 6.721026, min gradient is -8.000000, learning rate is 0.000458
Net2: layer bn50:max response is 12.524506, min response is -2.264174.
max gradient is 6.976500, min gradient is -8.000000, learning rate is 0.000916
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.654485, learning rate is 0.000458
Net2: layer bn49:max response is 7.670100, min response is -1.566271.
max gradient is 8.000000, min gradient is -6.946049, learning rate is 0.000916
Net2: layer deconv1:max response is , min response is .
max gradient is 6.255350, min gradient is -8.000000, learning rate is 0.000458
max inferred z is 3.85, min inferred z is -3.86, and std is 1.01
 4.26 s (23.5 data/s) [100/100]
training: epoch 08: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.800133, min gradient is -8.000000, learning rate is 0.067165
Net1: layer conv2:max response is , min response is .
max gradient is 4.654395, min gradient is -8.000000, learning rate is 0.067165
Net1: layer conv1:max response is , min response is .
max gradient is 6.461534, min gradient is -8.000000, learning rate is 0.067165
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.581519, learning rate is 0.000916
Net2: layer deconv3:max response is 8.985337, min response is -13.566267.
max gradient is 8.000001, min gradient is -7.027475, learning rate is 0.000458
Net2: layer bn50:max response is 13.069490, min response is -2.384161.
max gradient is 3.145257, min gradient is -8.000000, learning rate is 0.000916
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.593491, learning rate is 0.000458
Net2: layer bn49:max response is 6.922727, min response is -1.490776.
max gradient is 8.000001, min gradient is -6.391761, learning rate is 0.000916
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.942685, learning rate is 0.000458
max inferred z is 4.03, min inferred z is -3.81, and std is 1.01
 4.26 s (23.5 data/s) [100/100]
training: epoch 08: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.918009, min gradient is -8.000000, learning rate is 0.067165
Net1: layer conv2:max response is , min response is .
max gradient is 4.023090, min gradient is -8.000000, learning rate is 0.067165
Net1: layer conv1:max response is , min response is .
max gradient is 2.917233, min gradient is -8.000000, learning rate is 0.067165
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.583938, learning rate is 0.000916
Net2: layer deconv3:max response is 8.969624, min response is -12.232493.
max gradient is 8.000000, min gradient is -5.964725, learning rate is 0.000458
Net2: layer bn50:max response is 14.390826, min response is -2.345497.
max gradient is 3.395560, min gradient is -8.000000, learning rate is 0.000916
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.636889, learning rate is 0.000458
Net2: layer bn49:max response is 8.161302, min response is -1.460140.
max gradient is 8.000000, min gradient is -5.645487, learning rate is 0.000916
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.150112, learning rate is 0.000458
max inferred z is 4.07, min inferred z is -4.83, and std is 1.01
 4.35 s (23.0 data/s) [100/100]
Loss: 3.2671
Iteration 9 / 200
training: epoch 09: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.605926, learning rate is 0.063361
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.808779, learning rate is 0.063361
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.708739, learning rate is 0.063361
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.035126, learning rate is 0.000890
Net2: layer deconv3:max response is 9.047338, min response is -12.665939.
max gradient is 8.000000, min gradient is -5.335245, learning rate is 0.000445
Net2: layer bn50:max response is 13.642535, min response is -2.371905.
max gradient is 3.429578, min gradient is -8.000000, learning rate is 0.000890
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.352218, learning rate is 0.000445
Net2: layer bn49:max response is 6.381085, min response is -1.401181.
max gradient is 8.000000, min gradient is -7.562971, learning rate is 0.000890
Net2: layer deconv1:max response is , min response is .
max gradient is 6.176867, min gradient is -8.000000, learning rate is 0.000445
max inferred z is 3.91, min inferred z is -4.09, and std is 1.00
 4.19 s (23.9 data/s) [100/100]
training: epoch 09: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.076474, learning rate is 0.063361
Net1: layer conv2:max response is , min response is .
max gradient is 4.012447, min gradient is -8.000000, learning rate is 0.063361
Net1: layer conv1:max response is , min response is .
max gradient is 5.506699, min gradient is -8.000000, learning rate is 0.063361
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.579012, learning rate is 0.000890
Net2: layer deconv3:max response is 9.227648, min response is -11.655394.
max gradient is 8.000000, min gradient is -6.389858, learning rate is 0.000445
Net2: layer bn50:max response is 14.668361, min response is -2.691332.
max gradient is 3.604321, min gradient is -8.000000, learning rate is 0.000890
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.154919, learning rate is 0.000445
Net2: layer bn49:max response is 8.088800, min response is -1.436893.
max gradient is 8.000000, min gradient is -7.633905, learning rate is 0.000890
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.066865, learning rate is 0.000445
max inferred z is 4.12, min inferred z is -3.97, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 09: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.859223, learning rate is 0.063361
Net1: layer conv2:max response is , min response is .
max gradient is 4.256543, min gradient is -8.000000, learning rate is 0.063361
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.526426, learning rate is 0.063361
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.878840, learning rate is 0.000890
Net2: layer deconv3:max response is 10.479403, min response is -11.300975.
max gradient is 7.788459, min gradient is -8.000000, learning rate is 0.000445
Net2: layer bn50:max response is 15.251856, min response is -2.251979.
max gradient is 4.045957, min gradient is -8.000000, learning rate is 0.000890
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.806132, learning rate is 0.000445
Net2: layer bn49:max response is 6.962767, min response is -1.322166.
max gradient is 8.000000, min gradient is -7.642690, learning rate is 0.000890
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.927914, learning rate is 0.000445
max inferred z is 3.63, min inferred z is -3.94, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 09: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.117019, min gradient is -8.000000, learning rate is 0.063361
Net1: layer conv2:max response is , min response is .
max gradient is 4.447018, min gradient is -8.000000, learning rate is 0.063361
Net1: layer conv1:max response is , min response is .
max gradient is 3.975763, min gradient is -8.000000, learning rate is 0.063361
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.706646, learning rate is 0.000890
Net2: layer deconv3:max response is 9.345628, min response is -12.912741.
max gradient is 7.870428, min gradient is -8.000000, learning rate is 0.000445
Net2: layer bn50:max response is 15.944435, min response is -3.031280.
max gradient is 3.227833, min gradient is -8.000000, learning rate is 0.000890
Net2: layer deconv2:max response is , min response is .
max gradient is 6.853819, min gradient is -8.000000, learning rate is 0.000445
Net2: layer bn49:max response is 8.729796, min response is -1.234285.
max gradient is 8.000000, min gradient is -7.752043, learning rate is 0.000890
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.019258, learning rate is 0.000445
max inferred z is 4.07, min inferred z is -4.26, and std is 1.00
 4.45 s (22.5 data/s) [100/100]
training: epoch 09: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.460249, min gradient is -8.000000, learning rate is 0.063361
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.420858, learning rate is 0.063361
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.994931, learning rate is 0.063361
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 0.936330, learning rate is 0.000890
Net2: layer deconv3:max response is 8.804730, min response is -14.361385.
max gradient is 8.000000, min gradient is -6.916728, learning rate is 0.000445
Net2: layer bn50:max response is 13.760888, min response is -2.580437.
max gradient is 8.000000, min gradient is -7.316476, learning rate is 0.000890
Net2: layer deconv2:max response is , min response is .
max gradient is 5.617448, min gradient is -8.000000, learning rate is 0.000445
Net2: layer bn49:max response is 7.803260, min response is -1.442772.
max gradient is 7.871475, min gradient is -8.000000, learning rate is 0.000890
Net2: layer deconv1:max response is , min response is .
max gradient is 5.478015, min gradient is -8.000000, learning rate is 0.000445
max inferred z is 4.90, min inferred z is -4.03, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 09: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.749662, min gradient is -8.000000, learning rate is 0.063361
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.243245, learning rate is 0.063361
Net1: layer conv1:max response is , min response is .
max gradient is 3.534322, min gradient is -8.000000, learning rate is 0.063361
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.505724, learning rate is 0.000890
Net2: layer deconv3:max response is 8.305075, min response is -13.449940.
max gradient is 8.000000, min gradient is -6.866459, learning rate is 0.000445
Net2: layer bn50:max response is 13.189460, min response is -2.499555.
max gradient is 8.000000, min gradient is -5.128958, learning rate is 0.000890
Net2: layer deconv2:max response is , min response is .
max gradient is 6.052619, min gradient is -8.000000, learning rate is 0.000445
Net2: layer bn49:max response is 6.590361, min response is -1.382480.
max gradient is 7.480588, min gradient is -8.000000, learning rate is 0.000890
Net2: layer deconv1:max response is , min response is .
max gradient is 4.922631, min gradient is -8.000000, learning rate is 0.000445
max inferred z is 3.95, min inferred z is -3.96, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
training: epoch 09: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.702638, min gradient is -8.000000, learning rate is 0.063361
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.547933, learning rate is 0.063361
Net1: layer conv1:max response is , min response is .
max gradient is 5.105975, min gradient is -8.000000, learning rate is 0.063361
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.714196, learning rate is 0.000890
Net2: layer deconv3:max response is 8.939973, min response is -20.133181.
max gradient is 7.243225, min gradient is -8.000000, learning rate is 0.000445
Net2: layer bn50:max response is 17.484499, min response is -3.388589.
max gradient is 8.000000, min gradient is -4.306536, learning rate is 0.000890
Net2: layer deconv2:max response is , min response is .
max gradient is 4.716312, min gradient is -8.000000, learning rate is 0.000445
Net2: layer bn49:max response is 6.459138, min response is -1.346427.
max gradient is 8.000000, min gradient is -7.299192, learning rate is 0.000890
Net2: layer deconv1:max response is , min response is .
max gradient is 6.053212, min gradient is -8.000000, learning rate is 0.000445
max inferred z is 4.49, min inferred z is -4.64, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 09: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.500048, learning rate is 0.063361
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.889091, learning rate is 0.063361
Net1: layer conv1:max response is , min response is .
max gradient is 5.815088, min gradient is -8.000000, learning rate is 0.063361
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.693730, learning rate is 0.000890
Net2: layer deconv3:max response is 11.582861, min response is -24.488504.
max gradient is 4.810727, min gradient is -8.000000, learning rate is 0.000445
Net2: layer bn50:max response is 18.576254, min response is -3.746708.
max gradient is 8.000000, min gradient is -3.351563, learning rate is 0.000890
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.729004, learning rate is 0.000445
Net2: layer bn49:max response is 7.631449, min response is -1.319954.
max gradient is 8.000000, min gradient is -4.986364, learning rate is 0.000890
Net2: layer deconv1:max response is , min response is .
max gradient is 6.123697, min gradient is -8.000000, learning rate is 0.000445
max inferred z is 4.11, min inferred z is -4.50, and std is 1.00
 4.49 s (22.3 data/s) [100/100]
training: epoch 09: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.132857, learning rate is 0.063361
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.432811, learning rate is 0.063361
Net1: layer conv1:max response is , min response is .
max gradient is 5.568400, min gradient is -8.000000, learning rate is 0.063361
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.774534, learning rate is 0.000890
Net2: layer deconv3:max response is 10.885497, min response is -22.355228.
max gradient is 4.935933, min gradient is -8.000000, learning rate is 0.000445
Net2: layer bn50:max response is 15.724919, min response is -3.358535.
max gradient is 8.000000, min gradient is -2.359895, learning rate is 0.000890
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -3.782779, learning rate is 0.000445
Net2: layer bn49:max response is 7.253858, min response is -1.350466.
max gradient is 8.000000, min gradient is -2.577483, learning rate is 0.000890
Net2: layer deconv1:max response is , min response is .
max gradient is 6.730147, min gradient is -8.000000, learning rate is 0.000445
max inferred z is 3.86, min inferred z is -3.68, and std is 1.00
 4.41 s (22.7 data/s) [100/100]
training: epoch 09: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.828987, min gradient is -8.000000, learning rate is 0.063361
Net1: layer conv2:max response is , min response is .
max gradient is 6.041507, min gradient is -8.000000, learning rate is 0.063361
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.664439, learning rate is 0.063361
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.786743, learning rate is 0.000890
Net2: layer deconv3:max response is 11.953694, min response is -23.784351.
max gradient is 5.231596, min gradient is -8.000000, learning rate is 0.000445
Net2: layer bn50:max response is 16.419233, min response is -3.461003.
max gradient is 8.000000, min gradient is -2.486233, learning rate is 0.000890
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.088043, learning rate is 0.000445
Net2: layer bn49:max response is 7.951622, min response is -1.661989.
max gradient is 8.000000, min gradient is -2.326879, learning rate is 0.000890
Net2: layer deconv1:max response is , min response is .
max gradient is 5.592077, min gradient is -8.000000, learning rate is 0.000445
max inferred z is 4.40, min inferred z is -3.84, and std is 1.00
 4.28 s (23.3 data/s) [100/100]
Loss: 2.8507
Iteration 10 / 200
training: epoch 10: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.350973, min gradient is -8.000000, learning rate is 0.063361
Net1: layer conv2:max response is , min response is .
max gradient is 4.601182, min gradient is -8.000000, learning rate is 0.063361
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.424022, learning rate is 0.063361
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.815489, learning rate is 0.000890
Net2: layer deconv3:max response is 13.333391, min response is -28.782116.
max gradient is 5.440675, min gradient is -8.000000, learning rate is 0.000445
Net2: layer bn50:max response is 20.157532, min response is -4.274566.
max gradient is 8.000000, min gradient is -1.993008, learning rate is 0.000890
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.287368, learning rate is 0.000445
Net2: layer bn49:max response is 8.721410, min response is -1.590189.
max gradient is 8.000000, min gradient is -2.417765, learning rate is 0.000890
Net2: layer deconv1:max response is , min response is .
max gradient is 5.959661, min gradient is -8.000000, learning rate is 0.000445
max inferred z is 3.64, min inferred z is -4.06, and std is 1.01
 4.19 s (23.9 data/s) [100/100]
training: epoch 10: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.739467, min gradient is -8.000000, learning rate is 0.063361
Net1: layer conv2:max response is , min response is .
max gradient is 7.341352, min gradient is -8.000000, learning rate is 0.063361
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.070189, learning rate is 0.063361
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.855278, learning rate is 0.000890
Net2: layer deconv3:max response is 10.972096, min response is -21.885492.
max gradient is 6.019760, min gradient is -8.000000, learning rate is 0.000445
Net2: layer bn50:max response is 15.326435, min response is -3.286391.
max gradient is 8.000000, min gradient is -1.693590, learning rate is 0.000890
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.381841, learning rate is 0.000445
Net2: layer bn49:max response is 7.153148, min response is -1.502052.
max gradient is 8.000000, min gradient is -2.509908, learning rate is 0.000890
Net2: layer deconv1:max response is , min response is .
max gradient is 7.325472, min gradient is -8.000000, learning rate is 0.000445
max inferred z is 3.77, min inferred z is -3.83, and std is 1.01
 4.34 s (23.0 data/s) [100/100]
training: epoch 10: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.333990, min gradient is -8.000000, learning rate is 0.063361
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.877215, learning rate is 0.063361
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.113217, learning rate is 0.063361
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.706605, learning rate is 0.000890
Net2: layer deconv3:max response is 8.635989, min response is -20.058071.
max gradient is 8.000000, min gradient is -7.928586, learning rate is 0.000445
Net2: layer bn50:max response is 14.648021, min response is -2.978942.
max gradient is 8.000000, min gradient is -1.549498, learning rate is 0.000890
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.480616, learning rate is 0.000445
Net2: layer bn49:max response is 6.978279, min response is -1.553780.
max gradient is 8.000000, min gradient is -2.755832, learning rate is 0.000890
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.982912, learning rate is 0.000445
max inferred z is 4.19, min inferred z is -3.94, and std is 1.01
 4.33 s (23.1 data/s) [100/100]
training: epoch 10: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.293382, min gradient is -8.000000, learning rate is 0.063361
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.459226, learning rate is 0.063361
Net1: layer conv1:max response is , min response is .
max gradient is 5.104728, min gradient is -8.000000, learning rate is 0.063361
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.657738, learning rate is 0.000890
Net2: layer deconv3:max response is 10.519470, min response is -26.722565.
max gradient is 6.805445, min gradient is -8.000000, learning rate is 0.000445
Net2: layer bn50:max response is 19.603703, min response is -3.782300.
max gradient is 8.000000, min gradient is -3.169120, learning rate is 0.000890
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000001, min gradient is -5.583333, learning rate is 0.000445
Net2: layer bn49:max response is 7.545199, min response is -1.308880.
max gradient is 8.000000, min gradient is -2.726317, learning rate is 0.000890
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.195242, learning rate is 0.000445
max inferred z is 3.94, min inferred z is -3.93, and std is 1.01
 4.34 s (23.0 data/s) [100/100]
training: epoch 10: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.897071, min gradient is -8.000000, learning rate is 0.063361
Net1: layer conv2:max response is , min response is .
max gradient is 6.382334, min gradient is -8.000000, learning rate is 0.063361
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.291117, learning rate is 0.063361
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.229830, learning rate is 0.000890
Net2: layer deconv3:max response is 8.160768, min response is -19.001305.
max gradient is 6.504450, min gradient is -8.000000, learning rate is 0.000445
Net2: layer bn50:max response is 17.762661, min response is -3.083728.
max gradient is 8.000000, min gradient is -2.889982, learning rate is 0.000890
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.691141, learning rate is 0.000445
Net2: layer bn49:max response is 8.074760, min response is -1.647643.
max gradient is 8.000000, min gradient is -3.181682, learning rate is 0.000890
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.646379, learning rate is 0.000445
max inferred z is 4.26, min inferred z is -3.79, and std is 1.01
 4.40 s (22.7 data/s) [100/100]
training: epoch 10: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.614851, min gradient is -8.000000, learning rate is 0.063361
Net1: layer conv2:max response is , min response is .
max gradient is 6.279320, min gradient is -8.000000, learning rate is 0.063361
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -5.893548, learning rate is 0.063361
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.331409, learning rate is 0.000890
Net2: layer deconv3:max response is 8.893047, min response is -17.728046.
max gradient is 7.036360, min gradient is -8.000000, learning rate is 0.000445
Net2: layer bn50:max response is 17.324028, min response is -2.937968.
max gradient is 8.000000, min gradient is -2.943971, learning rate is 0.000890
Net2: layer deconv2:max response is , min response is .
max gradient is 7.409110, min gradient is -8.000001, learning rate is 0.000445
Net2: layer bn49:max response is 6.925821, min response is -1.741686.
max gradient is 8.000000, min gradient is -5.381851, learning rate is 0.000890
Net2: layer deconv1:max response is , min response is .
max gradient is 6.413718, min gradient is -8.000000, learning rate is 0.000445
max inferred z is 3.81, min inferred z is -4.21, and std is 1.01
 4.43 s (22.6 data/s) [100/100]
training: epoch 10: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.811637, min gradient is -8.000000, learning rate is 0.063361
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.986110, learning rate is 0.063361
Net1: layer conv1:max response is , min response is .
max gradient is 5.685210, min gradient is -8.000000, learning rate is 0.063361
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.985878, min gradient is -8.000000, learning rate is 0.000890
Net2: layer deconv3:max response is 8.300851, min response is -21.416986.
max gradient is 8.000000, min gradient is -7.999172, learning rate is 0.000445
Net2: layer bn50:max response is 17.961256, min response is -3.350162.
max gradient is 8.000001, min gradient is -2.846453, learning rate is 0.000890
Net2: layer deconv2:max response is , min response is .
max gradient is 6.404077, min gradient is -8.000000, learning rate is 0.000445
Net2: layer bn49:max response is 8.561104, min response is -1.539270.
max gradient is 7.290493, min gradient is -8.000000, learning rate is 0.000890
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.154822, learning rate is 0.000445
max inferred z is 4.29, min inferred z is -3.95, and std is 1.01
 4.33 s (23.1 data/s) [100/100]
training: epoch 10: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.244078, learning rate is 0.063361
Net1: layer conv2:max response is , min response is .
max gradient is 7.107164, min gradient is -8.000000, learning rate is 0.063361
Net1: layer conv1:max response is , min response is .
max gradient is 6.995881, min gradient is -8.000000, learning rate is 0.063361
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.937994, min gradient is -8.000000, learning rate is 0.000890
Net2: layer deconv3:max response is 7.761652, min response is -17.004734.
max gradient is 8.000000, min gradient is -6.799606, learning rate is 0.000445
Net2: layer bn50:max response is 18.121334, min response is -2.517194.
max gradient is 8.000000, min gradient is -2.708032, learning rate is 0.000890
Net2: layer deconv2:max response is , min response is .
max gradient is 6.414745, min gradient is -8.000000, learning rate is 0.000445
Net2: layer bn49:max response is 7.398664, min response is -1.514922.
max gradient is 5.525548, min gradient is -8.000000, learning rate is 0.000890
Net2: layer deconv1:max response is , min response is .
max gradient is 6.475398, min gradient is -8.000000, learning rate is 0.000445
max inferred z is 3.81, min inferred z is -4.02, and std is 1.01
 4.29 s (23.3 data/s) [100/100]
training: epoch 10: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.729370, learning rate is 0.063361
Net1: layer conv2:max response is , min response is .
max gradient is 6.810053, min gradient is -8.000000, learning rate is 0.063361
Net1: layer conv1:max response is , min response is .
max gradient is 5.237598, min gradient is -8.000000, learning rate is 0.063361
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.962990, learning rate is 0.000890
Net2: layer deconv3:max response is 10.546547, min response is -20.225599.
max gradient is 8.000000, min gradient is -7.189102, learning rate is 0.000445
Net2: layer bn50:max response is 17.711033, min response is -2.916656.
max gradient is 8.000000, min gradient is -2.635115, learning rate is 0.000890
Net2: layer deconv2:max response is , min response is .
max gradient is 5.724496, min gradient is -8.000000, learning rate is 0.000445
Net2: layer bn49:max response is 7.123559, min response is -1.462055.
max gradient is 6.034719, min gradient is -8.000000, learning rate is 0.000890
Net2: layer deconv1:max response is , min response is .
max gradient is 5.421902, min gradient is -8.000000, learning rate is 0.000445
max inferred z is 3.47, min inferred z is -3.86, and std is 1.01
 4.36 s (22.9 data/s) [100/100]
training: epoch 10: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.575180, min gradient is -8.000000, learning rate is 0.063361
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.689089, learning rate is 0.063361
Net1: layer conv1:max response is , min response is .
max gradient is 3.377977, min gradient is -8.000000, learning rate is 0.063361
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.546697, learning rate is 0.000890
Net2: layer deconv3:max response is 9.978831, min response is -22.897631.
max gradient is 6.692445, min gradient is -8.000000, learning rate is 0.000445
Net2: layer bn50:max response is 17.214323, min response is -2.956266.
max gradient is 8.000000, min gradient is -2.627552, learning rate is 0.000890
Net2: layer deconv2:max response is , min response is .
max gradient is 6.975756, min gradient is -8.000000, learning rate is 0.000445
Net2: layer bn49:max response is 9.035749, min response is -1.556307.
max gradient is 6.433015, min gradient is -8.000000, learning rate is 0.000890
Net2: layer deconv1:max response is , min response is .
max gradient is 5.919233, min gradient is -8.000000, learning rate is 0.000445
max inferred z is 4.13, min inferred z is -4.21, and std is 1.01
 4.36 s (22.9 data/s) [100/100]
Loss: 3.3069
Iteration 11 / 200
training: epoch 11: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.706058, min gradient is -8.000000, learning rate is 0.059773
Net1: layer conv2:max response is , min response is .
max gradient is 6.027075, min gradient is -8.000000, learning rate is 0.059773
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.226201, learning rate is 0.059773
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.554254, learning rate is 0.000864
Net2: layer deconv3:max response is 12.373275, min response is -21.547428.
max gradient is 6.821976, min gradient is -8.000000, learning rate is 0.000432
Net2: layer bn50:max response is 17.719416, min response is -2.782876.
max gradient is 8.000000, min gradient is -1.570599, learning rate is 0.000864
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.435488, learning rate is 0.000432
Net2: layer bn49:max response is 8.112202, min response is -1.458494.
max gradient is 8.000000, min gradient is -7.079691, learning rate is 0.000864
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.891381, learning rate is 0.000432
max inferred z is 3.61, min inferred z is -4.14, and std is 1.00
 4.17 s (24.0 data/s) [100/100]
training: epoch 11: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.050790, learning rate is 0.059773
Net1: layer conv2:max response is , min response is .
max gradient is 7.470994, min gradient is -8.000000, learning rate is 0.059773
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.185727, learning rate is 0.059773
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.331164, learning rate is 0.000864
Net2: layer deconv3:max response is 12.658042, min response is -21.363911.
max gradient is 7.580739, min gradient is -8.000000, learning rate is 0.000432
Net2: layer bn50:max response is 16.591927, min response is -2.520689.
max gradient is 8.000000, min gradient is -1.962433, learning rate is 0.000864
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000001, min gradient is -6.340839, learning rate is 0.000432
Net2: layer bn49:max response is 7.077137, min response is -1.382398.
max gradient is 8.000000, min gradient is -5.269834, learning rate is 0.000864
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.535002, learning rate is 0.000432
max inferred z is 4.12, min inferred z is -3.93, and std is 1.00
 4.41 s (22.7 data/s) [100/100]
training: epoch 11: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.556942, learning rate is 0.059773
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.569979, learning rate is 0.059773
Net1: layer conv1:max response is , min response is .
max gradient is 6.148782, min gradient is -8.000000, learning rate is 0.059773
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.738865, learning rate is 0.000864
Net2: layer deconv3:max response is 15.193889, min response is -20.789503.
max gradient is 7.810819, min gradient is -8.000000, learning rate is 0.000432
Net2: layer bn50:max response is 19.016205, min response is -2.975623.
max gradient is 8.000000, min gradient is -3.890808, learning rate is 0.000864
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.760572, learning rate is 0.000432
Net2: layer bn49:max response is 7.991906, min response is -1.479806.
max gradient is 8.000000, min gradient is -3.580199, learning rate is 0.000864
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.737360, learning rate is 0.000432
max inferred z is 4.03, min inferred z is -4.13, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 11: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.625347, learning rate is 0.059773
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.930781, learning rate is 0.059773
Net1: layer conv1:max response is , min response is .
max gradient is 6.011954, min gradient is -8.000000, learning rate is 0.059773
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.861123, learning rate is 0.000864
Net2: layer deconv3:max response is 13.852082, min response is -19.904480.
max gradient is 8.000000, min gradient is -7.800685, learning rate is 0.000432
Net2: layer bn50:max response is 17.465267, min response is -3.027812.
max gradient is 6.136672, min gradient is -8.000000, learning rate is 0.000864
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.655626, learning rate is 0.000432
Net2: layer bn49:max response is 7.819144, min response is -1.481377.
max gradient is 8.000000, min gradient is -3.302918, learning rate is 0.000864
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.301968, learning rate is 0.000432
max inferred z is 3.72, min inferred z is -4.23, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 11: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.510244, learning rate is 0.059773
Net1: layer conv2:max response is , min response is .
max gradient is 5.851253, min gradient is -8.000000, learning rate is 0.059773
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.896764, learning rate is 0.059773
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.523147, learning rate is 0.000864
Net2: layer deconv3:max response is 13.278769, min response is -18.774092.
max gradient is 8.000000, min gradient is -6.184808, learning rate is 0.000432
Net2: layer bn50:max response is 18.483278, min response is -3.146514.
max gradient is 4.363261, min gradient is -8.000000, learning rate is 0.000864
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.296726, learning rate is 0.000432
Net2: layer bn49:max response is 8.767288, min response is -1.360013.
max gradient is 8.000000, min gradient is -4.911793, learning rate is 0.000864
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.750648, learning rate is 0.000432
max inferred z is 4.07, min inferred z is -3.84, and std is 1.00
 4.22 s (23.7 data/s) [100/100]
training: epoch 11: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.499600, min gradient is -8.000000, learning rate is 0.059773
Net1: layer conv2:max response is , min response is .
max gradient is 5.516383, min gradient is -8.000000, learning rate is 0.059773
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.575715, learning rate is 0.059773
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.333902, learning rate is 0.000864
Net2: layer deconv3:max response is 13.850876, min response is -18.738005.
max gradient is 8.000001, min gradient is -6.980992, learning rate is 0.000432
Net2: layer bn50:max response is 17.506651, min response is -2.843683.
max gradient is 2.509997, min gradient is -8.000000, learning rate is 0.000864
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.031073, learning rate is 0.000432
Net2: layer bn49:max response is 6.812805, min response is -1.410145.
max gradient is 8.000000, min gradient is -6.720019, learning rate is 0.000864
Net2: layer deconv1:max response is , min response is .
max gradient is 7.595431, min gradient is -8.000001, learning rate is 0.000432
max inferred z is 4.77, min inferred z is -3.75, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 11: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.828278, learning rate is 0.059773
Net1: layer conv2:max response is , min response is .
max gradient is 5.298676, min gradient is -8.000000, learning rate is 0.059773
Net1: layer conv1:max response is , min response is .
max gradient is 5.011109, min gradient is -8.000000, learning rate is 0.059773
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.302615, learning rate is 0.000864
Net2: layer deconv3:max response is 10.962871, min response is -16.942028.
max gradient is 8.000000, min gradient is -7.683104, learning rate is 0.000432
Net2: layer bn50:max response is 17.080910, min response is -2.703045.
max gradient is 1.932346, min gradient is -8.000000, learning rate is 0.000864
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.300013, learning rate is 0.000432
Net2: layer bn49:max response is 6.966657, min response is -1.368138.
max gradient is 8.000000, min gradient is -6.627874, learning rate is 0.000864
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.633141, learning rate is 0.000432
max inferred z is 3.94, min inferred z is -4.04, and std is 1.00
 4.18 s (23.9 data/s) [100/100]
training: epoch 11: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.694430, learning rate is 0.059773
Net1: layer conv2:max response is , min response is .
max gradient is 4.225119, min gradient is -8.000000, learning rate is 0.059773
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.065538, learning rate is 0.059773
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.900308, learning rate is 0.000864
Net2: layer deconv3:max response is 10.879141, min response is -18.991585.
max gradient is 6.938894, min gradient is -8.000000, learning rate is 0.000432
Net2: layer bn50:max response is 15.787835, min response is -2.307654.
max gradient is 2.722096, min gradient is -8.000000, learning rate is 0.000864
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.540341, learning rate is 0.000432
Net2: layer bn49:max response is 7.100137, min response is -1.464489.
max gradient is 4.755937, min gradient is -8.000000, learning rate is 0.000864
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.274305, learning rate is 0.000432
max inferred z is 4.29, min inferred z is -3.66, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
training: epoch 11: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.121945, learning rate is 0.059773
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.385856, learning rate is 0.059773
Net1: layer conv1:max response is , min response is .
max gradient is 4.326710, min gradient is -8.000000, learning rate is 0.059773
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.561829, learning rate is 0.000864
Net2: layer deconv3:max response is 11.055080, min response is -20.564735.
max gradient is 5.117481, min gradient is -8.000000, learning rate is 0.000432
Net2: layer bn50:max response is 17.877234, min response is -2.610025.
max gradient is 1.806544, min gradient is -8.000000, learning rate is 0.000864
Net2: layer deconv2:max response is , min response is .
max gradient is 6.069814, min gradient is -8.000000, learning rate is 0.000432
Net2: layer bn49:max response is 7.048831, min response is -1.399422.
max gradient is 6.090549, min gradient is -8.000000, learning rate is 0.000864
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.008351, learning rate is 0.000432
max inferred z is 4.03, min inferred z is -4.03, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 11: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.506644, learning rate is 0.059773
Net1: layer conv2:max response is , min response is .
max gradient is 7.124420, min gradient is -8.000000, learning rate is 0.059773
Net1: layer conv1:max response is , min response is .
max gradient is 2.963136, min gradient is -8.000000, learning rate is 0.059773
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.555969, learning rate is 0.000864
Net2: layer deconv3:max response is 11.187898, min response is -19.837057.
max gradient is 4.645136, min gradient is -8.000001, learning rate is 0.000432
Net2: layer bn50:max response is 17.029928, min response is -2.691797.
max gradient is 2.301493, min gradient is -8.000000, learning rate is 0.000864
Net2: layer deconv2:max response is , min response is .
max gradient is 4.973707, min gradient is -8.000000, learning rate is 0.000432
Net2: layer bn49:max response is 7.583701, min response is -1.514794.
max gradient is 6.282500, min gradient is -8.000001, learning rate is 0.000864
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.846226, learning rate is 0.000432
max inferred z is 3.94, min inferred z is -3.91, and std is 1.00
 4.51 s (22.2 data/s) [100/100]
Loss: 2.925
Iteration 12 / 200
training: epoch 12: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.015310, learning rate is 0.059773
Net1: layer conv2:max response is , min response is .
max gradient is 3.258868, min gradient is -8.000000, learning rate is 0.059773
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.210177, learning rate is 0.059773
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.520750, min gradient is -8.000000, learning rate is 0.000864
Net2: layer deconv3:max response is 11.505381, min response is -19.447453.
max gradient is 4.667214, min gradient is -8.000000, learning rate is 0.000432
Net2: layer bn50:max response is 19.183437, min response is -2.953746.
max gradient is 8.000000, min gradient is -7.635351, learning rate is 0.000864
Net2: layer deconv2:max response is , min response is .
max gradient is 4.917168, min gradient is -8.000000, learning rate is 0.000432
Net2: layer bn49:max response is 7.510076, min response is -1.510604.
max gradient is 2.902589, min gradient is -8.000000, learning rate is 0.000864
Net2: layer deconv1:max response is , min response is .
max gradient is 6.703802, min gradient is -8.000000, learning rate is 0.000432
max inferred z is 3.78, min inferred z is -4.08, and std is 0.99
 4.14 s (24.1 data/s) [100/100]
training: epoch 12: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.028483, learning rate is 0.059773
Net1: layer conv2:max response is , min response is .
max gradient is 5.048223, min gradient is -8.000000, learning rate is 0.059773
Net1: layer conv1:max response is , min response is .
max gradient is 5.117224, min gradient is -8.000000, learning rate is 0.059773
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -5.802886, learning rate is 0.000864
Net2: layer deconv3:max response is 13.923941, min response is -26.439270.
max gradient is 4.137331, min gradient is -8.000000, learning rate is 0.000432
Net2: layer bn50:max response is 24.381254, min response is -3.703565.
max gradient is 8.000000, min gradient is -7.363533, learning rate is 0.000864
Net2: layer deconv2:max response is , min response is .
max gradient is 4.411692, min gradient is -8.000000, learning rate is 0.000432
Net2: layer bn49:max response is 7.594000, min response is -1.424689.
max gradient is 3.798102, min gradient is -8.000000, learning rate is 0.000864
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.716885, learning rate is 0.000432
max inferred z is 3.96, min inferred z is -3.88, and std is 0.99
 4.27 s (23.4 data/s) [100/100]
training: epoch 12: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.491118, min gradient is -8.000000, learning rate is 0.059773
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.258529, learning rate is 0.059773
Net1: layer conv1:max response is , min response is .
max gradient is 3.148925, min gradient is -8.000000, learning rate is 0.059773
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.618351, learning rate is 0.000864
Net2: layer deconv3:max response is 11.884100, min response is -23.752926.
max gradient is 4.080456, min gradient is -8.000000, learning rate is 0.000432
Net2: layer bn50:max response is 20.519709, min response is -3.170977.
max gradient is 5.784560, min gradient is -8.000000, learning rate is 0.000864
Net2: layer deconv2:max response is , min response is .
max gradient is 4.408225, min gradient is -8.000000, learning rate is 0.000432
Net2: layer bn49:max response is 8.819852, min response is -1.808846.
max gradient is 4.045064, min gradient is -8.000000, learning rate is 0.000864
Net2: layer deconv1:max response is , min response is .
max gradient is 5.733738, min gradient is -8.000000, learning rate is 0.000432
max inferred z is 3.69, min inferred z is -3.93, and std is 0.99
 4.33 s (23.1 data/s) [100/100]
training: epoch 12: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.527923, min gradient is -8.000000, learning rate is 0.059773
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.705506, learning rate is 0.059773
Net1: layer conv1:max response is , min response is .
max gradient is 3.462963, min gradient is -8.000000, learning rate is 0.059773
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.837105, learning rate is 0.000864
Net2: layer deconv3:max response is 11.938866, min response is -26.398045.
max gradient is 3.899172, min gradient is -8.000000, learning rate is 0.000432
Net2: layer bn50:max response is 20.298944, min response is -3.438237.
max gradient is 8.000000, min gradient is -6.635270, learning rate is 0.000864
Net2: layer deconv2:max response is , min response is .
max gradient is 4.613487, min gradient is -8.000000, learning rate is 0.000432
Net2: layer bn49:max response is 7.471555, min response is -1.471028.
max gradient is 3.522924, min gradient is -8.000000, learning rate is 0.000864
Net2: layer deconv1:max response is , min response is .
max gradient is 6.631594, min gradient is -8.000000, learning rate is 0.000432
max inferred z is 4.32, min inferred z is -4.00, and std is 0.99
 4.34 s (23.0 data/s) [100/100]
training: epoch 12: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.393899, learning rate is 0.059773
Net1: layer conv2:max response is , min response is .
max gradient is 3.347676, min gradient is -8.000000, learning rate is 0.059773
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.290761, learning rate is 0.059773
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.523649, learning rate is 0.000864
Net2: layer deconv3:max response is 11.444963, min response is -22.163391.
max gradient is 4.339370, min gradient is -8.000000, learning rate is 0.000432
Net2: layer bn50:max response is 18.389053, min response is -2.917626.
max gradient is 8.000000, min gradient is -3.909189, learning rate is 0.000864
Net2: layer deconv2:max response is , min response is .
max gradient is 5.630517, min gradient is -8.000000, learning rate is 0.000432
Net2: layer bn49:max response is 7.298589, min response is -1.500534.
max gradient is 6.205579, min gradient is -8.000000, learning rate is 0.000864
Net2: layer deconv1:max response is , min response is .
max gradient is 6.090880, min gradient is -8.000000, learning rate is 0.000432
max inferred z is 3.98, min inferred z is -3.70, and std is 0.99
 4.33 s (23.1 data/s) [100/100]
training: epoch 12: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.555553, min gradient is -8.000000, learning rate is 0.059773
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.000317, learning rate is 0.059773
Net1: layer conv1:max response is , min response is .
max gradient is 5.770080, min gradient is -8.000000, learning rate is 0.059773
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000001, min gradient is 7.472105, learning rate is 0.000864
Net2: layer deconv3:max response is 9.891982, min response is -20.794334.
max gradient is 4.497674, min gradient is -8.000000, learning rate is 0.000432
Net2: layer bn50:max response is 16.799341, min response is -2.672282.
max gradient is 8.000000, min gradient is -3.184147, learning rate is 0.000864
Net2: layer deconv2:max response is , min response is .
max gradient is 5.943561, min gradient is -8.000000, learning rate is 0.000432
Net2: layer bn49:max response is 6.940096, min response is -1.341496.
max gradient is 8.000000, min gradient is -7.464269, learning rate is 0.000864
Net2: layer deconv1:max response is , min response is .
max gradient is 6.343190, min gradient is -8.000000, learning rate is 0.000432
max inferred z is 3.75, min inferred z is -3.79, and std is 0.99
 4.32 s (23.1 data/s) [100/100]
training: epoch 12: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.028029, min gradient is -8.000000, learning rate is 0.059773
Net1: layer conv2:max response is , min response is .
max gradient is 6.516185, min gradient is -8.000000, learning rate is 0.059773
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.489902, learning rate is 0.059773
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.362931, learning rate is 0.000864
Net2: layer deconv3:max response is 10.830997, min response is -23.080173.
max gradient is 6.358949, min gradient is -8.000000, learning rate is 0.000432
Net2: layer bn50:max response is 16.682755, min response is -3.004712.
max gradient is 8.000000, min gradient is -2.087184, learning rate is 0.000864
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.554850, learning rate is 0.000432
Net2: layer bn49:max response is 7.943190, min response is -1.419329.
max gradient is 8.000000, min gradient is -7.669977, learning rate is 0.000864
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.323160, learning rate is 0.000432
max inferred z is 5.16, min inferred z is -4.43, and std is 0.99
 4.32 s (23.2 data/s) [100/100]
training: epoch 12: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.442552, min gradient is -8.000000, learning rate is 0.059773
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.814826, learning rate is 0.059773
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.080778, learning rate is 0.059773
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.349038, learning rate is 0.000864
Net2: layer deconv3:max response is 11.270769, min response is -22.305954.
max gradient is 6.990957, min gradient is -8.000000, learning rate is 0.000432
Net2: layer bn50:max response is 17.685738, min response is -3.127385.
max gradient is 8.000000, min gradient is -2.910405, learning rate is 0.000864
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.860403, learning rate is 0.000432
Net2: layer bn49:max response is 8.172568, min response is -1.579984.
max gradient is 7.959141, min gradient is -8.000000, learning rate is 0.000864
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.279734, learning rate is 0.000432
max inferred z is 4.05, min inferred z is -4.23, and std is 0.99
 4.21 s (23.8 data/s) [100/100]
training: epoch 12: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.281522, min gradient is -8.000000, learning rate is 0.059773
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.420158, learning rate is 0.059773
Net1: layer conv1:max response is , min response is .
max gradient is 7.413120, min gradient is -8.000000, learning rate is 0.059773
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.588667, learning rate is 0.000864
Net2: layer deconv3:max response is 11.864082, min response is -27.241121.
max gradient is 7.678630, min gradient is -8.000000, learning rate is 0.000432
Net2: layer bn50:max response is 21.848080, min response is -4.027540.
max gradient is 7.232667, min gradient is -8.000000, learning rate is 0.000864
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.947311, learning rate is 0.000432
Net2: layer bn49:max response is 8.329587, min response is -1.605624.
max gradient is 7.931817, min gradient is -8.000000, learning rate is 0.000864
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.435256, learning rate is 0.000432
max inferred z is 3.92, min inferred z is -4.05, and std is 0.99
 4.46 s (22.4 data/s) [100/100]
training: epoch 12: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.243301, min gradient is -8.000000, learning rate is 0.059773
Net1: layer conv2:max response is , min response is .
max gradient is 7.944336, min gradient is -8.000000, learning rate is 0.059773
Net1: layer conv1:max response is , min response is .
max gradient is 7.390812, min gradient is -8.000000, learning rate is 0.059773
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.512473, learning rate is 0.000864
Net2: layer deconv3:max response is 11.127645, min response is -27.263819.
max gradient is 8.000000, min gradient is -7.651500, learning rate is 0.000432
Net2: layer bn50:max response is 21.837294, min response is -3.415198.
max gradient is 6.280173, min gradient is -8.000000, learning rate is 0.000864
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.145414, learning rate is 0.000432
Net2: layer bn49:max response is 7.710268, min response is -1.566853.
max gradient is 6.998171, min gradient is -8.000000, learning rate is 0.000864
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.464262, learning rate is 0.000432
max inferred z is 4.36, min inferred z is -4.19, and std is 0.99
 4.34 s (23.1 data/s) [100/100]
Loss: 2.8229
Iteration 13 / 200
training: epoch 13: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.008136, min gradient is -8.000000, learning rate is 0.056389
Net1: layer conv2:max response is , min response is .
max gradient is 2.916452, min gradient is -8.000001, learning rate is 0.056389
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.228645, learning rate is 0.056389
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.771171, learning rate is 0.000840
Net2: layer deconv3:max response is 12.496694, min response is -25.156553.
max gradient is 8.000000, min gradient is -7.531283, learning rate is 0.000420
Net2: layer bn50:max response is 17.313171, min response is -3.025743.
max gradient is 8.000000, min gradient is -4.063330, learning rate is 0.000840
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.820484, learning rate is 0.000420
Net2: layer bn49:max response is 7.856326, min response is -1.495485.
max gradient is 6.956650, min gradient is -8.000000, learning rate is 0.000840
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.224614, learning rate is 0.000420
max inferred z is 4.10, min inferred z is -3.91, and std is 0.99
 4.19 s (23.9 data/s) [100/100]
training: epoch 13: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.818645, min gradient is -8.000001, learning rate is 0.056389
Net1: layer conv2:max response is , min response is .
max gradient is 3.421073, min gradient is -8.000000, learning rate is 0.056389
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.523756, learning rate is 0.056389
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.441642, min gradient is -8.000000, learning rate is 0.000840
Net2: layer deconv3:max response is 11.264936, min response is -24.677624.
max gradient is 7.883904, min gradient is -8.000000, learning rate is 0.000420
Net2: layer bn50:max response is 21.119162, min response is -3.349421.
max gradient is 8.000000, min gradient is -5.872073, learning rate is 0.000840
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.613523, learning rate is 0.000420
Net2: layer bn49:max response is 7.114931, min response is -1.611050.
max gradient is 7.222333, min gradient is -8.000000, learning rate is 0.000840
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.288206, learning rate is 0.000420
max inferred z is 3.82, min inferred z is -4.51, and std is 0.99
 4.36 s (23.0 data/s) [100/100]
training: epoch 13: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.146971, min gradient is -8.000000, learning rate is 0.056389
Net1: layer conv2:max response is , min response is .
max gradient is 7.457032, min gradient is -8.000000, learning rate is 0.056389
Net1: layer conv1:max response is , min response is .
max gradient is 3.997642, min gradient is -8.000000, learning rate is 0.056389
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.170744, min gradient is -8.000000, learning rate is 0.000840
Net2: layer deconv3:max response is 10.110115, min response is -20.975079.
max gradient is 6.511651, min gradient is -8.000000, learning rate is 0.000420
Net2: layer bn50:max response is 18.656126, min response is -3.376797.
max gradient is 8.000000, min gradient is -7.568107, learning rate is 0.000840
Net2: layer deconv2:max response is , min response is .
max gradient is 4.294733, min gradient is -8.000000, learning rate is 0.000420
Net2: layer bn49:max response is 8.116101, min response is -1.774390.
max gradient is 8.000000, min gradient is -6.177326, learning rate is 0.000840
Net2: layer deconv1:max response is , min response is .
max gradient is 4.225298, min gradient is -8.000000, learning rate is 0.000420
max inferred z is 4.60, min inferred z is -4.47, and std is 0.99
 4.28 s (23.3 data/s) [100/100]
training: epoch 13: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.130544, learning rate is 0.056389
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -3.900572, learning rate is 0.056389
Net1: layer conv1:max response is , min response is .
max gradient is 5.303488, min gradient is -8.000000, learning rate is 0.056389
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.898638, min gradient is -8.000000, learning rate is 0.000840
Net2: layer deconv3:max response is 11.501932, min response is -19.538248.
max gradient is 6.674197, min gradient is -8.000000, learning rate is 0.000420
Net2: layer bn50:max response is 17.948299, min response is -3.232080.
max gradient is 7.322022, min gradient is -8.000000, learning rate is 0.000840
Net2: layer deconv2:max response is , min response is .
max gradient is 3.164055, min gradient is -8.000000, learning rate is 0.000420
Net2: layer bn49:max response is 8.597335, min response is -1.649466.
max gradient is 7.378978, min gradient is -8.000000, learning rate is 0.000840
Net2: layer deconv1:max response is , min response is .
max gradient is 5.856776, min gradient is -8.000000, learning rate is 0.000420
max inferred z is 3.91, min inferred z is -3.91, and std is 0.99
 4.33 s (23.1 data/s) [100/100]
training: epoch 13: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.222885, learning rate is 0.056389
Net1: layer conv2:max response is , min response is .
max gradient is 6.440012, min gradient is -8.000000, learning rate is 0.056389
Net1: layer conv1:max response is , min response is .
max gradient is 7.037547, min gradient is -8.000000, learning rate is 0.056389
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.619502, min gradient is -8.000000, learning rate is 0.000840
Net2: layer deconv3:max response is 11.869111, min response is -21.556540.
max gradient is 7.477309, min gradient is -8.000000, learning rate is 0.000420
Net2: layer bn50:max response is 17.930714, min response is -3.049234.
max gradient is 8.000000, min gradient is -4.396668, learning rate is 0.000840
Net2: layer deconv2:max response is , min response is .
max gradient is 3.478637, min gradient is -8.000000, learning rate is 0.000420
Net2: layer bn49:max response is 8.102229, min response is -1.622341.
max gradient is 4.938623, min gradient is -8.000000, learning rate is 0.000840
Net2: layer deconv1:max response is , min response is .
max gradient is 6.053938, min gradient is -8.000000, learning rate is 0.000420
max inferred z is 3.81, min inferred z is -4.16, and std is 0.99
 4.40 s (22.7 data/s) [100/100]
training: epoch 13: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.147922, min gradient is -8.000000, learning rate is 0.056389
Net1: layer conv2:max response is , min response is .
max gradient is 6.837946, min gradient is -8.000000, learning rate is 0.056389
Net1: layer conv1:max response is , min response is .
max gradient is 4.111868, min gradient is -8.000000, learning rate is 0.056389
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -0.017959, min gradient is -8.000000, learning rate is 0.000840
Net2: layer deconv3:max response is 11.018919, min response is -19.207458.
max gradient is 6.907472, min gradient is -8.000000, learning rate is 0.000420
Net2: layer bn50:max response is 16.680216, min response is -2.484206.
max gradient is 8.000000, min gradient is -4.561648, learning rate is 0.000840
Net2: layer deconv2:max response is , min response is .
max gradient is 5.030133, min gradient is -8.000000, learning rate is 0.000420
Net2: layer bn49:max response is 6.868175, min response is -1.447394.
max gradient is 4.249712, min gradient is -8.000000, learning rate is 0.000840
Net2: layer deconv1:max response is , min response is .
max gradient is 4.438905, min gradient is -8.000000, learning rate is 0.000420
max inferred z is 3.89, min inferred z is -4.35, and std is 0.99
 4.36 s (22.9 data/s) [100/100]
training: epoch 13: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.417214, min gradient is -8.000000, learning rate is 0.056389
Net1: layer conv2:max response is , min response is .
max gradient is 7.498627, min gradient is -8.000000, learning rate is 0.056389
Net1: layer conv1:max response is , min response is .
max gradient is 5.151023, min gradient is -8.000000, learning rate is 0.056389
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.400724, learning rate is 0.000840
Net2: layer deconv3:max response is 11.166597, min response is -23.546375.
max gradient is 8.000000, min gradient is -7.676292, learning rate is 0.000420
Net2: layer bn50:max response is 19.480652, min response is -3.039146.
max gradient is 8.000000, min gradient is -2.636806, learning rate is 0.000840
Net2: layer deconv2:max response is , min response is .
max gradient is 5.937710, min gradient is -8.000000, learning rate is 0.000420
Net2: layer bn49:max response is 7.422063, min response is -1.453380.
max gradient is 5.920634, min gradient is -8.000000, learning rate is 0.000840
Net2: layer deconv1:max response is , min response is .
max gradient is 5.183790, min gradient is -8.000000, learning rate is 0.000420
max inferred z is 4.16, min inferred z is -3.90, and std is 0.99
 4.16 s (24.0 data/s) [100/100]
training: epoch 13: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.063715, min gradient is -8.000000, learning rate is 0.056389
Net1: layer conv2:max response is , min response is .
max gradient is 7.592087, min gradient is -8.000000, learning rate is 0.056389
Net1: layer conv1:max response is , min response is .
max gradient is 3.553447, min gradient is -8.000000, learning rate is 0.056389
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.387566, learning rate is 0.000840
Net2: layer deconv3:max response is 10.905584, min response is -19.393118.
max gradient is 8.000000, min gradient is -6.577972, learning rate is 0.000420
Net2: layer bn50:max response is 17.017563, min response is -3.242053.
max gradient is 8.000000, min gradient is -2.581859, learning rate is 0.000840
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.250675, learning rate is 0.000420
Net2: layer bn49:max response is 6.663321, min response is -1.861892.
max gradient is 6.829382, min gradient is -8.000001, learning rate is 0.000840
Net2: layer deconv1:max response is , min response is .
max gradient is 5.847036, min gradient is -8.000000, learning rate is 0.000420
max inferred z is 3.75, min inferred z is -4.25, and std is 0.99
 4.34 s (23.0 data/s) [100/100]
training: epoch 13: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.254948, min gradient is -8.000000, learning rate is 0.056389
Net1: layer conv2:max response is , min response is .
max gradient is 7.984490, min gradient is -8.000000, learning rate is 0.056389
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.396276, learning rate is 0.056389
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.620725, learning rate is 0.000840
Net2: layer deconv3:max response is 12.253436, min response is -24.643068.
max gradient is 8.000000, min gradient is -7.174879, learning rate is 0.000420
Net2: layer bn50:max response is 19.117682, min response is -3.291069.
max gradient is 8.000000, min gradient is -3.084972, learning rate is 0.000840
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000001, min gradient is -4.812592, learning rate is 0.000420
Net2: layer bn49:max response is 7.061347, min response is -1.442447.
max gradient is 8.000000, min gradient is -3.780075, learning rate is 0.000840
Net2: layer deconv1:max response is , min response is .
max gradient is 6.359509, min gradient is -8.000000, learning rate is 0.000420
max inferred z is 3.96, min inferred z is -3.97, and std is 0.99
 4.20 s (23.8 data/s) [100/100]
training: epoch 13: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.465523, min gradient is -8.000000, learning rate is 0.056389
Net1: layer conv2:max response is , min response is .
max gradient is 5.011620, min gradient is -8.000000, learning rate is 0.056389
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.515380, learning rate is 0.056389
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000001, min gradient is 7.585818, learning rate is 0.000840
Net2: layer deconv3:max response is 10.501211, min response is -23.500454.
max gradient is 8.000000, min gradient is -7.525956, learning rate is 0.000420
Net2: layer bn50:max response is 17.988819, min response is -2.875063.
max gradient is 8.000000, min gradient is -3.074365, learning rate is 0.000840
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.277937, learning rate is 0.000420
Net2: layer bn49:max response is 7.606869, min response is -1.519795.
max gradient is 8.000000, min gradient is -3.653712, learning rate is 0.000840
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.301906, learning rate is 0.000420
max inferred z is 4.02, min inferred z is -3.93, and std is 0.99
 4.19 s (23.9 data/s) [100/100]
Loss: 2.3743
Iteration 14 / 200
training: epoch 14: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.010423, min gradient is -8.000000, learning rate is 0.056389
Net1: layer conv2:max response is , min response is .
max gradient is 3.621331, min gradient is -8.000000, learning rate is 0.056389
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.772180, learning rate is 0.056389
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.739047, learning rate is 0.000840
Net2: layer deconv3:max response is 10.724242, min response is -25.278349.
max gradient is 8.000000, min gradient is -6.512601, learning rate is 0.000420
Net2: layer bn50:max response is 17.751432, min response is -3.058694.
max gradient is 8.000000, min gradient is -2.716114, learning rate is 0.000840
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.934899, learning rate is 0.000420
Net2: layer bn49:max response is 6.946220, min response is -1.487097.
max gradient is 8.000000, min gradient is -3.411614, learning rate is 0.000840
Net2: layer deconv1:max response is , min response is .
max gradient is 7.883508, min gradient is -8.000000, learning rate is 0.000420
max inferred z is 4.14, min inferred z is -3.94, and std is 1.00
 4.40 s (22.8 data/s) [100/100]
training: epoch 14: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.161716, learning rate is 0.056389
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.809003, learning rate is 0.056389
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.001183, learning rate is 0.056389
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.175023, min gradient is -8.000000, learning rate is 0.000840
Net2: layer deconv3:max response is 11.250395, min response is -23.269375.
max gradient is 8.000000, min gradient is -4.690232, learning rate is 0.000420
Net2: layer bn50:max response is 16.815643, min response is -2.750024.
max gradient is 8.000000, min gradient is -2.664328, learning rate is 0.000840
Net2: layer deconv2:max response is , min response is .
max gradient is 6.085454, min gradient is -8.000000, learning rate is 0.000420
Net2: layer bn49:max response is 8.090204, min response is -1.464680.
max gradient is 8.000000, min gradient is -3.754895, learning rate is 0.000840
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.241083, learning rate is 0.000420
max inferred z is 3.97, min inferred z is -4.35, and std is 1.00
 4.34 s (23.1 data/s) [100/100]
training: epoch 14: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.448174, learning rate is 0.056389
Net1: layer conv2:max response is , min response is .
max gradient is 7.248917, min gradient is -8.000000, learning rate is 0.056389
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.723281, learning rate is 0.056389
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.562586, learning rate is 0.000840
Net2: layer deconv3:max response is 10.716807, min response is -26.028774.
max gradient is 8.000000, min gradient is -5.314588, learning rate is 0.000420
Net2: layer bn50:max response is 14.816488, min response is -2.714444.
max gradient is 8.000000, min gradient is -5.982310, learning rate is 0.000840
Net2: layer deconv2:max response is , min response is .
max gradient is 3.447413, min gradient is -8.000000, learning rate is 0.000420
Net2: layer bn49:max response is 7.406772, min response is -1.505993.
max gradient is 6.710198, min gradient is -8.000000, learning rate is 0.000840
Net2: layer deconv1:max response is , min response is .
max gradient is 6.917934, min gradient is -8.000000, learning rate is 0.000420
max inferred z is 3.79, min inferred z is -4.47, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 14: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.525343, learning rate is 0.056389
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.297159, learning rate is 0.056389
Net1: layer conv1:max response is , min response is .
max gradient is 5.304180, min gradient is -8.000000, learning rate is 0.056389
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.605483, min gradient is -8.000000, learning rate is 0.000840
Net2: layer deconv3:max response is 10.143047, min response is -24.110952.
max gradient is 8.000000, min gradient is -5.795132, learning rate is 0.000420
Net2: layer bn50:max response is 17.609293, min response is -2.847812.
max gradient is 8.000000, min gradient is -2.614676, learning rate is 0.000840
Net2: layer deconv2:max response is , min response is .
max gradient is 2.714443, min gradient is -8.000000, learning rate is 0.000420
Net2: layer bn49:max response is 6.975814, min response is -1.508718.
max gradient is 6.476348, min gradient is -8.000000, learning rate is 0.000840
Net2: layer deconv1:max response is , min response is .
max gradient is 6.299721, min gradient is -8.000000, learning rate is 0.000420
max inferred z is 4.15, min inferred z is -4.36, and std is 1.00
 4.32 s (23.2 data/s) [100/100]
training: epoch 14: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.223409, learning rate is 0.056389
Net1: layer conv2:max response is , min response is .
max gradient is 6.154728, min gradient is -8.000000, learning rate is 0.056389
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.496982, learning rate is 0.056389
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.791334, min gradient is -8.000001, learning rate is 0.000840
Net2: layer deconv3:max response is 12.348907, min response is -26.497519.
max gradient is 8.000000, min gradient is -5.567029, learning rate is 0.000420
Net2: layer bn50:max response is 15.266613, min response is -2.857365.
max gradient is 8.000000, min gradient is -2.251426, learning rate is 0.000840
Net2: layer deconv2:max response is , min response is .
max gradient is 3.364360, min gradient is -8.000000, learning rate is 0.000420
Net2: layer bn49:max response is 7.209142, min response is -1.629718.
max gradient is 4.827631, min gradient is -8.000000, learning rate is 0.000840
Net2: layer deconv1:max response is , min response is .
max gradient is 7.788602, min gradient is -8.000000, learning rate is 0.000420
max inferred z is 4.52, min inferred z is -3.86, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 14: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.986768, min gradient is -8.000000, learning rate is 0.056389
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.933895, learning rate is 0.056389
Net1: layer conv1:max response is , min response is .
max gradient is 5.756460, min gradient is -8.000000, learning rate is 0.056389
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.632769, learning rate is 0.000840
Net2: layer deconv3:max response is 11.708824, min response is -26.342159.
max gradient is 8.000000, min gradient is -6.565845, learning rate is 0.000420
Net2: layer bn50:max response is 18.084679, min response is -3.253909.
max gradient is 8.000000, min gradient is -2.898466, learning rate is 0.000840
Net2: layer deconv2:max response is , min response is .
max gradient is 3.882643, min gradient is -8.000000, learning rate is 0.000420
Net2: layer bn49:max response is 10.447137, min response is -1.588784.
max gradient is 5.151484, min gradient is -8.000000, learning rate is 0.000840
Net2: layer deconv1:max response is , min response is .
max gradient is 6.207593, min gradient is -8.000000, learning rate is 0.000420
max inferred z is 4.37, min inferred z is -3.64, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 14: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.496984, min gradient is -8.000000, learning rate is 0.056389
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.738224, learning rate is 0.056389
Net1: layer conv1:max response is , min response is .
max gradient is 6.644286, min gradient is -8.000000, learning rate is 0.056389
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.624187, learning rate is 0.000840
Net2: layer deconv3:max response is 12.312708, min response is -24.748360.
max gradient is 8.000000, min gradient is -7.988629, learning rate is 0.000420
Net2: layer bn50:max response is 17.014925, min response is -2.918138.
max gradient is 8.000000, min gradient is -1.795185, learning rate is 0.000840
Net2: layer deconv2:max response is , min response is .
max gradient is 3.876175, min gradient is -8.000000, learning rate is 0.000420
Net2: layer bn49:max response is 7.926231, min response is -1.610220.
max gradient is 5.072957, min gradient is -8.000000, learning rate is 0.000840
Net2: layer deconv1:max response is , min response is .
max gradient is 7.048407, min gradient is -8.000000, learning rate is 0.000420
max inferred z is 3.92, min inferred z is -3.58, and std is 1.00
 4.51 s (22.2 data/s) [100/100]
training: epoch 14: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.693501, min gradient is -8.000000, learning rate is 0.056389
Net1: layer conv2:max response is , min response is .
max gradient is 5.942065, min gradient is -8.000000, learning rate is 0.056389
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.754740, learning rate is 0.056389
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.427611, min gradient is -8.000000, learning rate is 0.000840
Net2: layer deconv3:max response is 10.334196, min response is -31.614183.
max gradient is 7.209788, min gradient is -8.000000, learning rate is 0.000420
Net2: layer bn50:max response is 20.527800, min response is -3.418092.
max gradient is 8.000000, min gradient is -1.071307, learning rate is 0.000840
Net2: layer deconv2:max response is , min response is .
max gradient is 4.777972, min gradient is -8.000000, learning rate is 0.000420
Net2: layer bn49:max response is 7.436454, min response is -1.480123.
max gradient is 5.433568, min gradient is -8.000000, learning rate is 0.000840
Net2: layer deconv1:max response is , min response is .
max gradient is 6.624680, min gradient is -8.000000, learning rate is 0.000420
max inferred z is 4.27, min inferred z is -4.18, and std is 1.00
 4.41 s (22.7 data/s) [100/100]
training: epoch 14: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.915218, min gradient is -8.000000, learning rate is 0.056389
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.648237, learning rate is 0.056389
Net1: layer conv1:max response is , min response is .
max gradient is 7.391072, min gradient is -8.000000, learning rate is 0.056389
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.677009, learning rate is 0.000840
Net2: layer deconv3:max response is 11.179520, min response is -26.604668.
max gradient is 6.761658, min gradient is -8.000000, learning rate is 0.000420
Net2: layer bn50:max response is 15.356208, min response is -2.711951.
max gradient is 8.000000, min gradient is -1.828300, learning rate is 0.000840
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.352841, learning rate is 0.000420
Net2: layer bn49:max response is 7.744830, min response is -1.656368.
max gradient is 8.000000, min gradient is -4.063994, learning rate is 0.000840
Net2: layer deconv1:max response is , min response is .
max gradient is 6.755971, min gradient is -8.000000, learning rate is 0.000420
max inferred z is 3.92, min inferred z is -3.64, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 14: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.478575, learning rate is 0.056389
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.466999, learning rate is 0.056389
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.230321, learning rate is 0.056389
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.627806, learning rate is 0.000840
Net2: layer deconv3:max response is 9.877134, min response is -28.909145.
max gradient is 7.410784, min gradient is -8.000000, learning rate is 0.000420
Net2: layer bn50:max response is 15.518591, min response is -2.567212.
max gradient is 8.000000, min gradient is -2.137642, learning rate is 0.000840
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.091262, learning rate is 0.000420
Net2: layer bn49:max response is 7.306855, min response is -1.620767.
max gradient is 8.000000, min gradient is -2.630448, learning rate is 0.000840
Net2: layer deconv1:max response is , min response is .
max gradient is 7.148278, min gradient is -8.000000, learning rate is 0.000420
max inferred z is 4.29, min inferred z is -3.77, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
Loss: 2.5666
Iteration 15 / 200
training: epoch 15: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.743121, learning rate is 0.053195
Net1: layer conv2:max response is , min response is .
max gradient is 3.510366, min gradient is -8.000000, learning rate is 0.053195
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.882981, learning rate is 0.053195
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.989069, min gradient is -8.000000, learning rate is 0.000815
Net2: layer deconv3:max response is 12.952313, min response is -31.761789.
max gradient is 8.000000, min gradient is -6.438010, learning rate is 0.000408
Net2: layer bn50:max response is 17.497517, min response is -3.150274.
max gradient is 8.000000, min gradient is -1.322113, learning rate is 0.000815
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.089540, learning rate is 0.000408
Net2: layer bn49:max response is 9.804308, min response is -1.760353.
max gradient is 8.000000, min gradient is -4.604227, learning rate is 0.000815
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.642178, learning rate is 0.000408
max inferred z is 4.10, min inferred z is -3.91, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 15: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.545240, learning rate is 0.053195
Net1: layer conv2:max response is , min response is .
max gradient is 4.998811, min gradient is -8.000000, learning rate is 0.053195
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.358109, learning rate is 0.053195
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.886716, min gradient is -8.000000, learning rate is 0.000815
Net2: layer deconv3:max response is 10.829845, min response is -31.557619.
max gradient is 8.000000, min gradient is -4.710349, learning rate is 0.000408
Net2: layer bn50:max response is 18.271017, min response is -3.059191.
max gradient is 8.000000, min gradient is -2.429729, learning rate is 0.000815
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.594920, learning rate is 0.000408
Net2: layer bn49:max response is 8.765087, min response is -1.798158.
max gradient is 8.000000, min gradient is -3.996031, learning rate is 0.000815
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.361139, learning rate is 0.000408
max inferred z is 3.64, min inferred z is -3.88, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
training: epoch 15: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.550046, min gradient is -8.000000, learning rate is 0.053195
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -3.749380, learning rate is 0.053195
Net1: layer conv1:max response is , min response is .
max gradient is 5.627205, min gradient is -8.000000, learning rate is 0.053195
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.664475, learning rate is 0.000815
Net2: layer deconv3:max response is 9.867916, min response is -31.198315.
max gradient is 6.054076, min gradient is -8.000000, learning rate is 0.000408
Net2: layer bn50:max response is 16.984844, min response is -3.129058.
max gradient is 1.096143, min gradient is -8.000000, learning rate is 0.000815
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.121623, learning rate is 0.000408
Net2: layer bn49:max response is 7.771390, min response is -1.672429.
max gradient is 8.000000, min gradient is -3.759677, learning rate is 0.000815
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.453531, learning rate is 0.000408
max inferred z is 4.02, min inferred z is -3.73, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 15: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.461474, min gradient is -8.000000, learning rate is 0.053195
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.587198, learning rate is 0.053195
Net1: layer conv1:max response is , min response is .
max gradient is 4.708874, min gradient is -8.000000, learning rate is 0.053195
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.497534, learning rate is 0.000815
Net2: layer deconv3:max response is 10.037476, min response is -23.704615.
max gradient is 7.267410, min gradient is -8.000000, learning rate is 0.000408
Net2: layer bn50:max response is 16.848288, min response is -2.420702.
max gradient is 0.854628, min gradient is -8.000000, learning rate is 0.000815
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.960610, learning rate is 0.000408
Net2: layer bn49:max response is 7.292482, min response is -1.602898.
max gradient is 8.000000, min gradient is -5.139563, learning rate is 0.000815
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.436004, learning rate is 0.000408
max inferred z is 3.98, min inferred z is -3.50, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 15: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.942226, learning rate is 0.053195
Net1: layer conv2:max response is , min response is .
max gradient is 4.689409, min gradient is -8.000000, learning rate is 0.053195
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.956136, learning rate is 0.053195
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.653909, min gradient is -8.000000, learning rate is 0.000815
Net2: layer deconv3:max response is 11.288288, min response is -27.104868.
max gradient is 8.000000, min gradient is -5.047482, learning rate is 0.000408
Net2: layer bn50:max response is 15.466912, min response is -2.681566.
max gradient is 6.846991, min gradient is -8.000000, learning rate is 0.000815
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.087016, learning rate is 0.000408
Net2: layer bn49:max response is 9.023615, min response is -1.628729.
max gradient is 7.143993, min gradient is -8.000000, learning rate is 0.000815
Net2: layer deconv1:max response is , min response is .
max gradient is 7.483393, min gradient is -8.000000, learning rate is 0.000408
max inferred z is 3.96, min inferred z is -3.77, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 15: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.049740, learning rate is 0.053195
Net1: layer conv2:max response is , min response is .
max gradient is 7.013155, min gradient is -8.000000, learning rate is 0.053195
Net1: layer conv1:max response is , min response is .
max gradient is 5.348130, min gradient is -8.000000, learning rate is 0.053195
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.484330, min gradient is -8.000000, learning rate is 0.000815
Net2: layer deconv3:max response is 13.176023, min response is -25.525749.
max gradient is 8.000000, min gradient is -5.459639, learning rate is 0.000408
Net2: layer bn50:max response is 17.133003, min response is -2.883038.
max gradient is 2.737528, min gradient is -8.000000, learning rate is 0.000815
Net2: layer deconv2:max response is , min response is .
max gradient is 4.536494, min gradient is -8.000000, learning rate is 0.000408
Net2: layer bn49:max response is 7.546571, min response is -1.549860.
max gradient is 8.000000, min gradient is -7.302725, learning rate is 0.000815
Net2: layer deconv1:max response is , min response is .
max gradient is 7.776213, min gradient is -8.000000, learning rate is 0.000408
max inferred z is 3.66, min inferred z is -4.29, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 15: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.794565, learning rate is 0.053195
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.936185, learning rate is 0.053195
Net1: layer conv1:max response is , min response is .
max gradient is 4.962483, min gradient is -8.000000, learning rate is 0.053195
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.126838, min gradient is -8.000000, learning rate is 0.000815
Net2: layer deconv3:max response is 10.791319, min response is -23.518118.
max gradient is 6.924510, min gradient is -8.000000, learning rate is 0.000408
Net2: layer bn50:max response is 16.081324, min response is -3.081964.
max gradient is 6.907949, min gradient is -8.000000, learning rate is 0.000815
Net2: layer deconv2:max response is , min response is .
max gradient is 3.992984, min gradient is -8.000001, learning rate is 0.000408
Net2: layer bn49:max response is 7.243794, min response is -1.609271.
max gradient is 7.720493, min gradient is -8.000000, learning rate is 0.000815
Net2: layer deconv1:max response is , min response is .
max gradient is 5.465964, min gradient is -8.000000, learning rate is 0.000408
max inferred z is 4.42, min inferred z is -3.92, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 15: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.534636, learning rate is 0.053195
Net1: layer conv2:max response is , min response is .
max gradient is 5.892942, min gradient is -8.000000, learning rate is 0.053195
Net1: layer conv1:max response is , min response is .
max gradient is 4.704777, min gradient is -8.000000, learning rate is 0.053195
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 3.738041, min gradient is -8.000000, learning rate is 0.000815
Net2: layer deconv3:max response is 12.411901, min response is -29.722006.
max gradient is 6.618724, min gradient is -8.000000, learning rate is 0.000408
Net2: layer bn50:max response is 20.785612, min response is -3.585416.
max gradient is 8.000000, min gradient is -2.996670, learning rate is 0.000815
Net2: layer deconv2:max response is , min response is .
max gradient is 4.758563, min gradient is -8.000000, learning rate is 0.000408
Net2: layer bn49:max response is 9.037505, min response is -1.663235.
max gradient is 7.379981, min gradient is -8.000001, learning rate is 0.000815
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.394610, learning rate is 0.000408
max inferred z is 4.01, min inferred z is -3.53, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 15: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.021016, learning rate is 0.053195
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.700990, learning rate is 0.053195
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.542035, learning rate is 0.053195
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.788865, learning rate is 0.000815
Net2: layer deconv3:max response is 12.416696, min response is -26.652622.
max gradient is 4.545805, min gradient is -8.000000, learning rate is 0.000408
Net2: layer bn50:max response is 18.418854, min response is -3.255569.
max gradient is 8.000000, min gradient is -6.923636, learning rate is 0.000815
Net2: layer deconv2:max response is , min response is .
max gradient is 6.063545, min gradient is -8.000000, learning rate is 0.000408
Net2: layer bn49:max response is 8.393450, min response is -1.819876.
max gradient is 7.999999, min gradient is -7.018433, learning rate is 0.000815
Net2: layer deconv1:max response is , min response is .
max gradient is 7.528294, min gradient is -8.000000, learning rate is 0.000408
max inferred z is 3.89, min inferred z is -4.10, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 15: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.770093, learning rate is 0.053195
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.403015, learning rate is 0.053195
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.546557, learning rate is 0.053195
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.456357, learning rate is 0.000815
Net2: layer deconv3:max response is 11.309987, min response is -30.457508.
max gradient is 5.608292, min gradient is -8.000000, learning rate is 0.000408
Net2: layer bn50:max response is 16.174515, min response is -3.497054.
max gradient is 8.000000, min gradient is -2.615139, learning rate is 0.000815
Net2: layer deconv2:max response is , min response is .
max gradient is 6.819823, min gradient is -8.000000, learning rate is 0.000408
Net2: layer bn49:max response is 8.612123, min response is -1.504247.
max gradient is 7.123171, min gradient is -8.000000, learning rate is 0.000815
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.759816, learning rate is 0.000408
max inferred z is 3.58, min inferred z is -3.90, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
Loss: 2.5074
Iteration 16 / 200
training: epoch 16: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.870822, min gradient is -8.000000, learning rate is 0.053195
Net1: layer conv2:max response is , min response is .
max gradient is 4.283937, min gradient is -8.000000, learning rate is 0.053195
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.596729, learning rate is 0.053195
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -4.596675, min gradient is -8.000000, learning rate is 0.000815
Net2: layer deconv3:max response is 11.017893, min response is -25.551830.
max gradient is 6.856475, min gradient is -8.000000, learning rate is 0.000408
Net2: layer bn50:max response is 16.423859, min response is -2.970310.
max gradient is 8.000000, min gradient is -1.225676, learning rate is 0.000815
Net2: layer deconv2:max response is , min response is .
max gradient is 5.499608, min gradient is -8.000000, learning rate is 0.000408
Net2: layer bn49:max response is 7.530699, min response is -1.693588.
max gradient is 4.615329, min gradient is -8.000000, learning rate is 0.000815
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.060092, learning rate is 0.000408
max inferred z is 3.79, min inferred z is -4.43, and std is 1.00
 4.17 s (24.0 data/s) [100/100]
training: epoch 16: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.947853, learning rate is 0.053195
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.876702, learning rate is 0.053195
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.460168, learning rate is 0.053195
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.193110, learning rate is 0.000815
Net2: layer deconv3:max response is 11.328112, min response is -26.844833.
max gradient is 5.347389, min gradient is -8.000000, learning rate is 0.000408
Net2: layer bn50:max response is 17.402601, min response is -3.589714.
max gradient is 8.000000, min gradient is -3.184838, learning rate is 0.000815
Net2: layer deconv2:max response is , min response is .
max gradient is 3.975353, min gradient is -8.000000, learning rate is 0.000408
Net2: layer bn49:max response is 9.589620, min response is -1.575212.
max gradient is 4.054189, min gradient is -8.000000, learning rate is 0.000815
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.578783, learning rate is 0.000408
max inferred z is 3.93, min inferred z is -3.81, and std is 1.00
 4.21 s (23.7 data/s) [100/100]
training: epoch 16: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.636956, min gradient is -8.000000, learning rate is 0.053195
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.928492, learning rate is 0.053195
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.535963, learning rate is 0.053195
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.335005, learning rate is 0.000815
Net2: layer deconv3:max response is 10.881938, min response is -24.901031.
max gradient is 4.015310, min gradient is -8.000000, learning rate is 0.000408
Net2: layer bn50:max response is 15.912296, min response is -2.904087.
max gradient is 2.632932, min gradient is -8.000000, learning rate is 0.000815
Net2: layer deconv2:max response is , min response is .
max gradient is 5.083311, min gradient is -8.000000, learning rate is 0.000408
Net2: layer bn49:max response is 7.493512, min response is -1.791168.
max gradient is 8.000000, min gradient is -6.668812, learning rate is 0.000815
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.633892, learning rate is 0.000408
max inferred z is 4.26, min inferred z is -4.42, and std is 1.00
 4.18 s (23.9 data/s) [100/100]
training: epoch 16: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.898989, min gradient is -8.000000, learning rate is 0.053195
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -3.466072, learning rate is 0.053195
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.712033, learning rate is 0.053195
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.882955, learning rate is 0.000815
Net2: layer deconv3:max response is 12.231823, min response is -22.372040.
max gradient is 4.763384, min gradient is -8.000000, learning rate is 0.000408
Net2: layer bn50:max response is 16.643736, min response is -2.729225.
max gradient is 2.486980, min gradient is -8.000000, learning rate is 0.000815
Net2: layer deconv2:max response is , min response is .
max gradient is 5.929351, min gradient is -8.000000, learning rate is 0.000408
Net2: layer bn49:max response is 8.808610, min response is -1.701092.
max gradient is 8.000000, min gradient is -6.108734, learning rate is 0.000815
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.373053, learning rate is 0.000408
max inferred z is 3.95, min inferred z is -3.65, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 16: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.433620, min gradient is -8.000000, learning rate is 0.053195
Net1: layer conv2:max response is , min response is .
max gradient is 5.969539, min gradient is -8.000000, learning rate is 0.053195
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.683987, learning rate is 0.053195
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.001692, min gradient is -8.000000, learning rate is 0.000815
Net2: layer deconv3:max response is 13.297430, min response is -24.207781.
max gradient is 6.766242, min gradient is -8.000000, learning rate is 0.000408
Net2: layer bn50:max response is 19.376869, min response is -3.929514.
max gradient is 8.000000, min gradient is -2.650677, learning rate is 0.000815
Net2: layer deconv2:max response is , min response is .
max gradient is 7.285980, min gradient is -8.000000, learning rate is 0.000408
Net2: layer bn49:max response is 9.520644, min response is -1.545376.
max gradient is 5.095562, min gradient is -8.000000, learning rate is 0.000815
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.246750, learning rate is 0.000408
max inferred z is 3.96, min inferred z is -3.70, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
training: epoch 16: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.969503, min gradient is -8.000000, learning rate is 0.053195
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.191863, learning rate is 0.053195
Net1: layer conv1:max response is , min response is .
max gradient is 6.034873, min gradient is -8.000000, learning rate is 0.053195
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.402025, learning rate is 0.000815
Net2: layer deconv3:max response is 11.383670, min response is -23.915735.
max gradient is 4.392104, min gradient is -8.000000, learning rate is 0.000408
Net2: layer bn50:max response is 15.437037, min response is -3.298090.
max gradient is 1.197128, min gradient is -8.000000, learning rate is 0.000815
Net2: layer deconv2:max response is , min response is .
max gradient is 7.262593, min gradient is -8.000000, learning rate is 0.000408
Net2: layer bn49:max response is 8.707160, min response is -1.660501.
max gradient is 8.000000, min gradient is -7.906090, learning rate is 0.000815
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.680933, learning rate is 0.000408
max inferred z is 3.85, min inferred z is -3.80, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 16: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.609168, min gradient is -8.000000, learning rate is 0.053195
Net1: layer conv2:max response is , min response is .
max gradient is 4.090521, min gradient is -8.000000, learning rate is 0.053195
Net1: layer conv1:max response is , min response is .
max gradient is 6.947162, min gradient is -8.000000, learning rate is 0.053195
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.389596, min gradient is -8.000001, learning rate is 0.000815
Net2: layer deconv3:max response is 13.583048, min response is -22.713734.
max gradient is 5.462487, min gradient is -8.000000, learning rate is 0.000408
Net2: layer bn50:max response is 21.142214, min response is -3.140019.
max gradient is 8.000001, min gradient is -2.384591, learning rate is 0.000815
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.798153, learning rate is 0.000408
Net2: layer bn49:max response is 8.932182, min response is -1.693048.
max gradient is 5.688369, min gradient is -8.000000, learning rate is 0.000815
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.712277, learning rate is 0.000408
max inferred z is 3.66, min inferred z is -3.98, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 16: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.201170, min gradient is -8.000000, learning rate is 0.053195
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.157399, learning rate is 0.053195
Net1: layer conv1:max response is , min response is .
max gradient is 4.547515, min gradient is -8.000000, learning rate is 0.053195
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.070570, min gradient is -8.000000, learning rate is 0.000815
Net2: layer deconv3:max response is 11.223211, min response is -22.215429.
max gradient is 4.132473, min gradient is -8.000000, learning rate is 0.000408
Net2: layer bn50:max response is 16.402079, min response is -3.016526.
max gradient is 3.651761, min gradient is -8.000000, learning rate is 0.000815
Net2: layer deconv2:max response is , min response is .
max gradient is 7.860286, min gradient is -8.000000, learning rate is 0.000408
Net2: layer bn49:max response is 8.101307, min response is -1.794184.
max gradient is 8.000000, min gradient is -7.908441, learning rate is 0.000815
Net2: layer deconv1:max response is , min response is .
max gradient is 6.572871, min gradient is -8.000000, learning rate is 0.000408
max inferred z is 3.50, min inferred z is -4.18, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 16: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.624407, min gradient is -8.000000, learning rate is 0.053195
Net1: layer conv2:max response is , min response is .
max gradient is 6.575225, min gradient is -8.000000, learning rate is 0.053195
Net1: layer conv1:max response is , min response is .
max gradient is 6.647435, min gradient is -8.000000, learning rate is 0.053195
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.044034, learning rate is 0.000815
Net2: layer deconv3:max response is 11.307221, min response is -19.797464.
max gradient is 4.674525, min gradient is -8.000000, learning rate is 0.000408
Net2: layer bn50:max response is 14.800386, min response is -3.158025.
max gradient is 3.195882, min gradient is -8.000000, learning rate is 0.000815
Net2: layer deconv2:max response is , min response is .
max gradient is 6.702741, min gradient is -8.000000, learning rate is 0.000408
Net2: layer bn49:max response is 8.317290, min response is -1.733359.
max gradient is 8.000000, min gradient is -4.005285, learning rate is 0.000815
Net2: layer deconv1:max response is , min response is .
max gradient is 7.231127, min gradient is -8.000000, learning rate is 0.000408
max inferred z is 3.71, min inferred z is -4.09, and std is 1.00
 4.34 s (23.1 data/s) [100/100]
training: epoch 16: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.425509, min gradient is -8.000000, learning rate is 0.053195
Net1: layer conv2:max response is , min response is .
max gradient is 7.561051, min gradient is -8.000000, learning rate is 0.053195
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.674219, learning rate is 0.053195
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.874542, min gradient is -8.000000, learning rate is 0.000815
Net2: layer deconv3:max response is 12.512677, min response is -27.825100.
max gradient is 5.910314, min gradient is -8.000000, learning rate is 0.000408
Net2: layer bn50:max response is 17.504730, min response is -3.403018.
max gradient is 8.000000, min gradient is -3.467591, learning rate is 0.000815
Net2: layer deconv2:max response is , min response is .
max gradient is 4.657803, min gradient is -8.000000, learning rate is 0.000408
Net2: layer bn49:max response is 8.050198, min response is -1.979491.
max gradient is 8.000000, min gradient is -7.622976, learning rate is 0.000815
Net2: layer deconv1:max response is , min response is .
max gradient is 7.013591, min gradient is -8.000000, learning rate is 0.000408
max inferred z is 5.05, min inferred z is -4.24, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
Loss: 2.4562
Iteration 17 / 200
training: epoch 17: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.390180, learning rate is 0.050183
Net1: layer conv2:max response is , min response is .
max gradient is 3.992676, min gradient is -8.000000, learning rate is 0.050183
Net1: layer conv1:max response is , min response is .
max gradient is 7.720786, min gradient is -8.000000, learning rate is 0.050183
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.886657, min gradient is -8.000000, learning rate is 0.000792
Net2: layer deconv3:max response is 12.009130, min response is -23.259232.
max gradient is 6.500871, min gradient is -8.000000, learning rate is 0.000396
Net2: layer bn50:max response is 16.298079, min response is -3.165268.
max gradient is 8.000000, min gradient is -2.840114, learning rate is 0.000792
Net2: layer deconv2:max response is , min response is .
max gradient is 5.138995, min gradient is -8.000000, learning rate is 0.000396
Net2: layer bn49:max response is 8.873719, min response is -1.779937.
max gradient is 8.000000, min gradient is -7.695590, learning rate is 0.000792
Net2: layer deconv1:max response is , min response is .
max gradient is 6.165241, min gradient is -8.000000, learning rate is 0.000396
max inferred z is 3.86, min inferred z is -3.80, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 17: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.816027, min gradient is -8.000000, learning rate is 0.050183
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.105595, learning rate is 0.050183
Net1: layer conv1:max response is , min response is .
max gradient is 6.077109, min gradient is -8.000000, learning rate is 0.050183
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.671487, learning rate is 0.000792
Net2: layer deconv3:max response is 11.858647, min response is -22.089149.
max gradient is 3.533989, min gradient is -8.000000, learning rate is 0.000396
Net2: layer bn50:max response is 17.242462, min response is -3.623429.
max gradient is 8.000000, min gradient is -7.827090, learning rate is 0.000792
Net2: layer deconv2:max response is , min response is .
max gradient is 6.289332, min gradient is -8.000000, learning rate is 0.000396
Net2: layer bn49:max response is 8.319155, min response is -1.941121.
max gradient is 8.000000, min gradient is -5.692704, learning rate is 0.000792
Net2: layer deconv1:max response is , min response is .
max gradient is 7.472871, min gradient is -8.000000, learning rate is 0.000396
max inferred z is 3.52, min inferred z is -4.24, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 17: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.784000, min gradient is -8.000000, learning rate is 0.050183
Net1: layer conv2:max response is , min response is .
max gradient is 7.190890, min gradient is -8.000000, learning rate is 0.050183
Net1: layer conv1:max response is , min response is .
max gradient is 7.255999, min gradient is -8.000000, learning rate is 0.050183
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.422377, learning rate is 0.000792
Net2: layer deconv3:max response is 13.976627, min response is -20.204393.
max gradient is 3.331038, min gradient is -8.000000, learning rate is 0.000396
Net2: layer bn50:max response is 17.633568, min response is -2.867151.
max gradient is 8.000000, min gradient is -2.622030, learning rate is 0.000792
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.819212, learning rate is 0.000396
Net2: layer bn49:max response is 7.729226, min response is -1.791283.
max gradient is 8.000000, min gradient is -3.833883, learning rate is 0.000792
Net2: layer deconv1:max response is , min response is .
max gradient is 7.951703, min gradient is -8.000000, learning rate is 0.000396
max inferred z is 4.29, min inferred z is -4.18, and std is 1.00
 4.19 s (23.9 data/s) [100/100]
training: epoch 17: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.395615, min gradient is -8.000000, learning rate is 0.050183
Net1: layer conv2:max response is , min response is .
max gradient is 7.675998, min gradient is -8.000000, learning rate is 0.050183
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.005408, learning rate is 0.050183
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.876351, learning rate is 0.000792
Net2: layer deconv3:max response is 11.619966, min response is -19.998093.
max gradient is 4.366783, min gradient is -8.000000, learning rate is 0.000396
Net2: layer bn50:max response is 17.322054, min response is -3.230504.
max gradient is 8.000000, min gradient is -4.571400, learning rate is 0.000792
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.867578, learning rate is 0.000396
Net2: layer bn49:max response is 10.039841, min response is -1.707056.
max gradient is 8.000000, min gradient is -2.993093, learning rate is 0.000792
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.431843, learning rate is 0.000396
max inferred z is 4.94, min inferred z is -3.86, and std is 1.00
 4.16 s (24.0 data/s) [100/100]
training: epoch 17: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.851014, min gradient is -8.000000, learning rate is 0.050183
Net1: layer conv2:max response is , min response is .
max gradient is 6.690400, min gradient is -8.000000, learning rate is 0.050183
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.957202, learning rate is 0.050183
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -1.938339, min gradient is -8.000000, learning rate is 0.000792
Net2: layer deconv3:max response is 11.980181, min response is -20.177420.
max gradient is 8.000000, min gradient is -6.062983, learning rate is 0.000396
Net2: layer bn50:max response is 13.662144, min response is -2.996648.
max gradient is 8.000000, min gradient is -1.284366, learning rate is 0.000792
Net2: layer deconv2:max response is , min response is .
max gradient is 7.369033, min gradient is -8.000000, learning rate is 0.000396
Net2: layer bn49:max response is 9.200360, min response is -1.731100.
max gradient is 8.000000, min gradient is -4.853691, learning rate is 0.000792
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.568354, learning rate is 0.000396
max inferred z is 4.09, min inferred z is -3.96, and std is 1.00
 4.41 s (22.7 data/s) [100/100]
training: epoch 17: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.345453, min gradient is -8.000000, learning rate is 0.050183
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.475491, learning rate is 0.050183
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.108187, learning rate is 0.050183
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.459278, learning rate is 0.000792
Net2: layer deconv3:max response is 12.374527, min response is -20.732597.
max gradient is 7.721758, min gradient is -8.000000, learning rate is 0.000396
Net2: layer bn50:max response is 18.532408, min response is -2.673236.
max gradient is 8.000000, min gradient is -2.562668, learning rate is 0.000792
Net2: layer deconv2:max response is , min response is .
max gradient is 7.166461, min gradient is -8.000000, learning rate is 0.000396
Net2: layer bn49:max response is 10.845186, min response is -1.915686.
max gradient is 8.000000, min gradient is -4.548152, learning rate is 0.000792
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.252850, learning rate is 0.000396
max inferred z is 4.05, min inferred z is -3.71, and std is 1.00
 4.48 s (22.3 data/s) [100/100]
training: epoch 17: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.742341, min gradient is -8.000000, learning rate is 0.050183
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.484956, learning rate is 0.050183
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.744188, learning rate is 0.050183
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.926823, min gradient is -8.000000, learning rate is 0.000792
Net2: layer deconv3:max response is 11.734170, min response is -20.639948.
max gradient is 8.000000, min gradient is -6.626529, learning rate is 0.000396
Net2: layer bn50:max response is 15.006332, min response is -2.760191.
max gradient is 8.000000, min gradient is -1.301092, learning rate is 0.000792
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.576689, learning rate is 0.000396
Net2: layer bn49:max response is 8.229268, min response is -2.361957.
max gradient is 8.000000, min gradient is -5.297434, learning rate is 0.000792
Net2: layer deconv1:max response is , min response is .
max gradient is 7.487406, min gradient is -8.000000, learning rate is 0.000396
max inferred z is 4.09, min inferred z is -3.85, and std is 1.00
 4.40 s (22.8 data/s) [100/100]
training: epoch 17: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.961557, min gradient is -8.000000, learning rate is 0.050183
Net1: layer conv2:max response is , min response is .
max gradient is 6.987679, min gradient is -8.000001, learning rate is 0.050183
Net1: layer conv1:max response is , min response is .
max gradient is 7.485183, min gradient is -8.000000, learning rate is 0.050183
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.947557, min gradient is -8.000000, learning rate is 0.000792
Net2: layer deconv3:max response is 11.794642, min response is -16.933094.
max gradient is 7.595153, min gradient is -8.000000, learning rate is 0.000396
Net2: layer bn50:max response is 15.546897, min response is -2.329732.
max gradient is 8.000000, min gradient is -1.483047, learning rate is 0.000792
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.477489, learning rate is 0.000396
Net2: layer bn49:max response is 9.143564, min response is -2.318363.
max gradient is 6.229288, min gradient is -8.000000, learning rate is 0.000792
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.037448, learning rate is 0.000396
max inferred z is 4.26, min inferred z is -3.78, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 17: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.139105, learning rate is 0.050183
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -3.585512, learning rate is 0.050183
Net1: layer conv1:max response is , min response is .
max gradient is 4.742553, min gradient is -8.000000, learning rate is 0.050183
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.854189, min gradient is -8.000000, learning rate is 0.000792
Net2: layer deconv3:max response is 10.993311, min response is -19.259222.
max gradient is 4.940359, min gradient is -8.000000, learning rate is 0.000396
Net2: layer bn50:max response is 15.630978, min response is -2.943759.
max gradient is 8.000000, min gradient is -5.920774, learning rate is 0.000792
Net2: layer deconv2:max response is , min response is .
max gradient is 6.256909, min gradient is -8.000000, learning rate is 0.000396
Net2: layer bn49:max response is 9.250199, min response is -2.137661.
max gradient is 4.987738, min gradient is -8.000000, learning rate is 0.000792
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.939407, learning rate is 0.000396
max inferred z is 4.25, min inferred z is -3.88, and std is 1.00
 4.28 s (23.4 data/s) [100/100]
training: epoch 17: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.845827, learning rate is 0.050183
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.277021, learning rate is 0.050183
Net1: layer conv1:max response is , min response is .
max gradient is 6.090105, min gradient is -8.000000, learning rate is 0.050183
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.888290, min gradient is -8.000000, learning rate is 0.000792
Net2: layer deconv3:max response is 10.933991, min response is -19.544640.
max gradient is 6.905961, min gradient is -8.000000, learning rate is 0.000396
Net2: layer bn50:max response is 14.630934, min response is -2.705826.
max gradient is 8.000000, min gradient is -2.532148, learning rate is 0.000792
Net2: layer deconv2:max response is , min response is .
max gradient is 5.621664, min gradient is -8.000000, learning rate is 0.000396
Net2: layer bn49:max response is 9.998975, min response is -1.815933.
max gradient is 3.191070, min gradient is -8.000000, learning rate is 0.000792
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.946609, learning rate is 0.000396
max inferred z is 4.10, min inferred z is -4.16, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
Loss: 2.4073
Iteration 18 / 200
training: epoch 18: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.157854, min gradient is -8.000000, learning rate is 0.050183
Net1: layer conv2:max response is , min response is .
max gradient is 3.567784, min gradient is -8.000000, learning rate is 0.050183
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.028306, learning rate is 0.050183
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.672406, min gradient is -8.000000, learning rate is 0.000792
Net2: layer deconv3:max response is 10.251199, min response is -18.995358.
max gradient is 8.000000, min gradient is -5.344103, learning rate is 0.000396
Net2: layer bn50:max response is 15.027194, min response is -2.449093.
max gradient is 8.000000, min gradient is -1.181679, learning rate is 0.000792
Net2: layer deconv2:max response is , min response is .
max gradient is 6.185363, min gradient is -8.000000, learning rate is 0.000396
Net2: layer bn49:max response is 8.000350, min response is -1.969574.
max gradient is 3.256401, min gradient is -8.000000, learning rate is 0.000792
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.821932, learning rate is 0.000396
max inferred z is 3.93, min inferred z is -4.63, and std is 1.01
 4.21 s (23.8 data/s) [100/100]
training: epoch 18: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.986406, learning rate is 0.050183
Net1: layer conv2:max response is , min response is .
max gradient is 4.211695, min gradient is -8.000000, learning rate is 0.050183
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.105019, learning rate is 0.050183
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.739746, min gradient is -8.000000, learning rate is 0.000792
Net2: layer deconv3:max response is 12.212549, min response is -20.176367.
max gradient is 5.210684, min gradient is -8.000000, learning rate is 0.000396
Net2: layer bn50:max response is 18.622490, min response is -2.689879.
max gradient is 8.000000, min gradient is -2.296381, learning rate is 0.000792
Net2: layer deconv2:max response is , min response is .
max gradient is 5.740522, min gradient is -8.000000, learning rate is 0.000396
Net2: layer bn49:max response is 10.553686, min response is -1.660777.
max gradient is 3.260061, min gradient is -8.000000, learning rate is 0.000792
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.665555, learning rate is 0.000396
max inferred z is 3.78, min inferred z is -4.06, and std is 1.01
 4.29 s (23.3 data/s) [100/100]
training: epoch 18: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.048845, learning rate is 0.050183
Net1: layer conv2:max response is , min response is .
max gradient is 7.118018, min gradient is -8.000001, learning rate is 0.050183
Net1: layer conv1:max response is , min response is .
max gradient is 6.547564, min gradient is -8.000000, learning rate is 0.050183
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.396285, min gradient is -8.000000, learning rate is 0.000792
Net2: layer deconv3:max response is 10.543177, min response is -16.470608.
max gradient is 7.181421, min gradient is -8.000000, learning rate is 0.000396
Net2: layer bn50:max response is 15.939931, min response is -2.819906.
max gradient is 5.666301, min gradient is -8.000000, learning rate is 0.000792
Net2: layer deconv2:max response is , min response is .
max gradient is 5.305513, min gradient is -8.000000, learning rate is 0.000396
Net2: layer bn49:max response is 9.664315, min response is -2.239174.
max gradient is 4.151905, min gradient is -8.000000, learning rate is 0.000792
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.954434, learning rate is 0.000396
max inferred z is 4.13, min inferred z is -3.63, and std is 1.01
 4.31 s (23.2 data/s) [100/100]
training: epoch 18: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.199820, min gradient is -8.000000, learning rate is 0.050183
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.555022, learning rate is 0.050183
Net1: layer conv1:max response is , min response is .
max gradient is 6.642068, min gradient is -8.000000, learning rate is 0.050183
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.270936, learning rate is 0.000792
Net2: layer deconv3:max response is 12.558094, min response is -20.423372.
max gradient is 7.778184, min gradient is -8.000000, learning rate is 0.000396
Net2: layer bn50:max response is 16.912920, min response is -2.427331.
max gradient is 1.623394, min gradient is -8.000000, learning rate is 0.000792
Net2: layer deconv2:max response is , min response is .
max gradient is 4.905835, min gradient is -8.000000, learning rate is 0.000396
Net2: layer bn49:max response is 10.275439, min response is -1.893856.
max gradient is 6.970195, min gradient is -8.000000, learning rate is 0.000792
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.424459, learning rate is 0.000396
max inferred z is 4.06, min inferred z is -3.85, and std is 1.01
 4.21 s (23.7 data/s) [100/100]
training: epoch 18: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.894884, min gradient is -8.000000, learning rate is 0.050183
Net1: layer conv2:max response is , min response is .
max gradient is 5.284729, min gradient is -8.000000, learning rate is 0.050183
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.324878, learning rate is 0.050183
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.127122, learning rate is 0.000792
Net2: layer deconv3:max response is 12.464669, min response is -18.436691.
max gradient is 5.739920, min gradient is -8.000000, learning rate is 0.000396
Net2: layer bn50:max response is 14.727022, min response is -2.750135.
max gradient is 8.000000, min gradient is -2.966183, learning rate is 0.000792
Net2: layer deconv2:max response is , min response is .
max gradient is 5.944390, min gradient is -8.000000, learning rate is 0.000396
Net2: layer bn49:max response is 10.844320, min response is -2.201132.
max gradient is 4.600228, min gradient is -8.000000, learning rate is 0.000792
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.965788, learning rate is 0.000396
max inferred z is 4.51, min inferred z is -4.24, and std is 1.01
 4.39 s (22.8 data/s) [100/100]
training: epoch 18: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.036030, min gradient is -8.000000, learning rate is 0.050183
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.611133, learning rate is 0.050183
Net1: layer conv1:max response is , min response is .
max gradient is 7.900504, min gradient is -8.000000, learning rate is 0.050183
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.248846, learning rate is 0.000792
Net2: layer deconv3:max response is 11.476352, min response is -18.552725.
max gradient is 6.756181, min gradient is -8.000000, learning rate is 0.000396
Net2: layer bn50:max response is 15.663184, min response is -2.396871.
max gradient is 8.000000, min gradient is -5.934227, learning rate is 0.000792
Net2: layer deconv2:max response is , min response is .
max gradient is 7.798475, min gradient is -8.000000, learning rate is 0.000396
Net2: layer bn49:max response is 10.049383, min response is -1.995367.
max gradient is 5.731600, min gradient is -8.000000, learning rate is 0.000792
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.725469, learning rate is 0.000396
max inferred z is 3.74, min inferred z is -3.96, and std is 1.01
 4.29 s (23.3 data/s) [100/100]
training: epoch 18: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.776755, min gradient is -8.000000, learning rate is 0.050183
Net1: layer conv2:max response is , min response is .
max gradient is 6.056228, min gradient is -8.000000, learning rate is 0.050183
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.410670, learning rate is 0.050183
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.128439, learning rate is 0.000792
Net2: layer deconv3:max response is 11.202725, min response is -20.818281.
max gradient is 6.634102, min gradient is -8.000000, learning rate is 0.000396
Net2: layer bn50:max response is 16.447409, min response is -2.647481.
max gradient is 8.000000, min gradient is -5.077856, learning rate is 0.000792
Net2: layer deconv2:max response is , min response is .
max gradient is 7.838840, min gradient is -8.000000, learning rate is 0.000396
Net2: layer bn49:max response is 9.996327, min response is -2.231179.
max gradient is 8.000000, min gradient is -7.764112, learning rate is 0.000792
Net2: layer deconv1:max response is , min response is .
max gradient is 7.589084, min gradient is -8.000000, learning rate is 0.000396
max inferred z is 3.94, min inferred z is -3.83, and std is 1.01
 4.35 s (23.0 data/s) [100/100]
training: epoch 18: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.001310, min gradient is -8.000000, learning rate is 0.050183
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.111344, learning rate is 0.050183
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.639021, learning rate is 0.050183
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.706730, learning rate is 0.000792
Net2: layer deconv3:max response is 12.302681, min response is -20.443104.
max gradient is 6.479839, min gradient is -8.000000, learning rate is 0.000396
Net2: layer bn50:max response is 17.335743, min response is -2.584436.
max gradient is 7.820166, min gradient is -8.000000, learning rate is 0.000792
Net2: layer deconv2:max response is , min response is .
max gradient is 7.704812, min gradient is -8.000000, learning rate is 0.000396
Net2: layer bn49:max response is 8.624821, min response is -2.122534.
max gradient is 8.000000, min gradient is -6.942513, learning rate is 0.000792
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.584420, learning rate is 0.000396
max inferred z is 3.83, min inferred z is -3.99, and std is 1.01
 4.41 s (22.7 data/s) [100/100]
training: epoch 18: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.964676, min gradient is -8.000000, learning rate is 0.050183
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.414724, learning rate is 0.050183
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.490616, learning rate is 0.050183
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.190008, learning rate is 0.000792
Net2: layer deconv3:max response is 11.809338, min response is -18.539362.
max gradient is 4.868979, min gradient is -8.000000, learning rate is 0.000396
Net2: layer bn50:max response is 15.654081, min response is -2.695796.
max gradient is 8.000000, min gradient is -5.832671, learning rate is 0.000792
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.478385, learning rate is 0.000396
Net2: layer bn49:max response is 9.577431, min response is -2.158984.
max gradient is 8.000000, min gradient is -7.459739, learning rate is 0.000792
Net2: layer deconv1:max response is , min response is .
max gradient is 6.834912, min gradient is -8.000000, learning rate is 0.000396
max inferred z is 5.03, min inferred z is -4.10, and std is 1.01
 4.33 s (23.1 data/s) [100/100]
training: epoch 18: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.886288, min gradient is -8.000000, learning rate is 0.050183
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.135935, learning rate is 0.050183
Net1: layer conv1:max response is , min response is .
max gradient is 5.923392, min gradient is -8.000000, learning rate is 0.050183
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.141885, min gradient is -8.000000, learning rate is 0.000792
Net2: layer deconv3:max response is 12.011408, min response is -15.731870.
max gradient is 4.036518, min gradient is -8.000000, learning rate is 0.000396
Net2: layer bn50:max response is 15.393659, min response is -2.516516.
max gradient is 8.000000, min gradient is -5.316697, learning rate is 0.000792
Net2: layer deconv2:max response is , min response is .
max gradient is 7.363793, min gradient is -8.000000, learning rate is 0.000396
Net2: layer bn49:max response is 9.405659, min response is -1.747415.
max gradient is 7.206343, min gradient is -8.000000, learning rate is 0.000792
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.741557, learning rate is 0.000396
max inferred z is 4.07, min inferred z is -3.54, and std is 1.01
 4.23 s (23.6 data/s) [100/100]
Loss: 2.1514
Iteration 19 / 200
training: epoch 19: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -4.969460, learning rate is 0.047341
Net1: layer conv2:max response is , min response is .
max gradient is 5.692047, min gradient is -8.000000, learning rate is 0.047341
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.376568, learning rate is 0.047341
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.591252, min gradient is -8.000000, learning rate is 0.000769
Net2: layer deconv3:max response is 11.395068, min response is -17.189899.
max gradient is 8.000000, min gradient is -7.826025, learning rate is 0.000385
Net2: layer bn50:max response is 17.470694, min response is -2.672734.
max gradient is 8.000000, min gradient is -1.550453, learning rate is 0.000769
Net2: layer deconv2:max response is , min response is .
max gradient is 5.965352, min gradient is -8.000000, learning rate is 0.000385
Net2: layer bn49:max response is 8.680015, min response is -2.175999.
max gradient is 5.905406, min gradient is -8.000000, learning rate is 0.000769
Net2: layer deconv1:max response is , min response is .
max gradient is 7.178534, min gradient is -8.000000, learning rate is 0.000385
max inferred z is 4.52, min inferred z is -3.92, and std is 1.01
 4.29 s (23.3 data/s) [100/100]
training: epoch 19: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.667816, min gradient is -8.000000, learning rate is 0.047341
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.538118, learning rate is 0.047341
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.253355, learning rate is 0.047341
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.764796, learning rate is 0.000769
Net2: layer deconv3:max response is 11.139902, min response is -17.569410.
max gradient is 4.522554, min gradient is -8.000000, learning rate is 0.000385
Net2: layer bn50:max response is 14.780458, min response is -2.624279.
max gradient is 8.000000, min gradient is -6.407241, learning rate is 0.000769
Net2: layer deconv2:max response is , min response is .
max gradient is 7.031267, min gradient is -8.000000, learning rate is 0.000385
Net2: layer bn49:max response is 10.049299, min response is -2.026273.
max gradient is 8.000000, min gradient is -6.691780, learning rate is 0.000769
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.682965, learning rate is 0.000385
max inferred z is 4.24, min inferred z is -4.06, and std is 1.01
 4.22 s (23.7 data/s) [100/100]
training: epoch 19: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.267473, learning rate is 0.047341
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.257678, learning rate is 0.047341
Net1: layer conv1:max response is , min response is .
max gradient is 7.082883, min gradient is -8.000000, learning rate is 0.047341
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.542144, learning rate is 0.000769
Net2: layer deconv3:max response is 12.263005, min response is -17.560377.
max gradient is 5.026320, min gradient is -8.000000, learning rate is 0.000385
Net2: layer bn50:max response is 16.835264, min response is -2.330013.
max gradient is 8.000000, min gradient is -4.946090, learning rate is 0.000769
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.433169, learning rate is 0.000385
Net2: layer bn49:max response is 9.215494, min response is -1.876184.
max gradient is 8.000000, min gradient is -5.967835, learning rate is 0.000769
Net2: layer deconv1:max response is , min response is .
max gradient is 6.931526, min gradient is -8.000000, learning rate is 0.000385
max inferred z is 3.87, min inferred z is -3.91, and std is 1.01
 4.27 s (23.4 data/s) [100/100]
training: epoch 19: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.888007, learning rate is 0.047341
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -3.774039, learning rate is 0.047341
Net1: layer conv1:max response is , min response is .
max gradient is 7.275756, min gradient is -8.000000, learning rate is 0.047341
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.414515, learning rate is 0.000769
Net2: layer deconv3:max response is 12.697911, min response is -16.993986.
max gradient is 8.000000, min gradient is -7.666255, learning rate is 0.000385
Net2: layer bn50:max response is 19.877129, min response is -2.663949.
max gradient is 1.369259, min gradient is -8.000000, learning rate is 0.000769
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.363472, learning rate is 0.000385
Net2: layer bn49:max response is 9.798856, min response is -2.210244.
max gradient is 8.000000, min gradient is -6.603434, learning rate is 0.000769
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.517139, learning rate is 0.000385
max inferred z is 3.68, min inferred z is -3.68, and std is 1.01
 4.42 s (22.6 data/s) [100/100]
training: epoch 19: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.139668, learning rate is 0.047341
Net1: layer conv2:max response is , min response is .
max gradient is 7.181412, min gradient is -8.000000, learning rate is 0.047341
Net1: layer conv1:max response is , min response is .
max gradient is 7.496911, min gradient is -8.000000, learning rate is 0.047341
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.658291, learning rate is 0.000769
Net2: layer deconv3:max response is 11.659132, min response is -19.589424.
max gradient is 8.000000, min gradient is -6.693866, learning rate is 0.000385
Net2: layer bn50:max response is 15.778770, min response is -2.613575.
max gradient is 6.766657, min gradient is -8.000000, learning rate is 0.000769
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.294996, learning rate is 0.000385
Net2: layer bn49:max response is 8.810896, min response is -1.959743.
max gradient is 8.000000, min gradient is -6.899614, learning rate is 0.000769
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.579628, learning rate is 0.000385
max inferred z is 3.59, min inferred z is -4.45, and std is 1.01
 4.32 s (23.2 data/s) [100/100]
training: epoch 19: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.693263, learning rate is 0.047341
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.996623, learning rate is 0.047341
Net1: layer conv1:max response is , min response is .
max gradient is 4.583540, min gradient is -8.000000, learning rate is 0.047341
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.583672, min gradient is -8.000000, learning rate is 0.000769
Net2: layer deconv3:max response is 12.520704, min response is -19.784237.
max gradient is 8.000000, min gradient is -5.845687, learning rate is 0.000385
Net2: layer bn50:max response is 17.413593, min response is -2.905811.
max gradient is 8.000000, min gradient is -5.507070, learning rate is 0.000769
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.786595, learning rate is 0.000385
Net2: layer bn49:max response is 9.120093, min response is -1.862072.
max gradient is 8.000000, min gradient is -6.675769, learning rate is 0.000769
Net2: layer deconv1:max response is , min response is .
max gradient is 5.793910, min gradient is -8.000000, learning rate is 0.000385
max inferred z is 3.91, min inferred z is -3.90, and std is 1.01
 4.35 s (23.0 data/s) [100/100]
training: epoch 19: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -4.971270, learning rate is 0.047341
Net1: layer conv2:max response is , min response is .
max gradient is 4.819559, min gradient is -8.000000, learning rate is 0.047341
Net1: layer conv1:max response is , min response is .
max gradient is 6.064747, min gradient is -8.000000, learning rate is 0.047341
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.458604, min gradient is -8.000000, learning rate is 0.000769
Net2: layer deconv3:max response is 10.802266, min response is -18.202135.
max gradient is 8.000000, min gradient is -7.665718, learning rate is 0.000385
Net2: layer bn50:max response is 17.135777, min response is -2.596821.
max gradient is 8.000000, min gradient is -2.933540, learning rate is 0.000769
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.965431, learning rate is 0.000385
Net2: layer bn49:max response is 9.721495, min response is -1.967364.
max gradient is 6.844769, min gradient is -8.000000, learning rate is 0.000769
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.978082, learning rate is 0.000385
max inferred z is 3.84, min inferred z is -3.97, and std is 1.01
 4.44 s (22.5 data/s) [100/100]
training: epoch 19: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -4.789429, learning rate is 0.047341
Net1: layer conv2:max response is , min response is .
max gradient is 7.519137, min gradient is -8.000000, learning rate is 0.047341
Net1: layer conv1:max response is , min response is .
max gradient is 4.222735, min gradient is -8.000000, learning rate is 0.047341
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.251939, min gradient is -8.000000, learning rate is 0.000769
Net2: layer deconv3:max response is 11.648703, min response is -17.788168.
max gradient is 7.512438, min gradient is -8.000000, learning rate is 0.000385
Net2: layer bn50:max response is 15.581089, min response is -2.529973.
max gradient is 8.000000, min gradient is -2.621826, learning rate is 0.000769
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.914277, learning rate is 0.000385
Net2: layer bn49:max response is 10.098066, min response is -1.939776.
max gradient is 3.225129, min gradient is -8.000000, learning rate is 0.000769
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.596121, learning rate is 0.000385
max inferred z is 4.49, min inferred z is -4.05, and std is 1.01
 4.29 s (23.3 data/s) [100/100]
training: epoch 19: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.195004, learning rate is 0.047341
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.122805, learning rate is 0.047341
Net1: layer conv1:max response is , min response is .
max gradient is 5.456752, min gradient is -8.000000, learning rate is 0.047341
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.528187, min gradient is -8.000000, learning rate is 0.000769
Net2: layer deconv3:max response is 14.144431, min response is -18.220865.
max gradient is 5.800399, min gradient is -8.000001, learning rate is 0.000385
Net2: layer bn50:max response is 21.368807, min response is -2.786776.
max gradient is 8.000000, min gradient is -2.583700, learning rate is 0.000769
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.813193, learning rate is 0.000385
Net2: layer bn49:max response is 8.671212, min response is -2.418941.
max gradient is 2.784309, min gradient is -8.000000, learning rate is 0.000769
Net2: layer deconv1:max response is , min response is .
max gradient is 7.666325, min gradient is -8.000000, learning rate is 0.000385
max inferred z is 4.06, min inferred z is -4.04, and std is 1.01
 4.39 s (22.8 data/s) [100/100]
training: epoch 19: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.157247, min gradient is -8.000000, learning rate is 0.047341
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.327725, learning rate is 0.047341
Net1: layer conv1:max response is , min response is .
max gradient is 7.747101, min gradient is -8.000000, learning rate is 0.047341
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.662996, min gradient is -8.000000, learning rate is 0.000769
Net2: layer deconv3:max response is 16.950060, min response is -19.593811.
max gradient is 4.557806, min gradient is -8.000000, learning rate is 0.000385
Net2: layer bn50:max response is 24.824997, min response is -3.495891.
max gradient is 8.000000, min gradient is -1.731979, learning rate is 0.000769
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.217779, learning rate is 0.000385
Net2: layer bn49:max response is 8.687664, min response is -1.921521.
max gradient is 4.034601, min gradient is -8.000000, learning rate is 0.000769
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.196232, learning rate is 0.000385
max inferred z is 4.06, min inferred z is -3.91, and std is 1.01
 4.47 s (22.4 data/s) [100/100]
Loss: 2.4111
Iteration 20 / 200
training: epoch 20: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.128735, min gradient is -8.000000, learning rate is 0.047341
Net1: layer conv2:max response is , min response is .
max gradient is 3.652793, min gradient is -8.000000, learning rate is 0.047341
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.595594, learning rate is 0.047341
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.750080, min gradient is -8.000000, learning rate is 0.000769
Net2: layer deconv3:max response is 14.740417, min response is -20.378256.
max gradient is 6.999870, min gradient is -8.000000, learning rate is 0.000385
Net2: layer bn50:max response is 20.648386, min response is -2.910017.
max gradient is 8.000000, min gradient is -1.687017, learning rate is 0.000769
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.670760, learning rate is 0.000385
Net2: layer bn49:max response is 10.956876, min response is -1.882025.
max gradient is 4.219970, min gradient is -8.000000, learning rate is 0.000769
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.144361, learning rate is 0.000385
max inferred z is 4.29, min inferred z is -4.04, and std is 1.00
 4.16 s (24.1 data/s) [100/100]
training: epoch 20: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.370646, min gradient is -8.000000, learning rate is 0.047341
Net1: layer conv2:max response is , min response is .
max gradient is 4.387170, min gradient is -8.000000, learning rate is 0.047341
Net1: layer conv1:max response is , min response is .
max gradient is 7.304416, min gradient is -8.000000, learning rate is 0.047341
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.921791, min gradient is -8.000000, learning rate is 0.000769
Net2: layer deconv3:max response is 12.371170, min response is -20.227415.
max gradient is 5.739780, min gradient is -8.000000, learning rate is 0.000385
Net2: layer bn50:max response is 15.866152, min response is -2.498406.
max gradient is 8.000000, min gradient is -1.815038, learning rate is 0.000769
Net2: layer deconv2:max response is , min response is .
max gradient is 6.771778, min gradient is -8.000000, learning rate is 0.000385
Net2: layer bn49:max response is 9.438806, min response is -2.190539.
max gradient is 4.909309, min gradient is -8.000000, learning rate is 0.000769
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.360592, learning rate is 0.000385
max inferred z is 3.54, min inferred z is -3.71, and std is 1.00
 4.18 s (23.9 data/s) [100/100]
training: epoch 20: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.066990, min gradient is -8.000000, learning rate is 0.047341
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.645180, learning rate is 0.047341
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.755986, learning rate is 0.047341
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.839512, learning rate is 0.000769
Net2: layer deconv3:max response is 13.203293, min response is -19.070602.
max gradient is 6.626101, min gradient is -8.000000, learning rate is 0.000385
Net2: layer bn50:max response is 16.741194, min response is -2.878011.
max gradient is 5.031015, min gradient is -8.000000, learning rate is 0.000769
Net2: layer deconv2:max response is , min response is .
max gradient is 7.640571, min gradient is -8.000000, learning rate is 0.000385
Net2: layer bn49:max response is 8.729714, min response is -2.077804.
max gradient is 6.961957, min gradient is -8.000000, learning rate is 0.000769
Net2: layer deconv1:max response is , min response is .
max gradient is 7.946017, min gradient is -8.000000, learning rate is 0.000385
max inferred z is 4.26, min inferred z is -4.11, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 20: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.190707, min gradient is -8.000000, learning rate is 0.047341
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.607377, learning rate is 0.047341
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.533159, learning rate is 0.047341
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.938752, learning rate is 0.000769
Net2: layer deconv3:max response is 11.227212, min response is -21.201050.
max gradient is 6.722631, min gradient is -8.000000, learning rate is 0.000385
Net2: layer bn50:max response is 15.545474, min response is -2.761821.
max gradient is 8.000000, min gradient is -7.862751, learning rate is 0.000769
Net2: layer deconv2:max response is , min response is .
max gradient is 7.403108, min gradient is -8.000000, learning rate is 0.000385
Net2: layer bn49:max response is 8.744900, min response is -1.837998.
max gradient is 7.022254, min gradient is -8.000000, learning rate is 0.000769
Net2: layer deconv1:max response is , min response is .
max gradient is 6.445601, min gradient is -8.000000, learning rate is 0.000385
max inferred z is 3.73, min inferred z is -3.85, and std is 1.00
 4.28 s (23.4 data/s) [100/100]
training: epoch 20: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.921082, min gradient is -8.000000, learning rate is 0.047341
Net1: layer conv2:max response is , min response is .
max gradient is 6.001729, min gradient is -8.000000, learning rate is 0.047341
Net1: layer conv1:max response is , min response is .
max gradient is 6.074284, min gradient is -8.000000, learning rate is 0.047341
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.409585, learning rate is 0.000769
Net2: layer deconv3:max response is 11.825952, min response is -22.255346.
max gradient is 8.000000, min gradient is -7.627096, learning rate is 0.000385
Net2: layer bn50:max response is 17.709667, min response is -2.919078.
max gradient is 8.000000, min gradient is -4.172937, learning rate is 0.000769
Net2: layer deconv2:max response is , min response is .
max gradient is 6.630225, min gradient is -8.000000, learning rate is 0.000385
Net2: layer bn49:max response is 9.148260, min response is -2.228746.
max gradient is 7.005229, min gradient is -8.000000, learning rate is 0.000769
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.863462, learning rate is 0.000385
max inferred z is 4.07, min inferred z is -4.04, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 20: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.762385, min gradient is -8.000000, learning rate is 0.047341
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.248157, learning rate is 0.047341
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.769385, learning rate is 0.047341
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.348367, learning rate is 0.000769
Net2: layer deconv3:max response is 14.217216, min response is -21.507969.
max gradient is 8.000000, min gradient is -6.057448, learning rate is 0.000385
Net2: layer bn50:max response is 15.831620, min response is -2.848772.
max gradient is 5.171020, min gradient is -8.000000, learning rate is 0.000769
Net2: layer deconv2:max response is , min response is .
max gradient is 5.889469, min gradient is -8.000000, learning rate is 0.000385
Net2: layer bn49:max response is 11.385376, min response is -2.260674.
max gradient is 7.942055, min gradient is -8.000000, learning rate is 0.000769
Net2: layer deconv1:max response is , min response is .
max gradient is 6.326621, min gradient is -8.000000, learning rate is 0.000385
max inferred z is 3.95, min inferred z is -3.77, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 20: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.787916, min gradient is -8.000000, learning rate is 0.047341
Net1: layer conv2:max response is , min response is .
max gradient is 7.950542, min gradient is -8.000000, learning rate is 0.047341
Net1: layer conv1:max response is , min response is .
max gradient is 7.256116, min gradient is -8.000000, learning rate is 0.047341
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -2.483387, min gradient is -8.000000, learning rate is 0.000769
Net2: layer deconv3:max response is 11.911849, min response is -19.224077.
max gradient is 8.000000, min gradient is -6.470457, learning rate is 0.000385
Net2: layer bn50:max response is 15.434660, min response is -2.756629.
max gradient is 5.648441, min gradient is -8.000000, learning rate is 0.000769
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.674336, learning rate is 0.000385
Net2: layer bn49:max response is 9.070167, min response is -1.905520.
max gradient is 8.000000, min gradient is -5.662136, learning rate is 0.000769
Net2: layer deconv1:max response is , min response is .
max gradient is 7.218667, min gradient is -8.000000, learning rate is 0.000385
max inferred z is 3.97, min inferred z is -3.50, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 20: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.027394, learning rate is 0.047341
Net1: layer conv2:max response is , min response is .
max gradient is 7.436595, min gradient is -8.000000, learning rate is 0.047341
Net1: layer conv1:max response is , min response is .
max gradient is 4.277025, min gradient is -8.000000, learning rate is 0.047341
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.693948, min gradient is -8.000000, learning rate is 0.000769
Net2: layer deconv3:max response is 11.988595, min response is -19.235653.
max gradient is 8.000000, min gradient is -7.541146, learning rate is 0.000385
Net2: layer bn50:max response is 15.640616, min response is -2.719826.
max gradient is 8.000000, min gradient is -2.856937, learning rate is 0.000769
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.729674, learning rate is 0.000385
Net2: layer bn49:max response is 8.522953, min response is -1.928013.
max gradient is 8.000000, min gradient is -4.768332, learning rate is 0.000769
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.715851, learning rate is 0.000385
max inferred z is 4.00, min inferred z is -4.19, and std is 1.00
 4.50 s (22.2 data/s) [100/100]
training: epoch 20: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.675787, min gradient is -8.000000, learning rate is 0.047341
Net1: layer conv2:max response is , min response is .
max gradient is 5.816329, min gradient is -8.000000, learning rate is 0.047341
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.268653, learning rate is 0.047341
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.639575, learning rate is 0.000769
Net2: layer deconv3:max response is 11.141528, min response is -17.236835.
max gradient is 8.000000, min gradient is -6.606018, learning rate is 0.000385
Net2: layer bn50:max response is 14.666631, min response is -2.630357.
max gradient is 1.503508, min gradient is -8.000000, learning rate is 0.000769
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.896064, learning rate is 0.000385
Net2: layer bn49:max response is 9.827181, min response is -1.876121.
max gradient is 8.000000, min gradient is -3.632603, learning rate is 0.000769
Net2: layer deconv1:max response is , min response is .
max gradient is 6.727246, min gradient is -8.000000, learning rate is 0.000385
max inferred z is 4.16, min inferred z is -4.01, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 20: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.985030, learning rate is 0.047341
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.224540, learning rate is 0.047341
Net1: layer conv1:max response is , min response is .
max gradient is 4.862159, min gradient is -8.000000, learning rate is 0.047341
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.640005, min gradient is -8.000000, learning rate is 0.000769
Net2: layer deconv3:max response is 12.616757, min response is -17.754679.
max gradient is 5.558354, min gradient is -8.000001, learning rate is 0.000385
Net2: layer bn50:max response is 15.920364, min response is -3.071462.
max gradient is 8.000000, min gradient is -1.233846, learning rate is 0.000769
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.532611, learning rate is 0.000385
Net2: layer bn49:max response is 8.888959, min response is -2.254490.
max gradient is 8.000000, min gradient is -4.724940, learning rate is 0.000769
Net2: layer deconv1:max response is , min response is .
max gradient is 5.907639, min gradient is -8.000000, learning rate is 0.000385
max inferred z is 3.98, min inferred z is -3.74, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
Loss: 2.4246
Iteration 21 / 200
training: epoch 21: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.610393, learning rate is 0.044661
Net1: layer conv2:max response is , min response is .
max gradient is 7.301421, min gradient is -8.000000, learning rate is 0.044661
Net1: layer conv1:max response is , min response is .
max gradient is 7.804113, min gradient is -8.000000, learning rate is 0.044661
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.559340, min gradient is -8.000000, learning rate is 0.000747
Net2: layer deconv3:max response is 12.085655, min response is -18.380947.
max gradient is 7.201235, min gradient is -8.000000, learning rate is 0.000374
Net2: layer bn50:max response is 15.293116, min response is -2.805598.
max gradient is 8.000000, min gradient is -1.525551, learning rate is 0.000747
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.374411, learning rate is 0.000374
Net2: layer bn49:max response is 10.176618, min response is -1.870098.
max gradient is 8.000000, min gradient is -5.541659, learning rate is 0.000747
Net2: layer deconv1:max response is , min response is .
max gradient is 7.562511, min gradient is -8.000000, learning rate is 0.000374
max inferred z is 4.21, min inferred z is -4.13, and std is 1.01
 4.25 s (23.5 data/s) [100/100]
training: epoch 21: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.319751, learning rate is 0.044661
Net1: layer conv2:max response is , min response is .
max gradient is 6.789827, min gradient is -8.000000, learning rate is 0.044661
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.681757, learning rate is 0.044661
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.322749, learning rate is 0.000747
Net2: layer deconv3:max response is 12.394669, min response is -21.144144.
max gradient is 6.002188, min gradient is -8.000000, learning rate is 0.000374
Net2: layer bn50:max response is 17.161947, min response is -2.551332.
max gradient is 8.000000, min gradient is -1.396918, learning rate is 0.000747
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.326945, learning rate is 0.000374
Net2: layer bn49:max response is 9.487168, min response is -1.902507.
max gradient is 8.000000, min gradient is -4.216366, learning rate is 0.000747
Net2: layer deconv1:max response is , min response is .
max gradient is 5.324551, min gradient is -8.000000, learning rate is 0.000374
max inferred z is 4.01, min inferred z is -3.75, and std is 1.01
 4.20 s (23.8 data/s) [100/100]
training: epoch 21: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.114909, learning rate is 0.044661
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.380852, learning rate is 0.044661
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.995161, learning rate is 0.044661
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 0.195254, min gradient is -8.000001, learning rate is 0.000747
Net2: layer deconv3:max response is 14.135455, min response is -19.257261.
max gradient is 4.861868, min gradient is -8.000000, learning rate is 0.000374
Net2: layer bn50:max response is 16.522341, min response is -3.164253.
max gradient is 8.000000, min gradient is -2.316309, learning rate is 0.000747
Net2: layer deconv2:max response is , min response is .
max gradient is 7.269681, min gradient is -8.000000, learning rate is 0.000374
Net2: layer bn49:max response is 9.202962, min response is -2.126721.
max gradient is 8.000000, min gradient is -5.887404, learning rate is 0.000747
Net2: layer deconv1:max response is , min response is .
max gradient is 5.807767, min gradient is -8.000000, learning rate is 0.000374
max inferred z is 3.76, min inferred z is -4.21, and std is 1.01
 4.26 s (23.5 data/s) [100/100]
training: epoch 21: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.989625, learning rate is 0.044661
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.707776, learning rate is 0.044661
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.059184, learning rate is 0.044661
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.769470, learning rate is 0.000747
Net2: layer deconv3:max response is 12.964264, min response is -17.993181.
max gradient is 6.624423, min gradient is -8.000000, learning rate is 0.000374
Net2: layer bn50:max response is 18.107410, min response is -2.762780.
max gradient is 8.000000, min gradient is -6.719986, learning rate is 0.000747
Net2: layer deconv2:max response is , min response is .
max gradient is 7.983100, min gradient is -8.000000, learning rate is 0.000374
Net2: layer bn49:max response is 8.926707, min response is -2.187160.
max gradient is 8.000000, min gradient is -6.496114, learning rate is 0.000747
Net2: layer deconv1:max response is , min response is .
max gradient is 6.860816, min gradient is -8.000000, learning rate is 0.000374
max inferred z is 3.82, min inferred z is -4.13, and std is 1.01
 4.24 s (23.6 data/s) [100/100]
training: epoch 21: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.629502, min gradient is -8.000000, learning rate is 0.044661
Net1: layer conv2:max response is , min response is .
max gradient is 6.171589, min gradient is -8.000000, learning rate is 0.044661
Net1: layer conv1:max response is , min response is .
max gradient is 7.264655, min gradient is -8.000000, learning rate is 0.044661
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.399574, min gradient is -8.000000, learning rate is 0.000747
Net2: layer deconv3:max response is 13.747061, min response is -19.951860.
max gradient is 8.000000, min gradient is -5.318068, learning rate is 0.000374
Net2: layer bn50:max response is 14.822507, min response is -2.728577.
max gradient is 8.000000, min gradient is -2.166314, learning rate is 0.000747
Net2: layer deconv2:max response is , min response is .
max gradient is 7.665952, min gradient is -8.000000, learning rate is 0.000374
Net2: layer bn49:max response is 8.553987, min response is -1.828381.
max gradient is 8.000000, min gradient is -6.195580, learning rate is 0.000747
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.004086, learning rate is 0.000374
max inferred z is 3.96, min inferred z is -3.84, and std is 1.01
 4.27 s (23.4 data/s) [100/100]
training: epoch 21: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.450076, min gradient is -8.000000, learning rate is 0.044661
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.186954, learning rate is 0.044661
Net1: layer conv1:max response is , min response is .
max gradient is 7.459162, min gradient is -8.000000, learning rate is 0.044661
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.332312, learning rate is 0.000747
Net2: layer deconv3:max response is 12.961493, min response is -16.198473.
max gradient is 8.000000, min gradient is -5.471509, learning rate is 0.000374
Net2: layer bn50:max response is 15.918450, min response is -2.422702.
max gradient is 2.943922, min gradient is -8.000000, learning rate is 0.000747
Net2: layer deconv2:max response is , min response is .
max gradient is 6.651553, min gradient is -8.000000, learning rate is 0.000374
Net2: layer bn49:max response is 10.058228, min response is -1.941167.
max gradient is 7.444857, min gradient is -8.000000, learning rate is 0.000747
Net2: layer deconv1:max response is , min response is .
max gradient is 7.938894, min gradient is -8.000000, learning rate is 0.000374
max inferred z is 4.02, min inferred z is -3.91, and std is 1.01
 4.32 s (23.1 data/s) [100/100]
training: epoch 21: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.578742, min gradient is -8.000000, learning rate is 0.044661
Net1: layer conv2:max response is , min response is .
max gradient is 6.612473, min gradient is -8.000000, learning rate is 0.044661
Net1: layer conv1:max response is , min response is .
max gradient is 6.612869, min gradient is -8.000001, learning rate is 0.044661
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.005832, min gradient is -8.000000, learning rate is 0.000747
Net2: layer deconv3:max response is 13.309833, min response is -20.054262.
max gradient is 8.000000, min gradient is -4.705830, learning rate is 0.000374
Net2: layer bn50:max response is 17.671101, min response is -2.676304.
max gradient is 8.000000, min gradient is -7.133514, learning rate is 0.000747
Net2: layer deconv2:max response is , min response is .
max gradient is 7.222690, min gradient is -8.000000, learning rate is 0.000374
Net2: layer bn49:max response is 11.088163, min response is -1.920461.
max gradient is 3.965369, min gradient is -8.000000, learning rate is 0.000747
Net2: layer deconv1:max response is , min response is .
max gradient is 7.419736, min gradient is -8.000000, learning rate is 0.000374
max inferred z is 4.06, min inferred z is -4.57, and std is 1.01
 4.32 s (23.1 data/s) [100/100]
training: epoch 21: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.317917, min gradient is -8.000000, learning rate is 0.044661
Net1: layer conv2:max response is , min response is .
max gradient is 6.400808, min gradient is -8.000000, learning rate is 0.044661
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -6.645856, learning rate is 0.044661
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.356408, min gradient is -8.000000, learning rate is 0.000747
Net2: layer deconv3:max response is 11.821592, min response is -17.479942.
max gradient is 8.000000, min gradient is -4.309821, learning rate is 0.000374
Net2: layer bn50:max response is 14.805977, min response is -2.614740.
max gradient is 3.827516, min gradient is -8.000000, learning rate is 0.000747
Net2: layer deconv2:max response is , min response is .
max gradient is 7.679815, min gradient is -8.000000, learning rate is 0.000374
Net2: layer bn49:max response is 9.080223, min response is -1.971783.
max gradient is 4.125693, min gradient is -8.000001, learning rate is 0.000747
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.357619, learning rate is 0.000374
max inferred z is 4.29, min inferred z is -3.68, and std is 1.01
 4.45 s (22.5 data/s) [100/100]
training: epoch 21: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.133645, min gradient is -8.000000, learning rate is 0.044661
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.591360, learning rate is 0.044661
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.137030, learning rate is 0.044661
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.438226, learning rate is 0.000747
Net2: layer deconv3:max response is 11.647249, min response is -19.747477.
max gradient is 8.000000, min gradient is -6.405937, learning rate is 0.000374
Net2: layer bn50:max response is 16.415771, min response is -2.899862.
max gradient is 1.770402, min gradient is -8.000000, learning rate is 0.000747
Net2: layer deconv2:max response is , min response is .
max gradient is 5.741730, min gradient is -8.000000, learning rate is 0.000374
Net2: layer bn49:max response is 9.338711, min response is -1.834007.
max gradient is 4.808901, min gradient is -8.000001, learning rate is 0.000747
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.585279, learning rate is 0.000374
max inferred z is 3.94, min inferred z is -3.93, and std is 1.01
 4.39 s (22.8 data/s) [100/100]
training: epoch 21: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.423970, learning rate is 0.044661
Net1: layer conv2:max response is , min response is .
max gradient is 6.788473, min gradient is -8.000000, learning rate is 0.044661
Net1: layer conv1:max response is , min response is .
max gradient is 3.472538, min gradient is -8.000000, learning rate is 0.044661
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.913369, min gradient is -8.000000, learning rate is 0.000747
Net2: layer deconv3:max response is 13.732067, min response is -20.147436.
max gradient is 7.670912, min gradient is -8.000000, learning rate is 0.000374
Net2: layer bn50:max response is 17.589340, min response is -2.533445.
max gradient is 5.850531, min gradient is -8.000000, learning rate is 0.000747
Net2: layer deconv2:max response is , min response is .
max gradient is 7.036190, min gradient is -8.000000, learning rate is 0.000374
Net2: layer bn49:max response is 8.992031, min response is -2.077571.
max gradient is 3.198177, min gradient is -8.000000, learning rate is 0.000747
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.789917, learning rate is 0.000374
max inferred z is 4.11, min inferred z is -4.28, and std is 1.01
 4.37 s (22.9 data/s) [100/100]
Loss: 2.1741
Iteration 22 / 200
training: epoch 22: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.461065, min gradient is -8.000000, learning rate is 0.044661
Net1: layer conv2:max response is , min response is .
max gradient is 4.517714, min gradient is -8.000000, learning rate is 0.044661
Net1: layer conv1:max response is , min response is .
max gradient is 4.294318, min gradient is -8.000000, learning rate is 0.044661
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.081857, min gradient is -8.000000, learning rate is 0.000747
Net2: layer deconv3:max response is 14.120090, min response is -15.927949.
max gradient is 5.643714, min gradient is -8.000000, learning rate is 0.000374
Net2: layer bn50:max response is 21.750856, min response is -2.322465.
max gradient is 8.000000, min gradient is -1.373660, learning rate is 0.000747
Net2: layer deconv2:max response is , min response is .
max gradient is 7.836693, min gradient is -8.000000, learning rate is 0.000374
Net2: layer bn49:max response is 9.103581, min response is -2.231712.
max gradient is 3.043816, min gradient is -8.000000, learning rate is 0.000747
Net2: layer deconv1:max response is , min response is .
max gradient is 6.819005, min gradient is -8.000000, learning rate is 0.000374
max inferred z is 3.85, min inferred z is -3.82, and std is 1.00
 4.14 s (24.2 data/s) [100/100]
training: epoch 22: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.285446, min gradient is -8.000000, learning rate is 0.044661
Net1: layer conv2:max response is , min response is .
max gradient is 5.068042, min gradient is -8.000000, learning rate is 0.044661
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.170039, learning rate is 0.044661
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -4.686285, min gradient is -8.000000, learning rate is 0.000747
Net2: layer deconv3:max response is 10.988196, min response is -18.300598.
max gradient is 4.476340, min gradient is -8.000000, learning rate is 0.000374
Net2: layer bn50:max response is 17.263386, min response is -2.584580.
max gradient is 8.000000, min gradient is -2.357450, learning rate is 0.000747
Net2: layer deconv2:max response is , min response is .
max gradient is 7.190678, min gradient is -8.000000, learning rate is 0.000374
Net2: layer bn49:max response is 9.806734, min response is -1.945542.
max gradient is 3.891920, min gradient is -8.000000, learning rate is 0.000747
Net2: layer deconv1:max response is , min response is .
max gradient is 7.089145, min gradient is -8.000000, learning rate is 0.000374
max inferred z is 4.22, min inferred z is -4.10, and std is 1.00
 4.14 s (24.1 data/s) [100/100]
training: epoch 22: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.191675, min gradient is -8.000000, learning rate is 0.044661
Net1: layer conv2:max response is , min response is .
max gradient is 7.129243, min gradient is -8.000000, learning rate is 0.044661
Net1: layer conv1:max response is , min response is .
max gradient is 7.289083, min gradient is -8.000000, learning rate is 0.044661
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.459920, learning rate is 0.000747
Net2: layer deconv3:max response is 13.918946, min response is -16.444645.
max gradient is 4.648914, min gradient is -8.000000, learning rate is 0.000374
Net2: layer bn50:max response is 16.207806, min response is -2.667989.
max gradient is 6.299587, min gradient is -8.000000, learning rate is 0.000747
Net2: layer deconv2:max response is , min response is .
max gradient is 6.241525, min gradient is -8.000000, learning rate is 0.000374
Net2: layer bn49:max response is 8.200198, min response is -1.973207.
max gradient is 6.220039, min gradient is -8.000000, learning rate is 0.000747
Net2: layer deconv1:max response is , min response is .
max gradient is 6.723206, min gradient is -8.000000, learning rate is 0.000374
max inferred z is 3.83, min inferred z is -3.72, and std is 1.00
 4.15 s (24.1 data/s) [100/100]
training: epoch 22: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.135262, min gradient is -8.000001, learning rate is 0.044661
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.077307, learning rate is 0.044661
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.571892, learning rate is 0.044661
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.573295, learning rate is 0.000747
Net2: layer deconv3:max response is 13.258727, min response is -18.404751.
max gradient is 5.012432, min gradient is -8.000000, learning rate is 0.000374
Net2: layer bn50:max response is 16.740635, min response is -2.608267.
max gradient is 3.472660, min gradient is -8.000000, learning rate is 0.000747
Net2: layer deconv2:max response is , min response is .
max gradient is 7.001410, min gradient is -8.000000, learning rate is 0.000374
Net2: layer bn49:max response is 11.553245, min response is -1.893154.
max gradient is 8.000000, min gradient is -7.792274, learning rate is 0.000747
Net2: layer deconv1:max response is , min response is .
max gradient is 6.560505, min gradient is -8.000000, learning rate is 0.000374
max inferred z is 4.03, min inferred z is -4.48, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 22: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.580759, min gradient is -8.000000, learning rate is 0.044661
Net1: layer conv2:max response is , min response is .
max gradient is 4.680862, min gradient is -8.000000, learning rate is 0.044661
Net1: layer conv1:max response is , min response is .
max gradient is 4.848560, min gradient is -8.000000, learning rate is 0.044661
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.404896, learning rate is 0.000747
Net2: layer deconv3:max response is 14.108855, min response is -18.176054.
max gradient is 5.591011, min gradient is -8.000000, learning rate is 0.000374
Net2: layer bn50:max response is 18.594849, min response is -3.009613.
max gradient is 8.000000, min gradient is -2.510461, learning rate is 0.000747
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.935258, learning rate is 0.000374
Net2: layer bn49:max response is 10.427642, min response is -2.008628.
max gradient is 5.821240, min gradient is -8.000000, learning rate is 0.000747
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.835904, learning rate is 0.000374
max inferred z is 3.76, min inferred z is -3.82, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
training: epoch 22: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.943366, learning rate is 0.044661
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.980633, learning rate is 0.044661
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.528725, learning rate is 0.044661
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.064207, learning rate is 0.000747
Net2: layer deconv3:max response is 12.976939, min response is -22.762827.
max gradient is 7.069451, min gradient is -8.000000, learning rate is 0.000374
Net2: layer bn50:max response is 15.969799, min response is -3.168194.
max gradient is 8.000000, min gradient is -3.040832, learning rate is 0.000747
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.698323, learning rate is 0.000374
Net2: layer bn49:max response is 9.043795, min response is -2.235991.
max gradient is 5.781539, min gradient is -8.000000, learning rate is 0.000747
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.923299, learning rate is 0.000374
max inferred z is 3.89, min inferred z is -4.01, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 22: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.591398, learning rate is 0.044661
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.901270, learning rate is 0.044661
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.505712, learning rate is 0.044661
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.414644, learning rate is 0.000747
Net2: layer deconv3:max response is 11.898502, min response is -18.079748.
max gradient is 8.000000, min gradient is -6.493344, learning rate is 0.000374
Net2: layer bn50:max response is 15.600724, min response is -2.621069.
max gradient is 3.748960, min gradient is -8.000000, learning rate is 0.000747
Net2: layer deconv2:max response is , min response is .
max gradient is 7.832558, min gradient is -8.000000, learning rate is 0.000374
Net2: layer bn49:max response is 13.866092, min response is -2.118895.
max gradient is 6.309317, min gradient is -8.000000, learning rate is 0.000747
Net2: layer deconv1:max response is , min response is .
max gradient is 7.817288, min gradient is -8.000000, learning rate is 0.000374
max inferred z is 3.93, min inferred z is -4.28, and std is 1.00
 4.45 s (22.5 data/s) [100/100]
training: epoch 22: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.179690, learning rate is 0.044661
Net1: layer conv2:max response is , min response is .
max gradient is 4.488052, min gradient is -8.000000, learning rate is 0.044661
Net1: layer conv1:max response is , min response is .
max gradient is 4.566600, min gradient is -8.000000, learning rate is 0.044661
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.427175, learning rate is 0.000747
Net2: layer deconv3:max response is 13.349229, min response is -19.330732.
max gradient is 8.000000, min gradient is -5.795496, learning rate is 0.000374
Net2: layer bn50:max response is 14.477659, min response is -2.580132.
max gradient is 8.000000, min gradient is -7.512770, learning rate is 0.000747
Net2: layer deconv2:max response is , min response is .
max gradient is 7.436496, min gradient is -8.000000, learning rate is 0.000374
Net2: layer bn49:max response is 9.558024, min response is -1.865394.
max gradient is 8.000000, min gradient is -6.610063, learning rate is 0.000747
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.633254, learning rate is 0.000374
max inferred z is 3.74, min inferred z is -3.71, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 22: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.938733, min gradient is -8.000000, learning rate is 0.044661
Net1: layer conv2:max response is , min response is .
max gradient is 7.157886, min gradient is -8.000000, learning rate is 0.044661
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.424881, learning rate is 0.044661
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.987985, learning rate is 0.000747
Net2: layer deconv3:max response is 12.405066, min response is -17.861656.
max gradient is 8.000000, min gradient is -6.001878, learning rate is 0.000374
Net2: layer bn50:max response is 14.725279, min response is -2.865413.
max gradient is 3.614603, min gradient is -8.000000, learning rate is 0.000747
Net2: layer deconv2:max response is , min response is .
max gradient is 6.385797, min gradient is -8.000000, learning rate is 0.000374
Net2: layer bn49:max response is 11.099947, min response is -1.867615.
max gradient is 8.000000, min gradient is -4.975804, learning rate is 0.000747
Net2: layer deconv1:max response is , min response is .
max gradient is 7.574949, min gradient is -8.000000, learning rate is 0.000374
max inferred z is 4.27, min inferred z is -4.00, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 22: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.050460, learning rate is 0.044661
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.745653, learning rate is 0.044661
Net1: layer conv1:max response is , min response is .
max gradient is 3.711805, min gradient is -8.000000, learning rate is 0.044661
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.061790, min gradient is -8.000000, learning rate is 0.000747
Net2: layer deconv3:max response is 11.685808, min response is -19.945019.
max gradient is 8.000000, min gradient is -4.759513, learning rate is 0.000374
Net2: layer bn50:max response is 14.396767, min response is -2.728965.
max gradient is 8.000000, min gradient is -7.015810, learning rate is 0.000747
Net2: layer deconv2:max response is , min response is .
max gradient is 7.190395, min gradient is -8.000000, learning rate is 0.000374
Net2: layer bn49:max response is 9.677806, min response is -2.156975.
max gradient is 8.000000, min gradient is -5.205683, learning rate is 0.000747
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.242697, learning rate is 0.000374
max inferred z is 3.83, min inferred z is -4.21, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
Loss: 2.2169
Iteration 23 / 200
training: epoch 23: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.370544, min gradient is -8.000000, learning rate is 0.042132
Net1: layer conv2:max response is , min response is .
max gradient is 5.545479, min gradient is -8.000000, learning rate is 0.042132
Net1: layer conv1:max response is , min response is .
max gradient is 5.636992, min gradient is -8.000000, learning rate is 0.042132
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.369279, min gradient is -8.000000, learning rate is 0.000726
Net2: layer deconv3:max response is 11.774734, min response is -18.689718.
max gradient is 8.000000, min gradient is -5.154606, learning rate is 0.000363
Net2: layer bn50:max response is 13.977207, min response is -3.186520.
max gradient is 8.000000, min gradient is -1.495068, learning rate is 0.000726
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.639305, learning rate is 0.000363
Net2: layer bn49:max response is 9.946353, min response is -2.027921.
max gradient is 8.000000, min gradient is -5.199482, learning rate is 0.000726
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.799357, learning rate is 0.000363
max inferred z is 4.17, min inferred z is -3.81, and std is 1.01
 4.24 s (23.6 data/s) [100/100]
training: epoch 23: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.980900, learning rate is 0.042132
Net1: layer conv2:max response is , min response is .
max gradient is 5.530809, min gradient is -8.000000, learning rate is 0.042132
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.312909, learning rate is 0.042132
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000001, min gradient is -0.303353, learning rate is 0.000726
Net2: layer deconv3:max response is 11.287876, min response is -18.773464.
max gradient is 8.000000, min gradient is -5.101944, learning rate is 0.000363
Net2: layer bn50:max response is 15.511292, min response is -2.767720.
max gradient is 8.000000, min gradient is -7.565216, learning rate is 0.000726
Net2: layer deconv2:max response is , min response is .
max gradient is 7.297154, min gradient is -8.000000, learning rate is 0.000363
Net2: layer bn49:max response is 9.564217, min response is -2.639951.
max gradient is 8.000000, min gradient is -4.814925, learning rate is 0.000726
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.416958, learning rate is 0.000363
max inferred z is 3.72, min inferred z is -4.04, and std is 1.01
 4.26 s (23.5 data/s) [100/100]
training: epoch 23: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.374929, min gradient is -8.000000, learning rate is 0.042132
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.861734, learning rate is 0.042132
Net1: layer conv1:max response is , min response is .
max gradient is 5.287107, min gradient is -8.000000, learning rate is 0.042132
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.330792, min gradient is -8.000000, learning rate is 0.000726
Net2: layer deconv3:max response is 10.419493, min response is -16.931126.
max gradient is 6.949971, min gradient is -8.000000, learning rate is 0.000363
Net2: layer bn50:max response is 14.299006, min response is -2.540552.
max gradient is 8.000000, min gradient is -2.652400, learning rate is 0.000726
Net2: layer deconv2:max response is , min response is .
max gradient is 7.104492, min gradient is -8.000000, learning rate is 0.000363
Net2: layer bn49:max response is 9.969594, min response is -1.963582.
max gradient is 8.000000, min gradient is -5.547511, learning rate is 0.000726
Net2: layer deconv1:max response is , min response is .
max gradient is 6.760325, min gradient is -8.000000, learning rate is 0.000363
max inferred z is 4.00, min inferred z is -3.74, and std is 1.01
 4.34 s (23.0 data/s) [100/100]
training: epoch 23: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.532460, learning rate is 0.042132
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.554945, learning rate is 0.042132
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.586262, learning rate is 0.042132
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.765560, learning rate is 0.000726
Net2: layer deconv3:max response is 11.031691, min response is -16.462259.
max gradient is 8.000000, min gradient is -6.394816, learning rate is 0.000363
Net2: layer bn50:max response is 16.339739, min response is -2.541703.
max gradient is 3.648458, min gradient is -8.000000, learning rate is 0.000726
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.252898, learning rate is 0.000363
Net2: layer bn49:max response is 9.216842, min response is -1.848559.
max gradient is 8.000000, min gradient is -4.582751, learning rate is 0.000726
Net2: layer deconv1:max response is , min response is .
max gradient is 6.426193, min gradient is -8.000000, learning rate is 0.000363
max inferred z is 4.21, min inferred z is -4.06, and std is 1.01
 4.27 s (23.4 data/s) [100/100]
training: epoch 23: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.831638, learning rate is 0.042132
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.530199, learning rate is 0.042132
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.668167, learning rate is 0.042132
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.702859, min gradient is -8.000000, learning rate is 0.000726
Net2: layer deconv3:max response is 11.864419, min response is -17.811827.
max gradient is 6.245885, min gradient is -8.000000, learning rate is 0.000363
Net2: layer bn50:max response is 16.785501, min response is -2.735439.
max gradient is 8.000000, min gradient is -2.612060, learning rate is 0.000726
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.604772, learning rate is 0.000363
Net2: layer bn49:max response is 8.671885, min response is -1.945661.
max gradient is 7.155609, min gradient is -8.000000, learning rate is 0.000726
Net2: layer deconv1:max response is , min response is .
max gradient is 6.873794, min gradient is -8.000000, learning rate is 0.000363
max inferred z is 4.07, min inferred z is -4.13, and std is 1.01
 4.33 s (23.1 data/s) [100/100]
training: epoch 23: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.510535, min gradient is -8.000000, learning rate is 0.042132
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.974570, learning rate is 0.042132
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.907648, learning rate is 0.042132
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.646635, learning rate is 0.000726
Net2: layer deconv3:max response is 12.258919, min response is -17.925508.
max gradient is 8.000000, min gradient is -6.917398, learning rate is 0.000363
Net2: layer bn50:max response is 14.450129, min response is -2.735481.
max gradient is 8.000000, min gradient is -2.263758, learning rate is 0.000726
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.350943, learning rate is 0.000363
Net2: layer bn49:max response is 10.574088, min response is -1.706333.
max gradient is 6.722670, min gradient is -8.000000, learning rate is 0.000726
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.251832, learning rate is 0.000363
max inferred z is 4.48, min inferred z is -3.70, and std is 1.01
 4.37 s (22.9 data/s) [100/100]
training: epoch 23: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.377902, learning rate is 0.042132
Net1: layer conv2:max response is , min response is .
max gradient is 6.416965, min gradient is -8.000000, learning rate is 0.042132
Net1: layer conv1:max response is , min response is .
max gradient is 3.172488, min gradient is -8.000000, learning rate is 0.042132
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.078020, learning rate is 0.000726
Net2: layer deconv3:max response is 12.366540, min response is -17.777882.
max gradient is 8.000000, min gradient is -7.293790, learning rate is 0.000363
Net2: layer bn50:max response is 15.525680, min response is -2.514153.
max gradient is 8.000000, min gradient is -2.786657, learning rate is 0.000726
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.395710, learning rate is 0.000363
Net2: layer bn49:max response is 10.798337, min response is -1.941048.
max gradient is 5.500191, min gradient is -8.000000, learning rate is 0.000726
Net2: layer deconv1:max response is , min response is .
max gradient is 5.300681, min gradient is -8.000000, learning rate is 0.000363
max inferred z is 4.96, min inferred z is -3.97, and std is 1.01
 4.27 s (23.4 data/s) [100/100]
training: epoch 23: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.093596, learning rate is 0.042132
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.443697, learning rate is 0.042132
Net1: layer conv1:max response is , min response is .
max gradient is 7.316565, min gradient is -8.000000, learning rate is 0.042132
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.862428, learning rate is 0.000726
Net2: layer deconv3:max response is 10.724620, min response is -18.792423.
max gradient is 8.000000, min gradient is -5.084917, learning rate is 0.000363
Net2: layer bn50:max response is 14.671818, min response is -3.093076.
max gradient is 8.000000, min gradient is -4.635539, learning rate is 0.000726
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.202164, learning rate is 0.000363
Net2: layer bn49:max response is 10.348231, min response is -2.361770.
max gradient is 5.703115, min gradient is -8.000000, learning rate is 0.000726
Net2: layer deconv1:max response is , min response is .
max gradient is 7.954100, min gradient is -8.000000, learning rate is 0.000363
max inferred z is 4.46, min inferred z is -3.69, and std is 1.01
 4.24 s (23.6 data/s) [100/100]
training: epoch 23: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.493476, learning rate is 0.042132
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.521046, learning rate is 0.042132
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -5.260854, learning rate is 0.042132
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.158979, learning rate is 0.000726
Net2: layer deconv3:max response is 11.839527, min response is -22.438089.
max gradient is 8.000000, min gradient is -4.156723, learning rate is 0.000363
Net2: layer bn50:max response is 15.878618, min response is -2.541178.
max gradient is 3.103290, min gradient is -8.000000, learning rate is 0.000726
Net2: layer deconv2:max response is , min response is .
max gradient is 7.557608, min gradient is -8.000000, learning rate is 0.000363
Net2: layer bn49:max response is 10.803845, min response is -1.688342.
max gradient is 6.411685, min gradient is -8.000000, learning rate is 0.000726
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.817719, learning rate is 0.000363
max inferred z is 4.09, min inferred z is -4.21, and std is 1.01
 4.33 s (23.1 data/s) [100/100]
training: epoch 23: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.777011, learning rate is 0.042132
Net1: layer conv2:max response is , min response is .
max gradient is 4.934188, min gradient is -8.000000, learning rate is 0.042132
Net1: layer conv1:max response is , min response is .
max gradient is 5.250944, min gradient is -8.000000, learning rate is 0.042132
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.853759, min gradient is -8.000000, learning rate is 0.000726
Net2: layer deconv3:max response is 11.000203, min response is -17.268356.
max gradient is 8.000000, min gradient is -4.644578, learning rate is 0.000363
Net2: layer bn50:max response is 13.711403, min response is -2.725019.
max gradient is 8.000000, min gradient is -2.033553, learning rate is 0.000726
Net2: layer deconv2:max response is , min response is .
max gradient is 6.741821, min gradient is -8.000000, learning rate is 0.000363
Net2: layer bn49:max response is 11.077875, min response is -1.981271.
max gradient is 4.475862, min gradient is -8.000000, learning rate is 0.000726
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.879132, learning rate is 0.000363
max inferred z is 3.91, min inferred z is -3.69, and std is 1.01
 4.26 s (23.5 data/s) [100/100]
Loss: 2.1095
Iteration 24 / 200
training: epoch 24: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.768090, min gradient is -8.000000, learning rate is 0.042132
Net1: layer conv2:max response is , min response is .
max gradient is 4.198482, min gradient is -8.000000, learning rate is 0.042132
Net1: layer conv1:max response is , min response is .
max gradient is 4.073943, min gradient is -8.000000, learning rate is 0.042132
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.333345, min gradient is -8.000000, learning rate is 0.000726
Net2: layer deconv3:max response is 11.453440, min response is -16.387981.
max gradient is 8.000000, min gradient is -5.144427, learning rate is 0.000363
Net2: layer bn50:max response is 13.373995, min response is -2.853069.
max gradient is 8.000000, min gradient is -1.505866, learning rate is 0.000726
Net2: layer deconv2:max response is , min response is .
max gradient is 5.323162, min gradient is -8.000000, learning rate is 0.000363
Net2: layer bn49:max response is 8.507221, min response is -1.914237.
max gradient is 3.322257, min gradient is -8.000000, learning rate is 0.000726
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.503129, learning rate is 0.000363
max inferred z is 3.66, min inferred z is -4.13, and std is 1.00
 4.28 s (23.4 data/s) [100/100]
training: epoch 24: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.567115, min gradient is -8.000000, learning rate is 0.042132
Net1: layer conv2:max response is , min response is .
max gradient is 6.185924, min gradient is -8.000000, learning rate is 0.042132
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.303614, learning rate is 0.042132
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.749826, learning rate is 0.000726
Net2: layer deconv3:max response is 11.977724, min response is -15.881133.
max gradient is 6.159075, min gradient is -8.000000, learning rate is 0.000363
Net2: layer bn50:max response is 14.485464, min response is -2.731974.
max gradient is 7.738605, min gradient is -8.000000, learning rate is 0.000726
Net2: layer deconv2:max response is , min response is .
max gradient is 5.679965, min gradient is -8.000000, learning rate is 0.000363
Net2: layer bn49:max response is 9.086595, min response is -2.000559.
max gradient is 4.187582, min gradient is -8.000000, learning rate is 0.000726
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.185872, learning rate is 0.000363
max inferred z is 4.25, min inferred z is -3.97, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
training: epoch 24: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.974752, min gradient is -8.000001, learning rate is 0.042132
Net1: layer conv2:max response is , min response is .
max gradient is 5.694630, min gradient is -8.000000, learning rate is 0.042132
Net1: layer conv1:max response is , min response is .
max gradient is 5.324879, min gradient is -8.000000, learning rate is 0.042132
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 3.477559, min gradient is -8.000000, learning rate is 0.000726
Net2: layer deconv3:max response is 13.425591, min response is -18.602509.
max gradient is 5.153501, min gradient is -8.000000, learning rate is 0.000363
Net2: layer bn50:max response is 15.181758, min response is -3.002080.
max gradient is 8.000000, min gradient is -4.697204, learning rate is 0.000726
Net2: layer deconv2:max response is , min response is .
max gradient is 5.614461, min gradient is -8.000000, learning rate is 0.000363
Net2: layer bn49:max response is 8.646811, min response is -1.917321.
max gradient is 4.528507, min gradient is -8.000000, learning rate is 0.000726
Net2: layer deconv1:max response is , min response is .
max gradient is 7.740627, min gradient is -8.000000, learning rate is 0.000363
max inferred z is 4.63, min inferred z is -3.62, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 24: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.978647, min gradient is -8.000000, learning rate is 0.042132
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.548718, learning rate is 0.042132
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.814327, learning rate is 0.042132
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.534712, learning rate is 0.000726
Net2: layer deconv3:max response is 12.581068, min response is -16.081486.
max gradient is 5.782632, min gradient is -8.000000, learning rate is 0.000363
Net2: layer bn50:max response is 15.193634, min response is -2.871496.
max gradient is 4.447208, min gradient is -8.000000, learning rate is 0.000726
Net2: layer deconv2:max response is , min response is .
max gradient is 6.583332, min gradient is -8.000000, learning rate is 0.000363
Net2: layer bn49:max response is 8.754638, min response is -1.769535.
max gradient is 5.599934, min gradient is -8.000000, learning rate is 0.000726
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.566942, learning rate is 0.000363
max inferred z is 4.19, min inferred z is -3.68, and std is 1.00
 4.21 s (23.7 data/s) [100/100]
training: epoch 24: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.724416, min gradient is -8.000000, learning rate is 0.042132
Net1: layer conv2:max response is , min response is .
max gradient is 6.601327, min gradient is -8.000000, learning rate is 0.042132
Net1: layer conv1:max response is , min response is .
max gradient is 6.052823, min gradient is -8.000001, learning rate is 0.042132
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.005751, learning rate is 0.000726
Net2: layer deconv3:max response is 12.455933, min response is -18.322163.
max gradient is 5.490643, min gradient is -8.000000, learning rate is 0.000363
Net2: layer bn50:max response is 15.430651, min response is -2.724641.
max gradient is 8.000000, min gradient is -1.818100, learning rate is 0.000726
Net2: layer deconv2:max response is , min response is .
max gradient is 7.400851, min gradient is -8.000000, learning rate is 0.000363
Net2: layer bn49:max response is 8.662598, min response is -1.976459.
max gradient is 4.297880, min gradient is -8.000000, learning rate is 0.000726
Net2: layer deconv1:max response is , min response is .
max gradient is 6.555641, min gradient is -8.000000, learning rate is 0.000363
max inferred z is 4.05, min inferred z is -4.11, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 24: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.762911, learning rate is 0.042132
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.096545, learning rate is 0.042132
Net1: layer conv1:max response is , min response is .
max gradient is 7.908856, min gradient is -8.000000, learning rate is 0.042132
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.865182, learning rate is 0.000726
Net2: layer deconv3:max response is 12.263766, min response is -19.143663.
max gradient is 7.997416, min gradient is -8.000000, learning rate is 0.000363
Net2: layer bn50:max response is 13.817061, min response is -2.738762.
max gradient is 5.069506, min gradient is -8.000000, learning rate is 0.000726
Net2: layer deconv2:max response is , min response is .
max gradient is 6.773254, min gradient is -8.000000, learning rate is 0.000363
Net2: layer bn49:max response is 9.348737, min response is -1.860984.
max gradient is 3.345207, min gradient is -8.000000, learning rate is 0.000726
Net2: layer deconv1:max response is , min response is .
max gradient is 6.943429, min gradient is -8.000000, learning rate is 0.000363
max inferred z is 4.21, min inferred z is -4.09, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 24: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.405178, learning rate is 0.042132
Net1: layer conv2:max response is , min response is .
max gradient is 7.727920, min gradient is -8.000000, learning rate is 0.042132
Net1: layer conv1:max response is , min response is .
max gradient is 5.716637, min gradient is -8.000000, learning rate is 0.042132
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.026448, learning rate is 0.000726
Net2: layer deconv3:max response is 12.723983, min response is -20.231255.
max gradient is 6.514971, min gradient is -8.000000, learning rate is 0.000363
Net2: layer bn50:max response is 14.881162, min response is -2.549048.
max gradient is 7.822565, min gradient is -8.000000, learning rate is 0.000726
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.617972, learning rate is 0.000363
Net2: layer bn49:max response is 8.272325, min response is -2.389200.
max gradient is 2.842370, min gradient is -8.000000, learning rate is 0.000726
Net2: layer deconv1:max response is , min response is .
max gradient is 7.971133, min gradient is -8.000000, learning rate is 0.000363
max inferred z is 4.39, min inferred z is -3.84, and std is 1.00
 4.41 s (22.7 data/s) [100/100]
training: epoch 24: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.499944, learning rate is 0.042132
Net1: layer conv2:max response is , min response is .
max gradient is 5.448676, min gradient is -8.000000, learning rate is 0.042132
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.145149, learning rate is 0.042132
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.253042, learning rate is 0.000726
Net2: layer deconv3:max response is 14.658504, min response is -18.413620.
max gradient is 8.000000, min gradient is -7.867224, learning rate is 0.000363
Net2: layer bn50:max response is 13.521077, min response is -2.468921.
max gradient is 3.304579, min gradient is -8.000000, learning rate is 0.000726
Net2: layer deconv2:max response is , min response is .
max gradient is 7.970633, min gradient is -8.000000, learning rate is 0.000363
Net2: layer bn49:max response is 9.203614, min response is -2.142022.
max gradient is 4.383011, min gradient is -8.000000, learning rate is 0.000726
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.020139, learning rate is 0.000363
max inferred z is 4.39, min inferred z is -3.65, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 24: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.382954, min gradient is -8.000000, learning rate is 0.042132
Net1: layer conv2:max response is , min response is .
max gradient is 7.777787, min gradient is -8.000000, learning rate is 0.042132
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.683635, learning rate is 0.042132
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.714180, learning rate is 0.000726
Net2: layer deconv3:max response is 15.225615, min response is -19.932590.
max gradient is 8.000001, min gradient is -5.949631, learning rate is 0.000363
Net2: layer bn50:max response is 15.354807, min response is -2.974744.
max gradient is 3.058590, min gradient is -8.000000, learning rate is 0.000726
Net2: layer deconv2:max response is , min response is .
max gradient is 7.775609, min gradient is -8.000000, learning rate is 0.000363
Net2: layer bn49:max response is 8.440344, min response is -1.774153.
max gradient is 7.420538, min gradient is -8.000000, learning rate is 0.000726
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.985377, learning rate is 0.000363
max inferred z is 4.41, min inferred z is -4.46, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 24: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.067603, learning rate is 0.042132
Net1: layer conv2:max response is , min response is .
max gradient is 7.228384, min gradient is -8.000000, learning rate is 0.042132
Net1: layer conv1:max response is , min response is .
max gradient is 4.755953, min gradient is -8.000000, learning rate is 0.042132
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.458575, min gradient is -8.000000, learning rate is 0.000726
Net2: layer deconv3:max response is 14.812395, min response is -17.588161.
max gradient is 8.000000, min gradient is -5.831696, learning rate is 0.000363
Net2: layer bn50:max response is 15.864228, min response is -2.954473.
max gradient is 2.902352, min gradient is -8.000000, learning rate is 0.000726
Net2: layer deconv2:max response is , min response is .
max gradient is 7.740448, min gradient is -8.000000, learning rate is 0.000363
Net2: layer bn49:max response is 7.593791, min response is -1.620528.
max gradient is 7.583405, min gradient is -8.000000, learning rate is 0.000726
Net2: layer deconv1:max response is , min response is .
max gradient is 7.908233, min gradient is -8.000000, learning rate is 0.000363
max inferred z is 3.99, min inferred z is -3.77, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
Loss: 2.1813
Iteration 25 / 200
training: epoch 25: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.511864, learning rate is 0.039746
Net1: layer conv2:max response is , min response is .
max gradient is 6.829465, min gradient is -8.000000, learning rate is 0.039746
Net1: layer conv1:max response is , min response is .
max gradient is 6.727577, min gradient is -8.000000, learning rate is 0.039746
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.631342, min gradient is -8.000000, learning rate is 0.000705
Net2: layer deconv3:max response is 12.416163, min response is -20.275997.
max gradient is 8.000000, min gradient is -5.377705, learning rate is 0.000352
Net2: layer bn50:max response is 14.058789, min response is -3.191169.
max gradient is 8.000000, min gradient is -1.928827, learning rate is 0.000705
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.080256, learning rate is 0.000352
Net2: layer bn49:max response is 8.640971, min response is -2.129578.
max gradient is 8.000000, min gradient is -6.338753, learning rate is 0.000705
Net2: layer deconv1:max response is , min response is .
max gradient is 7.847555, min gradient is -8.000000, learning rate is 0.000352
max inferred z is 4.39, min inferred z is -4.24, and std is 1.00
 4.16 s (24.1 data/s) [100/100]
training: epoch 25: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.712916, min gradient is -8.000000, learning rate is 0.039746
Net1: layer conv2:max response is , min response is .
max gradient is 5.901057, min gradient is -8.000000, learning rate is 0.039746
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.431757, learning rate is 0.039746
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.341410, learning rate is 0.000705
Net2: layer deconv3:max response is 13.720895, min response is -19.523794.
max gradient is 5.571679, min gradient is -8.000000, learning rate is 0.000352
Net2: layer bn50:max response is 14.505861, min response is -2.682569.
max gradient is 1.512689, min gradient is -8.000000, learning rate is 0.000705
Net2: layer deconv2:max response is , min response is .
max gradient is 7.357600, min gradient is -8.000000, learning rate is 0.000352
Net2: layer bn49:max response is 7.711666, min response is -1.970929.
max gradient is 8.000000, min gradient is -3.787276, learning rate is 0.000705
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.896469, learning rate is 0.000352
max inferred z is 3.65, min inferred z is -4.03, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
training: epoch 25: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.597491, learning rate is 0.039746
Net1: layer conv2:max response is , min response is .
max gradient is 6.411540, min gradient is -8.000000, learning rate is 0.039746
Net1: layer conv1:max response is , min response is .
max gradient is 4.222719, min gradient is -8.000001, learning rate is 0.039746
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.838330, min gradient is -8.000000, learning rate is 0.000705
Net2: layer deconv3:max response is 13.798283, min response is -20.919016.
max gradient is 7.276731, min gradient is -8.000000, learning rate is 0.000352
Net2: layer bn50:max response is 16.448954, min response is -2.728695.
max gradient is 8.000000, min gradient is -7.995262, learning rate is 0.000705
Net2: layer deconv2:max response is , min response is .
max gradient is 7.060686, min gradient is -8.000000, learning rate is 0.000352
Net2: layer bn49:max response is 7.783869, min response is -2.017356.
max gradient is 8.000000, min gradient is -4.758339, learning rate is 0.000705
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.856663, learning rate is 0.000352
max inferred z is 4.05, min inferred z is -3.99, and std is 1.00
 4.32 s (23.2 data/s) [100/100]
training: epoch 25: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.850120, min gradient is -8.000000, learning rate is 0.039746
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.718231, learning rate is 0.039746
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.313391, learning rate is 0.039746
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.031877, learning rate is 0.000705
Net2: layer deconv3:max response is 10.827204, min response is -18.392433.
max gradient is 7.611892, min gradient is -8.000000, learning rate is 0.000352
Net2: layer bn50:max response is 13.259209, min response is -3.054140.
max gradient is 4.305655, min gradient is -8.000000, learning rate is 0.000705
Net2: layer deconv2:max response is , min response is .
max gradient is 6.986327, min gradient is -8.000000, learning rate is 0.000352
Net2: layer bn49:max response is 9.027133, min response is -1.567066.
max gradient is 8.000000, min gradient is -5.193364, learning rate is 0.000705
Net2: layer deconv1:max response is , min response is .
max gradient is 6.543898, min gradient is -8.000000, learning rate is 0.000352
max inferred z is 3.97, min inferred z is -4.23, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 25: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.496735, learning rate is 0.039746
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.910231, learning rate is 0.039746
Net1: layer conv1:max response is , min response is .
max gradient is 5.168251, min gradient is -8.000000, learning rate is 0.039746
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.435672, min gradient is -8.000000, learning rate is 0.000705
Net2: layer deconv3:max response is 11.441882, min response is -18.221914.
max gradient is 5.722386, min gradient is -8.000000, learning rate is 0.000352
Net2: layer bn50:max response is 12.843061, min response is -2.793166.
max gradient is 8.000000, min gradient is -2.148762, learning rate is 0.000705
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.939879, learning rate is 0.000352
Net2: layer bn49:max response is 8.151446, min response is -2.262741.
max gradient is 8.000000, min gradient is -7.320140, learning rate is 0.000705
Net2: layer deconv1:max response is , min response is .
max gradient is 7.351942, min gradient is -8.000000, learning rate is 0.000352
max inferred z is 3.68, min inferred z is -4.09, and std is 1.00
 4.51 s (22.2 data/s) [100/100]
training: epoch 25: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.899531, learning rate is 0.039746
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.188197, learning rate is 0.039746
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.396900, learning rate is 0.039746
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.751698, learning rate is 0.000705
Net2: layer deconv3:max response is 11.537994, min response is -20.650206.
max gradient is 4.878015, min gradient is -8.000000, learning rate is 0.000352
Net2: layer bn50:max response is 13.491869, min response is -3.302233.
max gradient is 8.000000, min gradient is -1.756554, learning rate is 0.000705
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.741031, learning rate is 0.000352
Net2: layer bn49:max response is 8.871963, min response is -2.003308.
max gradient is 8.000000, min gradient is -6.460996, learning rate is 0.000705
Net2: layer deconv1:max response is , min response is .
max gradient is 6.402090, min gradient is -8.000000, learning rate is 0.000352
max inferred z is 4.49, min inferred z is -4.70, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 25: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.012883, learning rate is 0.039746
Net1: layer conv2:max response is , min response is .
max gradient is 7.029479, min gradient is -8.000000, learning rate is 0.039746
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.861161, learning rate is 0.039746
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.670866, learning rate is 0.000705
Net2: layer deconv3:max response is 11.377829, min response is -20.764313.
max gradient is 7.762668, min gradient is -8.000000, learning rate is 0.000352
Net2: layer bn50:max response is 13.930957, min response is -2.897998.
max gradient is 8.000000, min gradient is -1.813710, learning rate is 0.000705
Net2: layer deconv2:max response is , min response is .
max gradient is 7.016998, min gradient is -8.000000, learning rate is 0.000352
Net2: layer bn49:max response is 8.336046, min response is -1.837736.
max gradient is 5.684045, min gradient is -8.000000, learning rate is 0.000705
Net2: layer deconv1:max response is , min response is .
max gradient is 6.705884, min gradient is -8.000000, learning rate is 0.000352
max inferred z is 3.95, min inferred z is -3.81, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 25: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.121534, learning rate is 0.039746
Net1: layer conv2:max response is , min response is .
max gradient is 7.946517, min gradient is -8.000000, learning rate is 0.039746
Net1: layer conv1:max response is , min response is .
max gradient is 5.315125, min gradient is -8.000000, learning rate is 0.039746
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.555682, learning rate is 0.000705
Net2: layer deconv3:max response is 12.617733, min response is -19.377211.
max gradient is 7.408967, min gradient is -8.000000, learning rate is 0.000352
Net2: layer bn50:max response is 13.988558, min response is -2.441675.
max gradient is 8.000000, min gradient is -3.765385, learning rate is 0.000705
Net2: layer deconv2:max response is , min response is .
max gradient is 7.829202, min gradient is -8.000000, learning rate is 0.000352
Net2: layer bn49:max response is 8.228163, min response is -1.954193.
max gradient is 5.652492, min gradient is -8.000000, learning rate is 0.000705
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.954442, learning rate is 0.000352
max inferred z is 4.22, min inferred z is -3.99, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 25: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.439104, learning rate is 0.039746
Net1: layer conv2:max response is , min response is .
max gradient is 7.994505, min gradient is -8.000000, learning rate is 0.039746
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.853334, learning rate is 0.039746
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.750500, learning rate is 0.000705
Net2: layer deconv3:max response is 11.491628, min response is -18.143538.
max gradient is 8.000000, min gradient is -5.587766, learning rate is 0.000352
Net2: layer bn50:max response is 13.707508, min response is -2.391463.
max gradient is 5.777849, min gradient is -8.000000, learning rate is 0.000705
Net2: layer deconv2:max response is , min response is .
max gradient is 5.151095, min gradient is -8.000000, learning rate is 0.000352
Net2: layer bn49:max response is 8.629836, min response is -1.773843.
max gradient is 4.835930, min gradient is -8.000000, learning rate is 0.000705
Net2: layer deconv1:max response is , min response is .
max gradient is 7.100111, min gradient is -8.000000, learning rate is 0.000352
max inferred z is 3.82, min inferred z is -4.37, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 25: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.703348, learning rate is 0.039746
Net1: layer conv2:max response is , min response is .
max gradient is 7.309808, min gradient is -8.000000, learning rate is 0.039746
Net1: layer conv1:max response is , min response is .
max gradient is 3.359633, min gradient is -8.000000, learning rate is 0.039746
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.062070, min gradient is -8.000000, learning rate is 0.000705
Net2: layer deconv3:max response is 15.623821, min response is -23.163206.
max gradient is 6.930230, min gradient is -8.000000, learning rate is 0.000352
Net2: layer bn50:max response is 20.623079, min response is -4.034146.
max gradient is 8.000000, min gradient is -1.931019, learning rate is 0.000705
Net2: layer deconv2:max response is , min response is .
max gradient is 5.479867, min gradient is -8.000000, learning rate is 0.000352
Net2: layer bn49:max response is 8.415028, min response is -1.845303.
max gradient is 3.886029, min gradient is -8.000000, learning rate is 0.000705
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.819302, learning rate is 0.000352
max inferred z is 4.32, min inferred z is -4.01, and std is 1.00
 4.46 s (22.4 data/s) [100/100]
Loss: 2.069
Iteration 26 / 200
training: epoch 26: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.792688, min gradient is -8.000000, learning rate is 0.039746
Net1: layer conv2:max response is , min response is .
max gradient is 5.121696, min gradient is -8.000000, learning rate is 0.039746
Net1: layer conv1:max response is , min response is .
max gradient is 4.115804, min gradient is -8.000000, learning rate is 0.039746
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.814701, min gradient is -8.000000, learning rate is 0.000705
Net2: layer deconv3:max response is 13.492832, min response is -18.417839.
max gradient is 6.044811, min gradient is -8.000000, learning rate is 0.000352
Net2: layer bn50:max response is 13.837653, min response is -2.464398.
max gradient is 8.000000, min gradient is -1.486102, learning rate is 0.000705
Net2: layer deconv2:max response is , min response is .
max gradient is 6.397926, min gradient is -8.000000, learning rate is 0.000352
Net2: layer bn49:max response is 10.680420, min response is -1.777052.
max gradient is 4.311462, min gradient is -8.000000, learning rate is 0.000705
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.829895, learning rate is 0.000352
max inferred z is 4.04, min inferred z is -4.23, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
training: epoch 26: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.933950, min gradient is -8.000000, learning rate is 0.039746
Net1: layer conv2:max response is , min response is .
max gradient is 6.856335, min gradient is -8.000000, learning rate is 0.039746
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.351854, learning rate is 0.039746
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.523725, learning rate is 0.000705
Net2: layer deconv3:max response is 13.184465, min response is -18.245886.
max gradient is 6.925297, min gradient is -8.000000, learning rate is 0.000352
Net2: layer bn50:max response is 15.228374, min response is -2.908952.
max gradient is 8.000000, min gradient is -5.779471, learning rate is 0.000705
Net2: layer deconv2:max response is , min response is .
max gradient is 7.703748, min gradient is -8.000000, learning rate is 0.000352
Net2: layer bn49:max response is 8.563251, min response is -1.863128.
max gradient is 7.215948, min gradient is -8.000000, learning rate is 0.000705
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.024808, learning rate is 0.000352
max inferred z is 4.43, min inferred z is -4.00, and std is 1.00
 4.21 s (23.8 data/s) [100/100]
training: epoch 26: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.233058, learning rate is 0.039746
Net1: layer conv2:max response is , min response is .
max gradient is 5.423251, min gradient is -8.000000, learning rate is 0.039746
Net1: layer conv1:max response is , min response is .
max gradient is 6.991940, min gradient is -8.000000, learning rate is 0.039746
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.650552, min gradient is -8.000000, learning rate is 0.000705
Net2: layer deconv3:max response is 12.167681, min response is -19.828440.
max gradient is 5.802031, min gradient is -8.000000, learning rate is 0.000352
Net2: layer bn50:max response is 17.426695, min response is -2.655443.
max gradient is 8.000000, min gradient is -1.594287, learning rate is 0.000705
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.706273, learning rate is 0.000352
Net2: layer bn49:max response is 8.360892, min response is -1.578511.
max gradient is 7.987058, min gradient is -8.000000, learning rate is 0.000705
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.720928, learning rate is 0.000352
max inferred z is 4.59, min inferred z is -4.11, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 26: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.030529, min gradient is -8.000000, learning rate is 0.039746
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.451782, learning rate is 0.039746
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.082120, learning rate is 0.039746
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.841725, learning rate is 0.000705
Net2: layer deconv3:max response is 13.964743, min response is -18.602379.
max gradient is 6.898761, min gradient is -8.000000, learning rate is 0.000352
Net2: layer bn50:max response is 13.528666, min response is -2.807548.
max gradient is 8.000000, min gradient is -7.661291, learning rate is 0.000705
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.671969, learning rate is 0.000352
Net2: layer bn49:max response is 8.412127, min response is -1.833468.
max gradient is 8.000000, min gradient is -7.510251, learning rate is 0.000705
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.017994, learning rate is 0.000352
max inferred z is 3.99, min inferred z is -3.93, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 26: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.679653, learning rate is 0.039746
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.802662, learning rate is 0.039746
Net1: layer conv1:max response is , min response is .
max gradient is 4.859368, min gradient is -8.000000, learning rate is 0.039746
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.505224, learning rate is 0.000705
Net2: layer deconv3:max response is 12.584276, min response is -19.495985.
max gradient is 4.561384, min gradient is -8.000001, learning rate is 0.000352
Net2: layer bn50:max response is 14.831120, min response is -2.773143.
max gradient is 8.000000, min gradient is -1.511388, learning rate is 0.000705
Net2: layer deconv2:max response is , min response is .
max gradient is 6.813223, min gradient is -8.000000, learning rate is 0.000352
Net2: layer bn49:max response is 10.560555, min response is -1.973482.
max gradient is 6.661764, min gradient is -8.000000, learning rate is 0.000705
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.098736, learning rate is 0.000352
max inferred z is 4.22, min inferred z is -4.39, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 26: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.100860, min gradient is -8.000000, learning rate is 0.039746
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.390477, learning rate is 0.039746
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.321657, learning rate is 0.039746
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.148263, learning rate is 0.000705
Net2: layer deconv3:max response is 14.833077, min response is -18.830320.
max gradient is 4.875041, min gradient is -8.000000, learning rate is 0.000352
Net2: layer bn50:max response is 16.886023, min response is -2.844551.
max gradient is 8.000000, min gradient is -2.825537, learning rate is 0.000705
Net2: layer deconv2:max response is , min response is .
max gradient is 7.087870, min gradient is -8.000001, learning rate is 0.000352
Net2: layer bn49:max response is 8.435233, min response is -1.766268.
max gradient is 5.425197, min gradient is -8.000000, learning rate is 0.000705
Net2: layer deconv1:max response is , min response is .
max gradient is 7.786457, min gradient is -8.000000, learning rate is 0.000352
max inferred z is 3.87, min inferred z is -4.03, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 26: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.664176, min gradient is -8.000000, learning rate is 0.039746
Net1: layer conv2:max response is , min response is .
max gradient is 7.909193, min gradient is -8.000000, learning rate is 0.039746
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.082111, learning rate is 0.039746
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.525295, learning rate is 0.000705
Net2: layer deconv3:max response is 13.343950, min response is -19.424299.
max gradient is 6.490423, min gradient is -8.000000, learning rate is 0.000352
Net2: layer bn50:max response is 14.048343, min response is -2.551837.
max gradient is 8.000000, min gradient is -5.613524, learning rate is 0.000705
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.088407, learning rate is 0.000352
Net2: layer bn49:max response is 8.374575, min response is -1.810624.
max gradient is 7.126802, min gradient is -8.000000, learning rate is 0.000705
Net2: layer deconv1:max response is , min response is .
max gradient is 6.162941, min gradient is -8.000000, learning rate is 0.000352
max inferred z is 4.30, min inferred z is -4.47, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 26: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.373166, min gradient is -8.000000, learning rate is 0.039746
Net1: layer conv2:max response is , min response is .
max gradient is 4.857996, min gradient is -8.000000, learning rate is 0.039746
Net1: layer conv1:max response is , min response is .
max gradient is 3.069947, min gradient is -8.000000, learning rate is 0.039746
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.493262, learning rate is 0.000705
Net2: layer deconv3:max response is 16.148762, min response is -18.066689.
max gradient is 8.000000, min gradient is -6.518939, learning rate is 0.000352
Net2: layer bn50:max response is 16.694546, min response is -2.578394.
max gradient is 6.902284, min gradient is -8.000000, learning rate is 0.000705
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.126544, learning rate is 0.000352
Net2: layer bn49:max response is 9.445295, min response is -1.708657.
max gradient is 6.945877, min gradient is -8.000000, learning rate is 0.000705
Net2: layer deconv1:max response is , min response is .
max gradient is 7.963517, min gradient is -8.000000, learning rate is 0.000352
max inferred z is 3.93, min inferred z is -4.34, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
training: epoch 26: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.736435, learning rate is 0.039746
Net1: layer conv2:max response is , min response is .
max gradient is 7.383739, min gradient is -8.000000, learning rate is 0.039746
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.778678, learning rate is 0.039746
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.987805, learning rate is 0.000705
Net2: layer deconv3:max response is 12.979466, min response is -17.308901.
max gradient is 8.000000, min gradient is -5.657160, learning rate is 0.000352
Net2: layer bn50:max response is 15.319839, min response is -2.454882.
max gradient is 3.210256, min gradient is -8.000000, learning rate is 0.000705
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.103927, learning rate is 0.000352
Net2: layer bn49:max response is 8.710731, min response is -2.247904.
max gradient is 8.000000, min gradient is -7.333141, learning rate is 0.000705
Net2: layer deconv1:max response is , min response is .
max gradient is 7.802473, min gradient is -8.000000, learning rate is 0.000352
max inferred z is 3.96, min inferred z is -4.17, and std is 1.00
 4.34 s (23.1 data/s) [100/100]
training: epoch 26: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.788404, learning rate is 0.039746
Net1: layer conv2:max response is , min response is .
max gradient is 5.019964, min gradient is -8.000000, learning rate is 0.039746
Net1: layer conv1:max response is , min response is .
max gradient is 6.036714, min gradient is -8.000000, learning rate is 0.039746
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -4.324940, min gradient is -8.000000, learning rate is 0.000705
Net2: layer deconv3:max response is 13.627707, min response is -17.438658.
max gradient is 8.000000, min gradient is -6.794920, learning rate is 0.000352
Net2: layer bn50:max response is 15.412241, min response is -3.076913.
max gradient is 4.060791, min gradient is -8.000000, learning rate is 0.000705
Net2: layer deconv2:max response is , min response is .
max gradient is 7.938656, min gradient is -8.000000, learning rate is 0.000352
Net2: layer bn49:max response is 8.728509, min response is -1.723043.
max gradient is 5.095285, min gradient is -8.000000, learning rate is 0.000705
Net2: layer deconv1:max response is , min response is .
max gradient is 6.804842, min gradient is -8.000000, learning rate is 0.000352
max inferred z is 3.75, min inferred z is -4.27, and std is 1.00
 4.21 s (23.8 data/s) [100/100]
Loss: 2.1574
Iteration 27 / 200
training: epoch 27: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -3.657350, learning rate is 0.037495
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.131279, learning rate is 0.037495
Net1: layer conv1:max response is , min response is .
max gradient is 6.152871, min gradient is -8.000000, learning rate is 0.037495
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.079508, min gradient is -8.000000, learning rate is 0.000685
Net2: layer deconv3:max response is 12.836771, min response is -16.791283.
max gradient is 8.000000, min gradient is -5.543851, learning rate is 0.000342
Net2: layer bn50:max response is 14.881787, min response is -2.554160.
max gradient is 8.000000, min gradient is -1.056268, learning rate is 0.000685
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.288049, learning rate is 0.000342
Net2: layer bn49:max response is 9.689859, min response is -1.949244.
max gradient is 5.727518, min gradient is -8.000000, learning rate is 0.000685
Net2: layer deconv1:max response is , min response is .
max gradient is 7.072335, min gradient is -8.000000, learning rate is 0.000342
max inferred z is 3.87, min inferred z is -3.88, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 27: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.500532, min gradient is -8.000000, learning rate is 0.037495
Net1: layer conv2:max response is , min response is .
max gradient is 6.502884, min gradient is -8.000000, learning rate is 0.037495
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.918394, learning rate is 0.037495
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.608049, learning rate is 0.000685
Net2: layer deconv3:max response is 14.391953, min response is -18.639841.
max gradient is 8.000000, min gradient is -7.586977, learning rate is 0.000342
Net2: layer bn50:max response is 17.188335, min response is -2.599946.
max gradient is 5.665394, min gradient is -8.000000, learning rate is 0.000685
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.462262, learning rate is 0.000342
Net2: layer bn49:max response is 9.922206, min response is -1.733477.
max gradient is 8.000000, min gradient is -6.396078, learning rate is 0.000685
Net2: layer deconv1:max response is , min response is .
max gradient is 6.755918, min gradient is -8.000000, learning rate is 0.000342
max inferred z is 4.40, min inferred z is -4.02, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 27: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000001, min gradient is -5.972763, learning rate is 0.037495
Net1: layer conv2:max response is , min response is .
max gradient is 4.784574, min gradient is -8.000000, learning rate is 0.037495
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.221778, learning rate is 0.037495
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 4.776387, min gradient is -8.000000, learning rate is 0.000685
Net2: layer deconv3:max response is 11.035676, min response is -18.509489.
max gradient is 6.975806, min gradient is -8.000000, learning rate is 0.000342
Net2: layer bn50:max response is 14.034201, min response is -2.429316.
max gradient is 6.131641, min gradient is -8.000000, learning rate is 0.000685
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.456579, learning rate is 0.000342
Net2: layer bn49:max response is 9.733034, min response is -1.916396.
max gradient is 8.000000, min gradient is -5.036371, learning rate is 0.000685
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.406065, learning rate is 0.000342
max inferred z is 4.04, min inferred z is -3.91, and std is 1.00
 4.36 s (23.0 data/s) [100/100]
training: epoch 27: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.040828, learning rate is 0.037495
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.247141, learning rate is 0.037495
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -6.545819, learning rate is 0.037495
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -4.457444, min gradient is -8.000000, learning rate is 0.000685
Net2: layer deconv3:max response is 13.660068, min response is -16.940754.
max gradient is 8.000000, min gradient is -6.525692, learning rate is 0.000342
Net2: layer bn50:max response is 16.668900, min response is -2.932876.
max gradient is 7.198747, min gradient is -8.000000, learning rate is 0.000685
Net2: layer deconv2:max response is , min response is .
max gradient is 7.287447, min gradient is -8.000000, learning rate is 0.000342
Net2: layer bn49:max response is 9.360490, min response is -1.808895.
max gradient is 8.000000, min gradient is -7.043233, learning rate is 0.000685
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.381556, learning rate is 0.000342
max inferred z is 4.15, min inferred z is -4.03, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 27: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.290800, learning rate is 0.037495
Net1: layer conv2:max response is , min response is .
max gradient is 7.640534, min gradient is -8.000000, learning rate is 0.037495
Net1: layer conv1:max response is , min response is .
max gradient is 6.260317, min gradient is -8.000000, learning rate is 0.037495
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.492382, min gradient is -8.000000, learning rate is 0.000685
Net2: layer deconv3:max response is 12.210163, min response is -19.280035.
max gradient is 7.243907, min gradient is -8.000000, learning rate is 0.000342
Net2: layer bn50:max response is 15.464741, min response is -2.700968.
max gradient is 8.000000, min gradient is -2.825866, learning rate is 0.000685
Net2: layer deconv2:max response is , min response is .
max gradient is 7.273658, min gradient is -8.000000, learning rate is 0.000342
Net2: layer bn49:max response is 8.608434, min response is -1.836209.
max gradient is 6.642060, min gradient is -8.000000, learning rate is 0.000685
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.526393, learning rate is 0.000342
max inferred z is 4.20, min inferred z is -4.01, and std is 1.00
 4.44 s (22.5 data/s) [100/100]
training: epoch 27: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.775244, learning rate is 0.037495
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.649704, learning rate is 0.037495
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.455412, learning rate is 0.037495
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.609888, learning rate is 0.000685
Net2: layer deconv3:max response is 11.874685, min response is -18.965527.
max gradient is 5.921943, min gradient is -8.000000, learning rate is 0.000342
Net2: layer bn50:max response is 13.432679, min response is -2.602940.
max gradient is 6.234451, min gradient is -8.000000, learning rate is 0.000685
Net2: layer deconv2:max response is , min response is .
max gradient is 6.384675, min gradient is -8.000000, learning rate is 0.000342
Net2: layer bn49:max response is 10.039242, min response is -1.968850.
max gradient is 8.000000, min gradient is -7.953440, learning rate is 0.000685
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.175530, learning rate is 0.000342
max inferred z is 4.16, min inferred z is -3.88, and std is 1.00
 4.22 s (23.7 data/s) [100/100]
training: epoch 27: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.640832, learning rate is 0.037495
Net1: layer conv2:max response is , min response is .
max gradient is 7.492273, min gradient is -8.000000, learning rate is 0.037495
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.760073, learning rate is 0.037495
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.432124, learning rate is 0.000685
Net2: layer deconv3:max response is 13.176489, min response is -17.453016.
max gradient is 6.606849, min gradient is -8.000000, learning rate is 0.000342
Net2: layer bn50:max response is 15.023479, min response is -2.782740.
max gradient is 8.000000, min gradient is -1.605759, learning rate is 0.000685
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.021285, learning rate is 0.000342
Net2: layer bn49:max response is 9.532020, min response is -1.784438.
max gradient is 5.088434, min gradient is -8.000000, learning rate is 0.000685
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.373635, learning rate is 0.000342
max inferred z is 3.82, min inferred z is -3.75, and std is 1.00
 4.21 s (23.8 data/s) [100/100]
training: epoch 27: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.671529, learning rate is 0.037495
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.915776, learning rate is 0.037495
Net1: layer conv1:max response is , min response is .
max gradient is 4.004170, min gradient is -8.000000, learning rate is 0.037495
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.761912, learning rate is 0.000685
Net2: layer deconv3:max response is 12.284225, min response is -17.189140.
max gradient is 7.313124, min gradient is -8.000000, learning rate is 0.000342
Net2: layer bn50:max response is 14.248948, min response is -2.412545.
max gradient is 8.000000, min gradient is -4.125635, learning rate is 0.000685
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.327580, learning rate is 0.000342
Net2: layer bn49:max response is 10.101391, min response is -2.098898.
max gradient is 4.842813, min gradient is -8.000000, learning rate is 0.000685
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.912991, learning rate is 0.000342
max inferred z is 3.82, min inferred z is -3.95, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 27: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.581928, learning rate is 0.037495
Net1: layer conv2:max response is , min response is .
max gradient is 7.085994, min gradient is -8.000000, learning rate is 0.037495
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.545360, learning rate is 0.037495
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.032687, learning rate is 0.000685
Net2: layer deconv3:max response is 11.895263, min response is -17.112608.
max gradient is 8.000000, min gradient is -5.793876, learning rate is 0.000342
Net2: layer bn50:max response is 13.977764, min response is -2.787006.
max gradient is 3.353981, min gradient is -8.000000, learning rate is 0.000685
Net2: layer deconv2:max response is , min response is .
max gradient is 7.032807, min gradient is -8.000000, learning rate is 0.000342
Net2: layer bn49:max response is 9.693695, min response is -2.299876.
max gradient is 5.909956, min gradient is -8.000000, learning rate is 0.000685
Net2: layer deconv1:max response is , min response is .
max gradient is 6.975653, min gradient is -8.000000, learning rate is 0.000342
max inferred z is 3.78, min inferred z is -4.25, and std is 1.00
 4.49 s (22.3 data/s) [100/100]
training: epoch 27: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.886916, learning rate is 0.037495
Net1: layer conv2:max response is , min response is .
max gradient is 6.438799, min gradient is -8.000000, learning rate is 0.037495
Net1: layer conv1:max response is , min response is .
max gradient is 5.900228, min gradient is -8.000000, learning rate is 0.037495
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -4.628078, min gradient is -8.000000, learning rate is 0.000685
Net2: layer deconv3:max response is 15.130651, min response is -17.701880.
max gradient is 8.000000, min gradient is -5.646835, learning rate is 0.000342
Net2: layer bn50:max response is 16.472528, min response is -2.647513.
max gradient is 8.000000, min gradient is -6.273597, learning rate is 0.000685
Net2: layer deconv2:max response is , min response is .
max gradient is 6.815060, min gradient is -8.000000, learning rate is 0.000342
Net2: layer bn49:max response is 8.599371, min response is -1.934113.
max gradient is 4.435929, min gradient is -8.000000, learning rate is 0.000685
Net2: layer deconv1:max response is , min response is .
max gradient is 7.717791, min gradient is -8.000000, learning rate is 0.000342
max inferred z is 3.96, min inferred z is -4.21, and std is 1.00
 4.51 s (22.2 data/s) [100/100]
Loss: 2.1463
Iteration 28 / 200
training: epoch 28: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.819530, min gradient is -8.000000, learning rate is 0.037495
Net1: layer conv2:max response is , min response is .
max gradient is 4.869236, min gradient is -8.000000, learning rate is 0.037495
Net1: layer conv1:max response is , min response is .
max gradient is 2.678099, min gradient is -8.000000, learning rate is 0.037495
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.489226, min gradient is -8.000000, learning rate is 0.000685
Net2: layer deconv3:max response is 13.967544, min response is -18.232100.
max gradient is 8.000001, min gradient is -6.800696, learning rate is 0.000342
Net2: layer bn50:max response is 14.693912, min response is -2.843315.
max gradient is 8.000000, min gradient is -2.762033, learning rate is 0.000685
Net2: layer deconv2:max response is , min response is .
max gradient is 7.044264, min gradient is -8.000000, learning rate is 0.000342
Net2: layer bn49:max response is 9.346946, min response is -2.251281.
max gradient is 3.953649, min gradient is -8.000000, learning rate is 0.000685
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.804304, learning rate is 0.000342
max inferred z is 4.13, min inferred z is -3.81, and std is 0.99
 4.18 s (23.9 data/s) [100/100]
training: epoch 28: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.591819, min gradient is -8.000000, learning rate is 0.037495
Net1: layer conv2:max response is , min response is .
max gradient is 6.559730, min gradient is -8.000000, learning rate is 0.037495
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.183211, learning rate is 0.037495
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 1.141029, min gradient is -8.000000, learning rate is 0.000685
Net2: layer deconv3:max response is 12.947355, min response is -16.975039.
max gradient is 8.000000, min gradient is -7.904769, learning rate is 0.000342
Net2: layer bn50:max response is 14.064763, min response is -2.485352.
max gradient is 8.000000, min gradient is -5.831180, learning rate is 0.000685
Net2: layer deconv2:max response is , min response is .
max gradient is 6.401034, min gradient is -8.000000, learning rate is 0.000342
Net2: layer bn49:max response is 9.584568, min response is -1.891285.
max gradient is 5.452640, min gradient is -8.000000, learning rate is 0.000685
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.234441, learning rate is 0.000342
max inferred z is 3.68, min inferred z is -4.27, and std is 0.99
 4.30 s (23.2 data/s) [100/100]
training: epoch 28: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.277622, learning rate is 0.037495
Net1: layer conv2:max response is , min response is .
max gradient is 5.355827, min gradient is -8.000000, learning rate is 0.037495
Net1: layer conv1:max response is , min response is .
max gradient is 5.288193, min gradient is -8.000000, learning rate is 0.037495
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.552866, min gradient is -8.000000, learning rate is 0.000685
Net2: layer deconv3:max response is 12.595164, min response is -18.196220.
max gradient is 6.873630, min gradient is -8.000000, learning rate is 0.000342
Net2: layer bn50:max response is 15.251023, min response is -2.771407.
max gradient is 8.000000, min gradient is -1.491934, learning rate is 0.000685
Net2: layer deconv2:max response is , min response is .
max gradient is 6.052355, min gradient is -8.000000, learning rate is 0.000342
Net2: layer bn49:max response is 9.620973, min response is -2.083218.
max gradient is 6.481874, min gradient is -8.000000, learning rate is 0.000685
Net2: layer deconv1:max response is , min response is .
max gradient is 7.378609, min gradient is -8.000000, learning rate is 0.000342
max inferred z is 3.71, min inferred z is -3.66, and std is 0.99
 4.33 s (23.1 data/s) [100/100]
training: epoch 28: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.010790, min gradient is -8.000000, learning rate is 0.037495
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.041017, learning rate is 0.037495
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.857183, learning rate is 0.037495
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 0.639817, learning rate is 0.000685
Net2: layer deconv3:max response is 13.813915, min response is -18.877438.
max gradient is 6.425458, min gradient is -8.000000, learning rate is 0.000342
Net2: layer bn50:max response is 16.016098, min response is -2.834693.
max gradient is 8.000000, min gradient is -5.682396, learning rate is 0.000685
Net2: layer deconv2:max response is , min response is .
max gradient is 7.240826, min gradient is -8.000000, learning rate is 0.000342
Net2: layer bn49:max response is 9.813775, min response is -1.958021.
max gradient is 8.000000, min gradient is -6.152211, learning rate is 0.000685
Net2: layer deconv1:max response is , min response is .
max gradient is 6.090003, min gradient is -8.000000, learning rate is 0.000342
max inferred z is 3.83, min inferred z is -3.62, and std is 0.99
 4.42 s (22.6 data/s) [100/100]
training: epoch 28: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.918457, min gradient is -8.000000, learning rate is 0.037495
Net1: layer conv2:max response is , min response is .
max gradient is 6.887861, min gradient is -8.000000, learning rate is 0.037495
Net1: layer conv1:max response is , min response is .
max gradient is 5.083898, min gradient is -8.000000, learning rate is 0.037495
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 0.583472, min gradient is -8.000000, learning rate is 0.000685
Net2: layer deconv3:max response is 13.688819, min response is -19.186081.
max gradient is 7.125769, min gradient is -8.000000, learning rate is 0.000342
Net2: layer bn50:max response is 15.486539, min response is -2.515197.
max gradient is 8.000000, min gradient is -1.323472, learning rate is 0.000685
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.383601, learning rate is 0.000342
Net2: layer bn49:max response is 10.518279, min response is -2.182916.
max gradient is 7.530476, min gradient is -8.000000, learning rate is 0.000685
Net2: layer deconv1:max response is , min response is .
max gradient is 7.744424, min gradient is -8.000000, learning rate is 0.000342
max inferred z is 4.07, min inferred z is -4.27, and std is 0.99
 4.41 s (22.7 data/s) [100/100]
training: epoch 28: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.078690, min gradient is -8.000000, learning rate is 0.037495
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.284902, learning rate is 0.037495
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.875334, learning rate is 0.037495
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.333275, learning rate is 0.000685
Net2: layer deconv3:max response is 14.819708, min response is -21.198370.
max gradient is 6.534437, min gradient is -8.000000, learning rate is 0.000342
Net2: layer bn50:max response is 16.437513, min response is -3.005607.
max gradient is 8.000000, min gradient is -1.133308, learning rate is 0.000685
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.903268, learning rate is 0.000342
Net2: layer bn49:max response is 8.594604, min response is -2.287300.
max gradient is 7.371313, min gradient is -8.000000, learning rate is 0.000685
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.893490, learning rate is 0.000342
max inferred z is 3.77, min inferred z is -4.03, and std is 0.99
 4.42 s (22.6 data/s) [100/100]
training: epoch 28: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.748406, learning rate is 0.037495
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.511358, learning rate is 0.037495
Net1: layer conv1:max response is , min response is .
max gradient is 6.817447, min gradient is -8.000000, learning rate is 0.037495
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.455736, learning rate is 0.000685
Net2: layer deconv3:max response is 13.180490, min response is -19.277514.
max gradient is 4.712136, min gradient is -8.000000, learning rate is 0.000342
Net2: layer bn50:max response is 13.886769, min response is -2.856946.
max gradient is 8.000000, min gradient is -1.373528, learning rate is 0.000685
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.462524, learning rate is 0.000342
Net2: layer bn49:max response is 10.140880, min response is -2.035494.
max gradient is 7.476568, min gradient is -8.000000, learning rate is 0.000685
Net2: layer deconv1:max response is , min response is .
max gradient is 7.109048, min gradient is -8.000000, learning rate is 0.000342
max inferred z is 3.84, min inferred z is -3.87, and std is 0.99
 4.33 s (23.1 data/s) [100/100]
training: epoch 28: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.109915, learning rate is 0.037495
Net1: layer conv2:max response is , min response is .
max gradient is 5.434778, min gradient is -8.000000, learning rate is 0.037495
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.021636, learning rate is 0.037495
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.982272, learning rate is 0.000685
Net2: layer deconv3:max response is 13.572659, min response is -19.900061.
max gradient is 5.539991, min gradient is -8.000000, learning rate is 0.000342
Net2: layer bn50:max response is 16.152630, min response is -2.594830.
max gradient is 8.000000, min gradient is -6.765671, learning rate is 0.000685
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.153700, learning rate is 0.000342
Net2: layer bn49:max response is 10.703626, min response is -1.716638.
max gradient is 8.000000, min gradient is -5.169615, learning rate is 0.000685
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.116205, learning rate is 0.000342
max inferred z is 4.34, min inferred z is -3.80, and std is 0.99
 4.17 s (24.0 data/s) [100/100]
training: epoch 28: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.132696, learning rate is 0.037495
Net1: layer conv2:max response is , min response is .
max gradient is 7.912552, min gradient is -8.000000, learning rate is 0.037495
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.093051, learning rate is 0.037495
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.180498, learning rate is 0.000685
Net2: layer deconv3:max response is 15.224503, min response is -20.552799.
max gradient is 8.000000, min gradient is -6.942035, learning rate is 0.000342
Net2: layer bn50:max response is 17.080635, min response is -2.829841.
max gradient is 3.552792, min gradient is -8.000000, learning rate is 0.000685
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.695006, learning rate is 0.000342
Net2: layer bn49:max response is 8.674385, min response is -1.749470.
max gradient is 8.000000, min gradient is -5.018514, learning rate is 0.000685
Net2: layer deconv1:max response is , min response is .
max gradient is 7.800297, min gradient is -8.000000, learning rate is 0.000342
max inferred z is 4.02, min inferred z is -4.07, and std is 0.99
 4.38 s (22.9 data/s) [100/100]
training: epoch 28: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.047883, learning rate is 0.037495
Net1: layer conv2:max response is , min response is .
max gradient is 5.198199, min gradient is -8.000000, learning rate is 0.037495
Net1: layer conv1:max response is , min response is .
max gradient is 4.243793, min gradient is -8.000000, learning rate is 0.037495
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -2.209806, min gradient is -8.000000, learning rate is 0.000685
Net2: layer deconv3:max response is 12.943137, min response is -18.467825.
max gradient is 8.000000, min gradient is -7.129107, learning rate is 0.000342
Net2: layer bn50:max response is 14.890594, min response is -2.535795.
max gradient is 2.813725, min gradient is -8.000000, learning rate is 0.000685
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.572290, learning rate is 0.000342
Net2: layer bn49:max response is 9.060727, min response is -1.809668.
max gradient is 8.000000, min gradient is -7.630078, learning rate is 0.000685
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.882079, learning rate is 0.000342
max inferred z is 4.73, min inferred z is -3.64, and std is 0.99
 4.38 s (22.8 data/s) [100/100]
Loss: 2.2439
Iteration 29 / 200
training: epoch 29: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.959734, min gradient is -8.000000, learning rate is 0.035372
Net1: layer conv2:max response is , min response is .
max gradient is 5.085923, min gradient is -8.000000, learning rate is 0.035372
Net1: layer conv1:max response is , min response is .
max gradient is 6.049804, min gradient is -8.000000, learning rate is 0.035372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.700804, min gradient is -8.000000, learning rate is 0.000665
Net2: layer deconv3:max response is 18.107084, min response is -18.715525.
max gradient is 8.000000, min gradient is -5.177698, learning rate is 0.000332
Net2: layer bn50:max response is 21.149746, min response is -3.403155.
max gradient is 8.000000, min gradient is -2.813215, learning rate is 0.000665
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.416291, learning rate is 0.000332
Net2: layer bn49:max response is 8.858553, min response is -2.152827.
max gradient is 6.838715, min gradient is -8.000000, learning rate is 0.000665
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.832423, learning rate is 0.000332
max inferred z is 3.98, min inferred z is -4.42, and std is 1.01
 4.18 s (23.9 data/s) [100/100]
training: epoch 29: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.657155, min gradient is -8.000000, learning rate is 0.035372
Net1: layer conv2:max response is , min response is .
max gradient is 6.424430, min gradient is -8.000000, learning rate is 0.035372
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.458757, learning rate is 0.035372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -3.460025, learning rate is 0.000665
Net2: layer deconv3:max response is 13.496053, min response is -16.507795.
max gradient is 6.822464, min gradient is -8.000000, learning rate is 0.000332
Net2: layer bn50:max response is 15.702061, min response is -2.672043.
max gradient is 2.679161, min gradient is -8.000000, learning rate is 0.000665
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.607886, learning rate is 0.000332
Net2: layer bn49:max response is 9.249190, min response is -2.078476.
max gradient is 8.000000, min gradient is -5.462986, learning rate is 0.000665
Net2: layer deconv1:max response is , min response is .
max gradient is 7.388520, min gradient is -8.000000, learning rate is 0.000332
max inferred z is 4.26, min inferred z is -3.73, and std is 1.01
 4.35 s (23.0 data/s) [100/100]
training: epoch 29: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.245392, learning rate is 0.035372
Net1: layer conv2:max response is , min response is .
max gradient is 6.559079, min gradient is -8.000000, learning rate is 0.035372
Net1: layer conv1:max response is , min response is .
max gradient is 5.079566, min gradient is -8.000000, learning rate is 0.035372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -0.030646, min gradient is -8.000000, learning rate is 0.000665
Net2: layer deconv3:max response is 13.482548, min response is -17.766554.
max gradient is 8.000000, min gradient is -7.042173, learning rate is 0.000332
Net2: layer bn50:max response is 17.314091, min response is -2.750459.
max gradient is 5.725525, min gradient is -8.000000, learning rate is 0.000665
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.100404, learning rate is 0.000332
Net2: layer bn49:max response is 10.887897, min response is -2.288156.
max gradient is 8.000000, min gradient is -5.567620, learning rate is 0.000665
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.150935, learning rate is 0.000332
max inferred z is 4.05, min inferred z is -4.04, and std is 1.01
 4.32 s (23.1 data/s) [100/100]
training: epoch 29: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.104394, learning rate is 0.035372
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.507353, learning rate is 0.035372
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.459072, learning rate is 0.035372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.080322, learning rate is 0.000665
Net2: layer deconv3:max response is 14.756329, min response is -18.790392.
max gradient is 7.855346, min gradient is -8.000000, learning rate is 0.000332
Net2: layer bn50:max response is 17.743105, min response is -3.201860.
max gradient is 2.370971, min gradient is -8.000000, learning rate is 0.000665
Net2: layer deconv2:max response is , min response is .
max gradient is 7.885489, min gradient is -8.000000, learning rate is 0.000332
Net2: layer bn49:max response is 8.667521, min response is -2.547722.
max gradient is 8.000000, min gradient is -5.146207, learning rate is 0.000665
Net2: layer deconv1:max response is , min response is .
max gradient is 6.817712, min gradient is -8.000000, learning rate is 0.000332
max inferred z is 3.99, min inferred z is -3.76, and std is 1.01
 4.33 s (23.1 data/s) [100/100]
training: epoch 29: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.688633, learning rate is 0.035372
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.114213, learning rate is 0.035372
Net1: layer conv1:max response is , min response is .
max gradient is 6.804089, min gradient is -8.000000, learning rate is 0.035372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -4.074887, min gradient is -8.000000, learning rate is 0.000665
Net2: layer deconv3:max response is 15.439188, min response is -21.394705.
max gradient is 7.681470, min gradient is -8.000000, learning rate is 0.000332
Net2: layer bn50:max response is 17.050997, min response is -2.977608.
max gradient is 8.000000, min gradient is -3.835893, learning rate is 0.000665
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.576726, learning rate is 0.000332
Net2: layer bn49:max response is 9.551346, min response is -1.778209.
max gradient is 7.205946, min gradient is -8.000000, learning rate is 0.000665
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.192512, learning rate is 0.000332
max inferred z is 4.20, min inferred z is -4.89, and std is 1.01
 4.46 s (22.4 data/s) [100/100]
training: epoch 29: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.576423, learning rate is 0.035372
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.649862, learning rate is 0.035372
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.719234, learning rate is 0.035372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.927803, learning rate is 0.000665
Net2: layer deconv3:max response is 14.068509, min response is -16.790449.
max gradient is 8.000000, min gradient is -7.311277, learning rate is 0.000332
Net2: layer bn50:max response is 17.859680, min response is -2.574088.
max gradient is 8.000000, min gradient is -2.849393, learning rate is 0.000665
Net2: layer deconv2:max response is , min response is .
max gradient is 6.730180, min gradient is -8.000000, learning rate is 0.000332
Net2: layer bn49:max response is 8.856437, min response is -1.676721.
max gradient is 8.000000, min gradient is -7.543442, learning rate is 0.000665
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.175603, learning rate is 0.000332
max inferred z is 3.61, min inferred z is -3.90, and std is 1.01
 4.24 s (23.6 data/s) [100/100]
training: epoch 29: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.147779, learning rate is 0.035372
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.400112, learning rate is 0.035372
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.209675, learning rate is 0.035372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.843190, learning rate is 0.000665
Net2: layer deconv3:max response is 14.535404, min response is -19.324917.
max gradient is 8.000000, min gradient is -6.565076, learning rate is 0.000332
Net2: layer bn50:max response is 18.222040, min response is -3.446053.
max gradient is 8.000000, min gradient is -6.032805, learning rate is 0.000665
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.029354, learning rate is 0.000332
Net2: layer bn49:max response is 10.067211, min response is -1.883272.
max gradient is 8.000000, min gradient is -5.414810, learning rate is 0.000665
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.994097, learning rate is 0.000332
max inferred z is 3.78, min inferred z is -4.29, and std is 1.01
 4.18 s (23.9 data/s) [100/100]
training: epoch 29: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.522164, learning rate is 0.035372
Net1: layer conv2:max response is , min response is .
max gradient is 6.519609, min gradient is -8.000000, learning rate is 0.035372
Net1: layer conv1:max response is , min response is .
max gradient is 7.332649, min gradient is -8.000000, learning rate is 0.035372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.904281, learning rate is 0.000665
Net2: layer deconv3:max response is 13.963482, min response is -17.345661.
max gradient is 8.000000, min gradient is -7.525799, learning rate is 0.000332
Net2: layer bn50:max response is 17.201099, min response is -3.000175.
max gradient is 8.000000, min gradient is -2.923562, learning rate is 0.000665
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.292898, learning rate is 0.000332
Net2: layer bn49:max response is 9.180150, min response is -2.199815.
max gradient is 6.772299, min gradient is -8.000000, learning rate is 0.000665
Net2: layer deconv1:max response is , min response is .
max gradient is 6.784823, min gradient is -8.000000, learning rate is 0.000332
max inferred z is 3.57, min inferred z is -4.24, and std is 1.01
 4.22 s (23.7 data/s) [100/100]
training: epoch 29: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.594062, learning rate is 0.035372
Net1: layer conv2:max response is , min response is .
max gradient is 7.959521, min gradient is -8.000000, learning rate is 0.035372
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.126115, learning rate is 0.035372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.390331, learning rate is 0.000665
Net2: layer deconv3:max response is 12.579448, min response is -20.695961.
max gradient is 8.000000, min gradient is -6.043313, learning rate is 0.000332
Net2: layer bn50:max response is 16.121641, min response is -2.629866.
max gradient is 6.047261, min gradient is -8.000000, learning rate is 0.000665
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.619177, learning rate is 0.000332
Net2: layer bn49:max response is 9.522699, min response is -2.274906.
max gradient is 4.996051, min gradient is -8.000000, learning rate is 0.000665
Net2: layer deconv1:max response is , min response is .
max gradient is 7.335904, min gradient is -8.000000, learning rate is 0.000332
max inferred z is 3.87, min inferred z is -3.88, and std is 1.01
 4.33 s (23.1 data/s) [100/100]
training: epoch 29: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.487545, learning rate is 0.035372
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.267837, learning rate is 0.035372
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.102400, learning rate is 0.035372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 4.198571, min gradient is -8.000000, learning rate is 0.000665
Net2: layer deconv3:max response is 13.382139, min response is -17.576826.
max gradient is 7.602339, min gradient is -8.000000, learning rate is 0.000332
Net2: layer bn50:max response is 18.419775, min response is -3.457905.
max gradient is 8.000000, min gradient is -3.770769, learning rate is 0.000665
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.914841, learning rate is 0.000332
Net2: layer bn49:max response is 8.575523, min response is -1.719811.
max gradient is 4.041332, min gradient is -8.000000, learning rate is 0.000665
Net2: layer deconv1:max response is , min response is .
max gradient is 6.920470, min gradient is -8.000000, learning rate is 0.000332
max inferred z is 3.97, min inferred z is -3.82, and std is 1.01
 4.43 s (22.6 data/s) [100/100]
Loss: 2.2563
Iteration 30 / 200
training: epoch 30: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.647198, min gradient is -8.000000, learning rate is 0.035372
Net1: layer conv2:max response is , min response is .
max gradient is 6.022009, min gradient is -8.000000, learning rate is 0.035372
Net1: layer conv1:max response is , min response is .
max gradient is 4.850375, min gradient is -8.000000, learning rate is 0.035372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.575103, min gradient is -8.000000, learning rate is 0.000665
Net2: layer deconv3:max response is 12.523219, min response is -16.883144.
max gradient is 8.000000, min gradient is -4.797552, learning rate is 0.000332
Net2: layer bn50:max response is 14.160450, min response is -2.567058.
max gradient is 8.000000, min gradient is -1.102468, learning rate is 0.000665
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.137342, learning rate is 0.000332
Net2: layer bn49:max response is 9.332633, min response is -2.182876.
max gradient is 3.966947, min gradient is -8.000000, learning rate is 0.000665
Net2: layer deconv1:max response is , min response is .
max gradient is 7.372240, min gradient is -8.000000, learning rate is 0.000332
max inferred z is 3.74, min inferred z is -4.05, and std is 1.00
 4.18 s (23.9 data/s) [100/100]
training: epoch 30: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.229114, min gradient is -8.000000, learning rate is 0.035372
Net1: layer conv2:max response is , min response is .
max gradient is 6.336888, min gradient is -8.000001, learning rate is 0.035372
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -4.941616, learning rate is 0.035372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -3.712783, min gradient is -8.000000, learning rate is 0.000665
Net2: layer deconv3:max response is 12.717854, min response is -18.289982.
max gradient is 8.000000, min gradient is -7.020827, learning rate is 0.000332
Net2: layer bn50:max response is 15.860071, min response is -2.707754.
max gradient is 8.000000, min gradient is -1.569282, learning rate is 0.000665
Net2: layer deconv2:max response is , min response is .
max gradient is 7.548573, min gradient is -8.000000, learning rate is 0.000332
Net2: layer bn49:max response is 9.585616, min response is -1.724039.
max gradient is 5.589800, min gradient is -8.000000, learning rate is 0.000665
Net2: layer deconv1:max response is , min response is .
max gradient is 7.689269, min gradient is -8.000000, learning rate is 0.000332
max inferred z is 3.66, min inferred z is -4.05, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
training: epoch 30: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.065593, min gradient is -8.000000, learning rate is 0.035372
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.891150, learning rate is 0.035372
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.666509, learning rate is 0.035372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.385424, learning rate is 0.000665
Net2: layer deconv3:max response is 15.544336, min response is -17.211246.
max gradient is 6.910405, min gradient is -8.000000, learning rate is 0.000332
Net2: layer bn50:max response is 17.656654, min response is -2.686694.
max gradient is 5.753191, min gradient is -8.000000, learning rate is 0.000665
Net2: layer deconv2:max response is , min response is .
max gradient is 6.409608, min gradient is -8.000000, learning rate is 0.000332
Net2: layer bn49:max response is 8.384486, min response is -1.669860.
max gradient is 8.000000, min gradient is -6.900461, learning rate is 0.000665
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.980343, learning rate is 0.000332
max inferred z is 4.30, min inferred z is -4.13, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
training: epoch 30: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.926337, min gradient is -8.000000, learning rate is 0.035372
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.051129, learning rate is 0.035372
Net1: layer conv1:max response is , min response is .
max gradient is 5.033284, min gradient is -8.000000, learning rate is 0.035372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.642899, min gradient is -8.000000, learning rate is 0.000665
Net2: layer deconv3:max response is 15.574408, min response is -19.784031.
max gradient is 6.154678, min gradient is -8.000000, learning rate is 0.000332
Net2: layer bn50:max response is 15.886182, min response is -2.649457.
max gradient is 8.000000, min gradient is -2.971842, learning rate is 0.000665
Net2: layer deconv2:max response is , min response is .
max gradient is 6.128767, min gradient is -8.000000, learning rate is 0.000332
Net2: layer bn49:max response is 7.872440, min response is -1.888212.
max gradient is 8.000000, min gradient is -6.041162, learning rate is 0.000665
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.160602, learning rate is 0.000332
max inferred z is 4.07, min inferred z is -3.90, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 30: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.842908, min gradient is -8.000000, learning rate is 0.035372
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.547779, learning rate is 0.035372
Net1: layer conv1:max response is , min response is .
max gradient is 6.521575, min gradient is -8.000000, learning rate is 0.035372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.734041, learning rate is 0.000665
Net2: layer deconv3:max response is 15.097949, min response is -19.541119.
max gradient is 5.702168, min gradient is -8.000000, learning rate is 0.000332
Net2: layer bn50:max response is 17.415369, min response is -3.105596.
max gradient is 8.000000, min gradient is -2.465719, learning rate is 0.000665
Net2: layer deconv2:max response is , min response is .
max gradient is 5.276833, min gradient is -8.000000, learning rate is 0.000332
Net2: layer bn49:max response is 8.686051, min response is -1.916350.
max gradient is 8.000000, min gradient is -5.726956, learning rate is 0.000665
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.647465, learning rate is 0.000332
max inferred z is 4.25, min inferred z is -3.56, and std is 1.00
 4.41 s (22.7 data/s) [100/100]
training: epoch 30: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.855720, min gradient is -8.000000, learning rate is 0.035372
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.257592, learning rate is 0.035372
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.309224, learning rate is 0.035372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.570127, learning rate is 0.000665
Net2: layer deconv3:max response is 13.369888, min response is -18.375153.
max gradient is 6.914293, min gradient is -8.000000, learning rate is 0.000332
Net2: layer bn50:max response is 15.607383, min response is -2.465292.
max gradient is 4.816143, min gradient is -8.000000, learning rate is 0.000665
Net2: layer deconv2:max response is , min response is .
max gradient is 5.600389, min gradient is -8.000000, learning rate is 0.000332
Net2: layer bn49:max response is 8.878174, min response is -1.833805.
max gradient is 8.000000, min gradient is -7.052125, learning rate is 0.000665
Net2: layer deconv1:max response is , min response is .
max gradient is 5.759626, min gradient is -8.000000, learning rate is 0.000332
max inferred z is 4.50, min inferred z is -3.84, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 30: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.948065, min gradient is -8.000000, learning rate is 0.035372
Net1: layer conv2:max response is , min response is .
max gradient is 6.322805, min gradient is -8.000000, learning rate is 0.035372
Net1: layer conv1:max response is , min response is .
max gradient is 7.566102, min gradient is -8.000000, learning rate is 0.035372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.079785, learning rate is 0.000665
Net2: layer deconv3:max response is 13.514548, min response is -22.005615.
max gradient is 4.806941, min gradient is -8.000000, learning rate is 0.000332
Net2: layer bn50:max response is 14.905091, min response is -3.147010.
max gradient is 8.000000, min gradient is -4.954906, learning rate is 0.000665
Net2: layer deconv2:max response is , min response is .
max gradient is 7.066057, min gradient is -8.000000, learning rate is 0.000332
Net2: layer bn49:max response is 8.570006, min response is -1.891012.
max gradient is 8.000000, min gradient is -7.778375, learning rate is 0.000665
Net2: layer deconv1:max response is , min response is .
max gradient is 6.292437, min gradient is -8.000000, learning rate is 0.000332
max inferred z is 4.02, min inferred z is -4.06, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 30: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.092952, min gradient is -8.000000, learning rate is 0.035372
Net1: layer conv2:max response is , min response is .
max gradient is 6.697668, min gradient is -8.000000, learning rate is 0.035372
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.918493, learning rate is 0.035372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.794102, learning rate is 0.000665
Net2: layer deconv3:max response is 17.204130, min response is -18.378916.
max gradient is 8.000000, min gradient is -6.576927, learning rate is 0.000332
Net2: layer bn50:max response is 18.564981, min response is -2.781264.
max gradient is 4.107921, min gradient is -8.000000, learning rate is 0.000665
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.951085, learning rate is 0.000332
Net2: layer bn49:max response is 7.885545, min response is -1.864635.
max gradient is 8.000000, min gradient is -7.494732, learning rate is 0.000665
Net2: layer deconv1:max response is , min response is .
max gradient is 7.944827, min gradient is -8.000000, learning rate is 0.000332
max inferred z is 4.35, min inferred z is -4.31, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 30: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.674879, learning rate is 0.035372
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.131502, learning rate is 0.035372
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -2.980861, learning rate is 0.035372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.217294, learning rate is 0.000665
Net2: layer deconv3:max response is 16.350092, min response is -20.474112.
max gradient is 8.000000, min gradient is -5.981545, learning rate is 0.000332
Net2: layer bn50:max response is 19.658648, min response is -2.855127.
max gradient is 3.204772, min gradient is -8.000000, learning rate is 0.000665
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.436811, learning rate is 0.000332
Net2: layer bn49:max response is 8.349246, min response is -1.787243.
max gradient is 8.000000, min gradient is -7.799170, learning rate is 0.000665
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.502701, learning rate is 0.000332
max inferred z is 3.92, min inferred z is -4.08, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 30: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.711860, learning rate is 0.035372
Net1: layer conv2:max response is , min response is .
max gradient is 6.048917, min gradient is -8.000000, learning rate is 0.035372
Net1: layer conv1:max response is , min response is .
max gradient is 3.398394, min gradient is -8.000000, learning rate is 0.035372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.694504, min gradient is -8.000000, learning rate is 0.000665
Net2: layer deconv3:max response is 13.233593, min response is -20.073898.
max gradient is 8.000000, min gradient is -6.591417, learning rate is 0.000332
Net2: layer bn50:max response is 15.675768, min response is -2.743496.
max gradient is 4.113447, min gradient is -8.000000, learning rate is 0.000665
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.522247, learning rate is 0.000332
Net2: layer bn49:max response is 7.693446, min response is -1.713918.
max gradient is 4.673621, min gradient is -8.000000, learning rate is 0.000665
Net2: layer deconv1:max response is , min response is .
max gradient is 7.265926, min gradient is -8.000000, learning rate is 0.000332
max inferred z is 4.21, min inferred z is -4.24, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
Loss: 2.1806
Iteration 31 / 200
training: epoch 31: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.224217, learning rate is 0.033369
Net1: layer conv2:max response is , min response is .
max gradient is 5.129027, min gradient is -8.000000, learning rate is 0.033369
Net1: layer conv1:max response is , min response is .
max gradient is 6.135303, min gradient is -8.000000, learning rate is 0.033369
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.204159, min gradient is -8.000000, learning rate is 0.000646
Net2: layer deconv3:max response is 13.787446, min response is -19.203789.
max gradient is 8.000000, min gradient is -6.747329, learning rate is 0.000323
Net2: layer bn50:max response is 16.032854, min response is -2.879678.
max gradient is 8.000000, min gradient is -3.344513, learning rate is 0.000646
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.664864, learning rate is 0.000323
Net2: layer bn49:max response is 9.638220, min response is -1.767632.
max gradient is 3.384061, min gradient is -8.000000, learning rate is 0.000646
Net2: layer deconv1:max response is , min response is .
max gradient is 6.804240, min gradient is -8.000000, learning rate is 0.000323
max inferred z is 4.50, min inferred z is -4.23, and std is 0.99
 4.17 s (24.0 data/s) [100/100]
training: epoch 31: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.004202, min gradient is -8.000000, learning rate is 0.033369
Net1: layer conv2:max response is , min response is .
max gradient is 7.911219, min gradient is -8.000000, learning rate is 0.033369
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.864381, learning rate is 0.033369
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 3.928632, min gradient is -8.000000, learning rate is 0.000646
Net2: layer deconv3:max response is 12.183484, min response is -17.450169.
max gradient is 8.000000, min gradient is -5.990915, learning rate is 0.000323
Net2: layer bn50:max response is 15.269815, min response is -2.552464.
max gradient is 4.898435, min gradient is -8.000000, learning rate is 0.000646
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.936707, learning rate is 0.000323
Net2: layer bn49:max response is 8.547071, min response is -1.902521.
max gradient is 7.153594, min gradient is -8.000000, learning rate is 0.000646
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.401036, learning rate is 0.000323
max inferred z is 3.96, min inferred z is -4.39, and std is 0.99
 4.25 s (23.5 data/s) [100/100]
training: epoch 31: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.264704, learning rate is 0.033369
Net1: layer conv2:max response is , min response is .
max gradient is 6.953635, min gradient is -8.000000, learning rate is 0.033369
Net1: layer conv1:max response is , min response is .
max gradient is 4.678597, min gradient is -8.000000, learning rate is 0.033369
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.272416, min gradient is -8.000000, learning rate is 0.000646
Net2: layer deconv3:max response is 11.917772, min response is -18.458000.
max gradient is 8.000000, min gradient is -4.842041, learning rate is 0.000323
Net2: layer bn50:max response is 15.403222, min response is -2.525069.
max gradient is 8.000000, min gradient is -3.655127, learning rate is 0.000646
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.593103, learning rate is 0.000323
Net2: layer bn49:max response is 9.730290, min response is -1.725212.
max gradient is 8.000000, min gradient is -6.305140, learning rate is 0.000646
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.261981, learning rate is 0.000323
max inferred z is 4.02, min inferred z is -3.90, and std is 0.99
 4.36 s (22.9 data/s) [100/100]
training: epoch 31: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.652257, learning rate is 0.033369
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.290589, learning rate is 0.033369
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.585418, learning rate is 0.033369
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.113024, learning rate is 0.000646
Net2: layer deconv3:max response is 15.220925, min response is -16.279703.
max gradient is 8.000000, min gradient is -7.210244, learning rate is 0.000323
Net2: layer bn50:max response is 16.350651, min response is -2.895771.
max gradient is 3.491957, min gradient is -8.000000, learning rate is 0.000646
Net2: layer deconv2:max response is , min response is .
max gradient is 6.359564, min gradient is -8.000000, learning rate is 0.000323
Net2: layer bn49:max response is 7.523190, min response is -1.901312.
max gradient is 8.000000, min gradient is -5.706369, learning rate is 0.000646
Net2: layer deconv1:max response is , min response is .
max gradient is 6.107193, min gradient is -8.000000, learning rate is 0.000323
max inferred z is 4.14, min inferred z is -3.96, and std is 0.99
 4.23 s (23.7 data/s) [100/100]
training: epoch 31: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.392462, learning rate is 0.033369
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.919003, learning rate is 0.033369
Net1: layer conv1:max response is , min response is .
max gradient is 7.640014, min gradient is -8.000000, learning rate is 0.033369
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 1.498483, min gradient is -8.000000, learning rate is 0.000646
Net2: layer deconv3:max response is 13.073060, min response is -18.364275.
max gradient is 8.000000, min gradient is -6.200796, learning rate is 0.000323
Net2: layer bn50:max response is 17.342957, min response is -2.772917.
max gradient is 8.000000, min gradient is -2.691396, learning rate is 0.000646
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.544518, learning rate is 0.000323
Net2: layer bn49:max response is 8.540749, min response is -2.495225.
max gradient is 7.697818, min gradient is -8.000000, learning rate is 0.000646
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.935315, learning rate is 0.000323
max inferred z is 4.29, min inferred z is -3.71, and std is 0.99
 4.36 s (22.9 data/s) [100/100]
training: epoch 31: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.849178, learning rate is 0.033369
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.711600, learning rate is 0.033369
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.977033, learning rate is 0.033369
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.208608, learning rate is 0.000646
Net2: layer deconv3:max response is 12.434066, min response is -17.327612.
max gradient is 6.476516, min gradient is -8.000000, learning rate is 0.000323
Net2: layer bn50:max response is 15.093268, min response is -2.830385.
max gradient is 8.000000, min gradient is -2.443955, learning rate is 0.000646
Net2: layer deconv2:max response is , min response is .
max gradient is 5.961325, min gradient is -8.000000, learning rate is 0.000323
Net2: layer bn49:max response is 7.946482, min response is -1.865088.
max gradient is 6.653356, min gradient is -8.000000, learning rate is 0.000646
Net2: layer deconv1:max response is , min response is .
max gradient is 7.166778, min gradient is -8.000000, learning rate is 0.000323
max inferred z is 4.46, min inferred z is -3.80, and std is 0.99
 4.17 s (24.0 data/s) [100/100]
training: epoch 31: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.295335, min gradient is -8.000000, learning rate is 0.033369
Net1: layer conv2:max response is , min response is .
max gradient is 6.942283, min gradient is -8.000000, learning rate is 0.033369
Net1: layer conv1:max response is , min response is .
max gradient is 7.240258, min gradient is -8.000000, learning rate is 0.033369
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.703475, learning rate is 0.000646
Net2: layer deconv3:max response is 13.029832, min response is -18.013266.
max gradient is 8.000000, min gradient is -6.831799, learning rate is 0.000323
Net2: layer bn50:max response is 16.365541, min response is -2.580368.
max gradient is 8.000000, min gradient is -2.198905, learning rate is 0.000646
Net2: layer deconv2:max response is , min response is .
max gradient is 7.689482, min gradient is -8.000000, learning rate is 0.000323
Net2: layer bn49:max response is 9.082504, min response is -2.123945.
max gradient is 4.116803, min gradient is -8.000000, learning rate is 0.000646
Net2: layer deconv1:max response is , min response is .
max gradient is 6.951372, min gradient is -8.000000, learning rate is 0.000323
max inferred z is 4.47, min inferred z is -3.61, and std is 0.99
 4.21 s (23.8 data/s) [100/100]
training: epoch 31: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.314914, min gradient is -8.000000, learning rate is 0.033369
Net1: layer conv2:max response is , min response is .
max gradient is 7.196676, min gradient is -8.000000, learning rate is 0.033369
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.663478, learning rate is 0.033369
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.910251, learning rate is 0.000646
Net2: layer deconv3:max response is 12.397110, min response is -17.690931.
max gradient is 8.000000, min gradient is -5.980636, learning rate is 0.000323
Net2: layer bn50:max response is 16.374304, min response is -2.522762.
max gradient is 8.000000, min gradient is -5.744930, learning rate is 0.000646
Net2: layer deconv2:max response is , min response is .
max gradient is 4.963907, min gradient is -8.000000, learning rate is 0.000323
Net2: layer bn49:max response is 8.260939, min response is -1.890179.
max gradient is 7.124006, min gradient is -8.000000, learning rate is 0.000646
Net2: layer deconv1:max response is , min response is .
max gradient is 6.889384, min gradient is -8.000000, learning rate is 0.000323
max inferred z is 3.49, min inferred z is -3.83, and std is 0.99
 4.35 s (23.0 data/s) [100/100]
training: epoch 31: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -4.645284, learning rate is 0.033369
Net1: layer conv2:max response is , min response is .
max gradient is 7.563046, min gradient is -8.000000, learning rate is 0.033369
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.739691, learning rate is 0.033369
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.792232, learning rate is 0.000646
Net2: layer deconv3:max response is 15.873779, min response is -18.489805.
max gradient is 8.000000, min gradient is -6.747642, learning rate is 0.000323
Net2: layer bn50:max response is 16.336695, min response is -3.308187.
max gradient is 5.009027, min gradient is -8.000000, learning rate is 0.000646
Net2: layer deconv2:max response is , min response is .
max gradient is 4.487478, min gradient is -8.000000, learning rate is 0.000323
Net2: layer bn49:max response is 8.532285, min response is -2.104961.
max gradient is 6.424300, min gradient is -8.000000, learning rate is 0.000646
Net2: layer deconv1:max response is , min response is .
max gradient is 7.595693, min gradient is -8.000000, learning rate is 0.000323
max inferred z is 4.50, min inferred z is -4.35, and std is 0.99
 4.54 s (22.0 data/s) [100/100]
training: epoch 31: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.616038, learning rate is 0.033369
Net1: layer conv2:max response is , min response is .
max gradient is 5.459846, min gradient is -8.000000, learning rate is 0.033369
Net1: layer conv1:max response is , min response is .
max gradient is 3.654908, min gradient is -8.000000, learning rate is 0.033369
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.001977, min gradient is -8.000000, learning rate is 0.000646
Net2: layer deconv3:max response is 15.443410, min response is -17.852236.
max gradient is 8.000000, min gradient is -7.004470, learning rate is 0.000323
Net2: layer bn50:max response is 17.822420, min response is -2.748435.
max gradient is 8.000000, min gradient is -3.883002, learning rate is 0.000646
Net2: layer deconv2:max response is , min response is .
max gradient is 7.433834, min gradient is -8.000000, learning rate is 0.000323
Net2: layer bn49:max response is 8.608311, min response is -1.720182.
max gradient is 4.730329, min gradient is -8.000000, learning rate is 0.000646
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.198409, learning rate is 0.000323
max inferred z is 4.25, min inferred z is -4.81, and std is 0.99
 4.27 s (23.4 data/s) [100/100]
Loss: 2.1288
Iteration 32 / 200
training: epoch 32: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.562456, min gradient is -8.000000, learning rate is 0.033369
Net1: layer conv2:max response is , min response is .
max gradient is 4.499864, min gradient is -8.000000, learning rate is 0.033369
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.820115, learning rate is 0.033369
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.996315, min gradient is -8.000000, learning rate is 0.000646
Net2: layer deconv3:max response is 15.363706, min response is -19.172115.
max gradient is 8.000000, min gradient is -6.080264, learning rate is 0.000323
Net2: layer bn50:max response is 18.483217, min response is -2.945715.
max gradient is 8.000000, min gradient is -2.846699, learning rate is 0.000646
Net2: layer deconv2:max response is , min response is .
max gradient is 7.485701, min gradient is -8.000000, learning rate is 0.000323
Net2: layer bn49:max response is 8.902435, min response is -2.020104.
max gradient is 4.134147, min gradient is -8.000000, learning rate is 0.000646
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.917046, learning rate is 0.000323
max inferred z is 3.97, min inferred z is -4.02, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
training: epoch 32: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.539391, min gradient is -8.000000, learning rate is 0.033369
Net1: layer conv2:max response is , min response is .
max gradient is 5.571974, min gradient is -8.000000, learning rate is 0.033369
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.351237, learning rate is 0.033369
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 6.041990, min gradient is -8.000000, learning rate is 0.000646
Net2: layer deconv3:max response is 14.822512, min response is -18.082975.
max gradient is 8.000000, min gradient is -5.986225, learning rate is 0.000323
Net2: layer bn50:max response is 18.509161, min response is -2.687331.
max gradient is 8.000000, min gradient is -5.993087, learning rate is 0.000646
Net2: layer deconv2:max response is , min response is .
max gradient is 7.412539, min gradient is -8.000000, learning rate is 0.000323
Net2: layer bn49:max response is 8.336081, min response is -1.803873.
max gradient is 5.578619, min gradient is -8.000000, learning rate is 0.000646
Net2: layer deconv1:max response is , min response is .
max gradient is 7.655749, min gradient is -8.000000, learning rate is 0.000323
max inferred z is 4.48, min inferred z is -3.66, and std is 1.00
 4.34 s (23.1 data/s) [100/100]
training: epoch 32: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.877826, learning rate is 0.033369
Net1: layer conv2:max response is , min response is .
max gradient is 7.730903, min gradient is -8.000000, learning rate is 0.033369
Net1: layer conv1:max response is , min response is .
max gradient is 3.638883, min gradient is -8.000000, learning rate is 0.033369
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.378955, min gradient is -8.000000, learning rate is 0.000646
Net2: layer deconv3:max response is 13.950545, min response is -19.283739.
max gradient is 7.163205, min gradient is -8.000000, learning rate is 0.000323
Net2: layer bn50:max response is 16.111017, min response is -2.689099.
max gradient is 8.000000, min gradient is -1.463328, learning rate is 0.000646
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.964233, learning rate is 0.000323
Net2: layer bn49:max response is 9.437132, min response is -1.807235.
max gradient is 6.284494, min gradient is -8.000000, learning rate is 0.000646
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.759461, learning rate is 0.000323
max inferred z is 3.80, min inferred z is -4.18, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 32: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.534327, learning rate is 0.033369
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.482105, learning rate is 0.033369
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.513970, learning rate is 0.033369
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.429715, learning rate is 0.000646
Net2: layer deconv3:max response is 13.118510, min response is -15.904879.
max gradient is 8.000000, min gradient is -7.508033, learning rate is 0.000323
Net2: layer bn50:max response is 15.578465, min response is -2.549111.
max gradient is 8.000000, min gradient is -7.981107, learning rate is 0.000646
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.703228, learning rate is 0.000323
Net2: layer bn49:max response is 8.837425, min response is -1.776215.
max gradient is 8.000000, min gradient is -4.909216, learning rate is 0.000646
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.849623, learning rate is 0.000323
max inferred z is 4.19, min inferred z is -3.70, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 32: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.391905, min gradient is -8.000000, learning rate is 0.033369
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.092124, learning rate is 0.033369
Net1: layer conv1:max response is , min response is .
max gradient is 4.361299, min gradient is -8.000000, learning rate is 0.033369
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.259674, min gradient is -8.000000, learning rate is 0.000646
Net2: layer deconv3:max response is 18.257053, min response is -19.451958.
max gradient is 8.000000, min gradient is -7.445781, learning rate is 0.000323
Net2: layer bn50:max response is 20.418741, min response is -2.827293.
max gradient is 8.000000, min gradient is -3.192406, learning rate is 0.000646
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.847873, learning rate is 0.000323
Net2: layer bn49:max response is 8.184599, min response is -2.048239.
max gradient is 8.000000, min gradient is -6.100291, learning rate is 0.000646
Net2: layer deconv1:max response is , min response is .
max gradient is 7.878142, min gradient is -8.000000, learning rate is 0.000323
max inferred z is 3.86, min inferred z is -3.67, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
training: epoch 32: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.437410, min gradient is -8.000000, learning rate is 0.033369
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -3.904209, learning rate is 0.033369
Net1: layer conv1:max response is , min response is .
max gradient is 4.918839, min gradient is -8.000000, learning rate is 0.033369
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -3.904135, min gradient is -8.000000, learning rate is 0.000646
Net2: layer deconv3:max response is 15.748869, min response is -23.462091.
max gradient is 7.798650, min gradient is -8.000000, learning rate is 0.000323
Net2: layer bn50:max response is 16.545300, min response is -2.735503.
max gradient is 8.000000, min gradient is -1.615999, learning rate is 0.000646
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.113397, learning rate is 0.000323
Net2: layer bn49:max response is 7.644553, min response is -1.838074.
max gradient is 8.000000, min gradient is -7.246042, learning rate is 0.000646
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.768074, learning rate is 0.000323
max inferred z is 3.80, min inferred z is -4.70, and std is 1.00
 4.19 s (23.9 data/s) [100/100]
training: epoch 32: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.341766, min gradient is -8.000000, learning rate is 0.033369
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.804653, learning rate is 0.033369
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.725374, learning rate is 0.033369
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.541865, learning rate is 0.000646
Net2: layer deconv3:max response is 13.386761, min response is -19.473927.
max gradient is 5.943314, min gradient is -8.000000, learning rate is 0.000323
Net2: layer bn50:max response is 16.825037, min response is -2.755737.
max gradient is 8.000000, min gradient is -1.163956, learning rate is 0.000646
Net2: layer deconv2:max response is , min response is .
max gradient is 7.669308, min gradient is -8.000000, learning rate is 0.000323
Net2: layer bn49:max response is 7.981881, min response is -1.748281.
max gradient is 7.928477, min gradient is -8.000000, learning rate is 0.000646
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.729520, learning rate is 0.000323
max inferred z is 3.80, min inferred z is -3.81, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 32: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.461303, min gradient is -8.000000, learning rate is 0.033369
Net1: layer conv2:max response is , min response is .
max gradient is 6.586069, min gradient is -8.000000, learning rate is 0.033369
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.025722, learning rate is 0.033369
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.384943, learning rate is 0.000646
Net2: layer deconv3:max response is 15.853305, min response is -21.381695.
max gradient is 7.309007, min gradient is -8.000000, learning rate is 0.000323
Net2: layer bn50:max response is 19.742647, min response is -2.855813.
max gradient is 8.000000, min gradient is -6.248796, learning rate is 0.000646
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.819526, learning rate is 0.000323
Net2: layer bn49:max response is 8.729193, min response is -1.711357.
max gradient is 8.000001, min gradient is -7.131297, learning rate is 0.000646
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.079682, learning rate is 0.000323
max inferred z is 3.52, min inferred z is -3.73, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 32: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.339081, learning rate is 0.033369
Net1: layer conv2:max response is , min response is .
max gradient is 7.842971, min gradient is -8.000000, learning rate is 0.033369
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.478965, learning rate is 0.033369
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.970395, learning rate is 0.000646
Net2: layer deconv3:max response is 14.424396, min response is -20.589602.
max gradient is 8.000000, min gradient is -6.338395, learning rate is 0.000323
Net2: layer bn50:max response is 16.800089, min response is -2.768557.
max gradient is 3.348674, min gradient is -8.000000, learning rate is 0.000646
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.848581, learning rate is 0.000323
Net2: layer bn49:max response is 9.610558, min response is -2.009816.
max gradient is 8.000000, min gradient is -5.958288, learning rate is 0.000646
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.613926, learning rate is 0.000323
max inferred z is 3.87, min inferred z is -4.00, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 32: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.667821, learning rate is 0.033369
Net1: layer conv2:max response is , min response is .
max gradient is 4.650182, min gradient is -8.000000, learning rate is 0.033369
Net1: layer conv1:max response is , min response is .
max gradient is 5.276553, min gradient is -8.000000, learning rate is 0.033369
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -4.415287, min gradient is -8.000000, learning rate is 0.000646
Net2: layer deconv3:max response is 17.509235, min response is -26.177830.
max gradient is 8.000000, min gradient is -7.161985, learning rate is 0.000323
Net2: layer bn50:max response is 20.691549, min response is -3.129438.
max gradient is 6.678967, min gradient is -8.000000, learning rate is 0.000646
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.156522, learning rate is 0.000323
Net2: layer bn49:max response is 8.326430, min response is -1.862456.
max gradient is 7.116455, min gradient is -8.000000, learning rate is 0.000646
Net2: layer deconv1:max response is , min response is .
max gradient is 7.351024, min gradient is -8.000000, learning rate is 0.000323
max inferred z is 3.66, min inferred z is -3.99, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
Loss: 2.1348
Iteration 33 / 200
training: epoch 33: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.137740, learning rate is 0.031479
Net1: layer conv2:max response is , min response is .
max gradient is 4.700801, min gradient is -8.000000, learning rate is 0.031479
Net1: layer conv1:max response is , min response is .
max gradient is 4.497014, min gradient is -8.000000, learning rate is 0.031479
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.365565, min gradient is -8.000000, learning rate is 0.000627
Net2: layer deconv3:max response is 16.401978, min response is -17.305424.
max gradient is 8.000000, min gradient is -7.323173, learning rate is 0.000314
Net2: layer bn50:max response is 19.107883, min response is -3.199028.
max gradient is 8.000000, min gradient is -5.243295, learning rate is 0.000627
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.803199, learning rate is 0.000314
Net2: layer bn49:max response is 8.097730, min response is -1.829994.
max gradient is 6.141696, min gradient is -8.000000, learning rate is 0.000627
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.159935, learning rate is 0.000314
max inferred z is 4.40, min inferred z is -3.74, and std is 1.00
 4.15 s (24.1 data/s) [100/100]
training: epoch 33: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.786800, learning rate is 0.031479
Net1: layer conv2:max response is , min response is .
max gradient is 7.120660, min gradient is -8.000000, learning rate is 0.031479
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.143811, learning rate is 0.031479
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 7.550318, min gradient is -8.000000, learning rate is 0.000627
Net2: layer deconv3:max response is 14.339711, min response is -20.047813.
max gradient is 6.617530, min gradient is -8.000000, learning rate is 0.000314
Net2: layer bn50:max response is 18.241957, min response is -3.230825.
max gradient is 2.435873, min gradient is -8.000000, learning rate is 0.000627
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.592581, learning rate is 0.000314
Net2: layer bn49:max response is 8.869956, min response is -1.729865.
max gradient is 8.000000, min gradient is -6.582183, learning rate is 0.000627
Net2: layer deconv1:max response is , min response is .
max gradient is 7.971374, min gradient is -8.000000, learning rate is 0.000314
max inferred z is 4.24, min inferred z is -3.70, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
training: epoch 33: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.777981, learning rate is 0.031479
Net1: layer conv2:max response is , min response is .
max gradient is 5.247622, min gradient is -8.000000, learning rate is 0.031479
Net1: layer conv1:max response is , min response is .
max gradient is 4.022617, min gradient is -8.000000, learning rate is 0.031479
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.292374, min gradient is -8.000000, learning rate is 0.000627
Net2: layer deconv3:max response is 13.968127, min response is -19.339472.
max gradient is 8.000000, min gradient is -6.361529, learning rate is 0.000314
Net2: layer bn50:max response is 17.930546, min response is -2.762558.
max gradient is 8.000000, min gradient is -7.642750, learning rate is 0.000627
Net2: layer deconv2:max response is , min response is .
max gradient is 7.157764, min gradient is -8.000000, learning rate is 0.000314
Net2: layer bn49:max response is 8.776140, min response is -1.804489.
max gradient is 8.000000, min gradient is -6.231185, learning rate is 0.000627
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.112088, learning rate is 0.000314
max inferred z is 4.53, min inferred z is -4.11, and std is 1.00
 4.22 s (23.7 data/s) [100/100]
training: epoch 33: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.428639, learning rate is 0.031479
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.406640, learning rate is 0.031479
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.009772, learning rate is 0.031479
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.593801, learning rate is 0.000627
Net2: layer deconv3:max response is 14.116352, min response is -19.925070.
max gradient is 8.000000, min gradient is -7.078638, learning rate is 0.000314
Net2: layer bn50:max response is 15.632215, min response is -3.447733.
max gradient is 3.344244, min gradient is -8.000000, learning rate is 0.000627
Net2: layer deconv2:max response is , min response is .
max gradient is 6.764935, min gradient is -8.000000, learning rate is 0.000314
Net2: layer bn49:max response is 7.846313, min response is -1.883114.
max gradient is 8.000000, min gradient is -6.374168, learning rate is 0.000627
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.471821, learning rate is 0.000314
max inferred z is 3.81, min inferred z is -4.70, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 33: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.190460, learning rate is 0.031479
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.142688, learning rate is 0.031479
Net1: layer conv1:max response is , min response is .
max gradient is 5.520607, min gradient is -8.000000, learning rate is 0.031479
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.609921, min gradient is -8.000000, learning rate is 0.000627
Net2: layer deconv3:max response is 14.874514, min response is -19.053858.
max gradient is 7.223364, min gradient is -8.000000, learning rate is 0.000314
Net2: layer bn50:max response is 16.100271, min response is -3.127334.
max gradient is 8.000000, min gradient is -2.561235, learning rate is 0.000627
Net2: layer deconv2:max response is , min response is .
max gradient is 7.274837, min gradient is -8.000000, learning rate is 0.000314
Net2: layer bn49:max response is 7.929024, min response is -1.821373.
max gradient is 7.671002, min gradient is -8.000000, learning rate is 0.000627
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.560651, learning rate is 0.000314
max inferred z is 3.59, min inferred z is -4.57, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 33: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.506259, min gradient is -8.000000, learning rate is 0.031479
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.730825, learning rate is 0.031479
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.598613, learning rate is 0.031479
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.236909, learning rate is 0.000627
Net2: layer deconv3:max response is 16.795483, min response is -20.253832.
max gradient is 6.509030, min gradient is -8.000000, learning rate is 0.000314
Net2: layer bn50:max response is 18.442165, min response is -3.040725.
max gradient is 8.000000, min gradient is -1.843795, learning rate is 0.000627
Net2: layer deconv2:max response is , min response is .
max gradient is 6.549436, min gradient is -8.000000, learning rate is 0.000314
Net2: layer bn49:max response is 9.100862, min response is -1.856392.
max gradient is 8.000000, min gradient is -6.880029, learning rate is 0.000627
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.589393, learning rate is 0.000314
max inferred z is 4.23, min inferred z is -3.71, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
training: epoch 33: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.031678, learning rate is 0.031479
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.592930, learning rate is 0.031479
Net1: layer conv1:max response is , min response is .
max gradient is 6.806160, min gradient is -8.000000, learning rate is 0.031479
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.359231, learning rate is 0.000627
Net2: layer deconv3:max response is 15.416815, min response is -17.757648.
max gradient is 7.544745, min gradient is -8.000000, learning rate is 0.000314
Net2: layer bn50:max response is 21.131544, min response is -3.788842.
max gradient is 8.000000, min gradient is -1.091739, learning rate is 0.000627
Net2: layer deconv2:max response is , min response is .
max gradient is 7.386366, min gradient is -8.000000, learning rate is 0.000314
Net2: layer bn49:max response is 8.736534, min response is -1.937899.
max gradient is 8.000000, min gradient is -5.056147, learning rate is 0.000627
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.740695, learning rate is 0.000314
max inferred z is 4.15, min inferred z is -3.98, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
training: epoch 33: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.731349, learning rate is 0.031479
Net1: layer conv2:max response is , min response is .
max gradient is 7.727955, min gradient is -8.000000, learning rate is 0.031479
Net1: layer conv1:max response is , min response is .
max gradient is 5.833790, min gradient is -8.000000, learning rate is 0.031479
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.053707, learning rate is 0.000627
Net2: layer deconv3:max response is 14.397898, min response is -20.003099.
max gradient is 8.000000, min gradient is -7.892196, learning rate is 0.000314
Net2: layer bn50:max response is 15.285648, min response is -2.710141.
max gradient is 8.000000, min gradient is -3.538122, learning rate is 0.000627
Net2: layer deconv2:max response is , min response is .
max gradient is 6.431983, min gradient is -8.000000, learning rate is 0.000314
Net2: layer bn49:max response is 7.866835, min response is -1.616990.
max gradient is 6.696443, min gradient is -8.000000, learning rate is 0.000627
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.715529, learning rate is 0.000314
max inferred z is 3.83, min inferred z is -4.20, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 33: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.533437, learning rate is 0.031479
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.820476, learning rate is 0.031479
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.050656, learning rate is 0.031479
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.893200, learning rate is 0.000627
Net2: layer deconv3:max response is 16.899874, min response is -18.343519.
max gradient is 7.196104, min gradient is -8.000000, learning rate is 0.000314
Net2: layer bn50:max response is 17.069138, min response is -2.662777.
max gradient is 3.170739, min gradient is -8.000000, learning rate is 0.000627
Net2: layer deconv2:max response is , min response is .
max gradient is 5.393398, min gradient is -8.000000, learning rate is 0.000314
Net2: layer bn49:max response is 8.511349, min response is -1.673977.
max gradient is 6.236373, min gradient is -8.000000, learning rate is 0.000627
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.607983, learning rate is 0.000314
max inferred z is 3.56, min inferred z is -3.86, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 33: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.688764, learning rate is 0.031479
Net1: layer conv2:max response is , min response is .
max gradient is 6.530470, min gradient is -8.000000, learning rate is 0.031479
Net1: layer conv1:max response is , min response is .
max gradient is 3.993613, min gradient is -8.000000, learning rate is 0.031479
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.188636, min gradient is -8.000000, learning rate is 0.000627
Net2: layer deconv3:max response is 13.957534, min response is -20.899330.
max gradient is 7.408715, min gradient is -8.000000, learning rate is 0.000314
Net2: layer bn50:max response is 15.077344, min response is -2.696070.
max gradient is 8.000000, min gradient is -3.796109, learning rate is 0.000627
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.936046, learning rate is 0.000314
Net2: layer bn49:max response is 8.516171, min response is -1.773510.
max gradient is 4.560122, min gradient is -8.000000, learning rate is 0.000627
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.630289, learning rate is 0.000314
max inferred z is 3.94, min inferred z is -4.41, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
Loss: 2.2401
Iteration 34 / 200
training: epoch 34: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.642551, min gradient is -8.000000, learning rate is 0.031479
Net1: layer conv2:max response is , min response is .
max gradient is 5.382729, min gradient is -8.000000, learning rate is 0.031479
Net1: layer conv1:max response is , min response is .
max gradient is 7.532071, min gradient is -8.000000, learning rate is 0.031479
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.487330, min gradient is -8.000000, learning rate is 0.000627
Net2: layer deconv3:max response is 13.390297, min response is -18.204966.
max gradient is 8.000000, min gradient is -7.215790, learning rate is 0.000314
Net2: layer bn50:max response is 14.882399, min response is -2.589430.
max gradient is 8.000000, min gradient is -4.580160, learning rate is 0.000627
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.498682, learning rate is 0.000314
Net2: layer bn49:max response is 8.823702, min response is -1.700608.
max gradient is 4.470978, min gradient is -8.000000, learning rate is 0.000627
Net2: layer deconv1:max response is , min response is .
max gradient is 7.894902, min gradient is -8.000000, learning rate is 0.000314
max inferred z is 3.93, min inferred z is -3.77, and std is 0.99
 4.16 s (24.0 data/s) [100/100]
training: epoch 34: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.455489, learning rate is 0.031479
Net1: layer conv2:max response is , min response is .
max gradient is 6.696783, min gradient is -8.000000, learning rate is 0.031479
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.108521, learning rate is 0.031479
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -4.748689, min gradient is -8.000000, learning rate is 0.000627
Net2: layer deconv3:max response is 13.885819, min response is -17.768034.
max gradient is 8.000000, min gradient is -7.603842, learning rate is 0.000314
Net2: layer bn50:max response is 14.894120, min response is -3.076765.
max gradient is 8.000000, min gradient is -6.261366, learning rate is 0.000627
Net2: layer deconv2:max response is , min response is .
max gradient is 7.583587, min gradient is -8.000000, learning rate is 0.000314
Net2: layer bn49:max response is 7.989867, min response is -1.807809.
max gradient is 5.009494, min gradient is -8.000000, learning rate is 0.000627
Net2: layer deconv1:max response is , min response is .
max gradient is 7.954829, min gradient is -8.000000, learning rate is 0.000314
max inferred z is 4.08, min inferred z is -4.00, and std is 0.99
 4.28 s (23.3 data/s) [100/100]
training: epoch 34: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.991078, min gradient is -8.000000, learning rate is 0.031479
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.789270, learning rate is 0.031479
Net1: layer conv1:max response is , min response is .
max gradient is 4.114173, min gradient is -8.000000, learning rate is 0.031479
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.340213, min gradient is -8.000000, learning rate is 0.000627
Net2: layer deconv3:max response is 15.654299, min response is -16.766459.
max gradient is 7.822649, min gradient is -8.000000, learning rate is 0.000314
Net2: layer bn50:max response is 17.449976, min response is -2.961211.
max gradient is 8.000000, min gradient is -1.507956, learning rate is 0.000627
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.531771, learning rate is 0.000314
Net2: layer bn49:max response is 8.221892, min response is -1.750083.
max gradient is 5.559330, min gradient is -8.000000, learning rate is 0.000627
Net2: layer deconv1:max response is , min response is .
max gradient is 7.804816, min gradient is -8.000000, learning rate is 0.000314
max inferred z is 3.70, min inferred z is -4.36, and std is 0.99
 4.21 s (23.8 data/s) [100/100]
training: epoch 34: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.601798, learning rate is 0.031479
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.381151, learning rate is 0.031479
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.457942, learning rate is 0.031479
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.744021, learning rate is 0.000627
Net2: layer deconv3:max response is 15.368933, min response is -18.494957.
max gradient is 7.932716, min gradient is -8.000000, learning rate is 0.000314
Net2: layer bn50:max response is 16.500584, min response is -2.818954.
max gradient is 7.629400, min gradient is -8.000000, learning rate is 0.000627
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.920491, learning rate is 0.000314
Net2: layer bn49:max response is 8.627914, min response is -1.774671.
max gradient is 8.000000, min gradient is -6.353047, learning rate is 0.000627
Net2: layer deconv1:max response is , min response is .
max gradient is 7.710717, min gradient is -8.000000, learning rate is 0.000314
max inferred z is 4.51, min inferred z is -3.87, and std is 0.99
 4.28 s (23.4 data/s) [100/100]
training: epoch 34: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.758126, min gradient is -8.000000, learning rate is 0.031479
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.224794, learning rate is 0.031479
Net1: layer conv1:max response is , min response is .
max gradient is 5.555648, min gradient is -8.000000, learning rate is 0.031479
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 1.107792, min gradient is -8.000000, learning rate is 0.000627
Net2: layer deconv3:max response is 16.165455, min response is -25.049683.
max gradient is 5.978174, min gradient is -8.000000, learning rate is 0.000314
Net2: layer bn50:max response is 19.285297, min response is -3.276060.
max gradient is 8.000000, min gradient is -3.394822, learning rate is 0.000627
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.947517, learning rate is 0.000314
Net2: layer bn49:max response is 9.171410, min response is -1.868040.
max gradient is 8.000000, min gradient is -5.718657, learning rate is 0.000627
Net2: layer deconv1:max response is , min response is .
max gradient is 6.360173, min gradient is -8.000000, learning rate is 0.000314
max inferred z is 3.90, min inferred z is -4.10, and std is 0.99
 4.24 s (23.6 data/s) [100/100]
training: epoch 34: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.126082, min gradient is -8.000000, learning rate is 0.031479
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.808305, learning rate is 0.031479
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.599623, learning rate is 0.031479
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.584729, learning rate is 0.000627
Net2: layer deconv3:max response is 16.869999, min response is -18.136282.
max gradient is 5.401788, min gradient is -8.000000, learning rate is 0.000314
Net2: layer bn50:max response is 17.882166, min response is -2.712215.
max gradient is 8.000000, min gradient is -5.239275, learning rate is 0.000627
Net2: layer deconv2:max response is , min response is .
max gradient is 6.221107, min gradient is -8.000000, learning rate is 0.000314
Net2: layer bn49:max response is 8.230593, min response is -1.980164.
max gradient is 8.000000, min gradient is -7.346391, learning rate is 0.000627
Net2: layer deconv1:max response is , min response is .
max gradient is 7.510674, min gradient is -8.000000, learning rate is 0.000314
max inferred z is 4.19, min inferred z is -4.21, and std is 0.99
 4.35 s (23.0 data/s) [100/100]
training: epoch 34: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.358344, learning rate is 0.031479
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.273278, learning rate is 0.031479
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.869104, learning rate is 0.031479
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.543435, learning rate is 0.000627
Net2: layer deconv3:max response is 15.583254, min response is -18.283638.
max gradient is 3.485686, min gradient is -8.000000, learning rate is 0.000314
Net2: layer bn50:max response is 17.262657, min response is -3.043969.
max gradient is 8.000000, min gradient is -1.296195, learning rate is 0.000627
Net2: layer deconv2:max response is , min response is .
max gradient is 7.115144, min gradient is -8.000000, learning rate is 0.000314
Net2: layer bn49:max response is 8.664452, min response is -1.648025.
max gradient is 6.845387, min gradient is -8.000000, learning rate is 0.000627
Net2: layer deconv1:max response is , min response is .
max gradient is 7.385291, min gradient is -8.000000, learning rate is 0.000314
max inferred z is 4.30, min inferred z is -3.57, and std is 0.99
 4.32 s (23.2 data/s) [100/100]
training: epoch 34: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.954635, min gradient is -8.000000, learning rate is 0.031479
Net1: layer conv2:max response is , min response is .
max gradient is 4.969824, min gradient is -8.000000, learning rate is 0.031479
Net1: layer conv1:max response is , min response is .
max gradient is 7.121761, min gradient is -8.000000, learning rate is 0.031479
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.359025, learning rate is 0.000627
Net2: layer deconv3:max response is 15.651930, min response is -24.296299.
max gradient is 7.104295, min gradient is -8.000000, learning rate is 0.000314
Net2: layer bn50:max response is 17.586538, min response is -3.024015.
max gradient is 8.000000, min gradient is -3.522543, learning rate is 0.000627
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.829514, learning rate is 0.000314
Net2: layer bn49:max response is 9.053809, min response is -1.867461.
max gradient is 6.784423, min gradient is -8.000000, learning rate is 0.000627
Net2: layer deconv1:max response is , min response is .
max gradient is 7.293928, min gradient is -8.000000, learning rate is 0.000314
max inferred z is 4.04, min inferred z is -4.13, and std is 0.99
 4.21 s (23.8 data/s) [100/100]
training: epoch 34: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.977966, min gradient is -8.000000, learning rate is 0.031479
Net1: layer conv2:max response is , min response is .
max gradient is 7.146769, min gradient is -8.000000, learning rate is 0.031479
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.831766, learning rate is 0.031479
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.995218, learning rate is 0.000627
Net2: layer deconv3:max response is 16.511471, min response is -19.701612.
max gradient is 8.000000, min gradient is -7.127631, learning rate is 0.000314
Net2: layer bn50:max response is 18.545031, min response is -2.807251.
max gradient is 2.797651, min gradient is -8.000000, learning rate is 0.000627
Net2: layer deconv2:max response is , min response is .
max gradient is 6.237936, min gradient is -8.000000, learning rate is 0.000314
Net2: layer bn49:max response is 8.635478, min response is -1.742007.
max gradient is 7.317311, min gradient is -8.000000, learning rate is 0.000627
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.753943, learning rate is 0.000314
max inferred z is 3.93, min inferred z is -4.04, and std is 0.99
 4.19 s (23.9 data/s) [100/100]
training: epoch 34: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.473941, min gradient is -8.000000, learning rate is 0.031479
Net1: layer conv2:max response is , min response is .
max gradient is 7.001248, min gradient is -8.000000, learning rate is 0.031479
Net1: layer conv1:max response is , min response is .
max gradient is 4.248610, min gradient is -8.000000, learning rate is 0.031479
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.763437, learning rate is 0.000627
Net2: layer deconv3:max response is 16.934595, min response is -17.603483.
max gradient is 8.000000, min gradient is -7.730818, learning rate is 0.000314
Net2: layer bn50:max response is 21.423218, min response is -2.824003.
max gradient is 5.526682, min gradient is -8.000000, learning rate is 0.000627
Net2: layer deconv2:max response is , min response is .
max gradient is 7.876127, min gradient is -8.000001, learning rate is 0.000314
Net2: layer bn49:max response is 8.272207, min response is -1.691577.
max gradient is 6.415040, min gradient is -8.000000, learning rate is 0.000627
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.149657, learning rate is 0.000314
max inferred z is 4.10, min inferred z is -4.10, and std is 0.99
 4.31 s (23.2 data/s) [100/100]
Loss: 2.2699
Iteration 35 / 200
training: epoch 35: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.949406, learning rate is 0.029697
Net1: layer conv2:max response is , min response is .
max gradient is 7.885240, min gradient is -8.000000, learning rate is 0.029697
Net1: layer conv1:max response is , min response is .
max gradient is 4.707710, min gradient is -8.000000, learning rate is 0.029697
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.820508, min gradient is -8.000000, learning rate is 0.000609
Net2: layer deconv3:max response is 14.899011, min response is -18.479044.
max gradient is 8.000000, min gradient is -6.452287, learning rate is 0.000305
Net2: layer bn50:max response is 17.349043, min response is -2.743245.
max gradient is 8.000000, min gradient is -1.441103, learning rate is 0.000609
Net2: layer deconv2:max response is , min response is .
max gradient is 6.647551, min gradient is -8.000000, learning rate is 0.000305
Net2: layer bn49:max response is 7.713620, min response is -1.596495.
max gradient is 6.413691, min gradient is -8.000000, learning rate is 0.000609
Net2: layer deconv1:max response is , min response is .
max gradient is 7.924452, min gradient is -8.000000, learning rate is 0.000305
max inferred z is 4.57, min inferred z is -4.13, and std is 1.00
 4.18 s (23.9 data/s) [100/100]
training: epoch 35: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.937972, learning rate is 0.029697
Net1: layer conv2:max response is , min response is .
max gradient is 5.995742, min gradient is -8.000000, learning rate is 0.029697
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.107770, learning rate is 0.029697
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -3.247143, min gradient is -8.000000, learning rate is 0.000609
Net2: layer deconv3:max response is 14.174306, min response is -15.874926.
max gradient is 7.309917, min gradient is -8.000000, learning rate is 0.000305
Net2: layer bn50:max response is 19.491291, min response is -3.062494.
max gradient is 8.000000, min gradient is -1.769136, learning rate is 0.000609
Net2: layer deconv2:max response is , min response is .
max gradient is 7.086742, min gradient is -8.000000, learning rate is 0.000305
Net2: layer bn49:max response is 7.485702, min response is -1.913711.
max gradient is 8.000000, min gradient is -7.390185, learning rate is 0.000609
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.201297, learning rate is 0.000305
max inferred z is 4.00, min inferred z is -3.51, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 35: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -4.515596, learning rate is 0.029697
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.688595, learning rate is 0.029697
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.684040, learning rate is 0.029697
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.198680, learning rate is 0.000609
Net2: layer deconv3:max response is 13.158713, min response is -15.087770.
max gradient is 7.930307, min gradient is -8.000000, learning rate is 0.000305
Net2: layer bn50:max response is 16.153831, min response is -2.648470.
max gradient is 3.606051, min gradient is -8.000000, learning rate is 0.000609
Net2: layer deconv2:max response is , min response is .
max gradient is 7.954015, min gradient is -8.000000, learning rate is 0.000305
Net2: layer bn49:max response is 8.356141, min response is -1.889979.
max gradient is 8.000000, min gradient is -6.220558, learning rate is 0.000609
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.307647, learning rate is 0.000305
max inferred z is 3.83, min inferred z is -4.82, and std is 1.00
 4.28 s (23.4 data/s) [100/100]
training: epoch 35: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.878697, learning rate is 0.029697
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -3.968750, learning rate is 0.029697
Net1: layer conv1:max response is , min response is .
max gradient is 5.685839, min gradient is -8.000000, learning rate is 0.029697
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.079457, min gradient is -8.000001, learning rate is 0.000609
Net2: layer deconv3:max response is 15.851904, min response is -17.838137.
max gradient is 7.358467, min gradient is -8.000000, learning rate is 0.000305
Net2: layer bn50:max response is 20.055666, min response is -3.632986.
max gradient is 8.000000, min gradient is -7.008065, learning rate is 0.000609
Net2: layer deconv2:max response is , min response is .
max gradient is 7.354869, min gradient is -8.000000, learning rate is 0.000305
Net2: layer bn49:max response is 7.710885, min response is -2.013239.
max gradient is 7.050378, min gradient is -8.000001, learning rate is 0.000609
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.449961, learning rate is 0.000305
max inferred z is 3.93, min inferred z is -3.88, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 35: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.357881, learning rate is 0.029697
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.548105, learning rate is 0.029697
Net1: layer conv1:max response is , min response is .
max gradient is 4.289267, min gradient is -8.000000, learning rate is 0.029697
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -4.076829, min gradient is -8.000000, learning rate is 0.000609
Net2: layer deconv3:max response is 14.470012, min response is -16.206242.
max gradient is 5.520831, min gradient is -8.000000, learning rate is 0.000305
Net2: layer bn50:max response is 16.796806, min response is -2.927135.
max gradient is 8.000000, min gradient is -2.495040, learning rate is 0.000609
Net2: layer deconv2:max response is , min response is .
max gradient is 6.623584, min gradient is -8.000000, learning rate is 0.000305
Net2: layer bn49:max response is 8.648535, min response is -1.874188.
max gradient is 7.530901, min gradient is -8.000000, learning rate is 0.000609
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.704066, learning rate is 0.000305
max inferred z is 4.03, min inferred z is -3.72, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 35: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.321688, min gradient is -8.000000, learning rate is 0.029697
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.238425, learning rate is 0.029697
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.685427, learning rate is 0.029697
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.722186, learning rate is 0.000609
Net2: layer deconv3:max response is 13.277403, min response is -19.861267.
max gradient is 8.000000, min gradient is -4.810694, learning rate is 0.000305
Net2: layer bn50:max response is 19.343796, min response is -3.064692.
max gradient is 3.001600, min gradient is -8.000000, learning rate is 0.000609
Net2: layer deconv2:max response is , min response is .
max gradient is 6.263312, min gradient is -8.000000, learning rate is 0.000305
Net2: layer bn49:max response is 8.554161, min response is -1.756946.
max gradient is 8.000000, min gradient is -5.757947, learning rate is 0.000609
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.912587, learning rate is 0.000305
max inferred z is 4.09, min inferred z is -4.14, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 35: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.473707, learning rate is 0.029697
Net1: layer conv2:max response is , min response is .
max gradient is 7.382816, min gradient is -8.000000, learning rate is 0.029697
Net1: layer conv1:max response is , min response is .
max gradient is 7.646300, min gradient is -8.000000, learning rate is 0.029697
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.065463, learning rate is 0.000609
Net2: layer deconv3:max response is 16.001284, min response is -17.180822.
max gradient is 7.570347, min gradient is -8.000000, learning rate is 0.000305
Net2: layer bn50:max response is 18.883814, min response is -3.188568.
max gradient is 8.000000, min gradient is -6.121156, learning rate is 0.000609
Net2: layer deconv2:max response is , min response is .
max gradient is 7.234435, min gradient is -8.000000, learning rate is 0.000305
Net2: layer bn49:max response is 9.276904, min response is -1.746272.
max gradient is 5.295656, min gradient is -8.000000, learning rate is 0.000609
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.493990, learning rate is 0.000305
max inferred z is 3.78, min inferred z is -3.56, and std is 1.00
 4.22 s (23.7 data/s) [100/100]
training: epoch 35: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.569099, learning rate is 0.029697
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.806165, learning rate is 0.029697
Net1: layer conv1:max response is , min response is .
max gradient is 3.464502, min gradient is -8.000000, learning rate is 0.029697
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.955974, learning rate is 0.000609
Net2: layer deconv3:max response is 13.572774, min response is -17.553661.
max gradient is 6.900580, min gradient is -8.000000, learning rate is 0.000305
Net2: layer bn50:max response is 15.138096, min response is -2.690077.
max gradient is 8.000000, min gradient is -5.029261, learning rate is 0.000609
Net2: layer deconv2:max response is , min response is .
max gradient is 7.080595, min gradient is -8.000000, learning rate is 0.000305
Net2: layer bn49:max response is 8.368333, min response is -1.658892.
max gradient is 5.744949, min gradient is -8.000000, learning rate is 0.000609
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.950921, learning rate is 0.000305
max inferred z is 3.76, min inferred z is -3.70, and std is 1.00
 4.19 s (23.8 data/s) [100/100]
training: epoch 35: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.334223, learning rate is 0.029697
Net1: layer conv2:max response is , min response is .
max gradient is 7.669092, min gradient is -8.000000, learning rate is 0.029697
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.070258, learning rate is 0.029697
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.925041, learning rate is 0.000609
Net2: layer deconv3:max response is 13.434498, min response is -16.624603.
max gradient is 8.000000, min gradient is -6.740664, learning rate is 0.000305
Net2: layer bn50:max response is 18.996956, min response is -2.899537.
max gradient is 3.193066, min gradient is -8.000000, learning rate is 0.000609
Net2: layer deconv2:max response is , min response is .
max gradient is 7.868300, min gradient is -8.000000, learning rate is 0.000305
Net2: layer bn49:max response is 8.292686, min response is -1.771651.
max gradient is 7.703374, min gradient is -8.000000, learning rate is 0.000609
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.570603, learning rate is 0.000305
max inferred z is 4.27, min inferred z is -4.42, and std is 1.00
 4.18 s (23.9 data/s) [100/100]
training: epoch 35: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.412540, learning rate is 0.029697
Net1: layer conv2:max response is , min response is .
max gradient is 5.474389, min gradient is -8.000000, learning rate is 0.029697
Net1: layer conv1:max response is , min response is .
max gradient is 6.293607, min gradient is -8.000000, learning rate is 0.029697
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.855126, min gradient is -8.000000, learning rate is 0.000609
Net2: layer deconv3:max response is 16.501030, min response is -15.786278.
max gradient is 6.554798, min gradient is -8.000000, learning rate is 0.000305
Net2: layer bn50:max response is 19.872805, min response is -2.773414.
max gradient is 8.000000, min gradient is -5.283973, learning rate is 0.000609
Net2: layer deconv2:max response is , min response is .
max gradient is 7.498227, min gradient is -8.000000, learning rate is 0.000305
Net2: layer bn49:max response is 7.683012, min response is -1.740842.
max gradient is 5.076516, min gradient is -8.000000, learning rate is 0.000609
Net2: layer deconv1:max response is , min response is .
max gradient is 6.510392, min gradient is -8.000000, learning rate is 0.000305
max inferred z is 4.18, min inferred z is -4.33, and std is 1.00
 4.36 s (23.0 data/s) [100/100]
Loss: 2.2401
Iteration 36 / 200
training: epoch 36: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.874532, min gradient is -8.000000, learning rate is 0.029697
Net1: layer conv2:max response is , min response is .
max gradient is 6.399477, min gradient is -8.000000, learning rate is 0.029697
Net1: layer conv1:max response is , min response is .
max gradient is 5.820759, min gradient is -8.000000, learning rate is 0.029697
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.729025, min gradient is -8.000000, learning rate is 0.000609
Net2: layer deconv3:max response is 13.485212, min response is -18.410496.
max gradient is 6.713928, min gradient is -8.000000, learning rate is 0.000305
Net2: layer bn50:max response is 16.108210, min response is -2.678176.
max gradient is 8.000000, min gradient is -2.045921, learning rate is 0.000609
Net2: layer deconv2:max response is , min response is .
max gradient is 7.888867, min gradient is -8.000000, learning rate is 0.000305
Net2: layer bn49:max response is 7.594392, min response is -1.764365.
max gradient is 3.764309, min gradient is -8.000000, learning rate is 0.000609
Net2: layer deconv1:max response is , min response is .
max gradient is 6.999228, min gradient is -8.000000, learning rate is 0.000305
max inferred z is 3.66, min inferred z is -4.31, and std is 1.01
 4.16 s (24.0 data/s) [100/100]
training: epoch 36: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.803319, min gradient is -8.000000, learning rate is 0.029697
Net1: layer conv2:max response is , min response is .
max gradient is 6.488295, min gradient is -8.000000, learning rate is 0.029697
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.090118, learning rate is 0.029697
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 6.195037, min gradient is -8.000000, learning rate is 0.000609
Net2: layer deconv3:max response is 14.552494, min response is -17.648983.
max gradient is 8.000000, min gradient is -7.156112, learning rate is 0.000305
Net2: layer bn50:max response is 18.047419, min response is -2.701603.
max gradient is 6.481114, min gradient is -8.000000, learning rate is 0.000609
Net2: layer deconv2:max response is , min response is .
max gradient is 6.628434, min gradient is -8.000000, learning rate is 0.000305
Net2: layer bn49:max response is 9.435257, min response is -1.779473.
max gradient is 6.168866, min gradient is -8.000000, learning rate is 0.000609
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.816354, learning rate is 0.000305
max inferred z is 4.82, min inferred z is -4.12, and std is 1.01
 4.39 s (22.8 data/s) [100/100]
training: epoch 36: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.567614, learning rate is 0.029697
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.588638, learning rate is 0.029697
Net1: layer conv1:max response is , min response is .
max gradient is 4.433359, min gradient is -8.000000, learning rate is 0.029697
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -4.851336, min gradient is -8.000000, learning rate is 0.000609
Net2: layer deconv3:max response is 14.449143, min response is -19.958529.
max gradient is 8.000000, min gradient is -7.952722, learning rate is 0.000305
Net2: layer bn50:max response is 16.940771, min response is -3.368301.
max gradient is 8.000000, min gradient is -4.397846, learning rate is 0.000609
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.945093, learning rate is 0.000305
Net2: layer bn49:max response is 8.091671, min response is -2.114243.
max gradient is 7.435967, min gradient is -8.000000, learning rate is 0.000609
Net2: layer deconv1:max response is , min response is .
max gradient is 7.222349, min gradient is -8.000000, learning rate is 0.000305
max inferred z is 3.89, min inferred z is -3.81, and std is 1.01
 4.25 s (23.5 data/s) [100/100]
training: epoch 36: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.526558, learning rate is 0.029697
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.839624, learning rate is 0.029697
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.033192, learning rate is 0.029697
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.262611, learning rate is 0.000609
Net2: layer deconv3:max response is 14.732705, min response is -18.681454.
max gradient is 6.139840, min gradient is -8.000000, learning rate is 0.000305
Net2: layer bn50:max response is 18.116587, min response is -3.291610.
max gradient is 7.218306, min gradient is -8.000000, learning rate is 0.000609
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.946698, learning rate is 0.000305
Net2: layer bn49:max response is 9.009643, min response is -1.680090.
max gradient is 8.000000, min gradient is -4.072120, learning rate is 0.000609
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.109381, learning rate is 0.000305
max inferred z is 4.13, min inferred z is -4.46, and std is 1.01
 4.42 s (22.6 data/s) [100/100]
training: epoch 36: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.747404, min gradient is -8.000000, learning rate is 0.029697
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.308072, learning rate is 0.029697
Net1: layer conv1:max response is , min response is .
max gradient is 5.087197, min gradient is -8.000000, learning rate is 0.029697
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -5.769516, learning rate is 0.000609
Net2: layer deconv3:max response is 14.526836, min response is -18.659784.
max gradient is 4.496569, min gradient is -8.000000, learning rate is 0.000305
Net2: layer bn50:max response is 19.258938, min response is -3.332981.
max gradient is 8.000000, min gradient is -2.412304, learning rate is 0.000609
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.670168, learning rate is 0.000305
Net2: layer bn49:max response is 9.968260, min response is -1.770528.
max gradient is 8.000000, min gradient is -5.764153, learning rate is 0.000609
Net2: layer deconv1:max response is , min response is .
max gradient is 7.865915, min gradient is -8.000000, learning rate is 0.000305
max inferred z is 3.82, min inferred z is -4.07, and std is 1.01
 4.23 s (23.6 data/s) [100/100]
training: epoch 36: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.207335, min gradient is -8.000000, learning rate is 0.029697
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.557196, learning rate is 0.029697
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.472279, learning rate is 0.029697
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.941164, learning rate is 0.000609
Net2: layer deconv3:max response is 14.983288, min response is -20.314461.
max gradient is 3.383882, min gradient is -8.000000, learning rate is 0.000305
Net2: layer bn50:max response is 18.157328, min response is -2.860217.
max gradient is 8.000000, min gradient is -4.597954, learning rate is 0.000609
Net2: layer deconv2:max response is , min response is .
max gradient is 6.343231, min gradient is -8.000000, learning rate is 0.000305
Net2: layer bn49:max response is 9.324001, min response is -1.774940.
max gradient is 7.186204, min gradient is -8.000000, learning rate is 0.000609
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.416800, learning rate is 0.000305
max inferred z is 4.33, min inferred z is -4.49, and std is 1.01
 4.26 s (23.5 data/s) [100/100]
training: epoch 36: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.657798, min gradient is -8.000000, learning rate is 0.029697
Net1: layer conv2:max response is , min response is .
max gradient is 7.501824, min gradient is -8.000000, learning rate is 0.029697
Net1: layer conv1:max response is , min response is .
max gradient is 6.182568, min gradient is -8.000000, learning rate is 0.029697
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.891963, learning rate is 0.000609
Net2: layer deconv3:max response is 14.801175, min response is -20.678894.
max gradient is 4.000575, min gradient is -8.000000, learning rate is 0.000305
Net2: layer bn50:max response is 17.432007, min response is -3.005678.
max gradient is 8.000000, min gradient is -1.908719, learning rate is 0.000609
Net2: layer deconv2:max response is , min response is .
max gradient is 6.659385, min gradient is -8.000000, learning rate is 0.000305
Net2: layer bn49:max response is 8.464603, min response is -1.823914.
max gradient is 7.354554, min gradient is -8.000000, learning rate is 0.000609
Net2: layer deconv1:max response is , min response is .
max gradient is 7.978214, min gradient is -8.000000, learning rate is 0.000305
max inferred z is 3.90, min inferred z is -4.26, and std is 1.01
 4.45 s (22.5 data/s) [100/100]
training: epoch 36: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.363271, min gradient is -8.000000, learning rate is 0.029697
Net1: layer conv2:max response is , min response is .
max gradient is 5.634608, min gradient is -8.000000, learning rate is 0.029697
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -2.664742, learning rate is 0.029697
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.481546, learning rate is 0.000609
Net2: layer deconv3:max response is 16.247349, min response is -20.479454.
max gradient is 6.445542, min gradient is -8.000000, learning rate is 0.000305
Net2: layer bn50:max response is 18.553797, min response is -2.849722.
max gradient is 4.927041, min gradient is -8.000000, learning rate is 0.000609
Net2: layer deconv2:max response is , min response is .
max gradient is 7.492444, min gradient is -8.000000, learning rate is 0.000305
Net2: layer bn49:max response is 7.870395, min response is -1.614931.
max gradient is 8.000000, min gradient is -6.927235, learning rate is 0.000609
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.121661, learning rate is 0.000305
max inferred z is 3.57, min inferred z is -4.09, and std is 1.01
 4.32 s (23.2 data/s) [100/100]
training: epoch 36: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.396028, learning rate is 0.029697
Net1: layer conv2:max response is , min response is .
max gradient is 7.348301, min gradient is -8.000000, learning rate is 0.029697
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.925922, learning rate is 0.029697
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.671790, learning rate is 0.000609
Net2: layer deconv3:max response is 12.476983, min response is -18.060373.
max gradient is 8.000000, min gradient is -6.949234, learning rate is 0.000305
Net2: layer bn50:max response is 14.954730, min response is -2.847281.
max gradient is 3.022010, min gradient is -8.000000, learning rate is 0.000609
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.296857, learning rate is 0.000305
Net2: layer bn49:max response is 8.442353, min response is -1.828324.
max gradient is 8.000000, min gradient is -7.411434, learning rate is 0.000609
Net2: layer deconv1:max response is , min response is .
max gradient is 7.633017, min gradient is -8.000000, learning rate is 0.000305
max inferred z is 3.66, min inferred z is -4.10, and std is 1.01
 4.36 s (22.9 data/s) [100/100]
training: epoch 36: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.247393, learning rate is 0.029697
Net1: layer conv2:max response is , min response is .
max gradient is 4.696762, min gradient is -8.000000, learning rate is 0.029697
Net1: layer conv1:max response is , min response is .
max gradient is 7.985647, min gradient is -8.000000, learning rate is 0.029697
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.541482, min gradient is -8.000000, learning rate is 0.000609
Net2: layer deconv3:max response is 17.222673, min response is -22.364567.
max gradient is 6.531467, min gradient is -8.000000, learning rate is 0.000305
Net2: layer bn50:max response is 22.251915, min response is -3.217878.
max gradient is 4.965462, min gradient is -8.000000, learning rate is 0.000609
Net2: layer deconv2:max response is , min response is .
max gradient is 5.731818, min gradient is -8.000000, learning rate is 0.000305
Net2: layer bn49:max response is 8.713363, min response is -2.100935.
max gradient is 5.576128, min gradient is -8.000000, learning rate is 0.000609
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.528316, learning rate is 0.000305
max inferred z is 3.93, min inferred z is -4.48, and std is 1.01
 4.42 s (22.6 data/s) [100/100]
Loss: 2.2622
Iteration 37 / 200
training: epoch 37: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.622940, learning rate is 0.028015
Net1: layer conv2:max response is , min response is .
max gradient is 6.391594, min gradient is -8.000000, learning rate is 0.028015
Net1: layer conv1:max response is , min response is .
max gradient is 4.320312, min gradient is -8.000000, learning rate is 0.028015
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.202915, min gradient is -8.000000, learning rate is 0.000592
Net2: layer deconv3:max response is 13.209659, min response is -17.345320.
max gradient is 6.098778, min gradient is -8.000000, learning rate is 0.000296
Net2: layer bn50:max response is 19.252895, min response is -3.347751.
max gradient is 8.000000, min gradient is -2.406199, learning rate is 0.000592
Net2: layer deconv2:max response is , min response is .
max gradient is 7.801900, min gradient is -8.000000, learning rate is 0.000296
Net2: layer bn49:max response is 8.897309, min response is -1.796857.
max gradient is 4.206121, min gradient is -8.000001, learning rate is 0.000592
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.994809, learning rate is 0.000296
max inferred z is 3.97, min inferred z is -4.01, and std is 1.00
 4.22 s (23.7 data/s) [100/100]
training: epoch 37: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.163944, learning rate is 0.028015
Net1: layer conv2:max response is , min response is .
max gradient is 7.941623, min gradient is -8.000000, learning rate is 0.028015
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.559297, learning rate is 0.028015
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -3.914683, min gradient is -8.000000, learning rate is 0.000592
Net2: layer deconv3:max response is 14.178281, min response is -17.042744.
max gradient is 8.000000, min gradient is -6.735679, learning rate is 0.000296
Net2: layer bn50:max response is 16.396170, min response is -2.892569.
max gradient is 8.000000, min gradient is -5.937844, learning rate is 0.000592
Net2: layer deconv2:max response is , min response is .
max gradient is 6.795121, min gradient is -8.000000, learning rate is 0.000296
Net2: layer bn49:max response is 10.445448, min response is -1.810102.
max gradient is 5.617756, min gradient is -8.000000, learning rate is 0.000592
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.256950, learning rate is 0.000296
max inferred z is 3.73, min inferred z is -3.70, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 37: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.621006, learning rate is 0.028015
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.076937, learning rate is 0.028015
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.454184, learning rate is 0.028015
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 3.009655, min gradient is -8.000000, learning rate is 0.000592
Net2: layer deconv3:max response is 16.795368, min response is -18.148430.
max gradient is 8.000000, min gradient is -5.757199, learning rate is 0.000296
Net2: layer bn50:max response is 19.312954, min response is -2.739752.
max gradient is 5.918260, min gradient is -8.000000, learning rate is 0.000592
Net2: layer deconv2:max response is , min response is .
max gradient is 7.304092, min gradient is -8.000000, learning rate is 0.000296
Net2: layer bn49:max response is 8.155938, min response is -1.806470.
max gradient is 8.000000, min gradient is -7.792675, learning rate is 0.000592
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.034816, learning rate is 0.000296
max inferred z is 3.90, min inferred z is -4.18, and std is 1.00
 4.19 s (23.8 data/s) [100/100]
training: epoch 37: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.997694, min gradient is -8.000000, learning rate is 0.028015
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.916555, learning rate is 0.028015
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.680310, learning rate is 0.028015
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.504797, learning rate is 0.000592
Net2: layer deconv3:max response is 14.970131, min response is -17.334665.
max gradient is 8.000000, min gradient is -6.634589, learning rate is 0.000296
Net2: layer bn50:max response is 15.220649, min response is -3.011639.
max gradient is 3.575364, min gradient is -8.000000, learning rate is 0.000592
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.791078, learning rate is 0.000296
Net2: layer bn49:max response is 7.750004, min response is -1.801191.
max gradient is 8.000000, min gradient is -7.527650, learning rate is 0.000592
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.413093, learning rate is 0.000296
max inferred z is 4.17, min inferred z is -3.74, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 37: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.214280, learning rate is 0.028015
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.912578, learning rate is 0.028015
Net1: layer conv1:max response is , min response is .
max gradient is 5.285987, min gradient is -8.000000, learning rate is 0.028015
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -6.232287, learning rate is 0.000592
Net2: layer deconv3:max response is 13.808448, min response is -20.475016.
max gradient is 7.076086, min gradient is -8.000000, learning rate is 0.000296
Net2: layer bn50:max response is 17.329514, min response is -2.656771.
max gradient is 8.000000, min gradient is -2.797399, learning rate is 0.000592
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.429845, learning rate is 0.000296
Net2: layer bn49:max response is 7.765985, min response is -1.919305.
max gradient is 7.966802, min gradient is -8.000000, learning rate is 0.000592
Net2: layer deconv1:max response is , min response is .
max gradient is 7.166939, min gradient is -8.000000, learning rate is 0.000296
max inferred z is 3.93, min inferred z is -3.78, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 37: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.129485, min gradient is -8.000000, learning rate is 0.028015
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.408694, learning rate is 0.028015
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.095971, learning rate is 0.028015
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.245286, learning rate is 0.000592
Net2: layer deconv3:max response is 18.966530, min response is -18.443634.
max gradient is 8.000000, min gradient is -7.084346, learning rate is 0.000296
Net2: layer bn50:max response is 15.220084, min response is -3.486971.
max gradient is 4.516497, min gradient is -8.000000, learning rate is 0.000592
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.883882, learning rate is 0.000296
Net2: layer bn49:max response is 7.916559, min response is -1.616522.
max gradient is 8.000000, min gradient is -5.711380, learning rate is 0.000592
Net2: layer deconv1:max response is , min response is .
max gradient is 7.345063, min gradient is -8.000000, learning rate is 0.000296
max inferred z is 4.05, min inferred z is -4.39, and std is 1.00
 4.43 s (22.6 data/s) [100/100]
training: epoch 37: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.464244, min gradient is -8.000000, learning rate is 0.028015
Net1: layer conv2:max response is , min response is .
max gradient is 6.068578, min gradient is -8.000000, learning rate is 0.028015
Net1: layer conv1:max response is , min response is .
max gradient is 6.625767, min gradient is -8.000000, learning rate is 0.028015
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.596055, learning rate is 0.000592
Net2: layer deconv3:max response is 15.022946, min response is -17.813295.
max gradient is 7.659199, min gradient is -8.000000, learning rate is 0.000296
Net2: layer bn50:max response is 15.484459, min response is -3.029979.
max gradient is 8.000000, min gradient is -5.797233, learning rate is 0.000592
Net2: layer deconv2:max response is , min response is .
max gradient is 5.879868, min gradient is -8.000000, learning rate is 0.000296
Net2: layer bn49:max response is 7.813991, min response is -1.595234.
max gradient is 5.249564, min gradient is -8.000000, learning rate is 0.000592
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.499528, learning rate is 0.000296
max inferred z is 3.96, min inferred z is -4.30, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 37: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.111132, learning rate is 0.028015
Net1: layer conv2:max response is , min response is .
max gradient is 6.524872, min gradient is -8.000000, learning rate is 0.028015
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.990750, learning rate is 0.028015
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.420303, learning rate is 0.000592
Net2: layer deconv3:max response is 15.982965, min response is -19.928541.
max gradient is 8.000000, min gradient is -6.918392, learning rate is 0.000296
Net2: layer bn50:max response is 17.322674, min response is -3.783906.
max gradient is 8.000000, min gradient is -7.001828, learning rate is 0.000592
Net2: layer deconv2:max response is , min response is .
max gradient is 6.433928, min gradient is -8.000000, learning rate is 0.000296
Net2: layer bn49:max response is 7.886311, min response is -1.622597.
max gradient is 7.661065, min gradient is -8.000000, learning rate is 0.000592
Net2: layer deconv1:max response is , min response is .
max gradient is 6.721340, min gradient is -8.000000, learning rate is 0.000296
max inferred z is 4.14, min inferred z is -4.17, and std is 1.00
 4.21 s (23.7 data/s) [100/100]
training: epoch 37: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.619035, learning rate is 0.028015
Net1: layer conv2:max response is , min response is .
max gradient is 7.895041, min gradient is -8.000000, learning rate is 0.028015
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.775480, learning rate is 0.028015
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.002289, learning rate is 0.000592
Net2: layer deconv3:max response is 18.505625, min response is -19.110445.
max gradient is 8.000000, min gradient is -4.304235, learning rate is 0.000296
Net2: layer bn50:max response is 16.480246, min response is -3.324617.
max gradient is 2.720069, min gradient is -8.000000, learning rate is 0.000592
Net2: layer deconv2:max response is , min response is .
max gradient is 5.872688, min gradient is -8.000000, learning rate is 0.000296
Net2: layer bn49:max response is 8.321675, min response is -1.877793.
max gradient is 7.159229, min gradient is -8.000000, learning rate is 0.000592
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.446898, learning rate is 0.000296
max inferred z is 3.66, min inferred z is -3.68, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 37: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.266119, learning rate is 0.028015
Net1: layer conv2:max response is , min response is .
max gradient is 4.750865, min gradient is -8.000000, learning rate is 0.028015
Net1: layer conv1:max response is , min response is .
max gradient is 3.896022, min gradient is -8.000000, learning rate is 0.028015
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.014153, min gradient is -8.000000, learning rate is 0.000592
Net2: layer deconv3:max response is 14.665403, min response is -20.633415.
max gradient is 7.260266, min gradient is -8.000000, learning rate is 0.000296
Net2: layer bn50:max response is 14.626041, min response is -3.383167.
max gradient is 8.000000, min gradient is -3.655339, learning rate is 0.000592
Net2: layer deconv2:max response is , min response is .
max gradient is 6.496130, min gradient is -8.000000, learning rate is 0.000296
Net2: layer bn49:max response is 7.428160, min response is -2.015556.
max gradient is 4.122247, min gradient is -8.000000, learning rate is 0.000592
Net2: layer deconv1:max response is , min response is .
max gradient is 6.353885, min gradient is -8.000000, learning rate is 0.000296
max inferred z is 3.65, min inferred z is -4.54, and std is 1.00
 4.16 s (24.0 data/s) [100/100]
Loss: 2.2031
Iteration 38 / 200
training: epoch 38: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.035474, min gradient is -8.000000, learning rate is 0.028015
Net1: layer conv2:max response is , min response is .
max gradient is 5.519999, min gradient is -8.000000, learning rate is 0.028015
Net1: layer conv1:max response is , min response is .
max gradient is 6.297450, min gradient is -8.000000, learning rate is 0.028015
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.977535, min gradient is -8.000000, learning rate is 0.000592
Net2: layer deconv3:max response is 14.726887, min response is -19.041924.
max gradient is 6.078716, min gradient is -8.000000, learning rate is 0.000296
Net2: layer bn50:max response is 16.627029, min response is -3.086427.
max gradient is 8.000000, min gradient is -1.030453, learning rate is 0.000592
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.616771, learning rate is 0.000296
Net2: layer bn49:max response is 8.449968, min response is -1.716033.
max gradient is 4.396304, min gradient is -8.000000, learning rate is 0.000592
Net2: layer deconv1:max response is , min response is .
max gradient is 7.378442, min gradient is -8.000000, learning rate is 0.000296
max inferred z is 4.12, min inferred z is -4.22, and std is 1.01
 4.18 s (23.9 data/s) [100/100]
training: epoch 38: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.186557, min gradient is -8.000000, learning rate is 0.028015
Net1: layer conv2:max response is , min response is .
max gradient is 7.038138, min gradient is -8.000000, learning rate is 0.028015
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.483493, learning rate is 0.028015
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 0.012094, min gradient is -8.000000, learning rate is 0.000592
Net2: layer deconv3:max response is 14.675962, min response is -19.065439.
max gradient is 8.000000, min gradient is -7.378922, learning rate is 0.000296
Net2: layer bn50:max response is 16.510696, min response is -2.968660.
max gradient is 8.000000, min gradient is -7.416621, learning rate is 0.000592
Net2: layer deconv2:max response is , min response is .
max gradient is 6.949193, min gradient is -8.000000, learning rate is 0.000296
Net2: layer bn49:max response is 8.250319, min response is -1.913641.
max gradient is 5.749534, min gradient is -8.000000, learning rate is 0.000592
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.610085, learning rate is 0.000296
max inferred z is 4.17, min inferred z is -4.01, and std is 1.01
 4.21 s (23.8 data/s) [100/100]
training: epoch 38: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.179748, learning rate is 0.028015
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.969795, learning rate is 0.028015
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.455275, learning rate is 0.028015
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -4.026766, min gradient is -8.000000, learning rate is 0.000592
Net2: layer deconv3:max response is 17.015749, min response is -22.630070.
max gradient is 8.000000, min gradient is -6.603408, learning rate is 0.000296
Net2: layer bn50:max response is 20.377129, min response is -2.985083.
max gradient is 8.000000, min gradient is -6.151563, learning rate is 0.000592
Net2: layer deconv2:max response is , min response is .
max gradient is 7.721465, min gradient is -8.000000, learning rate is 0.000296
Net2: layer bn49:max response is 8.940369, min response is -1.777303.
max gradient is 8.000000, min gradient is -6.560593, learning rate is 0.000592
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.751508, learning rate is 0.000296
max inferred z is 4.32, min inferred z is -4.30, and std is 1.01
 4.27 s (23.4 data/s) [100/100]
training: epoch 38: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.546093, learning rate is 0.028015
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.332328, learning rate is 0.028015
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.139388, learning rate is 0.028015
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.743885, learning rate is 0.000592
Net2: layer deconv3:max response is 14.876174, min response is -21.023111.
max gradient is 8.000000, min gradient is -7.858646, learning rate is 0.000296
Net2: layer bn50:max response is 16.592642, min response is -3.080217.
max gradient is 6.892707, min gradient is -8.000000, learning rate is 0.000592
Net2: layer deconv2:max response is , min response is .
max gradient is 6.294729, min gradient is -8.000000, learning rate is 0.000296
Net2: layer bn49:max response is 7.715575, min response is -2.035386.
max gradient is 8.000000, min gradient is -6.360906, learning rate is 0.000592
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.552984, learning rate is 0.000296
max inferred z is 3.69, min inferred z is -3.96, and std is 1.01
 4.30 s (23.2 data/s) [100/100]
training: epoch 38: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.144264, learning rate is 0.028015
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.929554, learning rate is 0.028015
Net1: layer conv1:max response is , min response is .
max gradient is 5.266430, min gradient is -8.000000, learning rate is 0.028015
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.566153, learning rate is 0.000592
Net2: layer deconv3:max response is 15.842793, min response is -20.011284.
max gradient is 5.893711, min gradient is -8.000000, learning rate is 0.000296
Net2: layer bn50:max response is 15.263399, min response is -3.355786.
max gradient is 8.000000, min gradient is -4.463280, learning rate is 0.000592
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.448519, learning rate is 0.000296
Net2: layer bn49:max response is 7.776669, min response is -1.685780.
max gradient is 5.671281, min gradient is -8.000000, learning rate is 0.000592
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.868670, learning rate is 0.000296
max inferred z is 4.02, min inferred z is -4.12, and std is 1.01
 4.41 s (22.7 data/s) [100/100]
training: epoch 38: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.424778, min gradient is -8.000000, learning rate is 0.028015
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -3.270800, learning rate is 0.028015
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.125526, learning rate is 0.028015
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.044281, learning rate is 0.000592
Net2: layer deconv3:max response is 14.350519, min response is -23.011831.
max gradient is 4.155646, min gradient is -8.000000, learning rate is 0.000296
Net2: layer bn50:max response is 15.718342, min response is -3.816933.
max gradient is 8.000000, min gradient is -3.379851, learning rate is 0.000592
Net2: layer deconv2:max response is , min response is .
max gradient is 6.339657, min gradient is -8.000000, learning rate is 0.000296
Net2: layer bn49:max response is 8.200668, min response is -1.634692.
max gradient is 8.000000, min gradient is -5.760459, learning rate is 0.000592
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.781907, learning rate is 0.000296
max inferred z is 4.54, min inferred z is -4.21, and std is 1.01
 4.34 s (23.0 data/s) [100/100]
training: epoch 38: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.231942, learning rate is 0.028015
Net1: layer conv2:max response is , min response is .
max gradient is 5.791458, min gradient is -8.000000, learning rate is 0.028015
Net1: layer conv1:max response is , min response is .
max gradient is 5.526802, min gradient is -8.000000, learning rate is 0.028015
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.155692, learning rate is 0.000592
Net2: layer deconv3:max response is 15.777164, min response is -25.525713.
max gradient is 5.299363, min gradient is -8.000000, learning rate is 0.000296
Net2: layer bn50:max response is 17.435183, min response is -3.062000.
max gradient is 8.000000, min gradient is -2.218678, learning rate is 0.000592
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.621694, learning rate is 0.000296
Net2: layer bn49:max response is 9.277043, min response is -1.797309.
max gradient is 8.000000, min gradient is -7.378216, learning rate is 0.000592
Net2: layer deconv1:max response is , min response is .
max gradient is 7.283305, min gradient is -8.000000, learning rate is 0.000296
max inferred z is 4.02, min inferred z is -3.95, and std is 1.01
 4.44 s (22.5 data/s) [100/100]
training: epoch 38: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.076108, min gradient is -8.000000, learning rate is 0.028015
Net1: layer conv2:max response is , min response is .
max gradient is 6.054080, min gradient is -8.000000, learning rate is 0.028015
Net1: layer conv1:max response is , min response is .
max gradient is 6.990006, min gradient is -8.000000, learning rate is 0.028015
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.835297, learning rate is 0.000592
Net2: layer deconv3:max response is 16.572180, min response is -20.536768.
max gradient is 7.748279, min gradient is -8.000000, learning rate is 0.000296
Net2: layer bn50:max response is 17.058868, min response is -3.297583.
max gradient is 8.000000, min gradient is -7.580207, learning rate is 0.000592
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.658075, learning rate is 0.000296
Net2: layer bn49:max response is 9.225017, min response is -1.601759.
max gradient is 8.000000, min gradient is -7.642280, learning rate is 0.000592
Net2: layer deconv1:max response is , min response is .
max gradient is 7.955457, min gradient is -8.000000, learning rate is 0.000296
max inferred z is 3.90, min inferred z is -3.54, and std is 1.01
 4.33 s (23.1 data/s) [100/100]
training: epoch 38: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.990770, learning rate is 0.028015
Net1: layer conv2:max response is , min response is .
max gradient is 7.786592, min gradient is -8.000000, learning rate is 0.028015
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.053270, learning rate is 0.028015
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.681166, learning rate is 0.000592
Net2: layer deconv3:max response is 15.614011, min response is -21.760012.
max gradient is 8.000000, min gradient is -6.284343, learning rate is 0.000296
Net2: layer bn50:max response is 16.294666, min response is -3.375407.
max gradient is 2.485024, min gradient is -8.000000, learning rate is 0.000592
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.059453, learning rate is 0.000296
Net2: layer bn49:max response is 7.810369, min response is -1.570738.
max gradient is 8.000000, min gradient is -7.010456, learning rate is 0.000592
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.221203, learning rate is 0.000296
max inferred z is 3.71, min inferred z is -4.31, and std is 1.01
 4.27 s (23.4 data/s) [100/100]
training: epoch 38: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.289994, learning rate is 0.028015
Net1: layer conv2:max response is , min response is .
max gradient is 4.504148, min gradient is -8.000000, learning rate is 0.028015
Net1: layer conv1:max response is , min response is .
max gradient is 3.071815, min gradient is -8.000000, learning rate is 0.028015
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.346824, min gradient is -8.000000, learning rate is 0.000592
Net2: layer deconv3:max response is 15.589401, min response is -19.592297.
max gradient is 5.832940, min gradient is -8.000000, learning rate is 0.000296
Net2: layer bn50:max response is 16.317158, min response is -3.415613.
max gradient is 7.124202, min gradient is -8.000000, learning rate is 0.000592
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.968353, learning rate is 0.000296
Net2: layer bn49:max response is 8.664250, min response is -1.692188.
max gradient is 4.463490, min gradient is -8.000001, learning rate is 0.000592
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.727264, learning rate is 0.000296
max inferred z is 3.89, min inferred z is -3.86, and std is 1.01
 4.29 s (23.3 data/s) [100/100]
Loss: 2.2661
Iteration 39 / 200
training: epoch 39: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.678136, learning rate is 0.026429
Net1: layer conv2:max response is , min response is .
max gradient is 5.764821, min gradient is -8.000000, learning rate is 0.026429
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.021106, learning rate is 0.026429
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.558008, min gradient is -8.000000, learning rate is 0.000575
Net2: layer deconv3:max response is 18.862556, min response is -18.675581.
max gradient is 6.759151, min gradient is -8.000000, learning rate is 0.000287
Net2: layer bn50:max response is 17.300648, min response is -3.883928.
max gradient is 8.000000, min gradient is -1.811516, learning rate is 0.000575
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.880437, learning rate is 0.000287
Net2: layer bn49:max response is 9.177110, min response is -1.654207.
max gradient is 3.315763, min gradient is -8.000000, learning rate is 0.000575
Net2: layer deconv1:max response is , min response is .
max gradient is 7.455813, min gradient is -8.000000, learning rate is 0.000287
max inferred z is 4.11, min inferred z is -3.91, and std is 1.00
 4.16 s (24.0 data/s) [100/100]
training: epoch 39: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.745442, learning rate is 0.026429
Net1: layer conv2:max response is , min response is .
max gradient is 6.924345, min gradient is -8.000000, learning rate is 0.026429
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.418154, learning rate is 0.026429
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 3.331901, min gradient is -8.000000, learning rate is 0.000575
Net2: layer deconv3:max response is 21.119059, min response is -20.698122.
max gradient is 7.570029, min gradient is -8.000000, learning rate is 0.000287
Net2: layer bn50:max response is 19.180817, min response is -3.390612.
max gradient is 3.829402, min gradient is -8.000000, learning rate is 0.000575
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.871248, learning rate is 0.000287
Net2: layer bn49:max response is 9.221255, min response is -1.691093.
max gradient is 6.036459, min gradient is -8.000000, learning rate is 0.000575
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.320472, learning rate is 0.000287
max inferred z is 4.45, min inferred z is -3.79, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 39: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.118835, learning rate is 0.026429
Net1: layer conv2:max response is , min response is .
max gradient is 7.322901, min gradient is -8.000000, learning rate is 0.026429
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -2.968248, learning rate is 0.026429
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -4.477605, min gradient is -8.000000, learning rate is 0.000575
Net2: layer deconv3:max response is 15.384850, min response is -22.347946.
max gradient is 8.000000, min gradient is -7.082938, learning rate is 0.000287
Net2: layer bn50:max response is 18.315275, min response is -3.307241.
max gradient is 8.000000, min gradient is -7.331697, learning rate is 0.000575
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.041630, learning rate is 0.000287
Net2: layer bn49:max response is 9.752914, min response is -1.812279.
max gradient is 7.041315, min gradient is -8.000000, learning rate is 0.000575
Net2: layer deconv1:max response is , min response is .
max gradient is 7.417430, min gradient is -8.000001, learning rate is 0.000287
max inferred z is 4.63, min inferred z is -3.74, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 39: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.488761, min gradient is -8.000000, learning rate is 0.026429
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.778624, learning rate is 0.026429
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.745249, learning rate is 0.026429
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.713359, learning rate is 0.000575
Net2: layer deconv3:max response is 16.415037, min response is -19.402126.
max gradient is 8.000000, min gradient is -6.271273, learning rate is 0.000287
Net2: layer bn50:max response is 17.900381, min response is -3.345887.
max gradient is 4.016054, min gradient is -8.000000, learning rate is 0.000575
Net2: layer deconv2:max response is , min response is .
max gradient is 6.129195, min gradient is -8.000000, learning rate is 0.000287
Net2: layer bn49:max response is 7.501979, min response is -1.721444.
max gradient is 6.968054, min gradient is -8.000000, learning rate is 0.000575
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.540101, learning rate is 0.000287
max inferred z is 3.90, min inferred z is -4.01, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 39: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.843479, min gradient is -8.000000, learning rate is 0.026429
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.358004, learning rate is 0.026429
Net1: layer conv1:max response is , min response is .
max gradient is 6.058868, min gradient is -8.000000, learning rate is 0.026429
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.938776, learning rate is 0.000575
Net2: layer deconv3:max response is 16.677887, min response is -22.079624.
max gradient is 6.592766, min gradient is -8.000000, learning rate is 0.000287
Net2: layer bn50:max response is 16.101692, min response is -3.320652.
max gradient is 8.000000, min gradient is -1.995022, learning rate is 0.000575
Net2: layer deconv2:max response is , min response is .
max gradient is 7.860950, min gradient is -8.000000, learning rate is 0.000287
Net2: layer bn49:max response is 8.132269, min response is -2.263322.
max gradient is 7.254334, min gradient is -8.000000, learning rate is 0.000575
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.383102, learning rate is 0.000287
max inferred z is 3.76, min inferred z is -4.14, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 39: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.188794, learning rate is 0.026429
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -3.615714, learning rate is 0.026429
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.440416, learning rate is 0.026429
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.240809, learning rate is 0.000575
Net2: layer deconv3:max response is 17.737024, min response is -19.216282.
max gradient is 5.720432, min gradient is -8.000000, learning rate is 0.000287
Net2: layer bn50:max response is 16.589025, min response is -3.785367.
max gradient is 8.000000, min gradient is -4.723736, learning rate is 0.000575
Net2: layer deconv2:max response is , min response is .
max gradient is 4.962257, min gradient is -8.000000, learning rate is 0.000287
Net2: layer bn49:max response is 9.397992, min response is -1.801240.
max gradient is 4.991516, min gradient is -8.000000, learning rate is 0.000575
Net2: layer deconv1:max response is , min response is .
max gradient is 7.137923, min gradient is -8.000000, learning rate is 0.000287
max inferred z is 5.12, min inferred z is -4.14, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 39: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.394528, min gradient is -8.000000, learning rate is 0.026429
Net1: layer conv2:max response is , min response is .
max gradient is 7.641431, min gradient is -8.000000, learning rate is 0.026429
Net1: layer conv1:max response is , min response is .
max gradient is 6.448336, min gradient is -8.000000, learning rate is 0.026429
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.869613, learning rate is 0.000575
Net2: layer deconv3:max response is 15.194654, min response is -24.737680.
max gradient is 6.643541, min gradient is -8.000000, learning rate is 0.000287
Net2: layer bn50:max response is 15.285438, min response is -3.483756.
max gradient is 8.000000, min gradient is -3.836835, learning rate is 0.000575
Net2: layer deconv2:max response is , min response is .
max gradient is 4.958859, min gradient is -8.000000, learning rate is 0.000287
Net2: layer bn49:max response is 7.916192, min response is -1.717296.
max gradient is 6.536550, min gradient is -8.000000, learning rate is 0.000575
Net2: layer deconv1:max response is , min response is .
max gradient is 7.836739, min gradient is -8.000000, learning rate is 0.000287
max inferred z is 3.58, min inferred z is -4.23, and std is 1.00
 4.30 s (23.3 data/s) [100/100]
training: epoch 39: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.352461, learning rate is 0.026429
Net1: layer conv2:max response is , min response is .
max gradient is 6.891062, min gradient is -8.000000, learning rate is 0.026429
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.300021, learning rate is 0.026429
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.968376, learning rate is 0.000575
Net2: layer deconv3:max response is 15.098621, min response is -22.967623.
max gradient is 8.000000, min gradient is -7.734306, learning rate is 0.000287
Net2: layer bn50:max response is 16.230198, min response is -3.167939.
max gradient is 8.000000, min gradient is -6.079212, learning rate is 0.000575
Net2: layer deconv2:max response is , min response is .
max gradient is 5.713762, min gradient is -8.000000, learning rate is 0.000287
Net2: layer bn49:max response is 8.393316, min response is -1.661911.
max gradient is 7.017503, min gradient is -8.000000, learning rate is 0.000575
Net2: layer deconv1:max response is , min response is .
max gradient is 7.534106, min gradient is -8.000000, learning rate is 0.000287
max inferred z is 4.21, min inferred z is -3.83, and std is 1.00
 4.36 s (23.0 data/s) [100/100]
training: epoch 39: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.950280, learning rate is 0.026429
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.974185, learning rate is 0.026429
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.346591, learning rate is 0.026429
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.151120, learning rate is 0.000575
Net2: layer deconv3:max response is 14.409377, min response is -21.309851.
max gradient is 8.000000, min gradient is -5.085502, learning rate is 0.000287
Net2: layer bn50:max response is 15.275218, min response is -3.519694.
max gradient is 2.890338, min gradient is -8.000000, learning rate is 0.000575
Net2: layer deconv2:max response is , min response is .
max gradient is 6.540811, min gradient is -8.000000, learning rate is 0.000287
Net2: layer bn49:max response is 8.993131, min response is -1.596716.
max gradient is 6.215083, min gradient is -8.000000, learning rate is 0.000575
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.521186, learning rate is 0.000287
max inferred z is 4.07, min inferred z is -4.19, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 39: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.038341, learning rate is 0.026429
Net1: layer conv2:max response is , min response is .
max gradient is 4.080264, min gradient is -8.000000, learning rate is 0.026429
Net1: layer conv1:max response is , min response is .
max gradient is 4.364885, min gradient is -8.000000, learning rate is 0.026429
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.981338, min gradient is -8.000001, learning rate is 0.000575
Net2: layer deconv3:max response is 15.105649, min response is -23.174353.
max gradient is 7.454134, min gradient is -8.000000, learning rate is 0.000287
Net2: layer bn50:max response is 16.099882, min response is -4.139461.
max gradient is 8.000000, min gradient is -3.132948, learning rate is 0.000575
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.921971, learning rate is 0.000287
Net2: layer bn49:max response is 9.516873, min response is -1.880338.
max gradient is 4.982309, min gradient is -8.000000, learning rate is 0.000575
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.686376, learning rate is 0.000287
max inferred z is 4.60, min inferred z is -4.64, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
Loss: 2.3006
Iteration 40 / 200
training: epoch 40: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.355056, min gradient is -8.000000, learning rate is 0.026429
Net1: layer conv2:max response is , min response is .
max gradient is 4.595670, min gradient is -8.000000, learning rate is 0.026429
Net1: layer conv1:max response is , min response is .
max gradient is 6.858468, min gradient is -8.000000, learning rate is 0.026429
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.766688, min gradient is -8.000000, learning rate is 0.000575
Net2: layer deconv3:max response is 14.707550, min response is -21.581963.
max gradient is 8.000000, min gradient is -7.180138, learning rate is 0.000287
Net2: layer bn50:max response is 17.760654, min response is -4.229114.
max gradient is 8.000000, min gradient is -1.573174, learning rate is 0.000575
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.430520, learning rate is 0.000287
Net2: layer bn49:max response is 7.844383, min response is -2.016370.
max gradient is 5.306412, min gradient is -8.000000, learning rate is 0.000575
Net2: layer deconv1:max response is , min response is .
max gradient is 5.980525, min gradient is -8.000000, learning rate is 0.000287
max inferred z is 3.92, min inferred z is -3.56, and std is 1.00
 4.14 s (24.2 data/s) [100/100]
training: epoch 40: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.425593, learning rate is 0.026429
Net1: layer conv2:max response is , min response is .
max gradient is 6.288455, min gradient is -8.000000, learning rate is 0.026429
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.385729, learning rate is 0.026429
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.190025, min gradient is -8.000000, learning rate is 0.000575
Net2: layer deconv3:max response is 16.331085, min response is -23.204859.
max gradient is 7.857477, min gradient is -8.000000, learning rate is 0.000287
Net2: layer bn50:max response is 17.183025, min response is -4.001808.
max gradient is 8.000000, min gradient is -3.588974, learning rate is 0.000575
Net2: layer deconv2:max response is , min response is .
max gradient is 6.082526, min gradient is -8.000000, learning rate is 0.000287
Net2: layer bn49:max response is 9.984472, min response is -1.729271.
max gradient is 8.000000, min gradient is -7.574077, learning rate is 0.000575
Net2: layer deconv1:max response is , min response is .
max gradient is 6.580673, min gradient is -8.000000, learning rate is 0.000287
max inferred z is 3.88, min inferred z is -4.15, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 40: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.328723, min gradient is -8.000000, learning rate is 0.026429
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.154243, learning rate is 0.026429
Net1: layer conv1:max response is , min response is .
max gradient is 5.759052, min gradient is -8.000000, learning rate is 0.026429
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.738043, min gradient is -8.000000, learning rate is 0.000575
Net2: layer deconv3:max response is 17.020050, min response is -19.779488.
max gradient is 8.000000, min gradient is -7.433686, learning rate is 0.000287
Net2: layer bn50:max response is 17.286739, min response is -3.793182.
max gradient is 8.000000, min gradient is -6.383975, learning rate is 0.000575
Net2: layer deconv2:max response is , min response is .
max gradient is 5.092253, min gradient is -8.000000, learning rate is 0.000287
Net2: layer bn49:max response is 7.365317, min response is -2.226997.
max gradient is 8.000000, min gradient is -6.691489, learning rate is 0.000575
Net2: layer deconv1:max response is , min response is .
max gradient is 7.834552, min gradient is -8.000000, learning rate is 0.000287
max inferred z is 3.76, min inferred z is -4.18, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 40: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.643969, min gradient is -8.000000, learning rate is 0.026429
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -3.967698, learning rate is 0.026429
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.187258, learning rate is 0.026429
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.481813, learning rate is 0.000575
Net2: layer deconv3:max response is 15.497961, min response is -22.324389.
max gradient is 7.537436, min gradient is -8.000000, learning rate is 0.000287
Net2: layer bn50:max response is 18.289566, min response is -3.678057.
max gradient is 5.430801, min gradient is -8.000000, learning rate is 0.000575
Net2: layer deconv2:max response is , min response is .
max gradient is 7.178939, min gradient is -8.000000, learning rate is 0.000287
Net2: layer bn49:max response is 8.483798, min response is -1.695901.
max gradient is 7.461180, min gradient is -8.000000, learning rate is 0.000575
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.530405, learning rate is 0.000287
max inferred z is 3.65, min inferred z is -3.97, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 40: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.888700, min gradient is -8.000000, learning rate is 0.026429
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.198258, learning rate is 0.026429
Net1: layer conv1:max response is , min response is .
max gradient is 4.775120, min gradient is -8.000000, learning rate is 0.026429
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.914472, learning rate is 0.000575
Net2: layer deconv3:max response is 17.481909, min response is -22.248255.
max gradient is 4.807349, min gradient is -8.000000, learning rate is 0.000287
Net2: layer bn50:max response is 15.528899, min response is -3.439485.
max gradient is 8.000000, min gradient is -6.206678, learning rate is 0.000575
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.975941, learning rate is 0.000287
Net2: layer bn49:max response is 8.281053, min response is -2.109448.
max gradient is 8.000000, min gradient is -6.924160, learning rate is 0.000575
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.676358, learning rate is 0.000287
max inferred z is 4.00, min inferred z is -5.06, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 40: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.834211, min gradient is -8.000000, learning rate is 0.026429
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -3.831279, learning rate is 0.026429
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.436602, learning rate is 0.026429
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.762991, learning rate is 0.000575
Net2: layer deconv3:max response is 18.718801, min response is -26.329512.
max gradient is 6.024071, min gradient is -8.000000, learning rate is 0.000287
Net2: layer bn50:max response is 21.053057, min response is -3.327780.
max gradient is 4.485369, min gradient is -8.000000, learning rate is 0.000575
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.324353, learning rate is 0.000287
Net2: layer bn49:max response is 7.776604, min response is -1.860748.
max gradient is 8.000000, min gradient is -5.145573, learning rate is 0.000575
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.560700, learning rate is 0.000287
max inferred z is 3.97, min inferred z is -3.96, and std is 1.00
 4.21 s (23.8 data/s) [100/100]
training: epoch 40: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.698003, learning rate is 0.026429
Net1: layer conv2:max response is , min response is .
max gradient is 6.248466, min gradient is -8.000000, learning rate is 0.026429
Net1: layer conv1:max response is , min response is .
max gradient is 6.634615, min gradient is -8.000000, learning rate is 0.026429
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.259847, learning rate is 0.000575
Net2: layer deconv3:max response is 18.799702, min response is -26.583197.
max gradient is 6.182053, min gradient is -8.000000, learning rate is 0.000287
Net2: layer bn50:max response is 15.925606, min response is -3.710740.
max gradient is 8.000000, min gradient is -4.761198, learning rate is 0.000575
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.049848, learning rate is 0.000287
Net2: layer bn49:max response is 8.812241, min response is -1.746085.
max gradient is 8.000000, min gradient is -6.129403, learning rate is 0.000575
Net2: layer deconv1:max response is , min response is .
max gradient is 7.995828, min gradient is -8.000000, learning rate is 0.000287
max inferred z is 3.84, min inferred z is -4.39, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 40: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.273428, min gradient is -8.000000, learning rate is 0.026429
Net1: layer conv2:max response is , min response is .
max gradient is 6.012946, min gradient is -8.000000, learning rate is 0.026429
Net1: layer conv1:max response is , min response is .
max gradient is 4.636031, min gradient is -8.000000, learning rate is 0.026429
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -0.156151, learning rate is 0.000575
Net2: layer deconv3:max response is 16.592186, min response is -20.496902.
max gradient is 6.969358, min gradient is -8.000000, learning rate is 0.000287
Net2: layer bn50:max response is 18.806620, min response is -3.297897.
max gradient is 8.000000, min gradient is -7.305288, learning rate is 0.000575
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.903557, learning rate is 0.000287
Net2: layer bn49:max response is 9.438972, min response is -1.806470.
max gradient is 7.914832, min gradient is -8.000001, learning rate is 0.000575
Net2: layer deconv1:max response is , min response is .
max gradient is 7.012155, min gradient is -8.000000, learning rate is 0.000287
max inferred z is 3.71, min inferred z is -4.11, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
training: epoch 40: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.145036, learning rate is 0.026429
Net1: layer conv2:max response is , min response is .
max gradient is 7.853610, min gradient is -8.000000, learning rate is 0.026429
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.502403, learning rate is 0.026429
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.597592, learning rate is 0.000575
Net2: layer deconv3:max response is 17.158497, min response is -20.454767.
max gradient is 8.000000, min gradient is -5.748558, learning rate is 0.000287
Net2: layer bn50:max response is 19.846977, min response is -3.168543.
max gradient is 2.190317, min gradient is -8.000000, learning rate is 0.000575
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.573870, learning rate is 0.000287
Net2: layer bn49:max response is 8.502692, min response is -1.747000.
max gradient is 8.000000, min gradient is -7.315487, learning rate is 0.000575
Net2: layer deconv1:max response is , min response is .
max gradient is 7.521734, min gradient is -8.000000, learning rate is 0.000287
max inferred z is 3.89, min inferred z is -4.17, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
training: epoch 40: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.433498, learning rate is 0.026429
Net1: layer conv2:max response is , min response is .
max gradient is 4.811041, min gradient is -8.000000, learning rate is 0.026429
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.825888, learning rate is 0.026429
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.348963, min gradient is -8.000000, learning rate is 0.000575
Net2: layer deconv3:max response is 18.256771, min response is -24.496950.
max gradient is 7.454846, min gradient is -8.000000, learning rate is 0.000287
Net2: layer bn50:max response is 20.800446, min response is -3.637337.
max gradient is 3.029210, min gradient is -8.000000, learning rate is 0.000575
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.882727, learning rate is 0.000287
Net2: layer bn49:max response is 8.448984, min response is -1.651171.
max gradient is 5.944728, min gradient is -8.000000, learning rate is 0.000575
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.855508, learning rate is 0.000287
max inferred z is 3.72, min inferred z is -4.20, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
Loss: 2.3471
Iteration 41 / 200
training: epoch 41: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -4.659610, learning rate is 0.024932
Net1: layer conv2:max response is , min response is .
max gradient is 7.690210, min gradient is -8.000000, learning rate is 0.024932
Net1: layer conv1:max response is , min response is .
max gradient is 4.059040, min gradient is -8.000000, learning rate is 0.024932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.782337, min gradient is -8.000000, learning rate is 0.000558
Net2: layer deconv3:max response is 17.043457, min response is -18.477612.
max gradient is 8.000000, min gradient is -6.008884, learning rate is 0.000279
Net2: layer bn50:max response is 17.064894, min response is -3.826704.
max gradient is 8.000000, min gradient is -3.838650, learning rate is 0.000558
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.986297, learning rate is 0.000279
Net2: layer bn49:max response is 7.787286, min response is -1.782393.
max gradient is 5.317318, min gradient is -8.000000, learning rate is 0.000558
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.110883, learning rate is 0.000279
max inferred z is 5.43, min inferred z is -4.06, and std is 1.00
 4.21 s (23.7 data/s) [100/100]
training: epoch 41: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.272193, learning rate is 0.024932
Net1: layer conv2:max response is , min response is .
max gradient is 4.580711, min gradient is -8.000000, learning rate is 0.024932
Net1: layer conv1:max response is , min response is .
max gradient is 6.405880, min gradient is -8.000000, learning rate is 0.024932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.171268, min gradient is -8.000000, learning rate is 0.000558
Net2: layer deconv3:max response is 18.135889, min response is -21.770470.
max gradient is 8.000000, min gradient is -7.308431, learning rate is 0.000279
Net2: layer bn50:max response is 17.672741, min response is -3.148029.
max gradient is 8.000000, min gradient is -3.440373, learning rate is 0.000558
Net2: layer deconv2:max response is , min response is .
max gradient is 7.226385, min gradient is -8.000000, learning rate is 0.000279
Net2: layer bn49:max response is 8.678281, min response is -1.862555.
max gradient is 6.656485, min gradient is -8.000000, learning rate is 0.000558
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.924552, learning rate is 0.000279
max inferred z is 3.78, min inferred z is -3.65, and std is 1.00
 4.34 s (23.1 data/s) [100/100]
training: epoch 41: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.916507, learning rate is 0.024932
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.617779, learning rate is 0.024932
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.057161, learning rate is 0.024932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.566724, learning rate is 0.000558
Net2: layer deconv3:max response is 16.217558, min response is -19.221731.
max gradient is 8.000000, min gradient is -6.164560, learning rate is 0.000279
Net2: layer bn50:max response is 14.346083, min response is -3.289979.
max gradient is 2.100893, min gradient is -8.000000, learning rate is 0.000558
Net2: layer deconv2:max response is , min response is .
max gradient is 7.534728, min gradient is -8.000000, learning rate is 0.000279
Net2: layer bn49:max response is 8.714363, min response is -1.611628.
max gradient is 7.680948, min gradient is -8.000000, learning rate is 0.000558
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.016882, learning rate is 0.000279
max inferred z is 3.99, min inferred z is -4.42, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 41: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.517475, min gradient is -8.000000, learning rate is 0.024932
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.341271, learning rate is 0.024932
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.900796, learning rate is 0.024932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.172239, learning rate is 0.000558
Net2: layer deconv3:max response is 18.681427, min response is -19.112394.
max gradient is 8.000000, min gradient is -6.502211, learning rate is 0.000279
Net2: layer bn50:max response is 16.602301, min response is -3.718400.
max gradient is 4.511648, min gradient is -8.000000, learning rate is 0.000558
Net2: layer deconv2:max response is , min response is .
max gradient is 5.417997, min gradient is -8.000000, learning rate is 0.000279
Net2: layer bn49:max response is 8.354964, min response is -1.634616.
max gradient is 8.000000, min gradient is -7.407679, learning rate is 0.000558
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.959976, learning rate is 0.000279
max inferred z is 3.93, min inferred z is -5.22, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 41: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.851707, learning rate is 0.024932
Net1: layer conv2:max response is , min response is .
max gradient is 7.600955, min gradient is -8.000000, learning rate is 0.024932
Net1: layer conv1:max response is , min response is .
max gradient is 5.332205, min gradient is -8.000000, learning rate is 0.024932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -0.840986, learning rate is 0.000558
Net2: layer deconv3:max response is 15.936028, min response is -24.439877.
max gradient is 8.000000, min gradient is -7.861863, learning rate is 0.000279
Net2: layer bn50:max response is 16.899174, min response is -3.250498.
max gradient is 8.000000, min gradient is -5.945593, learning rate is 0.000558
Net2: layer deconv2:max response is , min response is .
max gradient is 6.961725, min gradient is -8.000000, learning rate is 0.000279
Net2: layer bn49:max response is 8.233338, min response is -1.804326.
max gradient is 4.423276, min gradient is -8.000001, learning rate is 0.000558
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.420912, learning rate is 0.000279
max inferred z is 3.91, min inferred z is -4.03, and std is 1.00
 4.43 s (22.6 data/s) [100/100]
training: epoch 41: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.353311, learning rate is 0.024932
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.585980, learning rate is 0.024932
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.094157, learning rate is 0.024932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.439757, learning rate is 0.000558
Net2: layer deconv3:max response is 17.545301, min response is -22.614220.
max gradient is 8.000000, min gradient is -6.627230, learning rate is 0.000279
Net2: layer bn50:max response is 16.794500, min response is -3.219337.
max gradient is 6.225428, min gradient is -8.000000, learning rate is 0.000558
Net2: layer deconv2:max response is , min response is .
max gradient is 5.888604, min gradient is -8.000000, learning rate is 0.000279
Net2: layer bn49:max response is 8.836373, min response is -1.855467.
max gradient is 6.428065, min gradient is -8.000000, learning rate is 0.000558
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.041656, learning rate is 0.000279
max inferred z is 3.78, min inferred z is -3.80, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
training: epoch 41: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.884689, min gradient is -8.000000, learning rate is 0.024932
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.465552, learning rate is 0.024932
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.961182, learning rate is 0.024932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.492671, learning rate is 0.000558
Net2: layer deconv3:max response is 14.596091, min response is -19.605862.
max gradient is 8.000000, min gradient is -6.572725, learning rate is 0.000279
Net2: layer bn50:max response is 15.334545, min response is -3.186280.
max gradient is 8.000000, min gradient is -6.886584, learning rate is 0.000558
Net2: layer deconv2:max response is , min response is .
max gradient is 7.354490, min gradient is -8.000000, learning rate is 0.000279
Net2: layer bn49:max response is 8.752288, min response is -1.706643.
max gradient is 7.513041, min gradient is -8.000000, learning rate is 0.000558
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.262080, learning rate is 0.000279
max inferred z is 3.89, min inferred z is -3.58, and std is 1.00
 4.36 s (23.0 data/s) [100/100]
training: epoch 41: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.505251, learning rate is 0.024932
Net1: layer conv2:max response is , min response is .
max gradient is 5.620099, min gradient is -8.000000, learning rate is 0.024932
Net1: layer conv1:max response is , min response is .
max gradient is 5.400036, min gradient is -8.000000, learning rate is 0.024932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.465178, min gradient is -8.000000, learning rate is 0.000558
Net2: layer deconv3:max response is 17.243925, min response is -21.582100.
max gradient is 8.000000, min gradient is -7.090200, learning rate is 0.000279
Net2: layer bn50:max response is 18.154448, min response is -3.780249.
max gradient is 8.000000, min gradient is -3.532135, learning rate is 0.000558
Net2: layer deconv2:max response is , min response is .
max gradient is 7.277945, min gradient is -8.000000, learning rate is 0.000279
Net2: layer bn49:max response is 7.460762, min response is -1.575310.
max gradient is 5.893902, min gradient is -8.000000, learning rate is 0.000558
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.680373, learning rate is 0.000279
max inferred z is 4.27, min inferred z is -3.87, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 41: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.934004, min gradient is -8.000000, learning rate is 0.024932
Net1: layer conv2:max response is , min response is .
max gradient is 7.701701, min gradient is -8.000000, learning rate is 0.024932
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.072889, learning rate is 0.024932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.719469, learning rate is 0.000558
Net2: layer deconv3:max response is 18.121675, min response is -21.545496.
max gradient is 8.000000, min gradient is -6.713243, learning rate is 0.000279
Net2: layer bn50:max response is 20.741907, min response is -4.183075.
max gradient is 3.188254, min gradient is -8.000000, learning rate is 0.000558
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.416102, learning rate is 0.000279
Net2: layer bn49:max response is 9.758808, min response is -1.799274.
max gradient is 5.973920, min gradient is -8.000000, learning rate is 0.000558
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.515164, learning rate is 0.000279
max inferred z is 3.91, min inferred z is -3.91, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 41: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.092215, learning rate is 0.024932
Net1: layer conv2:max response is , min response is .
max gradient is 4.901139, min gradient is -8.000000, learning rate is 0.024932
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.381356, learning rate is 0.024932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.345130, min gradient is -8.000000, learning rate is 0.000558
Net2: layer deconv3:max response is 16.428965, min response is -21.320288.
max gradient is 7.458014, min gradient is -8.000000, learning rate is 0.000279
Net2: layer bn50:max response is 17.834217, min response is -3.272601.
max gradient is 8.000000, min gradient is -6.770880, learning rate is 0.000558
Net2: layer deconv2:max response is , min response is .
max gradient is 6.965428, min gradient is -8.000000, learning rate is 0.000279
Net2: layer bn49:max response is 8.518411, min response is -1.819052.
max gradient is 4.358193, min gradient is -8.000000, learning rate is 0.000558
Net2: layer deconv1:max response is , min response is .
max gradient is 7.105670, min gradient is -8.000000, learning rate is 0.000279
max inferred z is 4.22, min inferred z is -3.97, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
Loss: 2.3059
Iteration 42 / 200
training: epoch 42: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.575408, learning rate is 0.024932
Net1: layer conv2:max response is , min response is .
max gradient is 5.606866, min gradient is -8.000000, learning rate is 0.024932
Net1: layer conv1:max response is , min response is .
max gradient is 4.901607, min gradient is -8.000000, learning rate is 0.024932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.078348, min gradient is -8.000000, learning rate is 0.000558
Net2: layer deconv3:max response is 16.409002, min response is -21.425503.
max gradient is 8.000000, min gradient is -6.096579, learning rate is 0.000279
Net2: layer bn50:max response is 19.042122, min response is -3.628896.
max gradient is 8.000000, min gradient is -2.574195, learning rate is 0.000558
Net2: layer deconv2:max response is , min response is .
max gradient is 6.836684, min gradient is -8.000000, learning rate is 0.000279
Net2: layer bn49:max response is 7.986521, min response is -2.079987.
max gradient is 4.888723, min gradient is -8.000000, learning rate is 0.000558
Net2: layer deconv1:max response is , min response is .
max gradient is 6.908623, min gradient is -8.000000, learning rate is 0.000279
max inferred z is 3.95, min inferred z is -3.76, and std is 1.00
 4.13 s (24.2 data/s) [100/100]
training: epoch 42: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.335744, min gradient is -8.000000, learning rate is 0.024932
Net1: layer conv2:max response is , min response is .
max gradient is 5.430914, min gradient is -8.000000, learning rate is 0.024932
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.099046, learning rate is 0.024932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.703017, min gradient is -8.000000, learning rate is 0.000558
Net2: layer deconv3:max response is 15.291941, min response is -20.848845.
max gradient is 8.000000, min gradient is -7.306836, learning rate is 0.000279
Net2: layer bn50:max response is 16.255566, min response is -3.411283.
max gradient is 8.000000, min gradient is -1.689865, learning rate is 0.000558
Net2: layer deconv2:max response is , min response is .
max gradient is 7.145375, min gradient is -8.000000, learning rate is 0.000279
Net2: layer bn49:max response is 10.054171, min response is -1.728358.
max gradient is 6.885753, min gradient is -8.000000, learning rate is 0.000558
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.851830, learning rate is 0.000279
max inferred z is 3.53, min inferred z is -3.99, and std is 1.00
 4.12 s (24.3 data/s) [100/100]
training: epoch 42: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.604088, min gradient is -8.000000, learning rate is 0.024932
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.355908, learning rate is 0.024932
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.666001, learning rate is 0.024932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.095358, learning rate is 0.000558
Net2: layer deconv3:max response is 14.965441, min response is -21.890358.
max gradient is 7.315124, min gradient is -8.000000, learning rate is 0.000279
Net2: layer bn50:max response is 16.650913, min response is -2.915008.
max gradient is 6.429876, min gradient is -8.000000, learning rate is 0.000558
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.839748, learning rate is 0.000279
Net2: layer bn49:max response is 8.498674, min response is -1.990088.
max gradient is 8.000000, min gradient is -6.286964, learning rate is 0.000558
Net2: layer deconv1:max response is , min response is .
max gradient is 7.455309, min gradient is -8.000000, learning rate is 0.000279
max inferred z is 3.92, min inferred z is -4.46, and std is 1.00
 4.16 s (24.1 data/s) [100/100]
training: epoch 42: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.774902, min gradient is -8.000000, learning rate is 0.024932
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -3.959602, learning rate is 0.024932
Net1: layer conv1:max response is , min response is .
max gradient is 7.250529, min gradient is -8.000000, learning rate is 0.024932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.485971, learning rate is 0.000558
Net2: layer deconv3:max response is 15.984353, min response is -26.253487.
max gradient is 6.559385, min gradient is -8.000000, learning rate is 0.000279
Net2: layer bn50:max response is 17.528147, min response is -3.920710.
max gradient is 5.514411, min gradient is -8.000000, learning rate is 0.000558
Net2: layer deconv2:max response is , min response is .
max gradient is 7.314308, min gradient is -8.000000, learning rate is 0.000279
Net2: layer bn49:max response is 7.900955, min response is -1.897661.
max gradient is 8.000000, min gradient is -6.421163, learning rate is 0.000558
Net2: layer deconv1:max response is , min response is .
max gradient is 7.011264, min gradient is -8.000000, learning rate is 0.000279
max inferred z is 3.92, min inferred z is -4.21, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
training: epoch 42: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.864520, learning rate is 0.024932
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.810673, learning rate is 0.024932
Net1: layer conv1:max response is , min response is .
max gradient is 5.085218, min gradient is -8.000000, learning rate is 0.024932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.702838, learning rate is 0.000558
Net2: layer deconv3:max response is 15.718517, min response is -22.670952.
max gradient is 3.962039, min gradient is -8.000000, learning rate is 0.000279
Net2: layer bn50:max response is 14.425337, min response is -3.211174.
max gradient is 8.000000, min gradient is -3.140560, learning rate is 0.000558
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.444894, learning rate is 0.000279
Net2: layer bn49:max response is 7.095733, min response is -1.673487.
max gradient is 6.703625, min gradient is -8.000000, learning rate is 0.000558
Net2: layer deconv1:max response is , min response is .
max gradient is 7.882091, min gradient is -8.000000, learning rate is 0.000279
max inferred z is 4.35, min inferred z is -3.75, and std is 1.00
 4.19 s (23.8 data/s) [100/100]
training: epoch 42: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.262228, min gradient is -8.000000, learning rate is 0.024932
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.255690, learning rate is 0.024932
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.256362, learning rate is 0.024932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.357817, learning rate is 0.000558
Net2: layer deconv3:max response is 16.516508, min response is -25.130533.
max gradient is 8.000000, min gradient is -7.595176, learning rate is 0.000279
Net2: layer bn50:max response is 18.830864, min response is -3.401132.
max gradient is 8.000000, min gradient is -5.174514, learning rate is 0.000558
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.919776, learning rate is 0.000279
Net2: layer bn49:max response is 8.500852, min response is -1.837749.
max gradient is 8.000000, min gradient is -4.623999, learning rate is 0.000558
Net2: layer deconv1:max response is , min response is .
max gradient is 7.405684, min gradient is -8.000000, learning rate is 0.000279
max inferred z is 4.07, min inferred z is -4.35, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 42: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.008709, learning rate is 0.024932
Net1: layer conv2:max response is , min response is .
max gradient is 5.578990, min gradient is -8.000000, learning rate is 0.024932
Net1: layer conv1:max response is , min response is .
max gradient is 7.622436, min gradient is -8.000000, learning rate is 0.024932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.305290, learning rate is 0.000558
Net2: layer deconv3:max response is 16.187746, min response is -24.235584.
max gradient is 7.596121, min gradient is -8.000000, learning rate is 0.000279
Net2: layer bn50:max response is 16.281031, min response is -3.648047.
max gradient is 8.000000, min gradient is -4.802577, learning rate is 0.000558
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.720132, learning rate is 0.000279
Net2: layer bn49:max response is 8.281026, min response is -1.709492.
max gradient is 8.000000, min gradient is -6.782997, learning rate is 0.000558
Net2: layer deconv1:max response is , min response is .
max gradient is 7.521316, min gradient is -8.000001, learning rate is 0.000279
max inferred z is 4.54, min inferred z is -3.70, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 42: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.210634, min gradient is -8.000000, learning rate is 0.024932
Net1: layer conv2:max response is , min response is .
max gradient is 5.253554, min gradient is -8.000000, learning rate is 0.024932
Net1: layer conv1:max response is , min response is .
max gradient is 4.510046, min gradient is -8.000000, learning rate is 0.024932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.664139, learning rate is 0.000558
Net2: layer deconv3:max response is 19.143688, min response is -24.399172.
max gradient is 8.000000, min gradient is -7.810931, learning rate is 0.000279
Net2: layer bn50:max response is 17.997883, min response is -3.052487.
max gradient is 8.000000, min gradient is -6.252306, learning rate is 0.000558
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.603775, learning rate is 0.000279
Net2: layer bn49:max response is 9.316608, min response is -1.863588.
max gradient is 7.587344, min gradient is -8.000000, learning rate is 0.000558
Net2: layer deconv1:max response is , min response is .
max gradient is 6.757267, min gradient is -8.000000, learning rate is 0.000279
max inferred z is 3.86, min inferred z is -3.86, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 42: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.690032, learning rate is 0.024932
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.897411, learning rate is 0.024932
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.307837, learning rate is 0.024932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.860357, learning rate is 0.000558
Net2: layer deconv3:max response is 16.468346, min response is -21.105246.
max gradient is 6.878241, min gradient is -8.000000, learning rate is 0.000279
Net2: layer bn50:max response is 15.873067, min response is -2.718513.
max gradient is 2.679121, min gradient is -8.000000, learning rate is 0.000558
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.718612, learning rate is 0.000279
Net2: layer bn49:max response is 8.399841, min response is -1.639130.
max gradient is 7.785291, min gradient is -8.000000, learning rate is 0.000558
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.923519, learning rate is 0.000279
max inferred z is 4.14, min inferred z is -3.97, and std is 1.00
 4.32 s (23.2 data/s) [100/100]
training: epoch 42: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.687518, learning rate is 0.024932
Net1: layer conv2:max response is , min response is .
max gradient is 4.015924, min gradient is -8.000000, learning rate is 0.024932
Net1: layer conv1:max response is , min response is .
max gradient is 6.163434, min gradient is -8.000000, learning rate is 0.024932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -4.929359, min gradient is -8.000000, learning rate is 0.000558
Net2: layer deconv3:max response is 19.757963, min response is -20.031498.
max gradient is 6.327526, min gradient is -8.000000, learning rate is 0.000279
Net2: layer bn50:max response is 17.137690, min response is -3.637595.
max gradient is 8.000000, min gradient is -4.874406, learning rate is 0.000558
Net2: layer deconv2:max response is , min response is .
max gradient is 7.629766, min gradient is -8.000000, learning rate is 0.000279
Net2: layer bn49:max response is 8.300871, min response is -1.831360.
max gradient is 6.246974, min gradient is -8.000000, learning rate is 0.000558
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.637861, learning rate is 0.000279
max inferred z is 4.28, min inferred z is -3.75, and std is 1.00
 4.38 s (22.9 data/s) [100/100]
Loss: 2.3894
Iteration 43 / 200
training: epoch 43: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.822192, learning rate is 0.023520
Net1: layer conv2:max response is , min response is .
max gradient is 7.965856, min gradient is -8.000000, learning rate is 0.023520
Net1: layer conv1:max response is , min response is .
max gradient is 3.685086, min gradient is -8.000000, learning rate is 0.023520
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.235704, min gradient is -8.000000, learning rate is 0.000542
Net2: layer deconv3:max response is 18.421719, min response is -23.132202.
max gradient is 7.446781, min gradient is -8.000000, learning rate is 0.000271
Net2: layer bn50:max response is 16.959160, min response is -3.092333.
max gradient is 8.000000, min gradient is -4.087505, learning rate is 0.000542
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.035964, learning rate is 0.000271
Net2: layer bn49:max response is 8.637117, min response is -1.904708.
max gradient is 5.224084, min gradient is -8.000000, learning rate is 0.000542
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.961582, learning rate is 0.000271
max inferred z is 4.15, min inferred z is -3.80, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 43: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.005632, learning rate is 0.023520
Net1: layer conv2:max response is , min response is .
max gradient is 6.490902, min gradient is -8.000000, learning rate is 0.023520
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.469518, learning rate is 0.023520
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.066308, min gradient is -8.000000, learning rate is 0.000542
Net2: layer deconv3:max response is 18.327652, min response is -20.478531.
max gradient is 8.000000, min gradient is -7.548292, learning rate is 0.000271
Net2: layer bn50:max response is 16.993383, min response is -3.245438.
max gradient is 5.686367, min gradient is -8.000000, learning rate is 0.000542
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.815073, learning rate is 0.000271
Net2: layer bn49:max response is 8.487770, min response is -1.636361.
max gradient is 8.000000, min gradient is -6.815973, learning rate is 0.000542
Net2: layer deconv1:max response is , min response is .
max gradient is 6.035945, min gradient is -8.000000, learning rate is 0.000271
max inferred z is 4.15, min inferred z is -4.29, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 43: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.605152, learning rate is 0.023520
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.988620, learning rate is 0.023520
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.752284, learning rate is 0.023520
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.096515, learning rate is 0.000542
Net2: layer deconv3:max response is 16.686594, min response is -22.304594.
max gradient is 8.000000, min gradient is -6.716332, learning rate is 0.000271
Net2: layer bn50:max response is 17.706411, min response is -2.850152.
max gradient is 2.663455, min gradient is -8.000000, learning rate is 0.000542
Net2: layer deconv2:max response is , min response is .
max gradient is 6.951358, min gradient is -8.000000, learning rate is 0.000271
Net2: layer bn49:max response is 10.217960, min response is -1.727749.
max gradient is 7.772756, min gradient is -8.000000, learning rate is 0.000542
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.538119, learning rate is 0.000271
max inferred z is 3.99, min inferred z is -4.34, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 43: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.573421, learning rate is 0.023520
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.032118, learning rate is 0.023520
Net1: layer conv1:max response is , min response is .
max gradient is 4.379483, min gradient is -8.000000, learning rate is 0.023520
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.718236, learning rate is 0.000542
Net2: layer deconv3:max response is 23.370251, min response is -20.057573.
max gradient is 8.000000, min gradient is -6.521399, learning rate is 0.000271
Net2: layer bn50:max response is 17.656618, min response is -3.365698.
max gradient is 4.416140, min gradient is -8.000000, learning rate is 0.000542
Net2: layer deconv2:max response is , min response is .
max gradient is 6.607459, min gradient is -8.000000, learning rate is 0.000271
Net2: layer bn49:max response is 7.519232, min response is -1.886362.
max gradient is 6.196358, min gradient is -8.000000, learning rate is 0.000542
Net2: layer deconv1:max response is , min response is .
max gradient is 7.570840, min gradient is -8.000000, learning rate is 0.000271
max inferred z is 4.23, min inferred z is -3.76, and std is 1.00
 4.45 s (22.5 data/s) [100/100]
training: epoch 43: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.850380, learning rate is 0.023520
Net1: layer conv2:max response is , min response is .
max gradient is 7.214920, min gradient is -8.000000, learning rate is 0.023520
Net1: layer conv1:max response is , min response is .
max gradient is 6.024068, min gradient is -8.000000, learning rate is 0.023520
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.853851, learning rate is 0.000542
Net2: layer deconv3:max response is 17.265543, min response is -23.831375.
max gradient is 8.000000, min gradient is -6.831784, learning rate is 0.000271
Net2: layer bn50:max response is 16.405003, min response is -2.913090.
max gradient is 8.000000, min gradient is -7.389671, learning rate is 0.000542
Net2: layer deconv2:max response is , min response is .
max gradient is 7.450045, min gradient is -8.000000, learning rate is 0.000271
Net2: layer bn49:max response is 7.964373, min response is -1.987101.
max gradient is 7.973381, min gradient is -8.000000, learning rate is 0.000542
Net2: layer deconv1:max response is , min response is .
max gradient is 7.952425, min gradient is -8.000000, learning rate is 0.000271
max inferred z is 3.78, min inferred z is -3.83, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 43: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.945101, min gradient is -8.000000, learning rate is 0.023520
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.145176, learning rate is 0.023520
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.823448, learning rate is 0.023520
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.662088, learning rate is 0.000542
Net2: layer deconv3:max response is 19.998932, min response is -20.430361.
max gradient is 8.000000, min gradient is -7.424054, learning rate is 0.000271
Net2: layer bn50:max response is 20.333254, min response is -3.232204.
max gradient is 7.478288, min gradient is -8.000000, learning rate is 0.000542
Net2: layer deconv2:max response is , min response is .
max gradient is 5.820741, min gradient is -8.000000, learning rate is 0.000271
Net2: layer bn49:max response is 8.696707, min response is -1.837153.
max gradient is 4.931338, min gradient is -8.000000, learning rate is 0.000542
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.920049, learning rate is 0.000271
max inferred z is 4.07, min inferred z is -3.75, and std is 1.00
 4.16 s (24.0 data/s) [100/100]
training: epoch 43: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.957056, min gradient is -8.000000, learning rate is 0.023520
Net1: layer conv2:max response is , min response is .
max gradient is 6.043912, min gradient is -8.000000, learning rate is 0.023520
Net1: layer conv1:max response is , min response is .
max gradient is 6.037470, min gradient is -8.000000, learning rate is 0.023520
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.895199, learning rate is 0.000542
Net2: layer deconv3:max response is 14.909867, min response is -21.283428.
max gradient is 8.000000, min gradient is -6.744848, learning rate is 0.000271
Net2: layer bn50:max response is 16.235382, min response is -2.897587.
max gradient is 8.000000, min gradient is -5.310966, learning rate is 0.000542
Net2: layer deconv2:max response is , min response is .
max gradient is 7.211961, min gradient is -8.000000, learning rate is 0.000271
Net2: layer bn49:max response is 8.706604, min response is -1.647301.
max gradient is 7.584196, min gradient is -8.000000, learning rate is 0.000542
Net2: layer deconv1:max response is , min response is .
max gradient is 7.650095, min gradient is -8.000000, learning rate is 0.000271
max inferred z is 4.03, min inferred z is -4.85, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 43: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.743590, min gradient is -8.000000, learning rate is 0.023520
Net1: layer conv2:max response is , min response is .
max gradient is 6.016587, min gradient is -8.000000, learning rate is 0.023520
Net1: layer conv1:max response is , min response is .
max gradient is 5.004487, min gradient is -8.000000, learning rate is 0.023520
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.896191, learning rate is 0.000542
Net2: layer deconv3:max response is 16.954964, min response is -22.224783.
max gradient is 8.000000, min gradient is -5.642174, learning rate is 0.000271
Net2: layer bn50:max response is 18.547009, min response is -3.383325.
max gradient is 8.000000, min gradient is -6.398064, learning rate is 0.000542
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.442451, learning rate is 0.000271
Net2: layer bn49:max response is 8.155428, min response is -1.621401.
max gradient is 6.163504, min gradient is -8.000000, learning rate is 0.000542
Net2: layer deconv1:max response is , min response is .
max gradient is 7.831393, min gradient is -8.000000, learning rate is 0.000271
max inferred z is 3.81, min inferred z is -4.23, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 43: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.770324, learning rate is 0.023520
Net1: layer conv2:max response is , min response is .
max gradient is 8.000001, min gradient is -7.099351, learning rate is 0.023520
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.898524, learning rate is 0.023520
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.649278, learning rate is 0.000542
Net2: layer deconv3:max response is 17.209026, min response is -23.867319.
max gradient is 8.000000, min gradient is -4.583810, learning rate is 0.000271
Net2: layer bn50:max response is 18.818140, min response is -2.878211.
max gradient is 2.853884, min gradient is -8.000000, learning rate is 0.000542
Net2: layer deconv2:max response is , min response is .
max gradient is 7.456357, min gradient is -8.000000, learning rate is 0.000271
Net2: layer bn49:max response is 8.189862, min response is -1.525795.
max gradient is 5.862405, min gradient is -8.000000, learning rate is 0.000542
Net2: layer deconv1:max response is , min response is .
max gradient is 7.864382, min gradient is -8.000000, learning rate is 0.000271
max inferred z is 4.37, min inferred z is -4.01, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 43: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.626173, learning rate is 0.023520
Net1: layer conv2:max response is , min response is .
max gradient is 5.947538, min gradient is -8.000000, learning rate is 0.023520
Net1: layer conv1:max response is , min response is .
max gradient is 4.716932, min gradient is -8.000001, learning rate is 0.023520
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.471313, min gradient is -8.000000, learning rate is 0.000542
Net2: layer deconv3:max response is 17.725555, min response is -20.887428.
max gradient is 6.722204, min gradient is -8.000000, learning rate is 0.000271
Net2: layer bn50:max response is 17.751978, min response is -3.027292.
max gradient is 8.000000, min gradient is -4.156018, learning rate is 0.000542
Net2: layer deconv2:max response is , min response is .
max gradient is 5.240061, min gradient is -8.000000, learning rate is 0.000271
Net2: layer bn49:max response is 7.915994, min response is -1.817143.
max gradient is 4.749173, min gradient is -8.000000, learning rate is 0.000542
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.784108, learning rate is 0.000271
max inferred z is 4.48, min inferred z is -4.06, and std is 1.00
 4.30 s (23.2 data/s) [100/100]
Loss: 2.3257
Iteration 44 / 200
training: epoch 44: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.420637, min gradient is -8.000000, learning rate is 0.023520
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.822040, learning rate is 0.023520
Net1: layer conv1:max response is , min response is .
max gradient is 6.019179, min gradient is -8.000000, learning rate is 0.023520
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.783552, min gradient is -8.000000, learning rate is 0.000542
Net2: layer deconv3:max response is 16.605356, min response is -21.857149.
max gradient is 8.000000, min gradient is -5.331155, learning rate is 0.000271
Net2: layer bn50:max response is 19.908834, min response is -2.992360.
max gradient is 8.000000, min gradient is -2.085027, learning rate is 0.000542
Net2: layer deconv2:max response is , min response is .
max gradient is 6.846224, min gradient is -8.000000, learning rate is 0.000271
Net2: layer bn49:max response is 7.915636, min response is -1.667610.
max gradient is 5.049575, min gradient is -8.000000, learning rate is 0.000542
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.638829, learning rate is 0.000271
max inferred z is 3.72, min inferred z is -3.95, and std is 0.99
 4.33 s (23.1 data/s) [100/100]
training: epoch 44: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.014467, min gradient is -8.000000, learning rate is 0.023520
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.467056, learning rate is 0.023520
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.546998, learning rate is 0.023520
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 2.070608, min gradient is -8.000000, learning rate is 0.000542
Net2: layer deconv3:max response is 16.776676, min response is -20.913568.
max gradient is 8.000000, min gradient is -6.353630, learning rate is 0.000271
Net2: layer bn50:max response is 16.065123, min response is -4.019916.
max gradient is 8.000000, min gradient is -6.203612, learning rate is 0.000542
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.674496, learning rate is 0.000271
Net2: layer bn49:max response is 8.281933, min response is -1.658738.
max gradient is 7.921324, min gradient is -8.000000, learning rate is 0.000542
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.459524, learning rate is 0.000271
max inferred z is 3.94, min inferred z is -4.17, and std is 0.99
 4.36 s (23.0 data/s) [100/100]
training: epoch 44: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.301720, min gradient is -8.000000, learning rate is 0.023520
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.234534, learning rate is 0.023520
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.005712, learning rate is 0.023520
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -1.231718, min gradient is -8.000000, learning rate is 0.000542
Net2: layer deconv3:max response is 15.491161, min response is -24.927731.
max gradient is 7.897390, min gradient is -8.000000, learning rate is 0.000271
Net2: layer bn50:max response is 17.336924, min response is -2.928930.
max gradient is 8.000000, min gradient is -5.953645, learning rate is 0.000542
Net2: layer deconv2:max response is , min response is .
max gradient is 7.854760, min gradient is -8.000000, learning rate is 0.000271
Net2: layer bn49:max response is 12.038969, min response is -1.659824.
max gradient is 8.000000, min gradient is -5.589044, learning rate is 0.000542
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.711497, learning rate is 0.000271
max inferred z is 4.04, min inferred z is -3.99, and std is 0.99
 4.42 s (22.6 data/s) [100/100]
training: epoch 44: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.630948, learning rate is 0.023520
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.464369, learning rate is 0.023520
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.200818, learning rate is 0.023520
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.014313, learning rate is 0.000542
Net2: layer deconv3:max response is 17.420435, min response is -22.463865.
max gradient is 6.743714, min gradient is -8.000000, learning rate is 0.000271
Net2: layer bn50:max response is 16.097172, min response is -2.907658.
max gradient is 4.510633, min gradient is -8.000000, learning rate is 0.000542
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.412021, learning rate is 0.000271
Net2: layer bn49:max response is 8.292557, min response is -1.958978.
max gradient is 8.000000, min gradient is -5.746493, learning rate is 0.000542
Net2: layer deconv1:max response is , min response is .
max gradient is 7.530125, min gradient is -8.000000, learning rate is 0.000271
max inferred z is 4.53, min inferred z is -3.80, and std is 0.99
 4.41 s (22.7 data/s) [100/100]
training: epoch 44: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.575944, min gradient is -8.000000, learning rate is 0.023520
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.679346, learning rate is 0.023520
Net1: layer conv1:max response is , min response is .
max gradient is 4.509509, min gradient is -8.000000, learning rate is 0.023520
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.091566, learning rate is 0.000542
Net2: layer deconv3:max response is 16.362646, min response is -22.657555.
max gradient is 3.765505, min gradient is -8.000000, learning rate is 0.000271
Net2: layer bn50:max response is 15.889244, min response is -2.832883.
max gradient is 8.000000, min gradient is -5.019365, learning rate is 0.000542
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.739959, learning rate is 0.000271
Net2: layer bn49:max response is 8.861270, min response is -1.788005.
max gradient is 6.413857, min gradient is -8.000000, learning rate is 0.000542
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.227189, learning rate is 0.000271
max inferred z is 3.75, min inferred z is -4.47, and std is 0.99
 4.22 s (23.7 data/s) [100/100]
training: epoch 44: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.660493, min gradient is -8.000000, learning rate is 0.023520
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -3.667270, learning rate is 0.023520
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.409212, learning rate is 0.023520
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.200619, learning rate is 0.000542
Net2: layer deconv3:max response is 20.436018, min response is -23.735060.
max gradient is 6.844086, min gradient is -8.000000, learning rate is 0.000271
Net2: layer bn50:max response is 21.736568, min response is -2.997429.
max gradient is 6.815117, min gradient is -8.000000, learning rate is 0.000542
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.605406, learning rate is 0.000271
Net2: layer bn49:max response is 8.612977, min response is -1.862456.
max gradient is 8.000000, min gradient is -6.235856, learning rate is 0.000542
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.396484, learning rate is 0.000271
max inferred z is 4.13, min inferred z is -3.86, and std is 0.99
 4.27 s (23.4 data/s) [100/100]
training: epoch 44: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.419725, min gradient is -8.000000, learning rate is 0.023520
Net1: layer conv2:max response is , min response is .
max gradient is 4.836962, min gradient is -8.000000, learning rate is 0.023520
Net1: layer conv1:max response is , min response is .
max gradient is 4.990713, min gradient is -8.000000, learning rate is 0.023520
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.075962, learning rate is 0.000542
Net2: layer deconv3:max response is 16.685255, min response is -23.510201.
max gradient is 7.042424, min gradient is -8.000000, learning rate is 0.000271
Net2: layer bn50:max response is 16.738770, min response is -2.796555.
max gradient is 8.000000, min gradient is -4.077524, learning rate is 0.000542
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.290174, learning rate is 0.000271
Net2: layer bn49:max response is 8.831041, min response is -1.602686.
max gradient is 7.851288, min gradient is -8.000000, learning rate is 0.000542
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.922244, learning rate is 0.000271
max inferred z is 3.88, min inferred z is -4.05, and std is 0.99
 4.39 s (22.8 data/s) [100/100]
training: epoch 44: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.496866, min gradient is -8.000000, learning rate is 0.023520
Net1: layer conv2:max response is , min response is .
max gradient is 5.423549, min gradient is -8.000000, learning rate is 0.023520
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.875195, learning rate is 0.023520
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.579958, learning rate is 0.000542
Net2: layer deconv3:max response is 16.355461, min response is -23.593754.
max gradient is 8.000000, min gradient is -6.489045, learning rate is 0.000271
Net2: layer bn50:max response is 15.384790, min response is -3.113716.
max gradient is 8.000000, min gradient is -7.392804, learning rate is 0.000542
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.909878, learning rate is 0.000271
Net2: layer bn49:max response is 7.925533, min response is -1.809223.
max gradient is 7.228515, min gradient is -8.000000, learning rate is 0.000542
Net2: layer deconv1:max response is , min response is .
max gradient is 7.531353, min gradient is -8.000000, learning rate is 0.000271
max inferred z is 4.52, min inferred z is -3.59, and std is 0.99
 4.24 s (23.6 data/s) [100/100]
training: epoch 44: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.469411, learning rate is 0.023520
Net1: layer conv2:max response is , min response is .
max gradient is 5.073748, min gradient is -8.000000, learning rate is 0.023520
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.413363, learning rate is 0.023520
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -5.279544, learning rate is 0.000542
Net2: layer deconv3:max response is 19.713169, min response is -19.596100.
max gradient is 7.360099, min gradient is -8.000000, learning rate is 0.000271
Net2: layer bn50:max response is 16.377558, min response is -3.014606.
max gradient is 3.452400, min gradient is -8.000000, learning rate is 0.000542
Net2: layer deconv2:max response is , min response is .
max gradient is 7.910717, min gradient is -8.000000, learning rate is 0.000271
Net2: layer bn49:max response is 8.728626, min response is -2.194862.
max gradient is 5.974128, min gradient is -8.000000, learning rate is 0.000542
Net2: layer deconv1:max response is , min response is .
max gradient is 7.695158, min gradient is -8.000000, learning rate is 0.000271
max inferred z is 4.13, min inferred z is -4.22, and std is 0.99
 4.18 s (23.9 data/s) [100/100]
training: epoch 44: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000001, min gradient is -7.264056, learning rate is 0.023520
Net1: layer conv2:max response is , min response is .
max gradient is 6.219204, min gradient is -8.000000, learning rate is 0.023520
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.140623, learning rate is 0.023520
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.556839, min gradient is -8.000000, learning rate is 0.000542
Net2: layer deconv3:max response is 17.140440, min response is -26.496996.
max gradient is 7.346205, min gradient is -8.000000, learning rate is 0.000271
Net2: layer bn50:max response is 17.089005, min response is -3.259705.
max gradient is 6.457287, min gradient is -8.000000, learning rate is 0.000542
Net2: layer deconv2:max response is , min response is .
max gradient is 7.262668, min gradient is -8.000000, learning rate is 0.000271
Net2: layer bn49:max response is 8.383007, min response is -2.010189.
max gradient is 5.678243, min gradient is -8.000000, learning rate is 0.000542
Net2: layer deconv1:max response is , min response is .
max gradient is 7.518382, min gradient is -8.000000, learning rate is 0.000271
max inferred z is 3.69, min inferred z is -4.05, and std is 0.99
 4.24 s (23.6 data/s) [100/100]
Loss: 2.3543
Iteration 45 / 200
training: epoch 45: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.100006, learning rate is 0.022189
Net1: layer conv2:max response is , min response is .
max gradient is 7.498579, min gradient is -8.000000, learning rate is 0.022189
Net1: layer conv1:max response is , min response is .
max gradient is 4.995885, min gradient is -8.000000, learning rate is 0.022189
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.478663, min gradient is -8.000000, learning rate is 0.000527
Net2: layer deconv3:max response is 19.271935, min response is -20.918844.
max gradient is 6.289936, min gradient is -8.000000, learning rate is 0.000263
Net2: layer bn50:max response is 19.080080, min response is -3.239827.
max gradient is 8.000000, min gradient is -4.095039, learning rate is 0.000527
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.157261, learning rate is 0.000263
Net2: layer bn49:max response is 8.049987, min response is -1.943992.
max gradient is 4.733100, min gradient is -8.000000, learning rate is 0.000527
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.643860, learning rate is 0.000263
max inferred z is 4.00, min inferred z is -4.07, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 45: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -4.974652, learning rate is 0.022189
Net1: layer conv2:max response is , min response is .
max gradient is 5.325428, min gradient is -8.000000, learning rate is 0.022189
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.193299, learning rate is 0.022189
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.964732, min gradient is -8.000000, learning rate is 0.000527
Net2: layer deconv3:max response is 19.597795, min response is -23.631565.
max gradient is 7.087255, min gradient is -8.000000, learning rate is 0.000263
Net2: layer bn50:max response is 16.731895, min response is -2.865020.
max gradient is 8.000000, min gradient is -3.628455, learning rate is 0.000527
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.234308, learning rate is 0.000263
Net2: layer bn49:max response is 8.878184, min response is -1.756566.
max gradient is 5.569813, min gradient is -8.000000, learning rate is 0.000527
Net2: layer deconv1:max response is , min response is .
max gradient is 6.659837, min gradient is -8.000000, learning rate is 0.000263
max inferred z is 4.20, min inferred z is -4.10, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 45: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.519547, learning rate is 0.022189
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.710007, learning rate is 0.022189
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.425541, learning rate is 0.022189
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.107699, learning rate is 0.000527
Net2: layer deconv3:max response is 16.576437, min response is -22.217522.
max gradient is 7.290745, min gradient is -8.000000, learning rate is 0.000263
Net2: layer bn50:max response is 17.672577, min response is -3.101416.
max gradient is 1.541436, min gradient is -8.000000, learning rate is 0.000527
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.600942, learning rate is 0.000263
Net2: layer bn49:max response is 8.211465, min response is -2.135231.
max gradient is 8.000000, min gradient is -7.611658, learning rate is 0.000527
Net2: layer deconv1:max response is , min response is .
max gradient is 7.026585, min gradient is -8.000000, learning rate is 0.000263
max inferred z is 3.91, min inferred z is -3.87, and std is 1.00
 4.45 s (22.5 data/s) [100/100]
training: epoch 45: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.757421, learning rate is 0.022189
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.385721, learning rate is 0.022189
Net1: layer conv1:max response is , min response is .
max gradient is 6.394476, min gradient is -8.000000, learning rate is 0.022189
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.606171, learning rate is 0.000527
Net2: layer deconv3:max response is 17.609020, min response is -19.791672.
max gradient is 8.000000, min gradient is -7.126855, learning rate is 0.000263
Net2: layer bn50:max response is 15.625562, min response is -3.202272.
max gradient is 3.402038, min gradient is -8.000000, learning rate is 0.000527
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.154280, learning rate is 0.000263
Net2: layer bn49:max response is 8.447153, min response is -1.829841.
max gradient is 8.000000, min gradient is -7.360772, learning rate is 0.000527
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.388664, learning rate is 0.000263
max inferred z is 3.91, min inferred z is -3.65, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 45: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.929965, learning rate is 0.022189
Net1: layer conv2:max response is , min response is .
max gradient is 7.523494, min gradient is -8.000000, learning rate is 0.022189
Net1: layer conv1:max response is , min response is .
max gradient is 4.597900, min gradient is -8.000000, learning rate is 0.022189
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.402969, learning rate is 0.000527
Net2: layer deconv3:max response is 20.446314, min response is -23.248966.
max gradient is 5.392576, min gradient is -8.000000, learning rate is 0.000263
Net2: layer bn50:max response is 19.850641, min response is -3.047736.
max gradient is 8.000000, min gradient is -5.415339, learning rate is 0.000527
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.957501, learning rate is 0.000263
Net2: layer bn49:max response is 10.763919, min response is -1.837604.
max gradient is 5.858114, min gradient is -8.000000, learning rate is 0.000527
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.538162, learning rate is 0.000263
max inferred z is 4.29, min inferred z is -4.38, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 45: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.213221, min gradient is -8.000000, learning rate is 0.022189
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.428428, learning rate is 0.022189
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.565992, learning rate is 0.022189
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.981850, learning rate is 0.000527
Net2: layer deconv3:max response is 17.271448, min response is -23.995087.
max gradient is 8.000000, min gradient is -6.077425, learning rate is 0.000263
Net2: layer bn50:max response is 15.832088, min response is -2.721747.
max gradient is 7.172918, min gradient is -8.000000, learning rate is 0.000527
Net2: layer deconv2:max response is , min response is .
max gradient is 7.684972, min gradient is -8.000000, learning rate is 0.000263
Net2: layer bn49:max response is 8.193427, min response is -1.768993.
max gradient is 7.152236, min gradient is -8.000000, learning rate is 0.000527
Net2: layer deconv1:max response is , min response is .
max gradient is 7.267815, min gradient is -8.000000, learning rate is 0.000263
max inferred z is 4.55, min inferred z is -4.02, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 45: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.356583, learning rate is 0.022189
Net1: layer conv2:max response is , min response is .
max gradient is 5.760005, min gradient is -8.000000, learning rate is 0.022189
Net1: layer conv1:max response is , min response is .
max gradient is 5.807024, min gradient is -8.000000, learning rate is 0.022189
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.445500, learning rate is 0.000527
Net2: layer deconv3:max response is 20.237627, min response is -22.508493.
max gradient is 8.000000, min gradient is -7.107756, learning rate is 0.000263
Net2: layer bn50:max response is 21.331865, min response is -3.419628.
max gradient is 8.000000, min gradient is -4.222556, learning rate is 0.000527
Net2: layer deconv2:max response is , min response is .
max gradient is 7.378804, min gradient is -8.000000, learning rate is 0.000263
Net2: layer bn49:max response is 8.151713, min response is -2.010149.
max gradient is 5.879375, min gradient is -8.000000, learning rate is 0.000527
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.633731, learning rate is 0.000263
max inferred z is 4.06, min inferred z is -4.11, and std is 1.00
 4.44 s (22.5 data/s) [100/100]
training: epoch 45: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.697436, learning rate is 0.022189
Net1: layer conv2:max response is , min response is .
max gradient is 3.851110, min gradient is -8.000000, learning rate is 0.022189
Net1: layer conv1:max response is , min response is .
max gradient is 6.647866, min gradient is -8.000000, learning rate is 0.022189
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.336623, learning rate is 0.000527
Net2: layer deconv3:max response is 17.075609, min response is -22.569389.
max gradient is 8.000000, min gradient is -6.250620, learning rate is 0.000263
Net2: layer bn50:max response is 16.983274, min response is -3.609311.
max gradient is 8.000000, min gradient is -6.359664, learning rate is 0.000527
Net2: layer deconv2:max response is , min response is .
max gradient is 7.030643, min gradient is -8.000001, learning rate is 0.000263
Net2: layer bn49:max response is 9.477386, min response is -1.620610.
max gradient is 5.377934, min gradient is -8.000000, learning rate is 0.000527
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.247056, learning rate is 0.000263
max inferred z is 4.17, min inferred z is -4.03, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 45: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.452753, min gradient is -8.000000, learning rate is 0.022189
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.361631, learning rate is 0.022189
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.770791, learning rate is 0.022189
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.019185, learning rate is 0.000527
Net2: layer deconv3:max response is 18.466833, min response is -26.133930.
max gradient is 8.000000, min gradient is -5.390361, learning rate is 0.000263
Net2: layer bn50:max response is 17.083422, min response is -2.970516.
max gradient is 4.501381, min gradient is -8.000000, learning rate is 0.000527
Net2: layer deconv2:max response is , min response is .
max gradient is 7.690960, min gradient is -8.000000, learning rate is 0.000263
Net2: layer bn49:max response is 8.175120, min response is -1.679852.
max gradient is 4.863188, min gradient is -8.000000, learning rate is 0.000527
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.117689, learning rate is 0.000263
max inferred z is 4.48, min inferred z is -4.03, and std is 1.00
 4.28 s (23.4 data/s) [100/100]
training: epoch 45: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.770880, learning rate is 0.022189
Net1: layer conv2:max response is , min response is .
max gradient is 7.894022, min gradient is -8.000000, learning rate is 0.022189
Net1: layer conv1:max response is , min response is .
max gradient is 6.656709, min gradient is -8.000000, learning rate is 0.022189
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -4.946965, min gradient is -8.000000, learning rate is 0.000527
Net2: layer deconv3:max response is 15.954991, min response is -22.766685.
max gradient is 7.834926, min gradient is -8.000000, learning rate is 0.000263
Net2: layer bn50:max response is 17.091902, min response is -2.838690.
max gradient is 8.000000, min gradient is -2.951251, learning rate is 0.000527
Net2: layer deconv2:max response is , min response is .
max gradient is 5.577433, min gradient is -8.000000, learning rate is 0.000263
Net2: layer bn49:max response is 8.493016, min response is -1.813680.
max gradient is 5.375577, min gradient is -8.000000, learning rate is 0.000527
Net2: layer deconv1:max response is , min response is .
max gradient is 6.990716, min gradient is -8.000000, learning rate is 0.000263
max inferred z is 4.09, min inferred z is -3.80, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
Loss: 2.2906
Iteration 46 / 200
training: epoch 46: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.906596, learning rate is 0.022189
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.685452, learning rate is 0.022189
Net1: layer conv1:max response is , min response is .
max gradient is 6.867128, min gradient is -8.000000, learning rate is 0.022189
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.352979, min gradient is -8.000000, learning rate is 0.000527
Net2: layer deconv3:max response is 17.067911, min response is -26.485821.
max gradient is 7.687662, min gradient is -8.000000, learning rate is 0.000263
Net2: layer bn50:max response is 18.123989, min response is -3.918744.
max gradient is 8.000000, min gradient is -3.332593, learning rate is 0.000527
Net2: layer deconv2:max response is , min response is .
max gradient is 5.171737, min gradient is -8.000000, learning rate is 0.000263
Net2: layer bn49:max response is 10.419540, min response is -2.052189.
max gradient is 5.660704, min gradient is -8.000000, learning rate is 0.000527
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.706713, learning rate is 0.000263
max inferred z is 3.81, min inferred z is -3.91, and std is 0.99
 4.24 s (23.6 data/s) [100/100]
training: epoch 46: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.560169, min gradient is -8.000000, learning rate is 0.022189
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.019175, learning rate is 0.022189
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.601758, learning rate is 0.022189
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.337514, learning rate is 0.000527
Net2: layer deconv3:max response is 17.503288, min response is -22.949526.
max gradient is 8.000000, min gradient is -6.690558, learning rate is 0.000263
Net2: layer bn50:max response is 17.076210, min response is -2.841519.
max gradient is 8.000000, min gradient is -7.400106, learning rate is 0.000527
Net2: layer deconv2:max response is , min response is .
max gradient is 6.342335, min gradient is -8.000000, learning rate is 0.000263
Net2: layer bn49:max response is 8.459721, min response is -1.621450.
max gradient is 7.868597, min gradient is -8.000000, learning rate is 0.000527
Net2: layer deconv1:max response is , min response is .
max gradient is 5.977577, min gradient is -8.000000, learning rate is 0.000263
max inferred z is 4.45, min inferred z is -4.21, and std is 0.99
 4.22 s (23.7 data/s) [100/100]
training: epoch 46: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.019591, min gradient is -8.000000, learning rate is 0.022189
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.450603, learning rate is 0.022189
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.359791, learning rate is 0.022189
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.526918, learning rate is 0.000527
Net2: layer deconv3:max response is 17.225847, min response is -23.933958.
max gradient is 7.473577, min gradient is -8.000000, learning rate is 0.000263
Net2: layer bn50:max response is 18.512857, min response is -2.831647.
max gradient is 5.294687, min gradient is -8.000000, learning rate is 0.000527
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.595212, learning rate is 0.000263
Net2: layer bn49:max response is 8.889855, min response is -2.125552.
max gradient is 8.000000, min gradient is -7.411405, learning rate is 0.000527
Net2: layer deconv1:max response is , min response is .
max gradient is 7.760680, min gradient is -8.000000, learning rate is 0.000263
max inferred z is 4.33, min inferred z is -3.98, and std is 0.99
 4.25 s (23.5 data/s) [100/100]
training: epoch 46: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.125081, min gradient is -8.000000, learning rate is 0.022189
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -3.682878, learning rate is 0.022189
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.760813, learning rate is 0.022189
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.735746, learning rate is 0.000527
Net2: layer deconv3:max response is 18.951675, min response is -24.748833.
max gradient is 7.187033, min gradient is -8.000000, learning rate is 0.000263
Net2: layer bn50:max response is 17.706165, min response is -2.959458.
max gradient is 5.005139, min gradient is -8.000000, learning rate is 0.000527
Net2: layer deconv2:max response is , min response is .
max gradient is 6.857991, min gradient is -8.000000, learning rate is 0.000263
Net2: layer bn49:max response is 8.146162, min response is -1.552666.
max gradient is 6.464650, min gradient is -8.000000, learning rate is 0.000527
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000001, min gradient is -6.792361, learning rate is 0.000263
max inferred z is 4.10, min inferred z is -3.70, and std is 0.99
 4.36 s (22.9 data/s) [100/100]
training: epoch 46: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.166636, min gradient is -8.000000, learning rate is 0.022189
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.670244, learning rate is 0.022189
Net1: layer conv1:max response is , min response is .
max gradient is 4.017528, min gradient is -8.000000, learning rate is 0.022189
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.014402, learning rate is 0.000527
Net2: layer deconv3:max response is 18.757008, min response is -26.974365.
max gradient is 7.199880, min gradient is -8.000000, learning rate is 0.000263
Net2: layer bn50:max response is 20.915417, min response is -3.090245.
max gradient is 8.000000, min gradient is -6.661111, learning rate is 0.000527
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.216393, learning rate is 0.000263
Net2: layer bn49:max response is 8.933122, min response is -1.734869.
max gradient is 8.000000, min gradient is -4.678596, learning rate is 0.000527
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.346619, learning rate is 0.000263
max inferred z is 3.99, min inferred z is -3.78, and std is 0.99
 4.46 s (22.4 data/s) [100/100]
training: epoch 46: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.928261, min gradient is -8.000000, learning rate is 0.022189
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.769595, learning rate is 0.022189
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.353512, learning rate is 0.022189
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.144669, learning rate is 0.000527
Net2: layer deconv3:max response is 16.309849, min response is -29.084730.
max gradient is 8.000000, min gradient is -7.394743, learning rate is 0.000263
Net2: layer bn50:max response is 17.163282, min response is -3.070927.
max gradient is 8.000000, min gradient is -6.069720, learning rate is 0.000527
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.675084, learning rate is 0.000263
Net2: layer bn49:max response is 9.127342, min response is -1.771803.
max gradient is 8.000000, min gradient is -6.703105, learning rate is 0.000527
Net2: layer deconv1:max response is , min response is .
max gradient is 7.916063, min gradient is -8.000000, learning rate is 0.000263
max inferred z is 3.86, min inferred z is -4.22, and std is 0.99
 4.40 s (22.7 data/s) [100/100]
training: epoch 46: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.627883, min gradient is -8.000000, learning rate is 0.022189
Net1: layer conv2:max response is , min response is .
max gradient is 4.633782, min gradient is -8.000000, learning rate is 0.022189
Net1: layer conv1:max response is , min response is .
max gradient is 3.909495, min gradient is -8.000000, learning rate is 0.022189
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 6.758521, min gradient is -8.000000, learning rate is 0.000527
Net2: layer deconv3:max response is 15.868717, min response is -23.154095.
max gradient is 8.000000, min gradient is -7.448505, learning rate is 0.000263
Net2: layer bn50:max response is 15.314529, min response is -3.219089.
max gradient is 8.000000, min gradient is -3.042592, learning rate is 0.000527
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.777136, learning rate is 0.000263
Net2: layer bn49:max response is 8.608167, min response is -1.778013.
max gradient is 7.860622, min gradient is -8.000001, learning rate is 0.000527
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.360145, learning rate is 0.000263
max inferred z is 3.83, min inferred z is -4.10, and std is 0.99
 4.35 s (23.0 data/s) [100/100]
training: epoch 46: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.600814, learning rate is 0.022189
Net1: layer conv2:max response is , min response is .
max gradient is 5.271181, min gradient is -8.000000, learning rate is 0.022189
Net1: layer conv1:max response is , min response is .
max gradient is 6.746599, min gradient is -8.000000, learning rate is 0.022189
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -1.622206, min gradient is -8.000000, learning rate is 0.000527
Net2: layer deconv3:max response is 18.216795, min response is -23.439245.
max gradient is 6.463984, min gradient is -8.000000, learning rate is 0.000263
Net2: layer bn50:max response is 16.596418, min response is -3.166996.
max gradient is 8.000000, min gradient is -4.871939, learning rate is 0.000527
Net2: layer deconv2:max response is , min response is .
max gradient is 7.931437, min gradient is -8.000000, learning rate is 0.000263
Net2: layer bn49:max response is 8.239894, min response is -1.713444.
max gradient is 7.333538, min gradient is -8.000000, learning rate is 0.000527
Net2: layer deconv1:max response is , min response is .
max gradient is 7.676483, min gradient is -8.000000, learning rate is 0.000263
max inferred z is 3.89, min inferred z is -4.36, and std is 0.99
 4.19 s (23.9 data/s) [100/100]
training: epoch 46: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.501403, learning rate is 0.022189
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.779501, learning rate is 0.022189
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.199923, learning rate is 0.022189
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 4.169756, min gradient is -8.000000, learning rate is 0.000527
Net2: layer deconv3:max response is 18.921503, min response is -23.112478.
max gradient is 6.375690, min gradient is -8.000000, learning rate is 0.000263
Net2: layer bn50:max response is 17.169418, min response is -3.336221.
max gradient is 3.315779, min gradient is -8.000000, learning rate is 0.000527
Net2: layer deconv2:max response is , min response is .
max gradient is 7.307136, min gradient is -8.000000, learning rate is 0.000263
Net2: layer bn49:max response is 8.179574, min response is -1.721288.
max gradient is 7.877984, min gradient is -8.000000, learning rate is 0.000527
Net2: layer deconv1:max response is , min response is .
max gradient is 7.567898, min gradient is -8.000000, learning rate is 0.000263
max inferred z is 3.97, min inferred z is -3.77, and std is 0.99
 4.34 s (23.0 data/s) [100/100]
training: epoch 46: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.501374, learning rate is 0.022189
Net1: layer conv2:max response is , min response is .
max gradient is 7.149921, min gradient is -8.000000, learning rate is 0.022189
Net1: layer conv1:max response is , min response is .
max gradient is 7.015498, min gradient is -8.000000, learning rate is 0.022189
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.955909, min gradient is -8.000000, learning rate is 0.000527
Net2: layer deconv3:max response is 18.265203, min response is -23.398029.
max gradient is 6.246829, min gradient is -8.000000, learning rate is 0.000263
Net2: layer bn50:max response is 19.508846, min response is -2.695209.
max gradient is 8.000000, min gradient is -5.829348, learning rate is 0.000527
Net2: layer deconv2:max response is , min response is .
max gradient is 6.710033, min gradient is -8.000000, learning rate is 0.000263
Net2: layer bn49:max response is 7.100929, min response is -1.907364.
max gradient is 6.010706, min gradient is -8.000000, learning rate is 0.000527
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.565668, learning rate is 0.000263
max inferred z is 3.96, min inferred z is -4.19, and std is 0.99
 4.33 s (23.1 data/s) [100/100]
Loss: 2.379
Iteration 47 / 200
training: epoch 47: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.942316, learning rate is 0.020932
Net1: layer conv2:max response is , min response is .
max gradient is 7.226976, min gradient is -8.000000, learning rate is 0.020932
Net1: layer conv1:max response is , min response is .
max gradient is 4.711154, min gradient is -8.000000, learning rate is 0.020932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.029003, min gradient is -8.000000, learning rate is 0.000512
Net2: layer deconv3:max response is 19.250809, min response is -26.585823.
max gradient is 5.633142, min gradient is -8.000000, learning rate is 0.000256
Net2: layer bn50:max response is 21.699949, min response is -2.872715.
max gradient is 8.000000, min gradient is -4.073991, learning rate is 0.000512
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.629124, learning rate is 0.000256
Net2: layer bn49:max response is 9.189300, min response is -1.811584.
max gradient is 5.354364, min gradient is -8.000000, learning rate is 0.000512
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.743284, learning rate is 0.000256
max inferred z is 4.54, min inferred z is -3.84, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
training: epoch 47: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.333307, learning rate is 0.020932
Net1: layer conv2:max response is , min response is .
max gradient is 5.955580, min gradient is -8.000000, learning rate is 0.020932
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.947108, learning rate is 0.020932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -2.795609, min gradient is -8.000000, learning rate is 0.000512
Net2: layer deconv3:max response is 18.512131, min response is -21.264097.
max gradient is 7.402186, min gradient is -8.000000, learning rate is 0.000256
Net2: layer bn50:max response is 17.977665, min response is -2.771518.
max gradient is 7.225181, min gradient is -8.000000, learning rate is 0.000512
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.233900, learning rate is 0.000256
Net2: layer bn49:max response is 8.496351, min response is -1.986857.
max gradient is 5.492443, min gradient is -8.000000, learning rate is 0.000512
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.483620, learning rate is 0.000256
max inferred z is 4.04, min inferred z is -4.37, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
training: epoch 47: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.679190, learning rate is 0.020932
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.033229, learning rate is 0.020932
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.061207, learning rate is 0.020932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.776999, learning rate is 0.000512
Net2: layer deconv3:max response is 16.251307, min response is -24.249626.
max gradient is 7.295108, min gradient is -8.000000, learning rate is 0.000256
Net2: layer bn50:max response is 16.001326, min response is -2.978649.
max gradient is 1.990199, min gradient is -8.000000, learning rate is 0.000512
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.568719, learning rate is 0.000256
Net2: layer bn49:max response is 7.833058, min response is -1.813331.
max gradient is 8.000000, min gradient is -7.425277, learning rate is 0.000512
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.723960, learning rate is 0.000256
max inferred z is 3.96, min inferred z is -4.66, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 47: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.409117, min gradient is -8.000000, learning rate is 0.020932
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.927475, learning rate is 0.020932
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.282638, learning rate is 0.020932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.532110, learning rate is 0.000512
Net2: layer deconv3:max response is 20.563322, min response is -21.403046.
max gradient is 8.000000, min gradient is -6.749345, learning rate is 0.000256
Net2: layer bn50:max response is 17.978363, min response is -2.696587.
max gradient is 1.672766, min gradient is -8.000000, learning rate is 0.000512
Net2: layer deconv2:max response is , min response is .
max gradient is 6.130591, min gradient is -8.000000, learning rate is 0.000256
Net2: layer bn49:max response is 8.873260, min response is -1.523353.
max gradient is 8.000000, min gradient is -6.612520, learning rate is 0.000512
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.668768, learning rate is 0.000256
max inferred z is 4.01, min inferred z is -3.81, and std is 1.00
 4.19 s (23.9 data/s) [100/100]
training: epoch 47: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.134543, min gradient is -8.000000, learning rate is 0.020932
Net1: layer conv2:max response is , min response is .
max gradient is 7.089336, min gradient is -8.000000, learning rate is 0.020932
Net1: layer conv1:max response is , min response is .
max gradient is 4.628063, min gradient is -8.000000, learning rate is 0.020932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.373847, learning rate is 0.000512
Net2: layer deconv3:max response is 19.982798, min response is -27.737030.
max gradient is 6.498139, min gradient is -8.000000, learning rate is 0.000256
Net2: layer bn50:max response is 18.019146, min response is -3.225479.
max gradient is 8.000000, min gradient is -5.630711, learning rate is 0.000512
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.653675, learning rate is 0.000256
Net2: layer bn49:max response is 8.652423, min response is -2.057676.
max gradient is 4.073366, min gradient is -8.000000, learning rate is 0.000512
Net2: layer deconv1:max response is , min response is .
max gradient is 7.915904, min gradient is -8.000000, learning rate is 0.000256
max inferred z is 3.84, min inferred z is -4.22, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 47: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.225033, min gradient is -8.000000, learning rate is 0.020932
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.829144, learning rate is 0.020932
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.736938, learning rate is 0.020932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.903553, learning rate is 0.000512
Net2: layer deconv3:max response is 17.919701, min response is -23.063812.
max gradient is 8.000000, min gradient is -7.053934, learning rate is 0.000256
Net2: layer bn50:max response is 16.703840, min response is -2.762758.
max gradient is 8.000000, min gradient is -6.754776, learning rate is 0.000512
Net2: layer deconv2:max response is , min response is .
max gradient is 7.050497, min gradient is -8.000000, learning rate is 0.000256
Net2: layer bn49:max response is 7.890256, min response is -1.701532.
max gradient is 7.291349, min gradient is -8.000000, learning rate is 0.000512
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.891469, learning rate is 0.000256
max inferred z is 4.02, min inferred z is -4.08, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 47: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.848902, min gradient is -8.000000, learning rate is 0.020932
Net1: layer conv2:max response is , min response is .
max gradient is 5.537762, min gradient is -8.000000, learning rate is 0.020932
Net1: layer conv1:max response is , min response is .
max gradient is 4.524143, min gradient is -8.000000, learning rate is 0.020932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -3.045442, min gradient is -8.000000, learning rate is 0.000512
Net2: layer deconv3:max response is 17.924019, min response is -23.895342.
max gradient is 7.900834, min gradient is -8.000000, learning rate is 0.000256
Net2: layer bn50:max response is 18.670996, min response is -3.010782.
max gradient is 8.000000, min gradient is -2.775296, learning rate is 0.000512
Net2: layer deconv2:max response is , min response is .
max gradient is 6.564313, min gradient is -8.000000, learning rate is 0.000256
Net2: layer bn49:max response is 9.459713, min response is -1.859149.
max gradient is 6.130410, min gradient is -8.000000, learning rate is 0.000512
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.133667, learning rate is 0.000256
max inferred z is 4.70, min inferred z is -4.00, and std is 1.00
 4.22 s (23.7 data/s) [100/100]
training: epoch 47: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.469505, min gradient is -8.000000, learning rate is 0.020932
Net1: layer conv2:max response is , min response is .
max gradient is 5.801869, min gradient is -8.000000, learning rate is 0.020932
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.391268, learning rate is 0.020932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -5.380795, learning rate is 0.000512
Net2: layer deconv3:max response is 16.592947, min response is -21.672194.
max gradient is 8.000000, min gradient is -7.612724, learning rate is 0.000256
Net2: layer bn50:max response is 15.180353, min response is -3.143618.
max gradient is 8.000000, min gradient is -6.620019, learning rate is 0.000512
Net2: layer deconv2:max response is , min response is .
max gradient is 7.097382, min gradient is -8.000000, learning rate is 0.000256
Net2: layer bn49:max response is 8.213199, min response is -1.917365.
max gradient is 7.312578, min gradient is -8.000000, learning rate is 0.000512
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.591807, learning rate is 0.000256
max inferred z is 3.79, min inferred z is -3.86, and std is 1.00
 4.41 s (22.7 data/s) [100/100]
training: epoch 47: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.598762, min gradient is -8.000000, learning rate is 0.020932
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.534621, learning rate is 0.020932
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.107767, learning rate is 0.020932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -1.960508, learning rate is 0.000512
Net2: layer deconv3:max response is 17.989500, min response is -23.156820.
max gradient is 8.000000, min gradient is -6.533006, learning rate is 0.000256
Net2: layer bn50:max response is 16.845556, min response is -3.335265.
max gradient is 3.292346, min gradient is -8.000000, learning rate is 0.000512
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.670725, learning rate is 0.000256
Net2: layer bn49:max response is 9.025617, min response is -1.693481.
max gradient is 6.712946, min gradient is -8.000000, learning rate is 0.000512
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.315536, learning rate is 0.000256
max inferred z is 4.54, min inferred z is -4.03, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 47: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.925802, learning rate is 0.020932
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.719868, learning rate is 0.020932
Net1: layer conv1:max response is , min response is .
max gradient is 3.320038, min gradient is -8.000000, learning rate is 0.020932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.517403, min gradient is -8.000000, learning rate is 0.000512
Net2: layer deconv3:max response is 16.230434, min response is -21.915627.
max gradient is 7.258186, min gradient is -8.000000, learning rate is 0.000256
Net2: layer bn50:max response is 17.850161, min response is -2.906763.
max gradient is 8.000000, min gradient is -2.483602, learning rate is 0.000512
Net2: layer deconv2:max response is , min response is .
max gradient is 5.772832, min gradient is -8.000000, learning rate is 0.000256
Net2: layer bn49:max response is 8.203617, min response is -1.854584.
max gradient is 7.083694, min gradient is -8.000000, learning rate is 0.000512
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.621089, learning rate is 0.000256
max inferred z is 3.76, min inferred z is -3.83, and std is 1.00
 4.30 s (23.3 data/s) [100/100]
Loss: 2.3623
Iteration 48 / 200
training: epoch 48: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.045191, min gradient is -8.000000, learning rate is 0.020932
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.346114, learning rate is 0.020932
Net1: layer conv1:max response is , min response is .
max gradient is 5.406058, min gradient is -8.000000, learning rate is 0.020932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.561835, min gradient is -8.000000, learning rate is 0.000512
Net2: layer deconv3:max response is 17.090557, min response is -27.477484.
max gradient is 6.522442, min gradient is -8.000000, learning rate is 0.000256
Net2: layer bn50:max response is 17.553621, min response is -3.175527.
max gradient is 8.000000, min gradient is -2.998550, learning rate is 0.000512
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.760543, learning rate is 0.000256
Net2: layer bn49:max response is 10.535681, min response is -1.795246.
max gradient is 8.000000, min gradient is -7.293688, learning rate is 0.000512
Net2: layer deconv1:max response is , min response is .
max gradient is 7.276975, min gradient is -8.000000, learning rate is 0.000256
max inferred z is 4.23, min inferred z is -4.14, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 48: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.423622, min gradient is -8.000000, learning rate is 0.020932
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.941278, learning rate is 0.020932
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.804596, learning rate is 0.020932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 2.647986, min gradient is -8.000000, learning rate is 0.000512
Net2: layer deconv3:max response is 21.568237, min response is -23.910362.
max gradient is 8.000000, min gradient is -6.881565, learning rate is 0.000256
Net2: layer bn50:max response is 20.398067, min response is -3.629176.
max gradient is 8.000000, min gradient is -2.715211, learning rate is 0.000512
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.906360, learning rate is 0.000256
Net2: layer bn49:max response is 8.377886, min response is -1.964307.
max gradient is 8.000000, min gradient is -7.555889, learning rate is 0.000512
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.908125, learning rate is 0.000256
max inferred z is 4.20, min inferred z is -3.50, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 48: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.116343, min gradient is -8.000000, learning rate is 0.020932
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.836102, learning rate is 0.020932
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -5.459670, learning rate is 0.020932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.795673, learning rate is 0.000512
Net2: layer deconv3:max response is 17.560324, min response is -33.714558.
max gradient is 8.000000, min gradient is -6.725687, learning rate is 0.000256
Net2: layer bn50:max response is 20.133551, min response is -2.881575.
max gradient is 3.550283, min gradient is -8.000000, learning rate is 0.000512
Net2: layer deconv2:max response is , min response is .
max gradient is 6.127351, min gradient is -8.000000, learning rate is 0.000256
Net2: layer bn49:max response is 10.258903, min response is -1.702871.
max gradient is 6.129757, min gradient is -8.000000, learning rate is 0.000512
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.950918, learning rate is 0.000256
max inferred z is 3.66, min inferred z is -4.32, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 48: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.734497, min gradient is -8.000000, learning rate is 0.020932
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -3.608897, learning rate is 0.020932
Net1: layer conv1:max response is , min response is .
max gradient is 7.664584, min gradient is -8.000000, learning rate is 0.020932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.908659, learning rate is 0.000512
Net2: layer deconv3:max response is 18.386370, min response is -26.181795.
max gradient is 8.000000, min gradient is -5.911401, learning rate is 0.000256
Net2: layer bn50:max response is 17.191557, min response is -2.987456.
max gradient is 4.093527, min gradient is -8.000000, learning rate is 0.000512
Net2: layer deconv2:max response is , min response is .
max gradient is 6.521993, min gradient is -8.000000, learning rate is 0.000256
Net2: layer bn49:max response is 8.374055, min response is -2.009584.
max gradient is 8.000000, min gradient is -6.705387, learning rate is 0.000512
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.309174, learning rate is 0.000256
max inferred z is 3.68, min inferred z is -4.20, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 48: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.036991, min gradient is -8.000000, learning rate is 0.020932
Net1: layer conv2:max response is , min response is .
max gradient is 6.120417, min gradient is -8.000000, learning rate is 0.020932
Net1: layer conv1:max response is , min response is .
max gradient is 3.494604, min gradient is -8.000000, learning rate is 0.020932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.440414, learning rate is 0.000512
Net2: layer deconv3:max response is 19.984646, min response is -25.838484.
max gradient is 8.000000, min gradient is -7.327014, learning rate is 0.000256
Net2: layer bn50:max response is 20.857088, min response is -3.512847.
max gradient is 8.000000, min gradient is -5.558106, learning rate is 0.000512
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.468872, learning rate is 0.000256
Net2: layer bn49:max response is 10.932781, min response is -1.699602.
max gradient is 8.000000, min gradient is -7.340448, learning rate is 0.000512
Net2: layer deconv1:max response is , min response is .
max gradient is 7.847727, min gradient is -8.000000, learning rate is 0.000256
max inferred z is 3.89, min inferred z is -4.65, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
training: epoch 48: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.903786, min gradient is -8.000000, learning rate is 0.020932
Net1: layer conv2:max response is , min response is .
max gradient is 7.897891, min gradient is -8.000000, learning rate is 0.020932
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.480735, learning rate is 0.020932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.900892, learning rate is 0.000512
Net2: layer deconv3:max response is 19.086205, min response is -27.680767.
max gradient is 8.000000, min gradient is -5.903948, learning rate is 0.000256
Net2: layer bn50:max response is 15.802872, min response is -2.834632.
max gradient is 8.000000, min gradient is -7.763076, learning rate is 0.000512
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.736773, learning rate is 0.000256
Net2: layer bn49:max response is 8.331882, min response is -1.749188.
max gradient is 7.918231, min gradient is -8.000000, learning rate is 0.000512
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.367898, learning rate is 0.000256
max inferred z is 3.88, min inferred z is -3.83, and std is 1.00
 4.47 s (22.4 data/s) [100/100]
training: epoch 48: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.949579, learning rate is 0.020932
Net1: layer conv2:max response is , min response is .
max gradient is 5.036325, min gradient is -8.000000, learning rate is 0.020932
Net1: layer conv1:max response is , min response is .
max gradient is 5.893052, min gradient is -8.000000, learning rate is 0.020932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.539777, min gradient is -8.000000, learning rate is 0.000512
Net2: layer deconv3:max response is 20.738825, min response is -26.553022.
max gradient is 7.597295, min gradient is -8.000000, learning rate is 0.000256
Net2: layer bn50:max response is 21.606661, min response is -2.984891.
max gradient is 8.000000, min gradient is -3.781088, learning rate is 0.000512
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.658350, learning rate is 0.000256
Net2: layer bn49:max response is 11.714744, min response is -1.711210.
max gradient is 7.817873, min gradient is -8.000000, learning rate is 0.000512
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.563324, learning rate is 0.000256
max inferred z is 3.81, min inferred z is -3.66, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 48: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.846970, learning rate is 0.020932
Net1: layer conv2:max response is , min response is .
max gradient is 6.365422, min gradient is -8.000000, learning rate is 0.020932
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.172904, learning rate is 0.020932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.023251, min gradient is -8.000000, learning rate is 0.000512
Net2: layer deconv3:max response is 20.920206, min response is -24.393581.
max gradient is 7.374625, min gradient is -8.000000, learning rate is 0.000256
Net2: layer bn50:max response is 17.703024, min response is -2.671970.
max gradient is 8.000000, min gradient is -5.692751, learning rate is 0.000512
Net2: layer deconv2:max response is , min response is .
max gradient is 7.769466, min gradient is -8.000000, learning rate is 0.000256
Net2: layer bn49:max response is 8.191791, min response is -1.956936.
max gradient is 7.971979, min gradient is -8.000000, learning rate is 0.000512
Net2: layer deconv1:max response is , min response is .
max gradient is 6.859384, min gradient is -8.000000, learning rate is 0.000256
max inferred z is 4.03, min inferred z is -4.17, and std is 1.00
 4.41 s (22.7 data/s) [100/100]
training: epoch 48: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.448584, learning rate is 0.020932
Net1: layer conv2:max response is , min response is .
max gradient is 7.460954, min gradient is -8.000000, learning rate is 0.020932
Net1: layer conv1:max response is , min response is .
max gradient is 7.836142, min gradient is -8.000000, learning rate is 0.020932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -4.731147, min gradient is -8.000000, learning rate is 0.000512
Net2: layer deconv3:max response is 18.725851, min response is -22.440109.
max gradient is 7.631510, min gradient is -8.000000, learning rate is 0.000256
Net2: layer bn50:max response is 20.385693, min response is -2.955784.
max gradient is 4.076231, min gradient is -8.000000, learning rate is 0.000512
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.717521, learning rate is 0.000256
Net2: layer bn49:max response is 8.097775, min response is -2.153663.
max gradient is 8.000000, min gradient is -7.191150, learning rate is 0.000512
Net2: layer deconv1:max response is , min response is .
max gradient is 6.441105, min gradient is -8.000000, learning rate is 0.000256
max inferred z is 3.89, min inferred z is -4.66, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 48: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.848401, learning rate is 0.020932
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.656846, learning rate is 0.020932
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.098742, learning rate is 0.020932
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.042680, min gradient is -8.000000, learning rate is 0.000512
Net2: layer deconv3:max response is 19.035667, min response is -24.150423.
max gradient is 7.447564, min gradient is -8.000000, learning rate is 0.000256
Net2: layer bn50:max response is 20.910664, min response is -3.182651.
max gradient is 5.229260, min gradient is -8.000000, learning rate is 0.000512
Net2: layer deconv2:max response is , min response is .
max gradient is 7.591388, min gradient is -8.000000, learning rate is 0.000256
Net2: layer bn49:max response is 9.390671, min response is -1.689384.
max gradient is 7.020139, min gradient is -8.000000, learning rate is 0.000512
Net2: layer deconv1:max response is , min response is .
max gradient is 5.972482, min gradient is -8.000000, learning rate is 0.000256
max inferred z is 4.44, min inferred z is -4.05, and std is 1.00
 4.32 s (23.2 data/s) [100/100]
Loss: 2.3746
Iteration 49 / 200
training: epoch 49: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -4.010495, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 6.827846, min gradient is -8.000000, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 3.518177, min gradient is -8.000000, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.962141, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv3:max response is 19.473251, min response is -25.164869.
max gradient is 5.002308, min gradient is -8.000000, learning rate is 0.000248
Net2: layer bn50:max response is 17.236288, min response is -2.584883.
max gradient is 8.000000, min gradient is -4.683312, learning rate is 0.000497
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.986418, learning rate is 0.000248
Net2: layer bn49:max response is 7.878733, min response is -2.063766.
max gradient is 5.410288, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.588505, learning rate is 0.000248
max inferred z is 4.15, min inferred z is -5.16, and std is 1.01
 4.21 s (23.8 data/s) [100/100]
training: epoch 49: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.728019, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 5.967097, min gradient is -8.000000, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.605159, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -0.881939, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv3:max response is 18.213089, min response is -25.681477.
max gradient is 8.000000, min gradient is -7.968543, learning rate is 0.000248
Net2: layer bn50:max response is 16.802410, min response is -2.907459.
max gradient is 8.000000, min gradient is -4.582041, learning rate is 0.000497
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.112443, learning rate is 0.000248
Net2: layer bn49:max response is 8.195293, min response is -1.668299.
max gradient is 7.013511, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv1:max response is , min response is .
max gradient is 7.606500, min gradient is -8.000000, learning rate is 0.000248
max inferred z is 3.87, min inferred z is -3.79, and std is 1.01
 4.33 s (23.1 data/s) [100/100]
training: epoch 49: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.641611, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.927338, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.913655, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.387958, learning rate is 0.000497
Net2: layer deconv3:max response is 19.615532, min response is -24.875334.
max gradient is 8.000000, min gradient is -5.345572, learning rate is 0.000248
Net2: layer bn50:max response is 16.233746, min response is -3.398000.
max gradient is 2.199908, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv2:max response is , min response is .
max gradient is 5.637879, min gradient is -8.000000, learning rate is 0.000248
Net2: layer bn49:max response is 8.147547, min response is -1.659317.
max gradient is 8.000000, min gradient is -6.042934, learning rate is 0.000497
Net2: layer deconv1:max response is , min response is .
max gradient is 7.016209, min gradient is -8.000000, learning rate is 0.000248
max inferred z is 3.78, min inferred z is -4.25, and std is 1.01
 4.30 s (23.3 data/s) [100/100]
training: epoch 49: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.648972, min gradient is -8.000000, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.375779, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.751666, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.493178, learning rate is 0.000497
Net2: layer deconv3:max response is 19.483301, min response is -25.244768.
max gradient is 8.000000, min gradient is -6.195287, learning rate is 0.000248
Net2: layer bn50:max response is 18.548046, min response is -2.861267.
max gradient is 2.852913, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv2:max response is , min response is .
max gradient is 5.495461, min gradient is -8.000000, learning rate is 0.000248
Net2: layer bn49:max response is 7.383914, min response is -2.146858.
max gradient is 5.330653, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv1:max response is , min response is .
max gradient is 5.402123, min gradient is -8.000000, learning rate is 0.000248
max inferred z is 4.39, min inferred z is -3.76, and std is 1.01
 4.34 s (23.0 data/s) [100/100]
training: epoch 49: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.924764, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 5.003614, min gradient is -8.000000, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 4.258129, min gradient is -8.000000, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.535074, learning rate is 0.000497
Net2: layer deconv3:max response is 22.635519, min response is -26.785118.
max gradient is 7.709486, min gradient is -8.000000, learning rate is 0.000248
Net2: layer bn50:max response is 18.924406, min response is -3.337821.
max gradient is 8.000000, min gradient is -6.776088, learning rate is 0.000497
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.589524, learning rate is 0.000248
Net2: layer bn49:max response is 8.977403, min response is -1.769394.
max gradient is 8.000000, min gradient is -7.865037, learning rate is 0.000497
Net2: layer deconv1:max response is , min response is .
max gradient is 7.505970, min gradient is -8.000000, learning rate is 0.000248
max inferred z is 4.59, min inferred z is -3.95, and std is 1.01
 4.32 s (23.1 data/s) [100/100]
training: epoch 49: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.740206, min gradient is -8.000000, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.330260, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.565015, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.482314, learning rate is 0.000497
Net2: layer deconv3:max response is 17.204607, min response is -24.377342.
max gradient is 8.000000, min gradient is -6.025793, learning rate is 0.000248
Net2: layer bn50:max response is 15.196893, min response is -2.769552.
max gradient is 4.991819, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv2:max response is , min response is .
max gradient is 6.694507, min gradient is -8.000000, learning rate is 0.000248
Net2: layer bn49:max response is 7.669568, min response is -1.773016.
max gradient is 6.897063, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv1:max response is , min response is .
max gradient is 5.565495, min gradient is -8.000000, learning rate is 0.000248
max inferred z is 3.75, min inferred z is -3.86, and std is 1.01
 4.21 s (23.8 data/s) [100/100]
training: epoch 49: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.741520, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 6.203129, min gradient is -8.000000, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 7.361507, min gradient is -8.000000, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.699519, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv3:max response is 16.734209, min response is -23.221817.
max gradient is 8.000000, min gradient is -7.325721, learning rate is 0.000248
Net2: layer bn50:max response is 18.346109, min response is -3.135121.
max gradient is 8.000000, min gradient is -2.875400, learning rate is 0.000497
Net2: layer deconv2:max response is , min response is .
max gradient is 6.309620, min gradient is -8.000000, learning rate is 0.000248
Net2: layer bn49:max response is 8.179749, min response is -1.582544.
max gradient is 4.570448, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.866888, learning rate is 0.000248
max inferred z is 4.07, min inferred z is -3.78, and std is 1.01
 4.26 s (23.5 data/s) [100/100]
training: epoch 49: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.018641, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 6.225044, min gradient is -8.000000, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.377717, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.318069, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv3:max response is 20.524683, min response is -22.982300.
max gradient is 8.000000, min gradient is -7.733932, learning rate is 0.000248
Net2: layer bn50:max response is 21.351423, min response is -3.000732.
max gradient is 4.514279, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv2:max response is , min response is .
max gradient is 6.715903, min gradient is -8.000000, learning rate is 0.000248
Net2: layer bn49:max response is 7.729677, min response is -1.754902.
max gradient is 7.021835, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.410722, learning rate is 0.000248
max inferred z is 4.33, min inferred z is -4.20, and std is 1.01
 4.31 s (23.2 data/s) [100/100]
training: epoch 49: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.659526, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.742135, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.275213, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.053635, learning rate is 0.000497
Net2: layer deconv3:max response is 18.241287, min response is -26.818432.
max gradient is 8.000000, min gradient is -6.503233, learning rate is 0.000248
Net2: layer bn50:max response is 15.725435, min response is -2.824045.
max gradient is 4.285086, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv2:max response is , min response is .
max gradient is 7.508020, min gradient is -8.000000, learning rate is 0.000248
Net2: layer bn49:max response is 7.880442, min response is -1.688613.
max gradient is 8.000000, min gradient is -6.363399, learning rate is 0.000497
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.560721, learning rate is 0.000248
max inferred z is 4.83, min inferred z is -4.49, and std is 1.01
 4.26 s (23.5 data/s) [100/100]
training: epoch 49: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.587302, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.722964, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 3.419331, min gradient is -8.000000, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.781150, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv3:max response is 19.486473, min response is -28.989075.
max gradient is 6.518356, min gradient is -8.000000, learning rate is 0.000248
Net2: layer bn50:max response is 19.552843, min response is -3.615671.
max gradient is 8.000000, min gradient is -4.749049, learning rate is 0.000497
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.175244, learning rate is 0.000248
Net2: layer bn49:max response is 8.635317, min response is -2.157490.
max gradient is 8.000000, min gradient is -6.050020, learning rate is 0.000497
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.676212, learning rate is 0.000248
max inferred z is 4.21, min inferred z is -4.43, and std is 1.01
 4.24 s (23.6 data/s) [100/100]
Loss: 2.2816
Iteration 50 / 200
training: epoch 50: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.465869, min gradient is -8.000000, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.883090, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 5.329339, min gradient is -8.000000, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.831316, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv3:max response is 20.838533, min response is -26.952776.
max gradient is 5.911952, min gradient is -8.000000, learning rate is 0.000248
Net2: layer bn50:max response is 21.650297, min response is -3.039239.
max gradient is 8.000001, min gradient is -3.030833, learning rate is 0.000497
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.775393, learning rate is 0.000248
Net2: layer bn49:max response is 9.426200, min response is -1.636050.
max gradient is 8.000000, min gradient is -5.328120, learning rate is 0.000497
Net2: layer deconv1:max response is , min response is .
max gradient is 7.856284, min gradient is -8.000000, learning rate is 0.000248
max inferred z is 4.03, min inferred z is -4.01, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 50: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.667498, min gradient is -8.000000, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.744885, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.938767, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.832681, learning rate is 0.000497
Net2: layer deconv3:max response is 17.407671, min response is -29.788113.
max gradient is 8.000000, min gradient is -7.372693, learning rate is 0.000248
Net2: layer bn50:max response is 18.076559, min response is -3.002584.
max gradient is 8.000000, min gradient is -2.087078, learning rate is 0.000497
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.446493, learning rate is 0.000248
Net2: layer bn49:max response is 8.592921, min response is -1.664852.
max gradient is 8.000000, min gradient is -5.627731, learning rate is 0.000497
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.731086, learning rate is 0.000248
max inferred z is 3.72, min inferred z is -3.58, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 50: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.879894, min gradient is -8.000000, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 7.426569, min gradient is -8.000000, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.157854, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.022439, learning rate is 0.000497
Net2: layer deconv3:max response is 18.109547, min response is -28.347376.
max gradient is 8.000000, min gradient is -5.471157, learning rate is 0.000248
Net2: layer bn50:max response is 18.298979, min response is -3.321515.
max gradient is 3.699346, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv2:max response is , min response is .
max gradient is 6.039395, min gradient is -8.000000, learning rate is 0.000248
Net2: layer bn49:max response is 8.004695, min response is -1.719835.
max gradient is 8.000000, min gradient is -7.035037, learning rate is 0.000497
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.990299, learning rate is 0.000248
max inferred z is 3.82, min inferred z is -4.11, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
training: epoch 50: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.360274, min gradient is -8.000000, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.453582, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.845573, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.812071, learning rate is 0.000497
Net2: layer deconv3:max response is 18.881584, min response is -24.503963.
max gradient is 8.000000, min gradient is -5.964369, learning rate is 0.000248
Net2: layer bn50:max response is 20.007561, min response is -2.770617.
max gradient is 3.348102, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv2:max response is , min response is .
max gradient is 6.263881, min gradient is -8.000000, learning rate is 0.000248
Net2: layer bn49:max response is 9.218531, min response is -2.009439.
max gradient is 8.000000, min gradient is -6.785249, learning rate is 0.000497
Net2: layer deconv1:max response is , min response is .
max gradient is 7.438127, min gradient is -8.000000, learning rate is 0.000248
max inferred z is 4.03, min inferred z is -4.00, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 50: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.790318, min gradient is -8.000000, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 4.643886, min gradient is -8.000000, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 4.319877, min gradient is -8.000000, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -4.696335, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv3:max response is 18.698433, min response is -24.199944.
max gradient is 8.000000, min gradient is -7.828606, learning rate is 0.000248
Net2: layer bn50:max response is 18.709650, min response is -3.268567.
max gradient is 8.000000, min gradient is -7.798183, learning rate is 0.000497
Net2: layer deconv2:max response is , min response is .
max gradient is 7.660041, min gradient is -8.000000, learning rate is 0.000248
Net2: layer bn49:max response is 9.031599, min response is -1.673079.
max gradient is 8.000000, min gradient is -5.387651, learning rate is 0.000497
Net2: layer deconv1:max response is , min response is .
max gradient is 7.404549, min gradient is -8.000000, learning rate is 0.000248
max inferred z is 3.99, min inferred z is -4.08, and std is 1.00
 4.43 s (22.6 data/s) [100/100]
training: epoch 50: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.020874, min gradient is -8.000000, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 7.806006, min gradient is -8.000000, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.121727, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.816949, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv3:max response is 19.643890, min response is -24.991537.
max gradient is 8.000000, min gradient is -7.543093, learning rate is 0.000248
Net2: layer bn50:max response is 18.714157, min response is -3.016793.
max gradient is 2.514126, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.729534, learning rate is 0.000248
Net2: layer bn49:max response is 8.286987, min response is -2.176524.
max gradient is 7.907495, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.366391, learning rate is 0.000248
max inferred z is 4.70, min inferred z is -3.68, and std is 1.00
 4.43 s (22.6 data/s) [100/100]
training: epoch 50: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.127442, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 5.247279, min gradient is -8.000001, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 7.730492, min gradient is -8.000000, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.306402, min gradient is -8.000001, learning rate is 0.000497
Net2: layer deconv3:max response is 16.838512, min response is -27.851843.
max gradient is 7.276571, min gradient is -8.000000, learning rate is 0.000248
Net2: layer bn50:max response is 17.177763, min response is -3.169722.
max gradient is 8.000000, min gradient is -5.350091, learning rate is 0.000497
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.201183, learning rate is 0.000248
Net2: layer bn49:max response is 8.992723, min response is -1.743447.
max gradient is 8.000000, min gradient is -7.812654, learning rate is 0.000497
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.962796, learning rate is 0.000248
max inferred z is 3.98, min inferred z is -3.89, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 50: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.366283, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 7.052293, min gradient is -8.000000, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 7.435860, min gradient is -8.000000, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.213100, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv3:max response is 16.691046, min response is -25.106518.
max gradient is 7.307482, min gradient is -8.000000, learning rate is 0.000248
Net2: layer bn50:max response is 19.339775, min response is -3.053432.
max gradient is 7.632356, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.765363, learning rate is 0.000248
Net2: layer bn49:max response is 8.254954, min response is -1.952594.
max gradient is 8.000000, min gradient is -7.628905, learning rate is 0.000497
Net2: layer deconv1:max response is , min response is .
max gradient is 7.138677, min gradient is -8.000000, learning rate is 0.000248
max inferred z is 3.56, min inferred z is -3.71, and std is 1.00
 4.41 s (22.7 data/s) [100/100]
training: epoch 50: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.285703, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.865175, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.521909, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.179958, learning rate is 0.000497
Net2: layer deconv3:max response is 20.619375, min response is -25.731688.
max gradient is 8.000000, min gradient is -7.191728, learning rate is 0.000248
Net2: layer bn50:max response is 20.428856, min response is -2.798964.
max gradient is 2.390241, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv2:max response is , min response is .
max gradient is 7.684183, min gradient is -8.000000, learning rate is 0.000248
Net2: layer bn49:max response is 7.565428, min response is -1.724505.
max gradient is 8.000000, min gradient is -6.721272, learning rate is 0.000497
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.529297, learning rate is 0.000248
max inferred z is 4.21, min inferred z is -3.74, and std is 1.00
 4.44 s (22.5 data/s) [100/100]
training: epoch 50: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.882003, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.650271, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 4.077267, min gradient is -8.000000, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -4.947539, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv3:max response is 19.503506, min response is -23.555191.
max gradient is 6.579402, min gradient is -8.000000, learning rate is 0.000248
Net2: layer bn50:max response is 18.783796, min response is -2.786341.
max gradient is 6.014145, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.690701, learning rate is 0.000248
Net2: layer bn49:max response is 8.044562, min response is -1.790533.
max gradient is 7.375210, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.881735, learning rate is 0.000248
max inferred z is 4.02, min inferred z is -3.81, and std is 1.00
 4.45 s (22.4 data/s) [100/100]
Loss: 2.3649
Iteration 51 / 200
training: epoch 51: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.584485, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 7.355307, min gradient is -8.000000, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 4.794752, min gradient is -8.000000, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.581525, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv3:max response is 20.356691, min response is -24.449358.
max gradient is 7.103989, min gradient is -8.000000, learning rate is 0.000248
Net2: layer bn50:max response is 19.589117, min response is -2.910876.
max gradient is 8.000000, min gradient is -4.335654, learning rate is 0.000497
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.011165, learning rate is 0.000248
Net2: layer bn49:max response is 7.764260, min response is -1.667696.
max gradient is 7.375047, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.272723, learning rate is 0.000248
max inferred z is 4.18, min inferred z is -3.78, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 51: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.525679, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 5.757643, min gradient is -8.000000, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -6.311797, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.729356, learning rate is 0.000497
Net2: layer deconv3:max response is 17.070486, min response is -27.671551.
max gradient is 6.416364, min gradient is -8.000000, learning rate is 0.000248
Net2: layer bn50:max response is 17.049799, min response is -2.944712.
max gradient is 8.000000, min gradient is -7.494251, learning rate is 0.000497
Net2: layer deconv2:max response is , min response is .
max gradient is 7.399311, min gradient is -8.000000, learning rate is 0.000248
Net2: layer bn49:max response is 8.742917, min response is -1.863029.
max gradient is 8.000000, min gradient is -6.268003, learning rate is 0.000497
Net2: layer deconv1:max response is , min response is .
max gradient is 7.201480, min gradient is -8.000000, learning rate is 0.000248
max inferred z is 4.38, min inferred z is -4.23, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 51: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.129051, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.071177, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.901033, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.693038, learning rate is 0.000497
Net2: layer deconv3:max response is 20.418598, min response is -27.543859.
max gradient is 8.000000, min gradient is -6.093369, learning rate is 0.000248
Net2: layer bn50:max response is 18.342386, min response is -3.167272.
max gradient is 2.892540, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv2:max response is , min response is .
max gradient is 6.293975, min gradient is -8.000000, learning rate is 0.000248
Net2: layer bn49:max response is 7.544060, min response is -1.845162.
max gradient is 8.000000, min gradient is -5.140491, learning rate is 0.000497
Net2: layer deconv1:max response is , min response is .
max gradient is 7.982264, min gradient is -8.000000, learning rate is 0.000248
max inferred z is 3.77, min inferred z is -4.06, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 51: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.574577, min gradient is -8.000000, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.255501, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.656221, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.355723, learning rate is 0.000497
Net2: layer deconv3:max response is 18.437185, min response is -27.432035.
max gradient is 8.000000, min gradient is -4.944595, learning rate is 0.000248
Net2: layer bn50:max response is 15.125022, min response is -3.049109.
max gradient is 2.629459, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv2:max response is , min response is .
max gradient is 6.467683, min gradient is -8.000000, learning rate is 0.000248
Net2: layer bn49:max response is 9.745391, min response is -1.689790.
max gradient is 8.000000, min gradient is -5.747728, learning rate is 0.000497
Net2: layer deconv1:max response is , min response is .
max gradient is 7.095774, min gradient is -8.000000, learning rate is 0.000248
max inferred z is 3.50, min inferred z is -4.04, and std is 1.00
 4.47 s (22.4 data/s) [100/100]
training: epoch 51: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.502382, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 5.524151, min gradient is -8.000000, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 3.956653, min gradient is -8.000000, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -4.735110, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv3:max response is 17.460817, min response is -26.764442.
max gradient is 8.000000, min gradient is -7.729605, learning rate is 0.000248
Net2: layer bn50:max response is 15.551232, min response is -2.839597.
max gradient is 8.000000, min gradient is -6.094169, learning rate is 0.000497
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.850150, learning rate is 0.000248
Net2: layer bn49:max response is 8.645370, min response is -1.995989.
max gradient is 6.181573, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.291174, learning rate is 0.000248
max inferred z is 4.37, min inferred z is -4.08, and std is 1.00
 4.28 s (23.4 data/s) [100/100]
training: epoch 51: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.116833, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 8.000001, min gradient is -7.216699, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.801870, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 0.994433, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv3:max response is 20.580833, min response is -28.451868.
max gradient is 8.000000, min gradient is -5.055135, learning rate is 0.000248
Net2: layer bn50:max response is 19.372772, min response is -2.790192.
max gradient is 2.850026, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv2:max response is , min response is .
max gradient is 5.309182, min gradient is -8.000000, learning rate is 0.000248
Net2: layer bn49:max response is 8.778763, min response is -1.794896.
max gradient is 5.100163, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv1:max response is , min response is .
max gradient is 5.938960, min gradient is -8.000000, learning rate is 0.000248
max inferred z is 3.85, min inferred z is -3.83, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 51: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.926728, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.935810, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.964531, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 0.734437, learning rate is 0.000497
Net2: layer deconv3:max response is 18.117874, min response is -23.860273.
max gradient is 8.000000, min gradient is -5.344761, learning rate is 0.000248
Net2: layer bn50:max response is 15.563581, min response is -2.965336.
max gradient is 4.419984, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv2:max response is , min response is .
max gradient is 5.491078, min gradient is -8.000000, learning rate is 0.000248
Net2: layer bn49:max response is 8.171196, min response is -1.682961.
max gradient is 4.685572, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv1:max response is , min response is .
max gradient is 7.057274, min gradient is -8.000000, learning rate is 0.000248
max inferred z is 3.83, min inferred z is -3.75, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 51: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.167647, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 6.752897, min gradient is -8.000000, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 5.171797, min gradient is -8.000000, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.687367, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv3:max response is 20.342199, min response is -26.532021.
max gradient is 6.423976, min gradient is -8.000000, learning rate is 0.000248
Net2: layer bn50:max response is 17.942640, min response is -3.413431.
max gradient is 8.000000, min gradient is -4.390700, learning rate is 0.000497
Net2: layer deconv2:max response is , min response is .
max gradient is 7.215365, min gradient is -8.000000, learning rate is 0.000248
Net2: layer bn49:max response is 7.732873, min response is -1.689964.
max gradient is 5.806234, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv1:max response is , min response is .
max gradient is 7.882962, min gradient is -8.000000, learning rate is 0.000248
max inferred z is 4.61, min inferred z is -3.65, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
training: epoch 51: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.008584, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.297087, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.202130, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.170880, learning rate is 0.000497
Net2: layer deconv3:max response is 19.784389, min response is -24.428234.
max gradient is 8.000000, min gradient is -6.378250, learning rate is 0.000248
Net2: layer bn50:max response is 16.928900, min response is -3.469234.
max gradient is 3.016623, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv2:max response is , min response is .
max gradient is 6.768172, min gradient is -8.000001, learning rate is 0.000248
Net2: layer bn49:max response is 8.231885, min response is -1.704865.
max gradient is 8.000000, min gradient is -7.874357, learning rate is 0.000497
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.567822, learning rate is 0.000248
max inferred z is 4.20, min inferred z is -3.91, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 51: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.155506, min gradient is -8.000000, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.819706, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.548550, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -3.022738, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv3:max response is 17.419207, min response is -25.671696.
max gradient is 8.000000, min gradient is -7.459830, learning rate is 0.000248
Net2: layer bn50:max response is 17.629408, min response is -3.447787.
max gradient is 5.308295, min gradient is -8.000000, learning rate is 0.000497
Net2: layer deconv2:max response is , min response is .
max gradient is 7.939509, min gradient is -8.000000, learning rate is 0.000248
Net2: layer bn49:max response is 8.994125, min response is -1.805437.
max gradient is 8.000000, min gradient is -6.192923, learning rate is 0.000497
Net2: layer deconv1:max response is , min response is .
max gradient is 7.316027, min gradient is -8.000000, learning rate is 0.000248
max inferred z is 3.86, min inferred z is -4.68, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
Loss: 2.3215
Iteration 52 / 200
training: epoch 52: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.718120, min gradient is -8.000000, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.705090, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 4.116158, min gradient is -8.000000, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.309379, min gradient is -8.000000, learning rate is 0.000495
Net2: layer deconv3:max response is 21.803221, min response is -28.159418.
max gradient is 6.452535, min gradient is -8.000000, learning rate is 0.000247
Net2: layer bn50:max response is 17.856750, min response is -3.527689.
max gradient is 8.000000, min gradient is -3.709653, learning rate is 0.000495
Net2: layer deconv2:max response is , min response is .
max gradient is 7.398734, min gradient is -8.000000, learning rate is 0.000247
Net2: layer bn49:max response is 8.184345, min response is -2.113990.
max gradient is 8.000000, min gradient is -6.440137, learning rate is 0.000495
Net2: layer deconv1:max response is , min response is .
max gradient is 7.486889, min gradient is -8.000000, learning rate is 0.000247
max inferred z is 4.04, min inferred z is -3.84, and std is 1.00
 4.21 s (23.8 data/s) [100/100]
training: epoch 52: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.618156, min gradient is -8.000000, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 6.447259, min gradient is -8.000000, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 7.438252, min gradient is -8.000000, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.901574, learning rate is 0.000495
Net2: layer deconv3:max response is 21.587833, min response is -27.070950.
max gradient is 8.000000, min gradient is -7.412085, learning rate is 0.000247
Net2: layer bn50:max response is 18.975500, min response is -3.495576.
max gradient is 8.000000, min gradient is -4.560415, learning rate is 0.000495
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.847989, learning rate is 0.000247
Net2: layer bn49:max response is 8.783620, min response is -2.094374.
max gradient is 8.000000, min gradient is -5.198359, learning rate is 0.000495
Net2: layer deconv1:max response is , min response is .
max gradient is 7.250553, min gradient is -8.000000, learning rate is 0.000247
max inferred z is 3.73, min inferred z is -3.55, and std is 1.00
 4.18 s (23.9 data/s) [100/100]
training: epoch 52: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.323032, min gradient is -8.000000, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.281120, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.171816, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.700964, learning rate is 0.000495
Net2: layer deconv3:max response is 21.782078, min response is -26.680912.
max gradient is 8.000000, min gradient is -5.225042, learning rate is 0.000247
Net2: layer bn50:max response is 18.991968, min response is -3.131019.
max gradient is 5.093128, min gradient is -8.000000, learning rate is 0.000495
Net2: layer deconv2:max response is , min response is .
max gradient is 7.451131, min gradient is -8.000000, learning rate is 0.000247
Net2: layer bn49:max response is 9.019921, min response is -1.604495.
max gradient is 8.000000, min gradient is -6.909037, learning rate is 0.000495
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.587771, learning rate is 0.000247
max inferred z is 3.88, min inferred z is -4.54, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 52: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.674607, min gradient is -8.000000, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.711105, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.635022, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.397987, learning rate is 0.000495
Net2: layer deconv3:max response is 21.247080, min response is -25.826031.
max gradient is 8.000000, min gradient is -5.639010, learning rate is 0.000247
Net2: layer bn50:max response is 18.918879, min response is -3.229162.
max gradient is 4.099673, min gradient is -8.000000, learning rate is 0.000495
Net2: layer deconv2:max response is , min response is .
max gradient is 6.737602, min gradient is -8.000000, learning rate is 0.000247
Net2: layer bn49:max response is 8.711590, min response is -2.265101.
max gradient is 7.623023, min gradient is -8.000000, learning rate is 0.000495
Net2: layer deconv1:max response is , min response is .
max gradient is 7.794172, min gradient is -8.000000, learning rate is 0.000247
max inferred z is 4.35, min inferred z is -3.87, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
training: epoch 52: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.556855, min gradient is -8.000000, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 4.634356, min gradient is -8.000000, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 3.536781, min gradient is -8.000000, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -3.667545, min gradient is -8.000000, learning rate is 0.000495
Net2: layer deconv3:max response is 19.414921, min response is -22.758595.
max gradient is 5.752388, min gradient is -8.000000, learning rate is 0.000247
Net2: layer bn50:max response is 18.976038, min response is -2.991007.
max gradient is 8.000000, min gradient is -5.459461, learning rate is 0.000495
Net2: layer deconv2:max response is , min response is .
max gradient is 7.866036, min gradient is -8.000000, learning rate is 0.000247
Net2: layer bn49:max response is 8.201368, min response is -1.741752.
max gradient is 7.673128, min gradient is -8.000000, learning rate is 0.000495
Net2: layer deconv1:max response is , min response is .
max gradient is 6.162850, min gradient is -8.000000, learning rate is 0.000247
max inferred z is 3.78, min inferred z is -4.15, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 52: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.740941, min gradient is -8.000000, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.808440, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.939638, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.462316, min gradient is -8.000000, learning rate is 0.000495
Net2: layer deconv3:max response is 18.783337, min response is -23.744795.
max gradient is 7.495858, min gradient is -8.000000, learning rate is 0.000247
Net2: layer bn50:max response is 17.088301, min response is -3.290977.
max gradient is 6.063111, min gradient is -8.000000, learning rate is 0.000495
Net2: layer deconv2:max response is , min response is .
max gradient is 7.737097, min gradient is -8.000000, learning rate is 0.000247
Net2: layer bn49:max response is 7.888093, min response is -1.603731.
max gradient is 6.372038, min gradient is -8.000000, learning rate is 0.000495
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.669391, learning rate is 0.000247
max inferred z is 3.90, min inferred z is -3.75, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 52: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.443917, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 6.648267, min gradient is -8.000000, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 7.860144, min gradient is -8.000000, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.697208, min gradient is -8.000000, learning rate is 0.000495
Net2: layer deconv3:max response is 20.347626, min response is -24.183815.
max gradient is 6.725569, min gradient is -8.000000, learning rate is 0.000247
Net2: layer bn50:max response is 19.117577, min response is -3.783873.
max gradient is 8.000000, min gradient is -6.192714, learning rate is 0.000495
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.387300, learning rate is 0.000247
Net2: layer bn49:max response is 8.139849, min response is -1.854248.
max gradient is 6.861337, min gradient is -8.000000, learning rate is 0.000495
Net2: layer deconv1:max response is , min response is .
max gradient is 7.264733, min gradient is -8.000000, learning rate is 0.000247
max inferred z is 3.84, min inferred z is -4.01, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 52: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.552012, min gradient is -8.000000, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 7.525611, min gradient is -8.000000, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 6.821366, min gradient is -8.000000, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.362977, min gradient is -8.000000, learning rate is 0.000495
Net2: layer deconv3:max response is 18.465487, min response is -24.858982.
max gradient is 7.922197, min gradient is -8.000000, learning rate is 0.000247
Net2: layer bn50:max response is 18.440617, min response is -3.484459.
max gradient is 8.000000, min gradient is -6.213161, learning rate is 0.000495
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.481094, learning rate is 0.000247
Net2: layer bn49:max response is 7.842395, min response is -1.995543.
max gradient is 7.618141, min gradient is -8.000000, learning rate is 0.000495
Net2: layer deconv1:max response is , min response is .
max gradient is 7.652147, min gradient is -8.000000, learning rate is 0.000247
max inferred z is 3.68, min inferred z is -3.83, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 52: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.174013, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.015543, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.503491, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.513166, learning rate is 0.000495
Net2: layer deconv3:max response is 22.790775, min response is -22.754240.
max gradient is 7.020841, min gradient is -8.000000, learning rate is 0.000247
Net2: layer bn50:max response is 21.448376, min response is -3.164030.
max gradient is 1.799442, min gradient is -8.000000, learning rate is 0.000495
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.882616, learning rate is 0.000247
Net2: layer bn49:max response is 7.980787, min response is -1.608607.
max gradient is 8.000000, min gradient is -6.834272, learning rate is 0.000495
Net2: layer deconv1:max response is , min response is .
max gradient is 7.659620, min gradient is -8.000000, learning rate is 0.000247
max inferred z is 4.20, min inferred z is -3.89, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 52: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.055430, learning rate is 0.019747
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.925603, learning rate is 0.019747
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.380113, learning rate is 0.019747
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 0.973246, min gradient is -8.000000, learning rate is 0.000495
Net2: layer deconv3:max response is 18.779001, min response is -27.909811.
max gradient is 5.384398, min gradient is -8.000000, learning rate is 0.000247
Net2: layer bn50:max response is 16.528221, min response is -2.847832.
max gradient is 5.791759, min gradient is -8.000000, learning rate is 0.000495
Net2: layer deconv2:max response is , min response is .
max gradient is 7.548167, min gradient is -8.000000, learning rate is 0.000247
Net2: layer bn49:max response is 8.559929, min response is -1.770868.
max gradient is 7.825450, min gradient is -8.000000, learning rate is 0.000495
Net2: layer deconv1:max response is , min response is .
max gradient is 6.502254, min gradient is -8.000000, learning rate is 0.000247
max inferred z is 3.56, min inferred z is -4.69, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
Loss: 2.4884
Iteration 53 / 200
training: epoch 53: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.700457, learning rate is 0.016390
Net1: layer conv2:max response is , min response is .
max gradient is 7.060640, min gradient is -8.000000, learning rate is 0.016390
Net1: layer conv1:max response is , min response is .
max gradient is 4.280326, min gradient is -8.000000, learning rate is 0.016390
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.006356, min gradient is -8.000000, learning rate is 0.000493
Net2: layer deconv3:max response is 21.703051, min response is -25.072863.
max gradient is 7.814587, min gradient is -8.000000, learning rate is 0.000246
Net2: layer bn50:max response is 19.911114, min response is -3.229666.
max gradient is 8.000000, min gradient is -1.558161, learning rate is 0.000493
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.368866, learning rate is 0.000246
Net2: layer bn49:max response is 7.611821, min response is -1.730303.
max gradient is 8.000000, min gradient is -6.967028, learning rate is 0.000493
Net2: layer deconv1:max response is , min response is .
max gradient is 6.491621, min gradient is -8.000000, learning rate is 0.000246
max inferred z is 4.24, min inferred z is -3.56, and std is 1.00
 4.28 s (23.3 data/s) [100/100]
training: epoch 53: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.343961, learning rate is 0.016390
Net1: layer conv2:max response is , min response is .
max gradient is 6.351777, min gradient is -8.000000, learning rate is 0.016390
Net1: layer conv1:max response is , min response is .
max gradient is 6.687363, min gradient is -8.000000, learning rate is 0.016390
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.495171, learning rate is 0.000493
Net2: layer deconv3:max response is 21.080206, min response is -26.812132.
max gradient is 7.073766, min gradient is -8.000000, learning rate is 0.000246
Net2: layer bn50:max response is 18.898945, min response is -3.168786.
max gradient is 8.000000, min gradient is -4.120950, learning rate is 0.000493
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.734926, learning rate is 0.000246
Net2: layer bn49:max response is 10.438817, min response is -1.806717.
max gradient is 8.000000, min gradient is -6.428332, learning rate is 0.000493
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.788617, learning rate is 0.000246
max inferred z is 3.98, min inferred z is -3.91, and std is 1.00
 4.15 s (24.1 data/s) [100/100]
training: epoch 53: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.960324, learning rate is 0.016390
Net1: layer conv2:max response is , min response is .
max gradient is 7.114671, min gradient is -8.000000, learning rate is 0.016390
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.582579, learning rate is 0.016390
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.758675, learning rate is 0.000493
Net2: layer deconv3:max response is 21.261358, min response is -27.103128.
max gradient is 8.000000, min gradient is -5.069158, learning rate is 0.000246
Net2: layer bn50:max response is 18.199999, min response is -3.587809.
max gradient is 2.727321, min gradient is -8.000000, learning rate is 0.000493
Net2: layer deconv2:max response is , min response is .
max gradient is 7.908609, min gradient is -8.000000, learning rate is 0.000246
Net2: layer bn49:max response is 9.352649, min response is -1.663040.
max gradient is 8.000000, min gradient is -5.587785, learning rate is 0.000493
Net2: layer deconv1:max response is , min response is .
max gradient is 6.969989, min gradient is -8.000000, learning rate is 0.000246
max inferred z is 3.92, min inferred z is -3.84, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 53: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.880303, min gradient is -8.000000, learning rate is 0.016390
Net1: layer conv2:max response is , min response is .
max gradient is 6.735969, min gradient is -8.000000, learning rate is 0.016390
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.711092, learning rate is 0.016390
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.648254, learning rate is 0.000493
Net2: layer deconv3:max response is 20.499954, min response is -26.540981.
max gradient is 8.000000, min gradient is -7.907368, learning rate is 0.000246
Net2: layer bn50:max response is 15.289588, min response is -2.837244.
max gradient is 3.040138, min gradient is -8.000000, learning rate is 0.000493
Net2: layer deconv2:max response is , min response is .
max gradient is 5.286680, min gradient is -8.000000, learning rate is 0.000246
Net2: layer bn49:max response is 7.862085, min response is -1.743453.
max gradient is 8.000000, min gradient is -4.879546, learning rate is 0.000493
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.652297, learning rate is 0.000246
max inferred z is 4.18, min inferred z is -4.11, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 53: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.025558, learning rate is 0.016390
Net1: layer conv2:max response is , min response is .
max gradient is 5.940355, min gradient is -8.000000, learning rate is 0.016390
Net1: layer conv1:max response is , min response is .
max gradient is 4.454625, min gradient is -8.000000, learning rate is 0.016390
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.630733, learning rate is 0.000493
Net2: layer deconv3:max response is 22.500391, min response is -24.270861.
max gradient is 8.000000, min gradient is -6.155630, learning rate is 0.000246
Net2: layer bn50:max response is 20.261154, min response is -3.169924.
max gradient is 3.585571, min gradient is -8.000000, learning rate is 0.000493
Net2: layer deconv2:max response is , min response is .
max gradient is 7.247672, min gradient is -8.000000, learning rate is 0.000246
Net2: layer bn49:max response is 8.946632, min response is -1.617836.
max gradient is 5.171527, min gradient is -8.000000, learning rate is 0.000493
Net2: layer deconv1:max response is , min response is .
max gradient is 7.196269, min gradient is -8.000000, learning rate is 0.000246
max inferred z is 4.62, min inferred z is -4.23, and std is 1.00
 4.16 s (24.0 data/s) [100/100]
training: epoch 53: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.891855, min gradient is -8.000000, learning rate is 0.016390
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.902897, learning rate is 0.016390
Net1: layer conv1:max response is , min response is .
max gradient is 6.078249, min gradient is -8.000000, learning rate is 0.016390
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.107453, min gradient is -8.000000, learning rate is 0.000493
Net2: layer deconv3:max response is 17.492769, min response is -25.821424.
max gradient is 8.000000, min gradient is -7.151625, learning rate is 0.000246
Net2: layer bn50:max response is 17.777769, min response is -3.375661.
max gradient is 8.000000, min gradient is -3.174380, learning rate is 0.000493
Net2: layer deconv2:max response is , min response is .
max gradient is 7.159443, min gradient is -8.000000, learning rate is 0.000246
Net2: layer bn49:max response is 8.101954, min response is -1.830532.
max gradient is 3.558912, min gradient is -8.000000, learning rate is 0.000493
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.980514, learning rate is 0.000246
max inferred z is 4.94, min inferred z is -4.09, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 53: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.754349, learning rate is 0.016390
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.613244, learning rate is 0.016390
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.927670, learning rate is 0.016390
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -2.588416, min gradient is -8.000000, learning rate is 0.000493
Net2: layer deconv3:max response is 16.613190, min response is -25.579357.
max gradient is 8.000000, min gradient is -6.552125, learning rate is 0.000246
Net2: layer bn50:max response is 14.841180, min response is -2.763293.
max gradient is 6.192780, min gradient is -8.000000, learning rate is 0.000493
Net2: layer deconv2:max response is , min response is .
max gradient is 7.314813, min gradient is -8.000000, learning rate is 0.000246
Net2: layer bn49:max response is 7.695246, min response is -1.787835.
max gradient is 4.284599, min gradient is -8.000000, learning rate is 0.000493
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.507500, learning rate is 0.000246
max inferred z is 4.19, min inferred z is -3.94, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 53: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.324274, learning rate is 0.016390
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.182548, learning rate is 0.016390
Net1: layer conv1:max response is , min response is .
max gradient is 5.605099, min gradient is -8.000000, learning rate is 0.016390
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -4.866372, learning rate is 0.000493
Net2: layer deconv3:max response is 19.931021, min response is -26.721586.
max gradient is 8.000000, min gradient is -5.078399, learning rate is 0.000246
Net2: layer bn50:max response is 17.545414, min response is -3.485590.
max gradient is 8.000000, min gradient is -1.578859, learning rate is 0.000493
Net2: layer deconv2:max response is , min response is .
max gradient is 6.574685, min gradient is -8.000000, learning rate is 0.000246
Net2: layer bn49:max response is 8.696629, min response is -1.777036.
max gradient is 5.416350, min gradient is -8.000000, learning rate is 0.000493
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.977215, learning rate is 0.000246
max inferred z is 3.92, min inferred z is -4.49, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 53: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.061184, learning rate is 0.016390
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.553021, learning rate is 0.016390
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.060114, learning rate is 0.016390
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.658592, learning rate is 0.000493
Net2: layer deconv3:max response is 17.876919, min response is -26.431879.
max gradient is 8.000000, min gradient is -5.594490, learning rate is 0.000246
Net2: layer bn50:max response is 18.466747, min response is -2.878150.
max gradient is 5.533477, min gradient is -8.000000, learning rate is 0.000493
Net2: layer deconv2:max response is , min response is .
max gradient is 7.778950, min gradient is -8.000000, learning rate is 0.000246
Net2: layer bn49:max response is 8.678370, min response is -1.591072.
max gradient is 7.394156, min gradient is -8.000000, learning rate is 0.000493
Net2: layer deconv1:max response is , min response is .
max gradient is 7.505891, min gradient is -8.000000, learning rate is 0.000246
max inferred z is 3.82, min inferred z is -4.23, and std is 1.00
 4.30 s (23.2 data/s) [100/100]
training: epoch 53: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.748376, learning rate is 0.016390
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.707624, learning rate is 0.016390
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.730133, learning rate is 0.016390
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.993028, learning rate is 0.000493
Net2: layer deconv3:max response is 18.595352, min response is -28.665453.
max gradient is 8.000000, min gradient is -5.943043, learning rate is 0.000246
Net2: layer bn50:max response is 19.180872, min response is -3.487363.
max gradient is 8.000000, min gradient is -5.851443, learning rate is 0.000493
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.602589, learning rate is 0.000246
Net2: layer bn49:max response is 8.223930, min response is -1.913318.
max gradient is 7.296414, min gradient is -8.000000, learning rate is 0.000493
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.797003, learning rate is 0.000246
max inferred z is 3.79, min inferred z is -3.68, and std is 1.00
 4.41 s (22.7 data/s) [100/100]
Loss: 2.2344
Iteration 54 / 200
training: epoch 54: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.542521, learning rate is 0.016390
Net1: layer conv2:max response is , min response is .
max gradient is 5.694806, min gradient is -8.000000, learning rate is 0.016390
Net1: layer conv1:max response is , min response is .
max gradient is 4.224973, min gradient is -8.000000, learning rate is 0.016390
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.853811, min gradient is -8.000000, learning rate is 0.000491
Net2: layer deconv3:max response is 22.267725, min response is -29.422787.
max gradient is 8.000000, min gradient is -6.703657, learning rate is 0.000245
Net2: layer bn50:max response is 18.996908, min response is -3.482958.
max gradient is 8.000000, min gradient is -1.427387, learning rate is 0.000491
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.857445, learning rate is 0.000245
Net2: layer bn49:max response is 9.837338, min response is -1.757734.
max gradient is 8.000000, min gradient is -7.809025, learning rate is 0.000491
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.668347, learning rate is 0.000245
max inferred z is 3.97, min inferred z is -3.68, and std is 1.00
 4.16 s (24.0 data/s) [100/100]
training: epoch 54: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.951042, min gradient is -8.000000, learning rate is 0.016390
Net1: layer conv2:max response is , min response is .
max gradient is 5.046375, min gradient is -8.000000, learning rate is 0.016390
Net1: layer conv1:max response is , min response is .
max gradient is 4.397939, min gradient is -8.000000, learning rate is 0.016390
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -1.656353, min gradient is -8.000000, learning rate is 0.000491
Net2: layer deconv3:max response is 21.326696, min response is -23.975597.
max gradient is 8.000000, min gradient is -6.309214, learning rate is 0.000245
Net2: layer bn50:max response is 20.517008, min response is -2.633355.
max gradient is 8.000000, min gradient is -3.184952, learning rate is 0.000491
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.580977, learning rate is 0.000245
Net2: layer bn49:max response is 8.606398, min response is -1.645454.
max gradient is 8.000000, min gradient is -5.602039, learning rate is 0.000491
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.718576, learning rate is 0.000245
max inferred z is 4.37, min inferred z is -3.76, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 54: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.463624, min gradient is -8.000000, learning rate is 0.016390
Net1: layer conv2:max response is , min response is .
max gradient is 6.554796, min gradient is -8.000000, learning rate is 0.016390
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.150996, learning rate is 0.016390
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.893925, learning rate is 0.000491
Net2: layer deconv3:max response is 18.277205, min response is -26.339487.
max gradient is 8.000000, min gradient is -5.848175, learning rate is 0.000245
Net2: layer bn50:max response is 18.478117, min response is -3.228917.
max gradient is 6.203371, min gradient is -8.000000, learning rate is 0.000491
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.224037, learning rate is 0.000245
Net2: layer bn49:max response is 7.761661, min response is -1.568962.
max gradient is 8.000000, min gradient is -4.822946, learning rate is 0.000491
Net2: layer deconv1:max response is , min response is .
max gradient is 7.190444, min gradient is -8.000000, learning rate is 0.000245
max inferred z is 4.73, min inferred z is -4.20, and std is 1.00
 4.23 s (23.6 data/s) [100/100]
training: epoch 54: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.217502, min gradient is -8.000000, learning rate is 0.016390
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.190349, learning rate is 0.016390
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.937816, learning rate is 0.016390
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.220257, learning rate is 0.000491
Net2: layer deconv3:max response is 18.311604, min response is -24.339417.
max gradient is 8.000000, min gradient is -7.457340, learning rate is 0.000245
Net2: layer bn50:max response is 19.301371, min response is -3.413959.
max gradient is 3.219953, min gradient is -8.000000, learning rate is 0.000491
Net2: layer deconv2:max response is , min response is .
max gradient is 7.963369, min gradient is -8.000000, learning rate is 0.000245
Net2: layer bn49:max response is 7.958555, min response is -1.688496.
max gradient is 8.000000, min gradient is -5.702838, learning rate is 0.000491
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.571074, learning rate is 0.000245
max inferred z is 3.91, min inferred z is -4.15, and std is 1.00
 4.21 s (23.8 data/s) [100/100]
training: epoch 54: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.554131, min gradient is -8.000001, learning rate is 0.016390
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.761713, learning rate is 0.016390
Net1: layer conv1:max response is , min response is .
max gradient is 6.457341, min gradient is -8.000000, learning rate is 0.016390
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.285964, learning rate is 0.000491
Net2: layer deconv3:max response is 17.165564, min response is -27.932896.
max gradient is 8.000000, min gradient is -6.529562, learning rate is 0.000245
Net2: layer bn50:max response is 17.189789, min response is -3.215569.
max gradient is 5.798726, min gradient is -8.000001, learning rate is 0.000491
Net2: layer deconv2:max response is , min response is .
max gradient is 6.674971, min gradient is -8.000000, learning rate is 0.000245
Net2: layer bn49:max response is 8.202039, min response is -1.918038.
max gradient is 8.000000, min gradient is -5.436723, learning rate is 0.000491
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.701861, learning rate is 0.000245
max inferred z is 3.75, min inferred z is -4.44, and std is 1.00
 4.32 s (23.2 data/s) [100/100]
training: epoch 54: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.079986, min gradient is -8.000000, learning rate is 0.016390
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -3.935127, learning rate is 0.016390
Net1: layer conv1:max response is , min response is .
max gradient is 6.142891, min gradient is -8.000000, learning rate is 0.016390
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.533685, min gradient is -8.000000, learning rate is 0.000491
Net2: layer deconv3:max response is 21.367186, min response is -25.900515.
max gradient is 4.082046, min gradient is -8.000000, learning rate is 0.000245
Net2: layer bn50:max response is 18.690193, min response is -3.640015.
max gradient is 8.000000, min gradient is -2.754382, learning rate is 0.000491
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.666000, learning rate is 0.000245
Net2: layer bn49:max response is 8.307563, min response is -1.752394.
max gradient is 7.268103, min gradient is -8.000000, learning rate is 0.000491
Net2: layer deconv1:max response is , min response is .
max gradient is 7.704015, min gradient is -8.000000, learning rate is 0.000245
max inferred z is 3.63, min inferred z is -4.63, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
training: epoch 54: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.370337, min gradient is -8.000000, learning rate is 0.016390
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.908241, learning rate is 0.016390
Net1: layer conv1:max response is , min response is .
max gradient is 7.396458, min gradient is -8.000000, learning rate is 0.016390
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.914798, min gradient is -8.000000, learning rate is 0.000491
Net2: layer deconv3:max response is 22.644592, min response is -26.557934.
max gradient is 5.082678, min gradient is -8.000000, learning rate is 0.000245
Net2: layer bn50:max response is 21.590927, min response is -3.447898.
max gradient is 8.000000, min gradient is -4.420270, learning rate is 0.000491
Net2: layer deconv2:max response is , min response is .
max gradient is 7.729173, min gradient is -8.000000, learning rate is 0.000245
Net2: layer bn49:max response is 7.848602, min response is -1.933941.
max gradient is 6.770326, min gradient is -8.000000, learning rate is 0.000491
Net2: layer deconv1:max response is , min response is .
max gradient is 6.616763, min gradient is -8.000000, learning rate is 0.000245
max inferred z is 3.87, min inferred z is -4.92, and std is 1.00
 4.22 s (23.7 data/s) [100/100]
training: epoch 54: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.054432, min gradient is -8.000000, learning rate is 0.016390
Net1: layer conv2:max response is , min response is .
max gradient is 6.177557, min gradient is -8.000000, learning rate is 0.016390
Net1: layer conv1:max response is , min response is .
max gradient is 6.871070, min gradient is -8.000000, learning rate is 0.016390
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.507051, learning rate is 0.000491
Net2: layer deconv3:max response is 19.813925, min response is -28.266562.
max gradient is 8.000000, min gradient is -7.890579, learning rate is 0.000245
Net2: layer bn50:max response is 18.570843, min response is -3.108959.
max gradient is 8.000000, min gradient is -4.101375, learning rate is 0.000491
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.367010, learning rate is 0.000245
Net2: layer bn49:max response is 7.604913, min response is -1.646422.
max gradient is 6.701419, min gradient is -8.000000, learning rate is 0.000491
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.635570, learning rate is 0.000245
max inferred z is 3.95, min inferred z is -3.84, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 54: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.093354, min gradient is -8.000000, learning rate is 0.016390
Net1: layer conv2:max response is , min response is .
max gradient is 7.869737, min gradient is -8.000000, learning rate is 0.016390
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.946065, learning rate is 0.016390
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.300394, learning rate is 0.000491
Net2: layer deconv3:max response is 20.858274, min response is -27.817661.
max gradient is 8.000000, min gradient is -5.968040, learning rate is 0.000245
Net2: layer bn50:max response is 20.518707, min response is -3.206340.
max gradient is 8.000000, min gradient is -6.988948, learning rate is 0.000491
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.129353, learning rate is 0.000245
Net2: layer bn49:max response is 9.482930, min response is -1.719502.
max gradient is 6.876538, min gradient is -8.000000, learning rate is 0.000491
Net2: layer deconv1:max response is , min response is .
max gradient is 6.850977, min gradient is -8.000000, learning rate is 0.000245
max inferred z is 4.10, min inferred z is -3.88, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 54: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.876001, learning rate is 0.016390
Net1: layer conv2:max response is , min response is .
max gradient is 7.423799, min gradient is -8.000000, learning rate is 0.016390
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.328402, learning rate is 0.016390
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.114987, learning rate is 0.000491
Net2: layer deconv3:max response is 20.227491, min response is -22.982285.
max gradient is 8.000000, min gradient is -7.488019, learning rate is 0.000245
Net2: layer bn50:max response is 17.881777, min response is -3.062056.
max gradient is 6.780277, min gradient is -8.000000, learning rate is 0.000491
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.259540, learning rate is 0.000245
Net2: layer bn49:max response is 7.945888, min response is -1.514529.
max gradient is 4.806436, min gradient is -8.000000, learning rate is 0.000491
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.170530, learning rate is 0.000245
max inferred z is 4.51, min inferred z is -4.42, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
Loss: 2.3625
Iteration 55 / 200
training: epoch 55: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.454588, learning rate is 0.013604
Net1: layer conv2:max response is , min response is .
max gradient is 6.082482, min gradient is -8.000000, learning rate is 0.013604
Net1: layer conv1:max response is , min response is .
max gradient is 4.517248, min gradient is -8.000000, learning rate is 0.013604
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.839729, min gradient is -8.000000, learning rate is 0.000489
Net2: layer deconv3:max response is 28.349117, min response is -20.927334.
max gradient is 8.000000, min gradient is -4.815564, learning rate is 0.000244
Net2: layer bn50:max response is 26.597303, min response is -3.292598.
max gradient is 8.000000, min gradient is -2.780005, learning rate is 0.000489
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.010083, learning rate is 0.000244
Net2: layer bn49:max response is 8.229323, min response is -1.583097.
max gradient is 3.541573, min gradient is -8.000000, learning rate is 0.000489
Net2: layer deconv1:max response is , min response is .
max gradient is 7.017895, min gradient is -8.000000, learning rate is 0.000244
max inferred z is 4.10, min inferred z is -4.46, and std is 1.01
 4.20 s (23.8 data/s) [100/100]
training: epoch 55: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.199751, learning rate is 0.013604
Net1: layer conv2:max response is , min response is .
max gradient is 6.165454, min gradient is -8.000000, learning rate is 0.013604
Net1: layer conv1:max response is , min response is .
max gradient is 4.478948, min gradient is -8.000000, learning rate is 0.013604
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.719666, min gradient is -8.000000, learning rate is 0.000489
Net2: layer deconv3:max response is 21.531694, min response is -20.736296.
max gradient is 8.000000, min gradient is -6.562234, learning rate is 0.000244
Net2: layer bn50:max response is 20.092358, min response is -3.429749.
max gradient is 8.000000, min gradient is -4.013274, learning rate is 0.000489
Net2: layer deconv2:max response is , min response is .
max gradient is 7.387606, min gradient is -8.000000, learning rate is 0.000244
Net2: layer bn49:max response is 7.893655, min response is -1.742314.
max gradient is 5.098404, min gradient is -8.000000, learning rate is 0.000489
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.665605, learning rate is 0.000244
max inferred z is 3.89, min inferred z is -4.35, and std is 1.01
 4.39 s (22.8 data/s) [100/100]
training: epoch 55: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.350500, learning rate is 0.013604
Net1: layer conv2:max response is , min response is .
max gradient is 4.655402, min gradient is -8.000000, learning rate is 0.013604
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.182546, learning rate is 0.013604
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.908210, min gradient is -8.000000, learning rate is 0.000489
Net2: layer deconv3:max response is 18.949497, min response is -22.877443.
max gradient is 8.000000, min gradient is -6.143972, learning rate is 0.000244
Net2: layer bn50:max response is 16.357546, min response is -3.007856.
max gradient is 3.629864, min gradient is -8.000000, learning rate is 0.000489
Net2: layer deconv2:max response is , min response is .
max gradient is 5.975384, min gradient is -8.000000, learning rate is 0.000244
Net2: layer bn49:max response is 8.307493, min response is -1.929004.
max gradient is 6.959112, min gradient is -8.000000, learning rate is 0.000489
Net2: layer deconv1:max response is , min response is .
max gradient is 7.822917, min gradient is -8.000000, learning rate is 0.000244
max inferred z is 3.58, min inferred z is -4.31, and std is 1.01
 4.37 s (22.9 data/s) [100/100]
training: epoch 55: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.964599, learning rate is 0.013604
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.956381, learning rate is 0.013604
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.391068, learning rate is 0.013604
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.175868, learning rate is 0.000489
Net2: layer deconv3:max response is 24.301577, min response is -26.786736.
max gradient is 8.000000, min gradient is -7.582120, learning rate is 0.000244
Net2: layer bn50:max response is 22.223465, min response is -2.933741.
max gradient is 1.066424, min gradient is -8.000000, learning rate is 0.000489
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.918277, learning rate is 0.000244
Net2: layer bn49:max response is 7.940413, min response is -1.878623.
max gradient is 8.000000, min gradient is -7.703632, learning rate is 0.000489
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.988328, learning rate is 0.000244
max inferred z is 4.06, min inferred z is -4.05, and std is 1.01
 4.22 s (23.7 data/s) [100/100]
training: epoch 55: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.499184, learning rate is 0.013604
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.992332, learning rate is 0.013604
Net1: layer conv1:max response is , min response is .
max gradient is 5.553846, min gradient is -8.000000, learning rate is 0.013604
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.656348, learning rate is 0.000489
Net2: layer deconv3:max response is 20.844696, min response is -29.175329.
max gradient is 7.108950, min gradient is -8.000000, learning rate is 0.000244
Net2: layer bn50:max response is 18.552431, min response is -2.888791.
max gradient is 2.018387, min gradient is -8.000000, learning rate is 0.000489
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.370282, learning rate is 0.000244
Net2: layer bn49:max response is 8.554739, min response is -1.638251.
max gradient is 8.000000, min gradient is -6.511998, learning rate is 0.000489
Net2: layer deconv1:max response is , min response is .
max gradient is 6.944294, min gradient is -8.000000, learning rate is 0.000244
max inferred z is 4.28, min inferred z is -3.97, and std is 1.01
 4.43 s (22.6 data/s) [100/100]
training: epoch 55: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.956127, min gradient is -8.000000, learning rate is 0.013604
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.141761, learning rate is 0.013604
Net1: layer conv1:max response is , min response is .
max gradient is 5.960150, min gradient is -8.000000, learning rate is 0.013604
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.778171, learning rate is 0.000489
Net2: layer deconv3:max response is 19.783800, min response is -23.676069.
max gradient is 5.498861, min gradient is -8.000000, learning rate is 0.000244
Net2: layer bn50:max response is 16.076267, min response is -2.878726.
max gradient is 8.000000, min gradient is -6.232350, learning rate is 0.000489
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.685090, learning rate is 0.000244
Net2: layer bn49:max response is 8.210019, min response is -2.051694.
max gradient is 8.000000, min gradient is -6.104873, learning rate is 0.000489
Net2: layer deconv1:max response is , min response is .
max gradient is 6.587998, min gradient is -8.000000, learning rate is 0.000244
max inferred z is 4.31, min inferred z is -3.87, and std is 1.01
 4.31 s (23.2 data/s) [100/100]
training: epoch 55: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000001, min gradient is -7.495620, learning rate is 0.013604
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.572328, learning rate is 0.013604
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.615047, learning rate is 0.013604
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000001, min gradient is 4.159020, learning rate is 0.000489
Net2: layer deconv3:max response is 19.319489, min response is -27.235291.
max gradient is 6.522578, min gradient is -8.000000, learning rate is 0.000244
Net2: layer bn50:max response is 15.682071, min response is -3.467008.
max gradient is 8.000000, min gradient is -4.463953, learning rate is 0.000489
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.837026, learning rate is 0.000244
Net2: layer bn49:max response is 8.470970, min response is -1.892435.
max gradient is 8.000000, min gradient is -5.619426, learning rate is 0.000489
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.962726, learning rate is 0.000244
max inferred z is 3.90, min inferred z is -4.31, and std is 1.01
 4.36 s (22.9 data/s) [100/100]
training: epoch 55: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.409642, learning rate is 0.013604
Net1: layer conv2:max response is , min response is .
max gradient is 6.961756, min gradient is -8.000000, learning rate is 0.013604
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.465260, learning rate is 0.013604
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.286626, learning rate is 0.000489
Net2: layer deconv3:max response is 18.463806, min response is -27.760548.
max gradient is 7.663313, min gradient is -8.000000, learning rate is 0.000244
Net2: layer bn50:max response is 15.858147, min response is -3.031523.
max gradient is 8.000000, min gradient is -4.382234, learning rate is 0.000489
Net2: layer deconv2:max response is , min response is .
max gradient is 6.272040, min gradient is -8.000000, learning rate is 0.000244
Net2: layer bn49:max response is 7.749549, min response is -1.766023.
max gradient is 7.284737, min gradient is -8.000000, learning rate is 0.000489
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.901121, learning rate is 0.000244
max inferred z is 4.05, min inferred z is -4.02, and std is 1.01
 4.34 s (23.1 data/s) [100/100]
training: epoch 55: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.360386, learning rate is 0.013604
Net1: layer conv2:max response is , min response is .
max gradient is 6.967813, min gradient is -8.000000, learning rate is 0.013604
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.062176, learning rate is 0.013604
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.842824, learning rate is 0.000489
Net2: layer deconv3:max response is 21.616081, min response is -25.577129.
max gradient is 8.000000, min gradient is -7.197453, learning rate is 0.000244
Net2: layer bn50:max response is 16.374311, min response is -3.299011.
max gradient is 8.000000, min gradient is -7.518805, learning rate is 0.000489
Net2: layer deconv2:max response is , min response is .
max gradient is 5.938223, min gradient is -8.000000, learning rate is 0.000244
Net2: layer bn49:max response is 8.119893, min response is -1.876160.
max gradient is 8.000000, min gradient is -6.155283, learning rate is 0.000489
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.143936, learning rate is 0.000244
max inferred z is 3.97, min inferred z is -3.76, and std is 1.01
 4.41 s (22.7 data/s) [100/100]
training: epoch 55: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.852495, min gradient is -8.000000, learning rate is 0.013604
Net1: layer conv2:max response is , min response is .
max gradient is 6.568116, min gradient is -8.000000, learning rate is 0.013604
Net1: layer conv1:max response is , min response is .
max gradient is 6.711195, min gradient is -8.000000, learning rate is 0.013604
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.858032, learning rate is 0.000489
Net2: layer deconv3:max response is 19.663425, min response is -26.004740.
max gradient is 8.000000, min gradient is -6.321520, learning rate is 0.000244
Net2: layer bn50:max response is 18.533081, min response is -3.554760.
max gradient is 6.646903, min gradient is -8.000000, learning rate is 0.000489
Net2: layer deconv2:max response is , min response is .
max gradient is 6.005553, min gradient is -8.000000, learning rate is 0.000244
Net2: layer bn49:max response is 8.143705, min response is -2.006071.
max gradient is 5.850463, min gradient is -8.000000, learning rate is 0.000489
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.552247, learning rate is 0.000244
max inferred z is 3.95, min inferred z is -4.87, and std is 1.01
 4.39 s (22.8 data/s) [100/100]
Loss: 2.4551
Iteration 56 / 200
training: epoch 56: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.848856, min gradient is -8.000000, learning rate is 0.013604
Net1: layer conv2:max response is , min response is .
max gradient is 4.269880, min gradient is -8.000000, learning rate is 0.013604
Net1: layer conv1:max response is , min response is .
max gradient is 6.344706, min gradient is -8.000000, learning rate is 0.013604
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.342450, min gradient is -8.000000, learning rate is 0.000487
Net2: layer deconv3:max response is 17.872862, min response is -25.052414.
max gradient is 8.000000, min gradient is -7.303629, learning rate is 0.000243
Net2: layer bn50:max response is 15.267373, min response is -3.422170.
max gradient is 8.000000, min gradient is -3.251659, learning rate is 0.000487
Net2: layer deconv2:max response is , min response is .
max gradient is 6.274280, min gradient is -8.000000, learning rate is 0.000243
Net2: layer bn49:max response is 8.077348, min response is -1.730230.
max gradient is 3.027763, min gradient is -8.000000, learning rate is 0.000487
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.686514, learning rate is 0.000243
max inferred z is 4.35, min inferred z is -3.99, and std is 1.00
 4.13 s (24.2 data/s) [100/100]
training: epoch 56: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.688860, learning rate is 0.013604
Net1: layer conv2:max response is , min response is .
max gradient is 5.043960, min gradient is -8.000000, learning rate is 0.013604
Net1: layer conv1:max response is , min response is .
max gradient is 6.279008, min gradient is -8.000000, learning rate is 0.013604
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.585369, min gradient is -8.000000, learning rate is 0.000487
Net2: layer deconv3:max response is 20.023205, min response is -25.153103.
max gradient is 7.849762, min gradient is -8.000000, learning rate is 0.000243
Net2: layer bn50:max response is 17.828508, min response is -3.317994.
max gradient is 8.000000, min gradient is -4.002142, learning rate is 0.000487
Net2: layer deconv2:max response is , min response is .
max gradient is 5.917363, min gradient is -8.000000, learning rate is 0.000243
Net2: layer bn49:max response is 8.030400, min response is -1.876685.
max gradient is 3.248188, min gradient is -8.000000, learning rate is 0.000487
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.531284, learning rate is 0.000243
max inferred z is 3.81, min inferred z is -4.10, and std is 1.00
 4.21 s (23.8 data/s) [100/100]
training: epoch 56: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.126261, learning rate is 0.013604
Net1: layer conv2:max response is , min response is .
max gradient is 7.823847, min gradient is -8.000000, learning rate is 0.013604
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -2.716228, learning rate is 0.013604
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.292835, min gradient is -8.000000, learning rate is 0.000487
Net2: layer deconv3:max response is 17.983587, min response is -23.334137.
max gradient is 8.000000, min gradient is -7.202843, learning rate is 0.000243
Net2: layer bn50:max response is 15.902285, min response is -3.120301.
max gradient is 3.436836, min gradient is -8.000000, learning rate is 0.000487
Net2: layer deconv2:max response is , min response is .
max gradient is 6.331689, min gradient is -8.000000, learning rate is 0.000243
Net2: layer bn49:max response is 8.365404, min response is -1.642732.
max gradient is 4.778298, min gradient is -8.000000, learning rate is 0.000487
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000001, min gradient is -6.869594, learning rate is 0.000243
max inferred z is 3.68, min inferred z is -4.05, and std is 1.00
 4.22 s (23.7 data/s) [100/100]
training: epoch 56: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.014410, min gradient is -8.000000, learning rate is 0.013604
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.506923, learning rate is 0.013604
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.345428, learning rate is 0.013604
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.255579, learning rate is 0.000487
Net2: layer deconv3:max response is 18.842539, min response is -24.968464.
max gradient is 6.551631, min gradient is -8.000000, learning rate is 0.000243
Net2: layer bn50:max response is 15.141537, min response is -3.452348.
max gradient is 0.917689, min gradient is -8.000000, learning rate is 0.000487
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.698255, learning rate is 0.000243
Net2: layer bn49:max response is 8.543441, min response is -1.756275.
max gradient is 8.000000, min gradient is -6.680472, learning rate is 0.000487
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.175075, learning rate is 0.000243
max inferred z is 3.56, min inferred z is -3.83, and std is 1.00
 4.18 s (23.9 data/s) [100/100]
training: epoch 56: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.874777, min gradient is -8.000000, learning rate is 0.013604
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.892489, learning rate is 0.013604
Net1: layer conv1:max response is , min response is .
max gradient is 5.481647, min gradient is -8.000000, learning rate is 0.013604
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.280269, learning rate is 0.000487
Net2: layer deconv3:max response is 20.620035, min response is -26.680155.
max gradient is 7.881917, min gradient is -8.000000, learning rate is 0.000243
Net2: layer bn50:max response is 15.104871, min response is -2.923274.
max gradient is 1.816147, min gradient is -8.000000, learning rate is 0.000487
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.660709, learning rate is 0.000243
Net2: layer bn49:max response is 8.278629, min response is -1.780847.
max gradient is 8.000000, min gradient is -4.901757, learning rate is 0.000487
Net2: layer deconv1:max response is , min response is .
max gradient is 7.949595, min gradient is -8.000000, learning rate is 0.000243
max inferred z is 3.87, min inferred z is -3.82, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 56: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.719555, learning rate is 0.013604
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.619337, learning rate is 0.013604
Net1: layer conv1:max response is , min response is .
max gradient is 4.880587, min gradient is -8.000000, learning rate is 0.013604
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.921540, learning rate is 0.000487
Net2: layer deconv3:max response is 20.221989, min response is -26.561127.
max gradient is 5.896518, min gradient is -8.000000, learning rate is 0.000243
Net2: layer bn50:max response is 16.670921, min response is -3.096415.
max gradient is 8.000000, min gradient is -4.273499, learning rate is 0.000487
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.759558, learning rate is 0.000243
Net2: layer bn49:max response is 8.401726, min response is -1.640170.
max gradient is 8.000000, min gradient is -5.606896, learning rate is 0.000487
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.810988, learning rate is 0.000243
max inferred z is 4.58, min inferred z is -3.88, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 56: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.476783, learning rate is 0.013604
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.534745, learning rate is 0.013604
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.268996, learning rate is 0.013604
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.156285, learning rate is 0.000487
Net2: layer deconv3:max response is 17.817879, min response is -30.120626.
max gradient is 7.064913, min gradient is -8.000000, learning rate is 0.000243
Net2: layer bn50:max response is 15.798293, min response is -3.134908.
max gradient is 8.000000, min gradient is -2.135422, learning rate is 0.000487
Net2: layer deconv2:max response is , min response is .
max gradient is 7.860457, min gradient is -8.000000, learning rate is 0.000243
Net2: layer bn49:max response is 8.299403, min response is -1.966902.
max gradient is 8.000000, min gradient is -4.581601, learning rate is 0.000487
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.134762, learning rate is 0.000243
max inferred z is 4.35, min inferred z is -4.07, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 56: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.641267, min gradient is -8.000000, learning rate is 0.013604
Net1: layer conv2:max response is , min response is .
max gradient is 7.199996, min gradient is -8.000000, learning rate is 0.013604
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.572257, learning rate is 0.013604
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.023851, learning rate is 0.000487
Net2: layer deconv3:max response is 20.386850, min response is -26.313963.
max gradient is 7.118429, min gradient is -8.000000, learning rate is 0.000243
Net2: layer bn50:max response is 17.754494, min response is -3.207273.
max gradient is 8.000000, min gradient is -3.224632, learning rate is 0.000487
Net2: layer deconv2:max response is , min response is .
max gradient is 7.917480, min gradient is -8.000000, learning rate is 0.000243
Net2: layer bn49:max response is 9.466402, min response is -1.808317.
max gradient is 8.000000, min gradient is -4.913385, learning rate is 0.000487
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.913892, learning rate is 0.000243
max inferred z is 4.13, min inferred z is -3.53, and std is 1.00
 4.23 s (23.7 data/s) [100/100]
training: epoch 56: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.157818, min gradient is -8.000000, learning rate is 0.013604
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.432196, learning rate is 0.013604
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.888874, learning rate is 0.013604
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.659215, learning rate is 0.000487
Net2: layer deconv3:max response is 22.105696, min response is -25.358053.
max gradient is 6.473390, min gradient is -8.000000, learning rate is 0.000243
Net2: layer bn50:max response is 19.285503, min response is -3.174993.
max gradient is 3.832499, min gradient is -8.000000, learning rate is 0.000487
Net2: layer deconv2:max response is , min response is .
max gradient is 7.548327, min gradient is -8.000000, learning rate is 0.000243
Net2: layer bn49:max response is 7.981138, min response is -1.831585.
max gradient is 6.942966, min gradient is -8.000000, learning rate is 0.000487
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.456616, learning rate is 0.000243
max inferred z is 3.89, min inferred z is -4.06, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
training: epoch 56: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.648606, min gradient is -8.000000, learning rate is 0.013604
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.329434, learning rate is 0.013604
Net1: layer conv1:max response is , min response is .
max gradient is 7.977748, min gradient is -8.000000, learning rate is 0.013604
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.577253, learning rate is 0.000487
Net2: layer deconv3:max response is 17.751505, min response is -26.798222.
max gradient is 7.395740, min gradient is -8.000000, learning rate is 0.000243
Net2: layer bn50:max response is 16.392168, min response is -3.232552.
max gradient is 8.000000, min gradient is -5.725965, learning rate is 0.000487
Net2: layer deconv2:max response is , min response is .
max gradient is 6.249822, min gradient is -8.000000, learning rate is 0.000243
Net2: layer bn49:max response is 8.306276, min response is -1.781458.
max gradient is 7.339237, min gradient is -8.000000, learning rate is 0.000487
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.005082, learning rate is 0.000243
max inferred z is 4.11, min inferred z is -3.92, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
Loss: 2.4299
Iteration 57 / 200
training: epoch 57: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.760519, min gradient is -8.000000, learning rate is 0.011291
Net1: layer conv2:max response is , min response is .
max gradient is 7.451636, min gradient is -8.000000, learning rate is 0.011291
Net1: layer conv1:max response is , min response is .
max gradient is 3.784874, min gradient is -8.000000, learning rate is 0.011291
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.644495, min gradient is -8.000000, learning rate is 0.000485
Net2: layer deconv3:max response is 20.624216, min response is -27.049547.
max gradient is 7.303855, min gradient is -8.000000, learning rate is 0.000242
Net2: layer bn50:max response is 19.825090, min response is -4.042874.
max gradient is 8.000000, min gradient is -2.312052, learning rate is 0.000485
Net2: layer deconv2:max response is , min response is .
max gradient is 6.446994, min gradient is -8.000000, learning rate is 0.000242
Net2: layer bn49:max response is 8.768898, min response is -2.026914.
max gradient is 4.267949, min gradient is -8.000000, learning rate is 0.000485
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.962425, learning rate is 0.000242
max inferred z is 3.84, min inferred z is -3.64, and std is 1.00
 4.28 s (23.4 data/s) [100/100]
training: epoch 57: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.940042, min gradient is -8.000000, learning rate is 0.011291
Net1: layer conv2:max response is , min response is .
max gradient is 6.162610, min gradient is -8.000000, learning rate is 0.011291
Net1: layer conv1:max response is , min response is .
max gradient is 4.505241, min gradient is -8.000000, learning rate is 0.011291
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.962267, min gradient is -8.000000, learning rate is 0.000485
Net2: layer deconv3:max response is 20.978956, min response is -27.625156.
max gradient is 6.419031, min gradient is -8.000000, learning rate is 0.000242
Net2: layer bn50:max response is 17.287653, min response is -3.048161.
max gradient is 8.000000, min gradient is -2.348091, learning rate is 0.000485
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.878715, learning rate is 0.000242
Net2: layer bn49:max response is 8.047619, min response is -1.783444.
max gradient is 4.816153, min gradient is -8.000000, learning rate is 0.000485
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.166054, learning rate is 0.000242
max inferred z is 4.13, min inferred z is -4.25, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 57: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.425078, min gradient is -8.000000, learning rate is 0.011291
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.972833, learning rate is 0.011291
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.553061, learning rate is 0.011291
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 1.952947, min gradient is -8.000000, learning rate is 0.000485
Net2: layer deconv3:max response is 21.787071, min response is -33.299408.
max gradient is 7.265596, min gradient is -8.000000, learning rate is 0.000242
Net2: layer bn50:max response is 18.206694, min response is -4.531333.
max gradient is 4.710824, min gradient is -8.000000, learning rate is 0.000485
Net2: layer deconv2:max response is , min response is .
max gradient is 7.479018, min gradient is -8.000000, learning rate is 0.000242
Net2: layer bn49:max response is 10.514673, min response is -1.893723.
max gradient is 5.858300, min gradient is -8.000000, learning rate is 0.000485
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.471525, learning rate is 0.000242
max inferred z is 3.90, min inferred z is -4.13, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
training: epoch 57: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.399699, learning rate is 0.011291
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.046014, learning rate is 0.011291
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.901552, learning rate is 0.011291
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.386256, learning rate is 0.000485
Net2: layer deconv3:max response is 23.641184, min response is -32.036728.
max gradient is 8.000000, min gradient is -7.473244, learning rate is 0.000242
Net2: layer bn50:max response is 18.600010, min response is -3.549148.
max gradient is 2.911717, min gradient is -8.000000, learning rate is 0.000485
Net2: layer deconv2:max response is , min response is .
max gradient is 6.304949, min gradient is -8.000000, learning rate is 0.000242
Net2: layer bn49:max response is 8.363504, min response is -2.000063.
max gradient is 7.460976, min gradient is -8.000000, learning rate is 0.000485
Net2: layer deconv1:max response is , min response is .
max gradient is 7.322024, min gradient is -8.000000, learning rate is 0.000242
max inferred z is 3.90, min inferred z is -3.85, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 57: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.807220, min gradient is -8.000000, learning rate is 0.011291
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.180720, learning rate is 0.011291
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.876723, learning rate is 0.011291
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.522635, learning rate is 0.000485
Net2: layer deconv3:max response is 19.144138, min response is -30.087111.
max gradient is 8.000000, min gradient is -5.246406, learning rate is 0.000242
Net2: layer bn50:max response is 15.489743, min response is -2.990447.
max gradient is 4.846249, min gradient is -8.000001, learning rate is 0.000485
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.386770, learning rate is 0.000242
Net2: layer bn49:max response is 8.010977, min response is -1.887828.
max gradient is 7.553969, min gradient is -8.000000, learning rate is 0.000485
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.875821, learning rate is 0.000242
max inferred z is 3.76, min inferred z is -4.09, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 57: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.440717, learning rate is 0.011291
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.932567, learning rate is 0.011291
Net1: layer conv1:max response is , min response is .
max gradient is 3.655905, min gradient is -8.000000, learning rate is 0.011291
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 3.155898, min gradient is -8.000000, learning rate is 0.000485
Net2: layer deconv3:max response is 20.239405, min response is -29.783682.
max gradient is 6.334193, min gradient is -8.000000, learning rate is 0.000242
Net2: layer bn50:max response is 16.758558, min response is -3.437123.
max gradient is 8.000000, min gradient is -1.540852, learning rate is 0.000485
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.601071, learning rate is 0.000242
Net2: layer bn49:max response is 8.563571, min response is -2.155899.
max gradient is 6.443981, min gradient is -8.000000, learning rate is 0.000485
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.992891, learning rate is 0.000242
max inferred z is 3.91, min inferred z is -4.37, and std is 1.00
 4.43 s (22.6 data/s) [100/100]
training: epoch 57: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.635082, learning rate is 0.011291
Net1: layer conv2:max response is , min response is .
max gradient is 6.236005, min gradient is -8.000000, learning rate is 0.011291
Net1: layer conv1:max response is , min response is .
max gradient is 4.532506, min gradient is -8.000000, learning rate is 0.011291
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 0.440717, min gradient is -8.000000, learning rate is 0.000485
Net2: layer deconv3:max response is 19.991379, min response is -22.333664.
max gradient is 7.509584, min gradient is -8.000000, learning rate is 0.000242
Net2: layer bn50:max response is 16.351448, min response is -3.435783.
max gradient is 8.000001, min gradient is -1.026720, learning rate is 0.000485
Net2: layer deconv2:max response is , min response is .
max gradient is 6.095969, min gradient is -8.000000, learning rate is 0.000242
Net2: layer bn49:max response is 7.979637, min response is -1.718132.
max gradient is 5.484207, min gradient is -8.000000, learning rate is 0.000485
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000001, min gradient is -6.880618, learning rate is 0.000242
max inferred z is 3.91, min inferred z is -4.02, and std is 1.00
 4.21 s (23.7 data/s) [100/100]
training: epoch 57: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.884211, learning rate is 0.011291
Net1: layer conv2:max response is , min response is .
max gradient is 5.865851, min gradient is -8.000000, learning rate is 0.011291
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.901969, learning rate is 0.011291
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 5.553959, min gradient is -8.000000, learning rate is 0.000485
Net2: layer deconv3:max response is 20.282673, min response is -25.019144.
max gradient is 7.537775, min gradient is -8.000000, learning rate is 0.000242
Net2: layer bn50:max response is 16.511200, min response is -2.995085.
max gradient is 8.000000, min gradient is -2.496755, learning rate is 0.000485
Net2: layer deconv2:max response is , min response is .
max gradient is 7.690259, min gradient is -8.000000, learning rate is 0.000242
Net2: layer bn49:max response is 8.978491, min response is -1.657729.
max gradient is 7.121933, min gradient is -8.000000, learning rate is 0.000485
Net2: layer deconv1:max response is , min response is .
max gradient is 7.281649, min gradient is -8.000000, learning rate is 0.000242
max inferred z is 4.16, min inferred z is -3.88, and std is 1.00
 4.41 s (22.7 data/s) [100/100]
training: epoch 57: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.401104, learning rate is 0.011291
Net1: layer conv2:max response is , min response is .
max gradient is 5.781443, min gradient is -8.000000, learning rate is 0.011291
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.198141, learning rate is 0.011291
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 0.339907, learning rate is 0.000485
Net2: layer deconv3:max response is 23.777168, min response is -25.630459.
max gradient is 6.498304, min gradient is -8.000000, learning rate is 0.000242
Net2: layer bn50:max response is 17.262735, min response is -3.062455.
max gradient is 4.275024, min gradient is -8.000000, learning rate is 0.000485
Net2: layer deconv2:max response is , min response is .
max gradient is 7.685688, min gradient is -8.000000, learning rate is 0.000242
Net2: layer bn49:max response is 8.105972, min response is -1.698019.
max gradient is 8.000000, min gradient is -7.564993, learning rate is 0.000485
Net2: layer deconv1:max response is , min response is .
max gradient is 6.454239, min gradient is -8.000000, learning rate is 0.000242
max inferred z is 3.92, min inferred z is -4.51, and std is 1.00
 4.23 s (23.6 data/s) [100/100]
training: epoch 57: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.945699, learning rate is 0.011291
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.388818, learning rate is 0.011291
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.401923, learning rate is 0.011291
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.410667, learning rate is 0.000485
Net2: layer deconv3:max response is 21.036377, min response is -26.657116.
max gradient is 6.299415, min gradient is -8.000000, learning rate is 0.000242
Net2: layer bn50:max response is 18.570286, min response is -3.037154.
max gradient is 2.236541, min gradient is -8.000000, learning rate is 0.000485
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.798445, learning rate is 0.000242
Net2: layer bn49:max response is 7.869176, min response is -1.718723.
max gradient is 8.000000, min gradient is -6.751120, learning rate is 0.000485
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.735349, learning rate is 0.000242
max inferred z is 4.79, min inferred z is -4.10, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
Loss: 2.4125
Iteration 58 / 200
training: epoch 58: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.522760, learning rate is 0.011291
Net1: layer conv2:max response is , min response is .
max gradient is 7.996006, min gradient is -8.000000, learning rate is 0.011291
Net1: layer conv1:max response is , min response is .
max gradient is 4.114989, min gradient is -8.000000, learning rate is 0.011291
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.008657, min gradient is -8.000000, learning rate is 0.000483
Net2: layer deconv3:max response is 19.842800, min response is -24.726427.
max gradient is 6.160803, min gradient is -8.000000, learning rate is 0.000241
Net2: layer bn50:max response is 16.801935, min response is -3.405331.
max gradient is 7.729422, min gradient is -8.000000, learning rate is 0.000483
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.851938, learning rate is 0.000241
Net2: layer bn49:max response is 8.089185, min response is -1.938204.
max gradient is 5.926111, min gradient is -8.000000, learning rate is 0.000483
Net2: layer deconv1:max response is , min response is .
max gradient is 7.634291, min gradient is -8.000000, learning rate is 0.000241
max inferred z is 4.06, min inferred z is -4.34, and std is 1.00
 4.22 s (23.7 data/s) [100/100]
training: epoch 58: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.479466, learning rate is 0.011291
Net1: layer conv2:max response is , min response is .
max gradient is 5.896856, min gradient is -8.000000, learning rate is 0.011291
Net1: layer conv1:max response is , min response is .
max gradient is 7.018353, min gradient is -8.000000, learning rate is 0.011291
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.728666, min gradient is -8.000000, learning rate is 0.000483
Net2: layer deconv3:max response is 19.405272, min response is -23.628376.
max gradient is 7.247057, min gradient is -8.000000, learning rate is 0.000241
Net2: layer bn50:max response is 16.803343, min response is -3.696068.
max gradient is 5.028283, min gradient is -8.000000, learning rate is 0.000483
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.694051, learning rate is 0.000241
Net2: layer bn49:max response is 7.869410, min response is -1.543872.
max gradient is 8.000000, min gradient is -7.220263, learning rate is 0.000483
Net2: layer deconv1:max response is , min response is .
max gradient is 6.162381, min gradient is -8.000000, learning rate is 0.000241
max inferred z is 3.86, min inferred z is -3.74, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
training: epoch 58: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.613743, learning rate is 0.011291
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.354595, learning rate is 0.011291
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.321752, learning rate is 0.011291
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.214540, learning rate is 0.000483
Net2: layer deconv3:max response is 20.939373, min response is -27.856245.
max gradient is 8.000000, min gradient is -5.731541, learning rate is 0.000241
Net2: layer bn50:max response is 17.327675, min response is -3.383469.
max gradient is 2.337261, min gradient is -8.000000, learning rate is 0.000483
Net2: layer deconv2:max response is , min response is .
max gradient is 6.430192, min gradient is -8.000000, learning rate is 0.000241
Net2: layer bn49:max response is 9.017246, min response is -1.719162.
max gradient is 8.000000, min gradient is -6.647061, learning rate is 0.000483
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.651838, learning rate is 0.000241
max inferred z is 4.37, min inferred z is -4.24, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 58: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.622223, min gradient is -8.000000, learning rate is 0.011291
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.842934, learning rate is 0.011291
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.793215, learning rate is 0.011291
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.441916, learning rate is 0.000483
Net2: layer deconv3:max response is 20.090189, min response is -28.531483.
max gradient is 8.000000, min gradient is -6.165817, learning rate is 0.000241
Net2: layer bn50:max response is 16.247253, min response is -3.417624.
max gradient is 3.136334, min gradient is -8.000000, learning rate is 0.000483
Net2: layer deconv2:max response is , min response is .
max gradient is 5.417084, min gradient is -8.000000, learning rate is 0.000241
Net2: layer bn49:max response is 7.316027, min response is -1.742302.
max gradient is 8.000000, min gradient is -5.796523, learning rate is 0.000483
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.656375, learning rate is 0.000241
max inferred z is 4.08, min inferred z is -4.09, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 58: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.932736, min gradient is -8.000000, learning rate is 0.011291
Net1: layer conv2:max response is , min response is .
max gradient is 5.902736, min gradient is -8.000000, learning rate is 0.011291
Net1: layer conv1:max response is , min response is .
max gradient is 4.561415, min gradient is -8.000000, learning rate is 0.011291
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.418771, learning rate is 0.000483
Net2: layer deconv3:max response is 22.454056, min response is -25.871187.
max gradient is 8.000000, min gradient is -6.437043, learning rate is 0.000241
Net2: layer bn50:max response is 17.253431, min response is -3.447253.
max gradient is 4.707862, min gradient is -8.000000, learning rate is 0.000483
Net2: layer deconv2:max response is , min response is .
max gradient is 5.637280, min gradient is -8.000000, learning rate is 0.000241
Net2: layer bn49:max response is 9.058109, min response is -1.693216.
max gradient is 8.000000, min gradient is -7.434997, learning rate is 0.000483
Net2: layer deconv1:max response is , min response is .
max gradient is 7.055540, min gradient is -8.000000, learning rate is 0.000241
max inferred z is 3.77, min inferred z is -4.04, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 58: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.038929, min gradient is -8.000000, learning rate is 0.011291
Net1: layer conv2:max response is , min response is .
max gradient is 7.685997, min gradient is -8.000000, learning rate is 0.011291
Net1: layer conv1:max response is , min response is .
max gradient is 6.753047, min gradient is -8.000000, learning rate is 0.011291
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.453609, learning rate is 0.000483
Net2: layer deconv3:max response is 19.599234, min response is -23.053518.
max gradient is 6.679989, min gradient is -8.000000, learning rate is 0.000241
Net2: layer bn50:max response is 18.541721, min response is -2.960380.
max gradient is 8.000000, min gradient is -5.255938, learning rate is 0.000483
Net2: layer deconv2:max response is , min response is .
max gradient is 5.368158, min gradient is -8.000000, learning rate is 0.000241
Net2: layer bn49:max response is 8.087540, min response is -1.842526.
max gradient is 5.744413, min gradient is -8.000000, learning rate is 0.000483
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.463272, learning rate is 0.000241
max inferred z is 3.84, min inferred z is -4.04, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 58: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.956789, learning rate is 0.011291
Net1: layer conv2:max response is , min response is .
max gradient is 5.577647, min gradient is -8.000001, learning rate is 0.011291
Net1: layer conv1:max response is , min response is .
max gradient is 6.566022, min gradient is -8.000000, learning rate is 0.011291
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.265537, min gradient is -8.000000, learning rate is 0.000483
Net2: layer deconv3:max response is 21.758802, min response is -21.615475.
max gradient is 6.833287, min gradient is -8.000000, learning rate is 0.000241
Net2: layer bn50:max response is 19.448002, min response is -3.194776.
max gradient is 8.000000, min gradient is -5.684970, learning rate is 0.000483
Net2: layer deconv2:max response is , min response is .
max gradient is 7.545645, min gradient is -8.000000, learning rate is 0.000241
Net2: layer bn49:max response is 8.233307, min response is -1.824928.
max gradient is 5.380526, min gradient is -8.000000, learning rate is 0.000483
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.179823, learning rate is 0.000241
max inferred z is 3.80, min inferred z is -3.92, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 58: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -4.647247, learning rate is 0.011291
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.982437, learning rate is 0.011291
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.773594, learning rate is 0.011291
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.292779, min gradient is -8.000000, learning rate is 0.000483
Net2: layer deconv3:max response is 20.714327, min response is -27.177696.
max gradient is 6.684934, min gradient is -8.000000, learning rate is 0.000241
Net2: layer bn50:max response is 16.043348, min response is -3.677002.
max gradient is 8.000000, min gradient is -4.915049, learning rate is 0.000483
Net2: layer deconv2:max response is , min response is .
max gradient is 6.118366, min gradient is -8.000000, learning rate is 0.000241
Net2: layer bn49:max response is 8.009220, min response is -1.775748.
max gradient is 7.614327, min gradient is -8.000000, learning rate is 0.000483
Net2: layer deconv1:max response is , min response is .
max gradient is 7.214156, min gradient is -8.000000, learning rate is 0.000241
max inferred z is 3.77, min inferred z is -3.76, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 58: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.828194, learning rate is 0.011291
Net1: layer conv2:max response is , min response is .
max gradient is 7.988563, min gradient is -8.000000, learning rate is 0.011291
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.677691, learning rate is 0.011291
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.375642, learning rate is 0.000483
Net2: layer deconv3:max response is 21.635237, min response is -25.785374.
max gradient is 8.000000, min gradient is -6.318297, learning rate is 0.000241
Net2: layer bn50:max response is 17.386589, min response is -3.136195.
max gradient is 2.498651, min gradient is -8.000000, learning rate is 0.000483
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.932050, learning rate is 0.000241
Net2: layer bn49:max response is 7.753947, min response is -1.602456.
max gradient is 8.000000, min gradient is -5.230409, learning rate is 0.000483
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.277204, learning rate is 0.000241
max inferred z is 3.83, min inferred z is -4.22, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
training: epoch 58: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.747851, learning rate is 0.011291
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.044785, learning rate is 0.011291
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.468866, learning rate is 0.011291
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.279118, learning rate is 0.000483
Net2: layer deconv3:max response is 20.249149, min response is -26.828651.
max gradient is 8.000000, min gradient is -5.561720, learning rate is 0.000241
Net2: layer bn50:max response is 17.822094, min response is -3.100583.
max gradient is 3.364256, min gradient is -8.000000, learning rate is 0.000483
Net2: layer deconv2:max response is , min response is .
max gradient is 7.624988, min gradient is -8.000000, learning rate is 0.000241
Net2: layer bn49:max response is 9.665707, min response is -1.932634.
max gradient is 8.000000, min gradient is -3.760418, learning rate is 0.000483
Net2: layer deconv1:max response is , min response is .
max gradient is 7.923741, min gradient is -8.000000, learning rate is 0.000241
max inferred z is 4.05, min inferred z is -4.04, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
Loss: 2.4035
Iteration 59 / 200
training: epoch 59: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.254039, min gradient is -8.000000, learning rate is 0.009372
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -3.955487, learning rate is 0.009372
Net1: layer conv1:max response is , min response is .
max gradient is 4.566163, min gradient is -8.000000, learning rate is 0.009372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.461537, learning rate is 0.000481
Net2: layer deconv3:max response is 20.466356, min response is -28.194963.
max gradient is 7.097332, min gradient is -8.000000, learning rate is 0.000241
Net2: layer bn50:max response is 17.341621, min response is -3.133668.
max gradient is 8.000000, min gradient is -1.989031, learning rate is 0.000481
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.387193, learning rate is 0.000241
Net2: layer bn49:max response is 8.228209, min response is -1.604690.
max gradient is 8.000000, min gradient is -3.807873, learning rate is 0.000481
Net2: layer deconv1:max response is , min response is .
max gradient is 6.532553, min gradient is -8.000000, learning rate is 0.000241
max inferred z is 3.89, min inferred z is -4.02, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 59: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.768140, min gradient is -8.000000, learning rate is 0.009372
Net1: layer conv2:max response is , min response is .
max gradient is 7.616091, min gradient is -8.000000, learning rate is 0.009372
Net1: layer conv1:max response is , min response is .
max gradient is 4.851169, min gradient is -8.000000, learning rate is 0.009372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.983047, learning rate is 0.000481
Net2: layer deconv3:max response is 24.577385, min response is -29.859459.
max gradient is 8.000000, min gradient is -7.999626, learning rate is 0.000241
Net2: layer bn50:max response is 21.000648, min response is -3.492033.
max gradient is 8.000000, min gradient is -2.220702, learning rate is 0.000481
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.492537, learning rate is 0.000241
Net2: layer bn49:max response is 8.311763, min response is -1.729275.
max gradient is 8.000000, min gradient is -3.795184, learning rate is 0.000481
Net2: layer deconv1:max response is , min response is .
max gradient is 7.400052, min gradient is -8.000000, learning rate is 0.000241
max inferred z is 4.03, min inferred z is -3.70, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 59: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.006549, min gradient is -8.000000, learning rate is 0.009372
Net1: layer conv2:max response is , min response is .
max gradient is 5.491877, min gradient is -8.000000, learning rate is 0.009372
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.224016, learning rate is 0.009372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.693926, learning rate is 0.000481
Net2: layer deconv3:max response is 21.007410, min response is -25.446629.
max gradient is 8.000000, min gradient is -6.297756, learning rate is 0.000241
Net2: layer bn50:max response is 17.820391, min response is -3.585577.
max gradient is 8.000000, min gradient is -4.501050, learning rate is 0.000481
Net2: layer deconv2:max response is , min response is .
max gradient is 7.217917, min gradient is -8.000000, learning rate is 0.000241
Net2: layer bn49:max response is 9.484334, min response is -1.582697.
max gradient is 8.000000, min gradient is -5.329054, learning rate is 0.000481
Net2: layer deconv1:max response is , min response is .
max gradient is 7.299414, min gradient is -8.000000, learning rate is 0.000241
max inferred z is 3.55, min inferred z is -3.88, and std is 1.00
 4.21 s (23.8 data/s) [100/100]
training: epoch 59: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.560009, min gradient is -8.000000, learning rate is 0.009372
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.876172, learning rate is 0.009372
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.409422, learning rate is 0.009372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.351654, learning rate is 0.000481
Net2: layer deconv3:max response is 19.627298, min response is -25.189795.
max gradient is 6.869349, min gradient is -8.000000, learning rate is 0.000241
Net2: layer bn50:max response is 17.446640, min response is -3.260224.
max gradient is 5.705254, min gradient is -8.000000, learning rate is 0.000481
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.700666, learning rate is 0.000241
Net2: layer bn49:max response is 8.295871, min response is -1.681201.
max gradient is 8.000000, min gradient is -7.010720, learning rate is 0.000481
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.797535, learning rate is 0.000241
max inferred z is 3.69, min inferred z is -3.65, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 59: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.793041, min gradient is -8.000000, learning rate is 0.009372
Net1: layer conv2:max response is , min response is .
max gradient is 7.468655, min gradient is -8.000000, learning rate is 0.009372
Net1: layer conv1:max response is , min response is .
max gradient is 6.857237, min gradient is -8.000000, learning rate is 0.009372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.251135, learning rate is 0.000481
Net2: layer deconv3:max response is 23.010082, min response is -23.365345.
max gradient is 6.198382, min gradient is -8.000000, learning rate is 0.000241
Net2: layer bn50:max response is 21.486364, min response is -3.051220.
max gradient is 8.000000, min gradient is -6.428112, learning rate is 0.000481
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.313580, learning rate is 0.000241
Net2: layer bn49:max response is 7.692886, min response is -1.774491.
max gradient is 8.000000, min gradient is -7.136003, learning rate is 0.000481
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.469445, learning rate is 0.000241
max inferred z is 3.67, min inferred z is -4.02, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
training: epoch 59: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.704668, min gradient is -8.000000, learning rate is 0.009372
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.307251, learning rate is 0.009372
Net1: layer conv1:max response is , min response is .
max gradient is 7.248917, min gradient is -8.000000, learning rate is 0.009372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -0.744068, min gradient is -8.000000, learning rate is 0.000481
Net2: layer deconv3:max response is 19.007734, min response is -28.483072.
max gradient is 8.000000, min gradient is -7.606401, learning rate is 0.000241
Net2: layer bn50:max response is 18.796144, min response is -3.252530.
max gradient is 8.000000, min gradient is -5.061281, learning rate is 0.000481
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000001, min gradient is -6.459084, learning rate is 0.000241
Net2: layer bn49:max response is 8.253980, min response is -1.616009.
max gradient is 5.232284, min gradient is -8.000000, learning rate is 0.000481
Net2: layer deconv1:max response is , min response is .
max gradient is 6.638394, min gradient is -8.000000, learning rate is 0.000241
max inferred z is 3.68, min inferred z is -3.68, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 59: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.842101, min gradient is -8.000000, learning rate is 0.009372
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.378448, learning rate is 0.009372
Net1: layer conv1:max response is , min response is .
max gradient is 5.713983, min gradient is -8.000000, learning rate is 0.009372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.150378, min gradient is -8.000000, learning rate is 0.000481
Net2: layer deconv3:max response is 21.853006, min response is -30.956348.
max gradient is 8.000000, min gradient is -6.261914, learning rate is 0.000241
Net2: layer bn50:max response is 19.524677, min response is -3.523713.
max gradient is 8.000000, min gradient is -3.480584, learning rate is 0.000481
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.007295, learning rate is 0.000241
Net2: layer bn49:max response is 8.972126, min response is -1.788781.
max gradient is 5.750025, min gradient is -8.000000, learning rate is 0.000481
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.377604, learning rate is 0.000241
max inferred z is 3.99, min inferred z is -4.28, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 59: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000001, min gradient is -6.322526, learning rate is 0.009372
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.411434, learning rate is 0.009372
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.222826, learning rate is 0.009372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.469324, min gradient is -8.000000, learning rate is 0.000481
Net2: layer deconv3:max response is 20.011391, min response is -32.026737.
max gradient is 7.634593, min gradient is -8.000000, learning rate is 0.000241
Net2: layer bn50:max response is 17.551693, min response is -4.218025.
max gradient is 7.382277, min gradient is -8.000000, learning rate is 0.000481
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.927073, learning rate is 0.000241
Net2: layer bn49:max response is 8.666251, min response is -2.079163.
max gradient is 7.158636, min gradient is -8.000000, learning rate is 0.000481
Net2: layer deconv1:max response is , min response is .
max gradient is 7.182666, min gradient is -8.000000, learning rate is 0.000241
max inferred z is 3.82, min inferred z is -4.25, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 59: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.404855, min gradient is -8.000000, learning rate is 0.009372
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.474804, learning rate is 0.009372
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.781678, learning rate is 0.009372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.237968, learning rate is 0.000481
Net2: layer deconv3:max response is 19.566326, min response is -27.317230.
max gradient is 8.000000, min gradient is -7.115495, learning rate is 0.000241
Net2: layer bn50:max response is 17.671801, min response is -3.073502.
max gradient is 5.034961, min gradient is -8.000000, learning rate is 0.000481
Net2: layer deconv2:max response is , min response is .
max gradient is 7.296021, min gradient is -8.000000, learning rate is 0.000241
Net2: layer bn49:max response is 7.913020, min response is -1.719640.
max gradient is 6.985987, min gradient is -8.000000, learning rate is 0.000481
Net2: layer deconv1:max response is , min response is .
max gradient is 6.368910, min gradient is -8.000000, learning rate is 0.000241
max inferred z is 4.43, min inferred z is -4.27, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 59: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.697002, learning rate is 0.009372
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.564417, learning rate is 0.009372
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.787871, learning rate is 0.009372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.034261, learning rate is 0.000481
Net2: layer deconv3:max response is 21.559065, min response is -26.203169.
max gradient is 7.639811, min gradient is -8.000000, learning rate is 0.000241
Net2: layer bn50:max response is 18.093468, min response is -3.232728.
max gradient is 5.492936, min gradient is -8.000000, learning rate is 0.000481
Net2: layer deconv2:max response is , min response is .
max gradient is 7.581210, min gradient is -8.000000, learning rate is 0.000241
Net2: layer bn49:max response is 7.904222, min response is -1.541035.
max gradient is 6.854620, min gradient is -8.000000, learning rate is 0.000481
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.551456, learning rate is 0.000241
max inferred z is 3.98, min inferred z is -4.79, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
Loss: 2.2011
Iteration 60 / 200
training: epoch 60: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.884707, min gradient is -8.000000, learning rate is 0.009372
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.945370, learning rate is 0.009372
Net1: layer conv1:max response is , min response is .
max gradient is 3.956349, min gradient is -8.000000, learning rate is 0.009372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 0.941850, learning rate is 0.000479
Net2: layer deconv3:max response is 21.069654, min response is -28.423418.
max gradient is 7.162756, min gradient is -8.000000, learning rate is 0.000240
Net2: layer bn50:max response is 18.476728, min response is -3.028747.
max gradient is 8.000000, min gradient is -4.091596, learning rate is 0.000479
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.925128, learning rate is 0.000240
Net2: layer bn49:max response is 7.499838, min response is -1.808424.
max gradient is 7.008783, min gradient is -8.000000, learning rate is 0.000479
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.889250, learning rate is 0.000240
max inferred z is 4.70, min inferred z is -4.43, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
training: epoch 60: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.562030, min gradient is -8.000000, learning rate is 0.009372
Net1: layer conv2:max response is , min response is .
max gradient is 5.664584, min gradient is -8.000001, learning rate is 0.009372
Net1: layer conv1:max response is , min response is .
max gradient is 7.934813, min gradient is -8.000000, learning rate is 0.009372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 2.568541, min gradient is -8.000000, learning rate is 0.000479
Net2: layer deconv3:max response is 18.877058, min response is -30.706598.
max gradient is 8.000000, min gradient is -7.873417, learning rate is 0.000240
Net2: layer bn50:max response is 19.093878, min response is -3.211930.
max gradient is 8.000000, min gradient is -1.662055, learning rate is 0.000479
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.682944, learning rate is 0.000240
Net2: layer bn49:max response is 7.650586, min response is -1.787446.
max gradient is 4.545589, min gradient is -8.000001, learning rate is 0.000479
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.145412, learning rate is 0.000240
max inferred z is 3.95, min inferred z is -3.94, and std is 1.00
 4.19 s (23.9 data/s) [100/100]
training: epoch 60: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.211533, min gradient is -8.000000, learning rate is 0.009372
Net1: layer conv2:max response is , min response is .
max gradient is 5.781522, min gradient is -8.000000, learning rate is 0.009372
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.268600, learning rate is 0.009372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 0.765738, min gradient is -8.000000, learning rate is 0.000479
Net2: layer deconv3:max response is 23.511158, min response is -28.269175.
max gradient is 8.000000, min gradient is -7.344911, learning rate is 0.000240
Net2: layer bn50:max response is 17.977285, min response is -3.094322.
max gradient is 8.000000, min gradient is -2.933873, learning rate is 0.000479
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.812964, learning rate is 0.000240
Net2: layer bn49:max response is 9.040771, min response is -1.641751.
max gradient is 4.373837, min gradient is -8.000000, learning rate is 0.000479
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.928564, learning rate is 0.000240
max inferred z is 3.85, min inferred z is -4.56, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
training: epoch 60: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.068955, learning rate is 0.009372
Net1: layer conv2:max response is , min response is .
max gradient is 5.024879, min gradient is -8.000000, learning rate is 0.009372
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.749807, learning rate is 0.009372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 1.000092, min gradient is -8.000000, learning rate is 0.000479
Net2: layer deconv3:max response is 23.572010, min response is -29.043427.
max gradient is 7.661438, min gradient is -8.000000, learning rate is 0.000240
Net2: layer bn50:max response is 22.205454, min response is -3.371719.
max gradient is 5.590044, min gradient is -8.000000, learning rate is 0.000479
Net2: layer deconv2:max response is , min response is .
max gradient is 7.088845, min gradient is -8.000000, learning rate is 0.000240
Net2: layer bn49:max response is 9.536298, min response is -1.714044.
max gradient is 6.489403, min gradient is -8.000000, learning rate is 0.000479
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.759380, learning rate is 0.000240
max inferred z is 4.47, min inferred z is -3.85, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 60: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.716762, learning rate is 0.009372
Net1: layer conv2:max response is , min response is .
max gradient is 5.715594, min gradient is -8.000000, learning rate is 0.009372
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.341888, learning rate is 0.009372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -3.660605, min gradient is -8.000000, learning rate is 0.000479
Net2: layer deconv3:max response is 22.589281, min response is -28.887980.
max gradient is 7.883146, min gradient is -8.000000, learning rate is 0.000240
Net2: layer bn50:max response is 17.478094, min response is -3.703460.
max gradient is 3.710389, min gradient is -8.000000, learning rate is 0.000479
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.929391, learning rate is 0.000240
Net2: layer bn49:max response is 8.174144, min response is -1.851750.
max gradient is 6.438647, min gradient is -8.000000, learning rate is 0.000479
Net2: layer deconv1:max response is , min response is .
max gradient is 6.562327, min gradient is -8.000000, learning rate is 0.000240
max inferred z is 3.86, min inferred z is -3.76, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 60: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.217664, learning rate is 0.009372
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.560737, learning rate is 0.009372
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.646846, learning rate is 0.009372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.428051, min gradient is -8.000000, learning rate is 0.000479
Net2: layer deconv3:max response is 22.629683, min response is -27.297358.
max gradient is 8.000000, min gradient is -7.062191, learning rate is 0.000240
Net2: layer bn50:max response is 18.003941, min response is -3.000471.
max gradient is 3.281923, min gradient is -8.000000, learning rate is 0.000479
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.478494, learning rate is 0.000240
Net2: layer bn49:max response is 7.811227, min response is -1.759098.
max gradient is 5.762087, min gradient is -8.000000, learning rate is 0.000479
Net2: layer deconv1:max response is , min response is .
max gradient is 7.638226, min gradient is -8.000000, learning rate is 0.000240
max inferred z is 3.75, min inferred z is -5.07, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 60: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.859820, learning rate is 0.009372
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.118308, learning rate is 0.009372
Net1: layer conv1:max response is , min response is .
max gradient is 6.639754, min gradient is -8.000000, learning rate is 0.009372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -3.618757, min gradient is -8.000000, learning rate is 0.000479
Net2: layer deconv3:max response is 23.861439, min response is -34.721931.
max gradient is 6.519748, min gradient is -8.000000, learning rate is 0.000240
Net2: layer bn50:max response is 19.135971, min response is -3.934202.
max gradient is 4.626545, min gradient is -8.000000, learning rate is 0.000479
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.010350, learning rate is 0.000240
Net2: layer bn49:max response is 8.889211, min response is -1.864608.
max gradient is 5.486273, min gradient is -8.000000, learning rate is 0.000479
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.718913, learning rate is 0.000240
max inferred z is 4.40, min inferred z is -4.01, and std is 1.00
 4.32 s (23.2 data/s) [100/100]
training: epoch 60: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.729818, learning rate is 0.009372
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.593678, learning rate is 0.009372
Net1: layer conv1:max response is , min response is .
max gradient is 7.230353, min gradient is -8.000000, learning rate is 0.009372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.619365, learning rate is 0.000479
Net2: layer deconv3:max response is 25.299320, min response is -28.406731.
max gradient is 6.921117, min gradient is -8.000000, learning rate is 0.000240
Net2: layer bn50:max response is 22.252275, min response is -3.517934.
max gradient is 2.617801, min gradient is -8.000000, learning rate is 0.000479
Net2: layer deconv2:max response is , min response is .
max gradient is 7.984690, min gradient is -8.000000, learning rate is 0.000240
Net2: layer bn49:max response is 8.202675, min response is -1.664724.
max gradient is 8.000000, min gradient is -5.378504, learning rate is 0.000479
Net2: layer deconv1:max response is , min response is .
max gradient is 7.986319, min gradient is -8.000000, learning rate is 0.000240
max inferred z is 3.55, min inferred z is -4.07, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 60: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.715495, learning rate is 0.009372
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.196259, learning rate is 0.009372
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.957150, learning rate is 0.009372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.696213, learning rate is 0.000479
Net2: layer deconv3:max response is 25.475456, min response is -25.699263.
max gradient is 8.000000, min gradient is -6.122706, learning rate is 0.000240
Net2: layer bn50:max response is 16.775827, min response is -3.262549.
max gradient is 8.000000, min gradient is -7.132790, learning rate is 0.000479
Net2: layer deconv2:max response is , min response is .
max gradient is 7.958409, min gradient is -8.000000, learning rate is 0.000240
Net2: layer bn49:max response is 8.385531, min response is -1.617041.
max gradient is 8.000000, min gradient is -7.770387, learning rate is 0.000479
Net2: layer deconv1:max response is , min response is .
max gradient is 5.510032, min gradient is -8.000000, learning rate is 0.000240
max inferred z is 3.87, min inferred z is -4.04, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 60: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.636672, min gradient is -8.000000, learning rate is 0.009372
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.331166, learning rate is 0.009372
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.637081, learning rate is 0.009372
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.301212, learning rate is 0.000479
Net2: layer deconv3:max response is 24.826527, min response is -25.936668.
max gradient is 8.000000, min gradient is -5.877044, learning rate is 0.000240
Net2: layer bn50:max response is 16.086937, min response is -2.806484.
max gradient is 8.000000, min gradient is -6.713160, learning rate is 0.000479
Net2: layer deconv2:max response is , min response is .
max gradient is 7.418815, min gradient is -8.000000, learning rate is 0.000240
Net2: layer bn49:max response is 8.861857, min response is -1.744010.
max gradient is 8.000000, min gradient is -7.610765, learning rate is 0.000479
Net2: layer deconv1:max response is , min response is .
max gradient is 7.329275, min gradient is -8.000000, learning rate is 0.000240
max inferred z is 4.20, min inferred z is -4.05, and std is 1.00
 4.36 s (23.0 data/s) [100/100]
Loss: 2.4518
Iteration 61 / 200
training: epoch 61: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.343841, learning rate is 0.007779
Net1: layer conv2:max response is , min response is .
max gradient is 6.448561, min gradient is -8.000000, learning rate is 0.007779
Net1: layer conv1:max response is , min response is .
max gradient is 6.384320, min gradient is -8.000000, learning rate is 0.007779
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.851822, learning rate is 0.000477
Net2: layer deconv3:max response is 23.967239, min response is -28.968744.
max gradient is 8.000000, min gradient is -5.735608, learning rate is 0.000239
Net2: layer bn50:max response is 20.960989, min response is -3.108359.
max gradient is 8.000000, min gradient is -4.654451, learning rate is 0.000477
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000001, min gradient is -7.123010, learning rate is 0.000239
Net2: layer bn49:max response is 8.517327, min response is -1.769838.
max gradient is 8.000000, min gradient is -6.616284, learning rate is 0.000477
Net2: layer deconv1:max response is , min response is .
max gradient is 7.371242, min gradient is -8.000000, learning rate is 0.000239
max inferred z is 3.70, min inferred z is -4.03, and std is 1.01
 4.17 s (24.0 data/s) [100/100]
training: epoch 61: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.419219, min gradient is -8.000000, learning rate is 0.007779
Net1: layer conv2:max response is , min response is .
max gradient is 5.093276, min gradient is -8.000000, learning rate is 0.007779
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.343709, learning rate is 0.007779
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.436422, learning rate is 0.000477
Net2: layer deconv3:max response is 22.085546, min response is -21.773512.
max gradient is 8.000000, min gradient is -5.384272, learning rate is 0.000239
Net2: layer bn50:max response is 16.863401, min response is -2.728024.
max gradient is 8.000000, min gradient is -4.312790, learning rate is 0.000477
Net2: layer deconv2:max response is , min response is .
max gradient is 7.187921, min gradient is -8.000000, learning rate is 0.000239
Net2: layer bn49:max response is 8.691515, min response is -1.668246.
max gradient is 8.000000, min gradient is -7.016904, learning rate is 0.000477
Net2: layer deconv1:max response is , min response is .
max gradient is 7.356363, min gradient is -8.000000, learning rate is 0.000239
max inferred z is 3.62, min inferred z is -4.08, and std is 1.01
 4.37 s (22.9 data/s) [100/100]
training: epoch 61: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -5.971927, learning rate is 0.007779
Net1: layer conv2:max response is , min response is .
max gradient is 5.091027, min gradient is -8.000000, learning rate is 0.007779
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.498146, learning rate is 0.007779
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -0.400046, learning rate is 0.000477
Net2: layer deconv3:max response is 20.193527, min response is -26.736147.
max gradient is 8.000000, min gradient is -5.688399, learning rate is 0.000239
Net2: layer bn50:max response is 16.165436, min response is -3.212158.
max gradient is 8.000000, min gradient is -3.933677, learning rate is 0.000477
Net2: layer deconv2:max response is , min response is .
max gradient is 5.824806, min gradient is -8.000000, learning rate is 0.000239
Net2: layer bn49:max response is 8.790236, min response is -1.866064.
max gradient is 5.197578, min gradient is -8.000000, learning rate is 0.000477
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.945035, learning rate is 0.000239
max inferred z is 3.72, min inferred z is -3.67, and std is 1.01
 4.18 s (23.9 data/s) [100/100]
training: epoch 61: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.783049, min gradient is -8.000000, learning rate is 0.007779
Net1: layer conv2:max response is , min response is .
max gradient is 4.346326, min gradient is -8.000000, learning rate is 0.007779
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.819272, learning rate is 0.007779
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -0.873646, learning rate is 0.000477
Net2: layer deconv3:max response is 21.745384, min response is -21.915215.
max gradient is 8.000000, min gradient is -7.993045, learning rate is 0.000239
Net2: layer bn50:max response is 17.631969, min response is -3.100944.
max gradient is 4.143681, min gradient is -8.000000, learning rate is 0.000477
Net2: layer deconv2:max response is , min response is .
max gradient is 7.097519, min gradient is -8.000000, learning rate is 0.000239
Net2: layer bn49:max response is 7.970073, min response is -1.691233.
max gradient is 3.940320, min gradient is -8.000001, learning rate is 0.000477
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.697527, learning rate is 0.000239
max inferred z is 3.80, min inferred z is -4.07, and std is 1.01
 4.32 s (23.1 data/s) [100/100]
training: epoch 61: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.208668, learning rate is 0.007779
Net1: layer conv2:max response is , min response is .
max gradient is 4.828200, min gradient is -8.000000, learning rate is 0.007779
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.852870, learning rate is 0.007779
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -4.882683, learning rate is 0.000477
Net2: layer deconv3:max response is 23.375546, min response is -31.426479.
max gradient is 8.000000, min gradient is -7.118195, learning rate is 0.000239
Net2: layer bn50:max response is 17.857687, min response is -3.552444.
max gradient is 2.965371, min gradient is -8.000000, learning rate is 0.000477
Net2: layer deconv2:max response is , min response is .
max gradient is 6.277760, min gradient is -8.000000, learning rate is 0.000239
Net2: layer bn49:max response is 9.345095, min response is -1.960293.
max gradient is 4.210616, min gradient is -8.000000, learning rate is 0.000477
Net2: layer deconv1:max response is , min response is .
max gradient is 6.969317, min gradient is -8.000000, learning rate is 0.000239
max inferred z is 3.64, min inferred z is -3.80, and std is 1.01
 4.31 s (23.2 data/s) [100/100]
training: epoch 61: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.271988, min gradient is -8.000000, learning rate is 0.007779
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.453616, learning rate is 0.007779
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.346722, learning rate is 0.007779
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 1.151699, min gradient is -8.000000, learning rate is 0.000477
Net2: layer deconv3:max response is 21.796610, min response is -22.344536.
max gradient is 8.000000, min gradient is -7.503668, learning rate is 0.000239
Net2: layer bn50:max response is 18.732380, min response is -3.245352.
max gradient is 2.636809, min gradient is -8.000000, learning rate is 0.000477
Net2: layer deconv2:max response is , min response is .
max gradient is 6.754971, min gradient is -8.000000, learning rate is 0.000239
Net2: layer bn49:max response is 7.882800, min response is -1.607322.
max gradient is 4.373191, min gradient is -8.000000, learning rate is 0.000477
Net2: layer deconv1:max response is , min response is .
max gradient is 7.112872, min gradient is -8.000000, learning rate is 0.000239
max inferred z is 4.35, min inferred z is -4.25, and std is 1.01
 4.33 s (23.1 data/s) [100/100]
training: epoch 61: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.900887, min gradient is -8.000000, learning rate is 0.007779
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.713953, learning rate is 0.007779
Net1: layer conv1:max response is , min response is .
max gradient is 7.733944, min gradient is -8.000000, learning rate is 0.007779
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.182777, min gradient is -8.000000, learning rate is 0.000477
Net2: layer deconv3:max response is 21.919731, min response is -23.288803.
max gradient is 6.958423, min gradient is -8.000000, learning rate is 0.000239
Net2: layer bn50:max response is 19.363138, min response is -2.905615.
max gradient is 3.016699, min gradient is -8.000000, learning rate is 0.000477
Net2: layer deconv2:max response is , min response is .
max gradient is 6.663417, min gradient is -8.000000, learning rate is 0.000239
Net2: layer bn49:max response is 7.592283, min response is -1.769370.
max gradient is 7.603843, min gradient is -8.000000, learning rate is 0.000477
Net2: layer deconv1:max response is , min response is .
max gradient is 6.699510, min gradient is -8.000000, learning rate is 0.000239
max inferred z is 3.83, min inferred z is -4.07, and std is 1.01
 4.37 s (22.9 data/s) [100/100]
training: epoch 61: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.091449, learning rate is 0.007779
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.842502, learning rate is 0.007779
Net1: layer conv1:max response is , min response is .
max gradient is 6.791558, min gradient is -8.000000, learning rate is 0.007779
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.912591, learning rate is 0.000477
Net2: layer deconv3:max response is 21.443932, min response is -29.529078.
max gradient is 5.975945, min gradient is -8.000000, learning rate is 0.000239
Net2: layer bn50:max response is 16.535017, min response is -3.208040.
max gradient is 8.000000, min gradient is -3.954811, learning rate is 0.000477
Net2: layer deconv2:max response is , min response is .
max gradient is 7.232860, min gradient is -8.000000, learning rate is 0.000239
Net2: layer bn49:max response is 8.141032, min response is -1.546631.
max gradient is 8.000000, min gradient is -6.423410, learning rate is 0.000477
Net2: layer deconv1:max response is , min response is .
max gradient is 6.896402, min gradient is -8.000001, learning rate is 0.000239
max inferred z is 3.83, min inferred z is -3.75, and std is 1.01
 4.36 s (22.9 data/s) [100/100]
training: epoch 61: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000001, min gradient is -7.850163, learning rate is 0.007779
Net1: layer conv2:max response is , min response is .
max gradient is 7.680674, min gradient is -8.000000, learning rate is 0.007779
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.572441, learning rate is 0.007779
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.291670, learning rate is 0.000477
Net2: layer deconv3:max response is 23.798265, min response is -27.729437.
max gradient is 8.000000, min gradient is -7.710638, learning rate is 0.000239
Net2: layer bn50:max response is 20.123940, min response is -2.966967.
max gradient is 8.000000, min gradient is -4.759372, learning rate is 0.000477
Net2: layer deconv2:max response is , min response is .
max gradient is 5.346163, min gradient is -8.000000, learning rate is 0.000239
Net2: layer bn49:max response is 8.429901, min response is -1.613298.
max gradient is 8.000000, min gradient is -5.205966, learning rate is 0.000477
Net2: layer deconv1:max response is , min response is .
max gradient is 7.238599, min gradient is -8.000000, learning rate is 0.000239
max inferred z is 4.09, min inferred z is -4.18, and std is 1.01
 4.33 s (23.1 data/s) [100/100]
training: epoch 61: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.190314, min gradient is -8.000000, learning rate is 0.007779
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.059937, learning rate is 0.007779
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.584944, learning rate is 0.007779
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.517495, learning rate is 0.000477
Net2: layer deconv3:max response is 22.313244, min response is -27.409889.
max gradient is 8.000000, min gradient is -6.943714, learning rate is 0.000239
Net2: layer bn50:max response is 17.485298, min response is -3.244575.
max gradient is 8.000000, min gradient is -3.446505, learning rate is 0.000477
Net2: layer deconv2:max response is , min response is .
max gradient is 5.465761, min gradient is -8.000000, learning rate is 0.000239
Net2: layer bn49:max response is 9.158612, min response is -1.709474.
max gradient is 8.000000, min gradient is -5.346970, learning rate is 0.000477
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.782193, learning rate is 0.000239
max inferred z is 4.05, min inferred z is -3.71, and std is 1.01
 4.35 s (23.0 data/s) [100/100]
Loss: 2.3362
Iteration 62 / 200
training: epoch 62: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.720427, min gradient is -8.000000, learning rate is 0.007779
Net1: layer conv2:max response is , min response is .
max gradient is 7.001440, min gradient is -8.000000, learning rate is 0.007779
Net1: layer conv1:max response is , min response is .
max gradient is 4.000393, min gradient is -8.000000, learning rate is 0.007779
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.346745, learning rate is 0.000475
Net2: layer deconv3:max response is 21.585567, min response is -23.712347.
max gradient is 8.000000, min gradient is -6.543175, learning rate is 0.000238
Net2: layer bn50:max response is 16.965027, min response is -3.674987.
max gradient is 8.000000, min gradient is -1.530614, learning rate is 0.000475
Net2: layer deconv2:max response is , min response is .
max gradient is 7.393283, min gradient is -8.000000, learning rate is 0.000238
Net2: layer bn49:max response is 8.334288, min response is -1.649921.
max gradient is 8.000000, min gradient is -4.790922, learning rate is 0.000475
Net2: layer deconv1:max response is , min response is .
max gradient is 7.747575, min gradient is -8.000001, learning rate is 0.000238
max inferred z is 3.73, min inferred z is -3.58, and std is 1.00
 4.12 s (24.2 data/s) [100/100]
training: epoch 62: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.360445, min gradient is -8.000000, learning rate is 0.007779
Net1: layer conv2:max response is , min response is .
max gradient is 5.976301, min gradient is -8.000000, learning rate is 0.007779
Net1: layer conv1:max response is , min response is .
max gradient is 7.755006, min gradient is -8.000000, learning rate is 0.007779
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -1.670213, learning rate is 0.000475
Net2: layer deconv3:max response is 20.577332, min response is -24.535721.
max gradient is 8.000000, min gradient is -6.019600, learning rate is 0.000238
Net2: layer bn50:max response is 17.494080, min response is -3.094136.
max gradient is 8.000000, min gradient is -1.362947, learning rate is 0.000475
Net2: layer deconv2:max response is , min response is .
max gradient is 7.467845, min gradient is -8.000000, learning rate is 0.000238
Net2: layer bn49:max response is 7.875169, min response is -1.600975.
max gradient is 8.000000, min gradient is -6.116150, learning rate is 0.000475
Net2: layer deconv1:max response is , min response is .
max gradient is 6.755566, min gradient is -8.000000, learning rate is 0.000238
max inferred z is 4.55, min inferred z is -3.84, and std is 1.00
 4.12 s (24.2 data/s) [100/100]
training: epoch 62: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.167829, min gradient is -8.000000, learning rate is 0.007779
Net1: layer conv2:max response is , min response is .
max gradient is 5.483473, min gradient is -8.000000, learning rate is 0.007779
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.136758, learning rate is 0.007779
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -4.640932, learning rate is 0.000475
Net2: layer deconv3:max response is 21.399971, min response is -23.514101.
max gradient is 5.813700, min gradient is -8.000000, learning rate is 0.000238
Net2: layer bn50:max response is 20.628357, min response is -3.477826.
max gradient is 8.000000, min gradient is -3.806190, learning rate is 0.000475
Net2: layer deconv2:max response is , min response is .
max gradient is 6.656802, min gradient is -8.000000, learning rate is 0.000238
Net2: layer bn49:max response is 7.508619, min response is -1.769303.
max gradient is 8.000000, min gradient is -5.140669, learning rate is 0.000475
Net2: layer deconv1:max response is , min response is .
max gradient is 7.815516, min gradient is -8.000000, learning rate is 0.000238
max inferred z is 4.14, min inferred z is -4.38, and std is 1.00
 4.13 s (24.2 data/s) [100/100]
training: epoch 62: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.882300, min gradient is -8.000000, learning rate is 0.007779
Net1: layer conv2:max response is , min response is .
max gradient is 5.080223, min gradient is -8.000000, learning rate is 0.007779
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.896062, learning rate is 0.007779
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -6.797176, learning rate is 0.000475
Net2: layer deconv3:max response is 24.444096, min response is -24.100760.
max gradient is 7.258270, min gradient is -8.000000, learning rate is 0.000238
Net2: layer bn50:max response is 17.679823, min response is -3.639544.
max gradient is 6.245520, min gradient is -8.000000, learning rate is 0.000475
Net2: layer deconv2:max response is , min response is .
max gradient is 6.006996, min gradient is -8.000000, learning rate is 0.000238
Net2: layer bn49:max response is 6.932096, min response is -1.657247.
max gradient is 8.000000, min gradient is -6.630702, learning rate is 0.000475
Net2: layer deconv1:max response is , min response is .
max gradient is 6.982679, min gradient is -8.000000, learning rate is 0.000238
max inferred z is 4.04, min inferred z is -3.70, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 62: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.988836, min gradient is -8.000000, learning rate is 0.007779
Net1: layer conv2:max response is , min response is .
max gradient is 7.535716, min gradient is -8.000001, learning rate is 0.007779
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.779215, learning rate is 0.007779
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 3.552566, min gradient is -8.000000, learning rate is 0.000475
Net2: layer deconv3:max response is 20.281088, min response is -29.897936.
max gradient is 7.962371, min gradient is -8.000001, learning rate is 0.000238
Net2: layer bn50:max response is 18.298546, min response is -3.086156.
max gradient is 4.730502, min gradient is -8.000000, learning rate is 0.000475
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.843293, learning rate is 0.000238
Net2: layer bn49:max response is 7.889617, min response is -1.970712.
max gradient is 5.531648, min gradient is -8.000000, learning rate is 0.000475
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.820361, learning rate is 0.000238
max inferred z is 4.18, min inferred z is -4.26, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 62: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.524044, learning rate is 0.007779
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.961968, learning rate is 0.007779
Net1: layer conv1:max response is , min response is .
max gradient is 7.456529, min gradient is -8.000000, learning rate is 0.007779
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 0.925453, min gradient is -8.000000, learning rate is 0.000475
Net2: layer deconv3:max response is 21.685347, min response is -28.188141.
max gradient is 8.000000, min gradient is -7.829060, learning rate is 0.000238
Net2: layer bn50:max response is 18.903328, min response is -3.500451.
max gradient is 4.066308, min gradient is -8.000000, learning rate is 0.000475
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.452278, learning rate is 0.000238
Net2: layer bn49:max response is 7.890358, min response is -1.810901.
max gradient is 6.448416, min gradient is -8.000000, learning rate is 0.000475
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.261562, learning rate is 0.000238
max inferred z is 3.62, min inferred z is -4.22, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 62: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.804597, min gradient is -8.000000, learning rate is 0.007779
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.484019, learning rate is 0.007779
Net1: layer conv1:max response is , min response is .
max gradient is 7.362976, min gradient is -8.000000, learning rate is 0.007779
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 0.903935, min gradient is -8.000001, learning rate is 0.000475
Net2: layer deconv3:max response is 22.954535, min response is -31.670462.
max gradient is 5.010034, min gradient is -8.000000, learning rate is 0.000238
Net2: layer bn50:max response is 19.902596, min response is -3.617642.
max gradient is 4.483568, min gradient is -8.000000, learning rate is 0.000475
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.638941, learning rate is 0.000238
Net2: layer bn49:max response is 8.876753, min response is -1.721332.
max gradient is 6.992678, min gradient is -8.000000, learning rate is 0.000475
Net2: layer deconv1:max response is , min response is .
max gradient is 7.410010, min gradient is -8.000000, learning rate is 0.000238
max inferred z is 4.37, min inferred z is -3.54, and std is 1.00
 4.43 s (22.6 data/s) [100/100]
training: epoch 62: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.958574, learning rate is 0.007779
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.362634, learning rate is 0.007779
Net1: layer conv1:max response is , min response is .
max gradient is 7.060299, min gradient is -8.000000, learning rate is 0.007779
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 6.574436, min gradient is -8.000000, learning rate is 0.000475
Net2: layer deconv3:max response is 23.468416, min response is -29.327736.
max gradient is 8.000000, min gradient is -7.048890, learning rate is 0.000238
Net2: layer bn50:max response is 18.140800, min response is -3.264273.
max gradient is 7.871966, min gradient is -8.000000, learning rate is 0.000475
Net2: layer deconv2:max response is , min response is .
max gradient is 7.903836, min gradient is -8.000001, learning rate is 0.000238
Net2: layer bn49:max response is 7.661194, min response is -1.707204.
max gradient is 8.000000, min gradient is -6.647061, learning rate is 0.000475
Net2: layer deconv1:max response is , min response is .
max gradient is 7.925492, min gradient is -8.000000, learning rate is 0.000238
max inferred z is 4.51, min inferred z is -3.84, and std is 1.00
 4.41 s (22.7 data/s) [100/100]
training: epoch 62: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.692140, min gradient is -8.000000, learning rate is 0.007779
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.865201, learning rate is 0.007779
Net1: layer conv1:max response is , min response is .
max gradient is 6.999596, min gradient is -8.000000, learning rate is 0.007779
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.721232, learning rate is 0.000475
Net2: layer deconv3:max response is 23.972729, min response is -33.835735.
max gradient is 8.000000, min gradient is -6.301660, learning rate is 0.000238
Net2: layer bn50:max response is 17.797758, min response is -2.937622.
max gradient is 8.000000, min gradient is -3.460763, learning rate is 0.000475
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.737358, learning rate is 0.000238
Net2: layer bn49:max response is 7.537405, min response is -1.666839.
max gradient is 8.000000, min gradient is -4.175373, learning rate is 0.000475
Net2: layer deconv1:max response is , min response is .
max gradient is 6.075110, min gradient is -8.000000, learning rate is 0.000238
max inferred z is 3.84, min inferred z is -3.57, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 62: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.882851, min gradient is -8.000000, learning rate is 0.007779
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.554007, learning rate is 0.007779
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.157988, learning rate is 0.007779
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.070760, learning rate is 0.000475
Net2: layer deconv3:max response is 22.595764, min response is -28.656740.
max gradient is 8.000000, min gradient is -5.777462, learning rate is 0.000238
Net2: layer bn50:max response is 17.670366, min response is -3.790994.
max gradient is 8.000000, min gradient is -3.770489, learning rate is 0.000475
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.453619, learning rate is 0.000238
Net2: layer bn49:max response is 8.050521, min response is -1.906013.
max gradient is 5.915499, min gradient is -8.000000, learning rate is 0.000475
Net2: layer deconv1:max response is , min response is .
max gradient is 7.430616, min gradient is -8.000000, learning rate is 0.000238
max inferred z is 4.14, min inferred z is -3.68, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
Loss: 2.2059
Iteration 63 / 200
training: epoch 63: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.034009, min gradient is -8.000000, learning rate is 0.006456
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.113782, learning rate is 0.006456
Net1: layer conv1:max response is , min response is .
max gradient is 4.985052, min gradient is -8.000000, learning rate is 0.006456
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -0.434421, learning rate is 0.000473
Net2: layer deconv3:max response is 22.917233, min response is -27.484627.
max gradient is 8.000000, min gradient is -6.139917, learning rate is 0.000237
Net2: layer bn50:max response is 19.558741, min response is -3.460145.
max gradient is 8.000000, min gradient is -1.527836, learning rate is 0.000473
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.392458, learning rate is 0.000237
Net2: layer bn49:max response is 10.090752, min response is -1.706463.
max gradient is 8.000000, min gradient is -7.962505, learning rate is 0.000473
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.765576, learning rate is 0.000237
max inferred z is 3.79, min inferred z is -4.02, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 63: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.830184, min gradient is -8.000000, learning rate is 0.006456
Net1: layer conv2:max response is , min response is .
max gradient is 5.993021, min gradient is -8.000000, learning rate is 0.006456
Net1: layer conv1:max response is , min response is .
max gradient is 7.720693, min gradient is -8.000000, learning rate is 0.006456
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 7.292994, min gradient is -8.000000, learning rate is 0.000473
Net2: layer deconv3:max response is 24.569906, min response is -24.360312.
max gradient is 8.000000, min gradient is -6.032208, learning rate is 0.000237
Net2: layer bn50:max response is 18.978844, min response is -3.223982.
max gradient is 8.000000, min gradient is -1.409556, learning rate is 0.000473
Net2: layer deconv2:max response is , min response is .
max gradient is 7.927498, min gradient is -8.000000, learning rate is 0.000237
Net2: layer bn49:max response is 8.400887, min response is -1.740382.
max gradient is 3.849267, min gradient is -8.000000, learning rate is 0.000473
Net2: layer deconv1:max response is , min response is .
max gradient is 7.080735, min gradient is -8.000000, learning rate is 0.000237
max inferred z is 3.83, min inferred z is -4.04, and std is 1.00
 4.23 s (23.6 data/s) [100/100]
training: epoch 63: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.669983, min gradient is -8.000000, learning rate is 0.006456
Net1: layer conv2:max response is , min response is .
max gradient is 6.207260, min gradient is -8.000001, learning rate is 0.006456
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.576976, learning rate is 0.006456
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 4.400012, min gradient is -8.000000, learning rate is 0.000473
Net2: layer deconv3:max response is 24.298473, min response is -25.363646.
max gradient is 8.000000, min gradient is -5.771796, learning rate is 0.000237
Net2: layer bn50:max response is 19.633125, min response is -2.962234.
max gradient is 8.000000, min gradient is -3.262553, learning rate is 0.000473
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.454797, learning rate is 0.000237
Net2: layer bn49:max response is 8.109481, min response is -1.730914.
max gradient is 3.497076, min gradient is -8.000000, learning rate is 0.000473
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.859085, learning rate is 0.000237
max inferred z is 3.95, min inferred z is -4.29, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 63: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.501320, min gradient is -8.000000, learning rate is 0.006456
Net1: layer conv2:max response is , min response is .
max gradient is 6.087602, min gradient is -8.000000, learning rate is 0.006456
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.953932, learning rate is 0.006456
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 4.745317, min gradient is -8.000000, learning rate is 0.000473
Net2: layer deconv3:max response is 19.450592, min response is -27.233547.
max gradient is 8.000000, min gradient is -7.172931, learning rate is 0.000237
Net2: layer bn50:max response is 19.157549, min response is -2.901415.
max gradient is 5.727090, min gradient is -8.000000, learning rate is 0.000473
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.743373, learning rate is 0.000237
Net2: layer bn49:max response is 8.310189, min response is -1.844552.
max gradient is 5.426358, min gradient is -8.000000, learning rate is 0.000473
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.265453, learning rate is 0.000237
max inferred z is 4.03, min inferred z is -4.45, and std is 1.00
 4.22 s (23.7 data/s) [100/100]
training: epoch 63: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.605277, min gradient is -8.000000, learning rate is 0.006456
Net1: layer conv2:max response is , min response is .
max gradient is 5.520323, min gradient is -8.000000, learning rate is 0.006456
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.919713, learning rate is 0.006456
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 4.566301, min gradient is -8.000000, learning rate is 0.000473
Net2: layer deconv3:max response is 22.215071, min response is -23.786911.
max gradient is 7.590630, min gradient is -8.000000, learning rate is 0.000237
Net2: layer bn50:max response is 18.575512, min response is -3.001379.
max gradient is 1.922290, min gradient is -8.000000, learning rate is 0.000473
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.473748, learning rate is 0.000237
Net2: layer bn49:max response is 7.426148, min response is -1.683028.
max gradient is 5.152595, min gradient is -8.000000, learning rate is 0.000473
Net2: layer deconv1:max response is , min response is .
max gradient is 6.740265, min gradient is -8.000000, learning rate is 0.000237
max inferred z is 4.14, min inferred z is -3.98, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 63: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.216770, learning rate is 0.006456
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.370393, learning rate is 0.006456
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.717548, learning rate is 0.006456
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -2.268671, learning rate is 0.000473
Net2: layer deconv3:max response is 22.151630, min response is -26.924685.
max gradient is 4.557630, min gradient is -8.000000, learning rate is 0.000237
Net2: layer bn50:max response is 18.032207, min response is -2.959270.
max gradient is 1.066354, min gradient is -8.000000, learning rate is 0.000473
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.143519, learning rate is 0.000237
Net2: layer bn49:max response is 7.530620, min response is -1.676753.
max gradient is 6.375978, min gradient is -8.000000, learning rate is 0.000473
Net2: layer deconv1:max response is , min response is .
max gradient is 7.360906, min gradient is -8.000000, learning rate is 0.000237
max inferred z is 3.89, min inferred z is -4.04, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
training: epoch 63: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.820097, learning rate is 0.006456
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.041132, learning rate is 0.006456
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.308911, learning rate is 0.006456
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 0.795575, learning rate is 0.000473
Net2: layer deconv3:max response is 22.912962, min response is -25.453892.
max gradient is 5.952924, min gradient is -8.000000, learning rate is 0.000237
Net2: layer bn50:max response is 20.653931, min response is -3.463080.
max gradient is 3.015426, min gradient is -8.000000, learning rate is 0.000473
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.474729, learning rate is 0.000237
Net2: layer bn49:max response is 8.301015, min response is -1.770246.
max gradient is 8.000000, min gradient is -7.306156, learning rate is 0.000473
Net2: layer deconv1:max response is , min response is .
max gradient is 7.533532, min gradient is -8.000000, learning rate is 0.000237
max inferred z is 4.06, min inferred z is -3.94, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 63: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.517930, min gradient is -8.000000, learning rate is 0.006456
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.141543, learning rate is 0.006456
Net1: layer conv1:max response is , min response is .
max gradient is 4.920324, min gradient is -8.000000, learning rate is 0.006456
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000001, min gradient is 1.874074, learning rate is 0.000473
Net2: layer deconv3:max response is 21.447824, min response is -32.916786.
max gradient is 6.828890, min gradient is -8.000000, learning rate is 0.000237
Net2: layer bn50:max response is 19.634451, min response is -3.592576.
max gradient is 6.171969, min gradient is -8.000001, learning rate is 0.000473
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.894549, learning rate is 0.000237
Net2: layer bn49:max response is 7.578207, min response is -1.688114.
max gradient is 8.000000, min gradient is -3.883854, learning rate is 0.000473
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.473925, learning rate is 0.000237
max inferred z is 3.76, min inferred z is -3.95, and std is 1.00
 4.28 s (23.4 data/s) [100/100]
training: epoch 63: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.039642, learning rate is 0.006456
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.816170, learning rate is 0.006456
Net1: layer conv1:max response is , min response is .
max gradient is 6.184012, min gradient is -8.000000, learning rate is 0.006456
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.090309, learning rate is 0.000473
Net2: layer deconv3:max response is 20.964287, min response is -28.678127.
max gradient is 8.000000, min gradient is -6.234564, learning rate is 0.000237
Net2: layer bn50:max response is 20.253736, min response is -3.087562.
max gradient is 8.000000, min gradient is -5.732891, learning rate is 0.000473
Net2: layer deconv2:max response is , min response is .
max gradient is 7.753174, min gradient is -8.000000, learning rate is 0.000237
Net2: layer bn49:max response is 7.473979, min response is -1.758932.
max gradient is 8.000000, min gradient is -7.795877, learning rate is 0.000473
Net2: layer deconv1:max response is , min response is .
max gradient is 6.859759, min gradient is -8.000000, learning rate is 0.000237
max inferred z is 3.84, min inferred z is -3.65, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 63: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.228970, min gradient is -8.000000, learning rate is 0.006456
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.747798, learning rate is 0.006456
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.192981, learning rate is 0.006456
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.603922, learning rate is 0.000473
Net2: layer deconv3:max response is 22.560877, min response is -26.712303.
max gradient is 8.000000, min gradient is -5.822134, learning rate is 0.000237
Net2: layer bn50:max response is 19.214300, min response is -2.989709.
max gradient is 8.000000, min gradient is -4.663177, learning rate is 0.000473
Net2: layer deconv2:max response is , min response is .
max gradient is 7.383357, min gradient is -8.000000, learning rate is 0.000237
Net2: layer bn49:max response is 9.243940, min response is -1.765547.
max gradient is 7.499603, min gradient is -8.000000, learning rate is 0.000473
Net2: layer deconv1:max response is , min response is .
max gradient is 6.202123, min gradient is -8.000000, learning rate is 0.000237
max inferred z is 4.16, min inferred z is -3.97, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
Loss: 2.2093
Iteration 64 / 200
training: epoch 64: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.149144, min gradient is -8.000000, learning rate is 0.006456
Net1: layer conv2:max response is , min response is .
max gradient is 5.102667, min gradient is -8.000000, learning rate is 0.006456
Net1: layer conv1:max response is , min response is .
max gradient is 6.367456, min gradient is -8.000000, learning rate is 0.006456
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -2.532991, learning rate is 0.000471
Net2: layer deconv3:max response is 23.027063, min response is -26.123684.
max gradient is 8.000000, min gradient is -6.063227, learning rate is 0.000236
Net2: layer bn50:max response is 19.180635, min response is -3.355085.
max gradient is 8.000000, min gradient is -1.660226, learning rate is 0.000471
Net2: layer deconv2:max response is , min response is .
max gradient is 7.365826, min gradient is -8.000000, learning rate is 0.000236
Net2: layer bn49:max response is 7.781454, min response is -1.690497.
max gradient is 6.417757, min gradient is -8.000000, learning rate is 0.000471
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.506460, learning rate is 0.000236
max inferred z is 4.08, min inferred z is -4.01, and std is 1.00
 4.18 s (23.9 data/s) [100/100]
training: epoch 64: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.707892, min gradient is -8.000000, learning rate is 0.006456
Net1: layer conv2:max response is , min response is .
max gradient is 5.458998, min gradient is -8.000000, learning rate is 0.006456
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.529462, learning rate is 0.006456
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 3.152599, min gradient is -8.000000, learning rate is 0.000471
Net2: layer deconv3:max response is 20.033918, min response is -23.346821.
max gradient is 8.000000, min gradient is -6.012373, learning rate is 0.000236
Net2: layer bn50:max response is 18.633125, min response is -2.922904.
max gradient is 8.000000, min gradient is -2.566821, learning rate is 0.000471
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.920646, learning rate is 0.000236
Net2: layer bn49:max response is 7.117327, min response is -1.670759.
max gradient is 5.750681, min gradient is -8.000000, learning rate is 0.000471
Net2: layer deconv1:max response is , min response is .
max gradient is 7.882340, min gradient is -8.000000, learning rate is 0.000236
max inferred z is 3.84, min inferred z is -4.10, and std is 1.00
 4.18 s (23.9 data/s) [100/100]
training: epoch 64: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.587201, learning rate is 0.006456
Net1: layer conv2:max response is , min response is .
max gradient is 5.287488, min gradient is -8.000000, learning rate is 0.006456
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.272284, learning rate is 0.006456
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 2.164825, min gradient is -8.000000, learning rate is 0.000471
Net2: layer deconv3:max response is 22.826382, min response is -25.968576.
max gradient is 8.000000, min gradient is -7.201070, learning rate is 0.000236
Net2: layer bn50:max response is 20.037947, min response is -3.328735.
max gradient is 8.000000, min gradient is -5.980668, learning rate is 0.000471
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.540689, learning rate is 0.000236
Net2: layer bn49:max response is 8.413349, min response is -1.563349.
max gradient is 3.864333, min gradient is -8.000000, learning rate is 0.000471
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.952238, learning rate is 0.000236
max inferred z is 3.80, min inferred z is -4.15, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 64: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.658289, learning rate is 0.006456
Net1: layer conv2:max response is , min response is .
max gradient is 5.364819, min gradient is -8.000000, learning rate is 0.006456
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.243412, learning rate is 0.006456
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -5.114940, learning rate is 0.000471
Net2: layer deconv3:max response is 27.546793, min response is -25.094851.
max gradient is 5.920722, min gradient is -8.000000, learning rate is 0.000236
Net2: layer bn50:max response is 23.036436, min response is -3.305033.
max gradient is 1.306395, min gradient is -8.000000, learning rate is 0.000471
Net2: layer deconv2:max response is , min response is .
max gradient is 7.957913, min gradient is -8.000000, learning rate is 0.000236
Net2: layer bn49:max response is 7.970354, min response is -2.079864.
max gradient is 6.250500, min gradient is -8.000000, learning rate is 0.000471
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.951826, learning rate is 0.000236
max inferred z is 4.04, min inferred z is -3.88, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 64: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.842223, min gradient is -8.000000, learning rate is 0.006456
Net1: layer conv2:max response is , min response is .
max gradient is 6.687768, min gradient is -8.000000, learning rate is 0.006456
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.567635, learning rate is 0.006456
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.175428, learning rate is 0.000471
Net2: layer deconv3:max response is 24.891562, min response is -26.163504.
max gradient is 6.573699, min gradient is -8.000000, learning rate is 0.000236
Net2: layer bn50:max response is 17.896883, min response is -3.452646.
max gradient is 1.518491, min gradient is -8.000000, learning rate is 0.000471
Net2: layer deconv2:max response is , min response is .
max gradient is 7.068588, min gradient is -8.000000, learning rate is 0.000236
Net2: layer bn49:max response is 7.714694, min response is -1.931913.
max gradient is 8.000000, min gradient is -7.668090, learning rate is 0.000471
Net2: layer deconv1:max response is , min response is .
max gradient is 7.954955, min gradient is -8.000000, learning rate is 0.000236
max inferred z is 3.81, min inferred z is -4.04, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 64: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.229685, min gradient is -8.000000, learning rate is 0.006456
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.047941, learning rate is 0.006456
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.016926, learning rate is 0.006456
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.124162, learning rate is 0.000471
Net2: layer deconv3:max response is 23.567802, min response is -31.318932.
max gradient is 8.000000, min gradient is -5.833119, learning rate is 0.000236
Net2: layer bn50:max response is 19.442236, min response is -3.210014.
max gradient is 3.078367, min gradient is -8.000000, learning rate is 0.000471
Net2: layer deconv2:max response is , min response is .
max gradient is 7.300853, min gradient is -8.000000, learning rate is 0.000236
Net2: layer bn49:max response is 8.918710, min response is -1.612332.
max gradient is 8.000000, min gradient is -7.453959, learning rate is 0.000471
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.125571, learning rate is 0.000236
max inferred z is 3.76, min inferred z is -3.99, and std is 1.00
 4.23 s (23.6 data/s) [100/100]
training: epoch 64: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.948896, learning rate is 0.006456
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.387399, learning rate is 0.006456
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.903390, learning rate is 0.006456
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.128713, learning rate is 0.000471
Net2: layer deconv3:max response is 25.243191, min response is -29.123796.
max gradient is 8.000000, min gradient is -6.472326, learning rate is 0.000236
Net2: layer bn50:max response is 16.694805, min response is -3.184663.
max gradient is 7.002977, min gradient is -8.000000, learning rate is 0.000471
Net2: layer deconv2:max response is , min response is .
max gradient is 7.662172, min gradient is -8.000000, learning rate is 0.000236
Net2: layer bn49:max response is 7.425628, min response is -1.695054.
max gradient is 8.000000, min gradient is -7.962526, learning rate is 0.000471
Net2: layer deconv1:max response is , min response is .
max gradient is 6.669652, min gradient is -8.000000, learning rate is 0.000236
max inferred z is 4.25, min inferred z is -4.05, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 64: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.085901, min gradient is -8.000000, learning rate is 0.006456
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.425778, learning rate is 0.006456
Net1: layer conv1:max response is , min response is .
max gradient is 4.293730, min gradient is -8.000000, learning rate is 0.006456
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.307686, learning rate is 0.000471
Net2: layer deconv3:max response is 23.577286, min response is -28.353500.
max gradient is 8.000000, min gradient is -6.608586, learning rate is 0.000236
Net2: layer bn50:max response is 18.341257, min response is -3.603008.
max gradient is 8.000000, min gradient is -1.684948, learning rate is 0.000471
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.815370, learning rate is 0.000236
Net2: layer bn49:max response is 7.885894, min response is -1.792214.
max gradient is 6.490698, min gradient is -8.000000, learning rate is 0.000471
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.996539, learning rate is 0.000236
max inferred z is 3.87, min inferred z is -4.01, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
training: epoch 64: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.975801, learning rate is 0.006456
Net1: layer conv2:max response is , min response is .
max gradient is 7.048676, min gradient is -8.000000, learning rate is 0.006456
Net1: layer conv1:max response is , min response is .
max gradient is 7.712823, min gradient is -8.000000, learning rate is 0.006456
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.904161, learning rate is 0.000471
Net2: layer deconv3:max response is 24.787748, min response is -26.883978.
max gradient is 8.000000, min gradient is -6.116556, learning rate is 0.000236
Net2: layer bn50:max response is 19.646830, min response is -3.642553.
max gradient is 8.000000, min gradient is -1.325436, learning rate is 0.000471
Net2: layer deconv2:max response is , min response is .
max gradient is 7.244888, min gradient is -8.000000, learning rate is 0.000236
Net2: layer bn49:max response is 7.616326, min response is -1.712905.
max gradient is 8.000000, min gradient is -4.614084, learning rate is 0.000471
Net2: layer deconv1:max response is , min response is .
max gradient is 7.234970, min gradient is -8.000000, learning rate is 0.000236
max inferred z is 4.06, min inferred z is -4.26, and std is 1.00
 4.21 s (23.7 data/s) [100/100]
training: epoch 64: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.757258, min gradient is -8.000001, learning rate is 0.006456
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.445940, learning rate is 0.006456
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.640130, learning rate is 0.006456
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -0.569439, learning rate is 0.000471
Net2: layer deconv3:max response is 22.879389, min response is -28.476707.
max gradient is 8.000000, min gradient is -6.774795, learning rate is 0.000236
Net2: layer bn50:max response is 19.199421, min response is -3.252203.
max gradient is 8.000000, min gradient is -3.471219, learning rate is 0.000471
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.857572, learning rate is 0.000236
Net2: layer bn49:max response is 7.749197, min response is -1.724775.
max gradient is 7.572672, min gradient is -8.000000, learning rate is 0.000471
Net2: layer deconv1:max response is , min response is .
max gradient is 7.357724, min gradient is -8.000000, learning rate is 0.000236
max inferred z is 4.38, min inferred z is -4.41, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
Loss: 2.1672
Iteration 65 / 200
training: epoch 65: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.631331, min gradient is -8.000000, learning rate is 0.005359
Net1: layer conv2:max response is , min response is .
max gradient is 5.361636, min gradient is -8.000000, learning rate is 0.005359
Net1: layer conv1:max response is , min response is .
max gradient is 5.189055, min gradient is -8.000000, learning rate is 0.005359
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 2.589823, min gradient is -8.000000, learning rate is 0.000469
Net2: layer deconv3:max response is 21.288540, min response is -31.057602.
max gradient is 8.000000, min gradient is -5.653959, learning rate is 0.000235
Net2: layer bn50:max response is 19.187975, min response is -3.106979.
max gradient is 8.000000, min gradient is -5.833063, learning rate is 0.000469
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.271501, learning rate is 0.000235
Net2: layer bn49:max response is 8.376026, min response is -1.901076.
max gradient is 7.946834, min gradient is -8.000000, learning rate is 0.000469
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.150073, learning rate is 0.000235
max inferred z is 3.87, min inferred z is -3.78, and std is 1.00
 4.19 s (23.9 data/s) [100/100]
training: epoch 65: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.070448, min gradient is -8.000000, learning rate is 0.005359
Net1: layer conv2:max response is , min response is .
max gradient is 5.843619, min gradient is -8.000000, learning rate is 0.005359
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.998421, learning rate is 0.005359
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 2.416847, min gradient is -8.000000, learning rate is 0.000469
Net2: layer deconv3:max response is 20.131786, min response is -23.122881.
max gradient is 8.000000, min gradient is -6.661865, learning rate is 0.000235
Net2: layer bn50:max response is 16.949841, min response is -3.265348.
max gradient is 8.000000, min gradient is -5.175480, learning rate is 0.000469
Net2: layer deconv2:max response is , min response is .
max gradient is 6.080727, min gradient is -8.000000, learning rate is 0.000235
Net2: layer bn49:max response is 7.033842, min response is -1.535598.
max gradient is 6.958474, min gradient is -8.000000, learning rate is 0.000469
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.785986, learning rate is 0.000235
max inferred z is 4.22, min inferred z is -4.39, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 65: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.814120, min gradient is -8.000000, learning rate is 0.005359
Net1: layer conv2:max response is , min response is .
max gradient is 7.595038, min gradient is -8.000000, learning rate is 0.005359
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.882534, learning rate is 0.005359
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -6.116681, learning rate is 0.000469
Net2: layer deconv3:max response is 23.641853, min response is -29.033909.
max gradient is 8.000000, min gradient is -5.088000, learning rate is 0.000235
Net2: layer bn50:max response is 18.642311, min response is -3.361447.
max gradient is 4.861400, min gradient is -8.000000, learning rate is 0.000469
Net2: layer deconv2:max response is , min response is .
max gradient is 7.834009, min gradient is -8.000000, learning rate is 0.000235
Net2: layer bn49:max response is 8.355631, min response is -1.743474.
max gradient is 8.000000, min gradient is -7.510013, learning rate is 0.000469
Net2: layer deconv1:max response is , min response is .
max gradient is 7.840732, min gradient is -8.000000, learning rate is 0.000235
max inferred z is 4.58, min inferred z is -4.65, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 65: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.898504, min gradient is -8.000000, learning rate is 0.005359
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.912943, learning rate is 0.005359
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.443673, learning rate is 0.005359
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.611780, learning rate is 0.000469
Net2: layer deconv3:max response is 23.381493, min response is -23.748262.
max gradient is 7.578678, min gradient is -8.000000, learning rate is 0.000235
Net2: layer bn50:max response is 17.816172, min response is -4.137194.
max gradient is 5.798949, min gradient is -8.000000, learning rate is 0.000469
Net2: layer deconv2:max response is , min response is .
max gradient is 5.941214, min gradient is -8.000000, learning rate is 0.000235
Net2: layer bn49:max response is 8.426395, min response is -2.048055.
max gradient is 8.000000, min gradient is -7.901044, learning rate is 0.000469
Net2: layer deconv1:max response is , min response is .
max gradient is 7.752898, min gradient is -8.000000, learning rate is 0.000235
max inferred z is 3.96, min inferred z is -3.70, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
training: epoch 65: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.779347, min gradient is -8.000000, learning rate is 0.005359
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.631789, learning rate is 0.005359
Net1: layer conv1:max response is , min response is .
max gradient is 7.477156, min gradient is -8.000000, learning rate is 0.005359
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.043359, learning rate is 0.000469
Net2: layer deconv3:max response is 20.721031, min response is -25.568232.
max gradient is 6.471020, min gradient is -8.000000, learning rate is 0.000235
Net2: layer bn50:max response is 19.278093, min response is -3.819024.
max gradient is 4.835338, min gradient is -8.000000, learning rate is 0.000469
Net2: layer deconv2:max response is , min response is .
max gradient is 7.965249, min gradient is -8.000000, learning rate is 0.000235
Net2: layer bn49:max response is 8.572374, min response is -1.606109.
max gradient is 8.000000, min gradient is -6.664020, learning rate is 0.000469
Net2: layer deconv1:max response is , min response is .
max gradient is 7.309393, min gradient is -8.000000, learning rate is 0.000235
max inferred z is 4.04, min inferred z is -3.99, and std is 1.00
 4.28 s (23.4 data/s) [100/100]
training: epoch 65: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.486727, min gradient is -8.000000, learning rate is 0.005359
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.614921, learning rate is 0.005359
Net1: layer conv1:max response is , min response is .
max gradient is 6.030005, min gradient is -8.000000, learning rate is 0.005359
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.084671, learning rate is 0.000469
Net2: layer deconv3:max response is 22.692293, min response is -30.431761.
max gradient is 8.000000, min gradient is -6.466663, learning rate is 0.000235
Net2: layer bn50:max response is 17.935911, min response is -3.373900.
max gradient is 8.000000, min gradient is -6.567501, learning rate is 0.000469
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.659476, learning rate is 0.000235
Net2: layer bn49:max response is 7.648845, min response is -1.786336.
max gradient is 8.000000, min gradient is -5.905142, learning rate is 0.000469
Net2: layer deconv1:max response is , min response is .
max gradient is 7.361668, min gradient is -8.000000, learning rate is 0.000235
max inferred z is 3.92, min inferred z is -3.96, and std is 1.00
 4.18 s (23.9 data/s) [100/100]
training: epoch 65: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.289446, min gradient is -8.000000, learning rate is 0.005359
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.031118, learning rate is 0.005359
Net1: layer conv1:max response is , min response is .
max gradient is 3.242861, min gradient is -8.000000, learning rate is 0.005359
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -0.940294, learning rate is 0.000469
Net2: layer deconv3:max response is 21.234650, min response is -31.401825.
max gradient is 6.354280, min gradient is -8.000000, learning rate is 0.000235
Net2: layer bn50:max response is 18.771862, min response is -3.844835.
max gradient is 8.000000, min gradient is -5.430176, learning rate is 0.000469
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.944715, learning rate is 0.000235
Net2: layer bn49:max response is 7.694456, min response is -1.717888.
max gradient is 8.000000, min gradient is -6.691503, learning rate is 0.000469
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.466727, learning rate is 0.000235
max inferred z is 4.14, min inferred z is -4.08, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 65: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.623573, min gradient is -8.000000, learning rate is 0.005359
Net1: layer conv2:max response is , min response is .
max gradient is 6.653209, min gradient is -8.000000, learning rate is 0.005359
Net1: layer conv1:max response is , min response is .
max gradient is 3.968224, min gradient is -8.000000, learning rate is 0.005359
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 0.599597, min gradient is -8.000000, learning rate is 0.000469
Net2: layer deconv3:max response is 23.820343, min response is -25.392353.
max gradient is 8.000000, min gradient is -7.791974, learning rate is 0.000235
Net2: layer bn50:max response is 18.892517, min response is -3.456757.
max gradient is 8.000000, min gradient is -4.433689, learning rate is 0.000469
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.195813, learning rate is 0.000235
Net2: layer bn49:max response is 8.508476, min response is -1.702052.
max gradient is 7.209362, min gradient is -8.000000, learning rate is 0.000469
Net2: layer deconv1:max response is , min response is .
max gradient is 6.416924, min gradient is -8.000000, learning rate is 0.000235
max inferred z is 4.18, min inferred z is -4.12, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 65: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.629870, min gradient is -8.000000, learning rate is 0.005359
Net1: layer conv2:max response is , min response is .
max gradient is 6.570374, min gradient is -8.000000, learning rate is 0.005359
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.514205, learning rate is 0.005359
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 3.160436, min gradient is -8.000000, learning rate is 0.000469
Net2: layer deconv3:max response is 23.602728, min response is -29.593452.
max gradient is 5.254720, min gradient is -8.000000, learning rate is 0.000235
Net2: layer bn50:max response is 18.199137, min response is -3.739826.
max gradient is 4.222289, min gradient is -8.000000, learning rate is 0.000469
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.030609, learning rate is 0.000235
Net2: layer bn49:max response is 8.107281, min response is -1.684621.
max gradient is 4.999949, min gradient is -8.000000, learning rate is 0.000469
Net2: layer deconv1:max response is , min response is .
max gradient is 7.733715, min gradient is -8.000000, learning rate is 0.000235
max inferred z is 3.74, min inferred z is -4.06, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
training: epoch 65: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.771312, learning rate is 0.005359
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.398362, learning rate is 0.005359
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.991026, learning rate is 0.005359
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 5.038868, min gradient is -8.000000, learning rate is 0.000469
Net2: layer deconv3:max response is 23.725742, min response is -24.666250.
max gradient is 6.085035, min gradient is -8.000000, learning rate is 0.000235
Net2: layer bn50:max response is 18.083679, min response is -3.397397.
max gradient is 3.727759, min gradient is -8.000000, learning rate is 0.000469
Net2: layer deconv2:max response is , min response is .
max gradient is 5.303370, min gradient is -8.000000, learning rate is 0.000235
Net2: layer bn49:max response is 8.048990, min response is -1.729944.
max gradient is 5.231540, min gradient is -8.000000, learning rate is 0.000469
Net2: layer deconv1:max response is , min response is .
max gradient is 6.723080, min gradient is -8.000000, learning rate is 0.000235
max inferred z is 3.70, min inferred z is -4.28, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
Loss: 2.0591
Iteration 66 / 200
training: epoch 66: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.743293, learning rate is 0.005359
Net1: layer conv2:max response is , min response is .
max gradient is 7.037769, min gradient is -8.000000, learning rate is 0.005359
Net1: layer conv1:max response is , min response is .
max gradient is 5.426544, min gradient is -8.000000, learning rate is 0.005359
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 1.173019, min gradient is -8.000000, learning rate is 0.000467
Net2: layer deconv3:max response is 27.985826, min response is -31.780844.
max gradient is 8.000000, min gradient is -4.711034, learning rate is 0.000234
Net2: layer bn50:max response is 19.489868, min response is -3.551156.
max gradient is 8.000000, min gradient is -5.293421, learning rate is 0.000467
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.241571, learning rate is 0.000234
Net2: layer bn49:max response is 9.016647, min response is -1.882531.
max gradient is 7.501971, min gradient is -8.000000, learning rate is 0.000467
Net2: layer deconv1:max response is , min response is .
max gradient is 7.575259, min gradient is -8.000000, learning rate is 0.000234
max inferred z is 3.70, min inferred z is -3.51, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 66: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.578286, min gradient is -8.000000, learning rate is 0.005359
Net1: layer conv2:max response is , min response is .
max gradient is 7.837752, min gradient is -8.000000, learning rate is 0.005359
Net1: layer conv1:max response is , min response is .
max gradient is 6.570310, min gradient is -8.000000, learning rate is 0.005359
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 4.453384, min gradient is -8.000000, learning rate is 0.000467
Net2: layer deconv3:max response is 22.465109, min response is -24.307627.
max gradient is 8.000000, min gradient is -6.599135, learning rate is 0.000234
Net2: layer bn50:max response is 17.354216, min response is -3.832772.
max gradient is 8.000000, min gradient is -6.358992, learning rate is 0.000467
Net2: layer deconv2:max response is , min response is .
max gradient is 6.597281, min gradient is -8.000000, learning rate is 0.000234
Net2: layer bn49:max response is 8.356854, min response is -1.662552.
max gradient is 5.315625, min gradient is -8.000000, learning rate is 0.000467
Net2: layer deconv1:max response is , min response is .
max gradient is 7.819239, min gradient is -8.000000, learning rate is 0.000234
max inferred z is 4.01, min inferred z is -4.44, and std is 1.00
 4.28 s (23.4 data/s) [100/100]
training: epoch 66: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.890042, learning rate is 0.005359
Net1: layer conv2:max response is , min response is .
max gradient is 5.976040, min gradient is -8.000000, learning rate is 0.005359
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.694086, learning rate is 0.005359
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.985593, learning rate is 0.000467
Net2: layer deconv3:max response is 25.502071, min response is -30.844500.
max gradient is 8.000000, min gradient is -3.988311, learning rate is 0.000234
Net2: layer bn50:max response is 18.295315, min response is -3.179313.
max gradient is 5.126792, min gradient is -8.000000, learning rate is 0.000467
Net2: layer deconv2:max response is , min response is .
max gradient is 7.750532, min gradient is -8.000000, learning rate is 0.000234
Net2: layer bn49:max response is 7.810272, min response is -1.795392.
max gradient is 6.991992, min gradient is -8.000000, learning rate is 0.000467
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.829255, learning rate is 0.000234
max inferred z is 3.93, min inferred z is -3.71, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 66: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.329569, min gradient is -8.000000, learning rate is 0.005359
Net1: layer conv2:max response is , min response is .
max gradient is 7.335626, min gradient is -8.000000, learning rate is 0.005359
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.669500, learning rate is 0.005359
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.174990, learning rate is 0.000467
Net2: layer deconv3:max response is 23.738100, min response is -26.977581.
max gradient is 8.000000, min gradient is -7.217144, learning rate is 0.000234
Net2: layer bn50:max response is 19.502102, min response is -4.563562.
max gradient is 3.260605, min gradient is -8.000000, learning rate is 0.000467
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.499751, learning rate is 0.000234
Net2: layer bn49:max response is 8.671186, min response is -2.111935.
max gradient is 8.000000, min gradient is -6.831392, learning rate is 0.000467
Net2: layer deconv1:max response is , min response is .
max gradient is 6.453901, min gradient is -8.000000, learning rate is 0.000234
max inferred z is 4.32, min inferred z is -4.16, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 66: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.019560, min gradient is -8.000000, learning rate is 0.005359
Net1: layer conv2:max response is , min response is .
max gradient is 6.045771, min gradient is -8.000000, learning rate is 0.005359
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.826440, learning rate is 0.005359
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.423466, learning rate is 0.000467
Net2: layer deconv3:max response is 23.185104, min response is -24.593451.
max gradient is 4.976866, min gradient is -8.000000, learning rate is 0.000234
Net2: layer bn50:max response is 19.711418, min response is -3.394070.
max gradient is 1.966247, min gradient is -8.000000, learning rate is 0.000467
Net2: layer deconv2:max response is , min response is .
max gradient is 6.531483, min gradient is -8.000000, learning rate is 0.000234
Net2: layer bn49:max response is 7.983705, min response is -1.610979.
max gradient is 5.445301, min gradient is -8.000000, learning rate is 0.000467
Net2: layer deconv1:max response is , min response is .
max gradient is 7.520001, min gradient is -8.000000, learning rate is 0.000234
max inferred z is 3.70, min inferred z is -3.55, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 66: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.219756, min gradient is -8.000000, learning rate is 0.005359
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.584940, learning rate is 0.005359
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.134889, learning rate is 0.005359
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -6.031747, learning rate is 0.000467
Net2: layer deconv3:max response is 23.703060, min response is -29.339151.
max gradient is 8.000000, min gradient is -7.376348, learning rate is 0.000234
Net2: layer bn50:max response is 17.781523, min response is -4.195553.
max gradient is 4.224959, min gradient is -8.000000, learning rate is 0.000467
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.048400, learning rate is 0.000234
Net2: layer bn49:max response is 9.884927, min response is -1.813439.
max gradient is 8.000000, min gradient is -7.604406, learning rate is 0.000467
Net2: layer deconv1:max response is , min response is .
max gradient is 7.585078, min gradient is -8.000000, learning rate is 0.000234
max inferred z is 3.68, min inferred z is -3.89, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 66: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.845746, min gradient is -8.000000, learning rate is 0.005359
Net1: layer conv2:max response is , min response is .
max gradient is 7.553493, min gradient is -8.000000, learning rate is 0.005359
Net1: layer conv1:max response is , min response is .
max gradient is 3.922297, min gradient is -8.000000, learning rate is 0.005359
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 0.466611, min gradient is -8.000000, learning rate is 0.000467
Net2: layer deconv3:max response is 27.498678, min response is -27.099672.
max gradient is 8.000000, min gradient is -7.313724, learning rate is 0.000234
Net2: layer bn50:max response is 22.006771, min response is -3.413759.
max gradient is 8.000000, min gradient is -4.114864, learning rate is 0.000467
Net2: layer deconv2:max response is , min response is .
max gradient is 6.427200, min gradient is -8.000000, learning rate is 0.000234
Net2: layer bn49:max response is 7.654383, min response is -1.664148.
max gradient is 6.513508, min gradient is -8.000000, learning rate is 0.000467
Net2: layer deconv1:max response is , min response is .
max gradient is 6.394360, min gradient is -8.000000, learning rate is 0.000234
max inferred z is 4.08, min inferred z is -4.33, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 66: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.741564, min gradient is -8.000000, learning rate is 0.005359
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.725358, learning rate is 0.005359
Net1: layer conv1:max response is , min response is .
max gradient is 7.053584, min gradient is -8.000000, learning rate is 0.005359
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 2.481240, min gradient is -8.000000, learning rate is 0.000467
Net2: layer deconv3:max response is 21.636208, min response is -25.014673.
max gradient is 8.000000, min gradient is -5.826276, learning rate is 0.000234
Net2: layer bn50:max response is 16.740480, min response is -3.397847.
max gradient is 8.000000, min gradient is -6.106609, learning rate is 0.000467
Net2: layer deconv2:max response is , min response is .
max gradient is 6.747277, min gradient is -8.000000, learning rate is 0.000234
Net2: layer bn49:max response is 8.678403, min response is -1.691312.
max gradient is 5.904544, min gradient is -8.000000, learning rate is 0.000467
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.330283, learning rate is 0.000234
max inferred z is 4.53, min inferred z is -3.88, and std is 1.00
 4.30 s (23.2 data/s) [100/100]
training: epoch 66: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.511977, min gradient is -8.000000, learning rate is 0.005359
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.637027, learning rate is 0.005359
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.318506, learning rate is 0.005359
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -0.484432, learning rate is 0.000467
Net2: layer deconv3:max response is 26.201078, min response is -28.316372.
max gradient is 7.927952, min gradient is -8.000000, learning rate is 0.000234
Net2: layer bn50:max response is 17.058651, min response is -3.418460.
max gradient is 6.473271, min gradient is -8.000000, learning rate is 0.000467
Net2: layer deconv2:max response is , min response is .
max gradient is 7.144657, min gradient is -8.000000, learning rate is 0.000234
Net2: layer bn49:max response is 8.936525, min response is -1.647927.
max gradient is 8.000000, min gradient is -7.125556, learning rate is 0.000467
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.783680, learning rate is 0.000234
max inferred z is 3.63, min inferred z is -3.94, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 66: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.048081, min gradient is -8.000000, learning rate is 0.005359
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.620075, learning rate is 0.005359
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.472695, learning rate is 0.005359
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.198961, learning rate is 0.000467
Net2: layer deconv3:max response is 27.076729, min response is -26.529791.
max gradient is 6.662163, min gradient is -8.000000, learning rate is 0.000234
Net2: layer bn50:max response is 21.460011, min response is -3.388510.
max gradient is 3.912806, min gradient is -8.000000, learning rate is 0.000467
Net2: layer deconv2:max response is , min response is .
max gradient is 7.988279, min gradient is -8.000000, learning rate is 0.000234
Net2: layer bn49:max response is 8.133133, min response is -1.814215.
max gradient is 6.198466, min gradient is -8.000000, learning rate is 0.000467
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.302522, learning rate is 0.000234
max inferred z is 3.89, min inferred z is -4.35, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
Loss: 2.0093
Iteration 67 / 200
training: epoch 67: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.106175, min gradient is -8.000000, learning rate is 0.004448
Net1: layer conv2:max response is , min response is .
max gradient is 5.549263, min gradient is -8.000000, learning rate is 0.004448
Net1: layer conv1:max response is , min response is .
max gradient is 5.337783, min gradient is -8.000000, learning rate is 0.004448
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.736024, learning rate is 0.000465
Net2: layer deconv3:max response is 23.036243, min response is -29.142618.
max gradient is 7.556299, min gradient is -8.000000, learning rate is 0.000233
Net2: layer bn50:max response is 19.017807, min response is -3.561996.
max gradient is 8.000001, min gradient is -6.767716, learning rate is 0.000465
Net2: layer deconv2:max response is , min response is .
max gradient is 6.541356, min gradient is -8.000000, learning rate is 0.000233
Net2: layer bn49:max response is 9.309367, min response is -1.738923.
max gradient is 4.448463, min gradient is -8.000000, learning rate is 0.000465
Net2: layer deconv1:max response is , min response is .
max gradient is 7.317894, min gradient is -8.000000, learning rate is 0.000233
max inferred z is 3.94, min inferred z is -3.96, and std is 1.01
 4.18 s (23.9 data/s) [100/100]
training: epoch 67: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.749326, min gradient is -8.000000, learning rate is 0.004448
Net1: layer conv2:max response is , min response is .
max gradient is 6.538342, min gradient is -8.000000, learning rate is 0.004448
Net1: layer conv1:max response is , min response is .
max gradient is 7.706634, min gradient is -8.000000, learning rate is 0.004448
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.975602, learning rate is 0.000465
Net2: layer deconv3:max response is 24.260475, min response is -32.001526.
max gradient is 8.000000, min gradient is -4.994416, learning rate is 0.000233
Net2: layer bn50:max response is 16.986555, min response is -4.039104.
max gradient is 8.000000, min gradient is -7.548001, learning rate is 0.000465
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.803393, learning rate is 0.000233
Net2: layer bn49:max response is 8.944813, min response is -1.734555.
max gradient is 4.233664, min gradient is -8.000000, learning rate is 0.000465
Net2: layer deconv1:max response is , min response is .
max gradient is 7.894163, min gradient is -8.000000, learning rate is 0.000233
max inferred z is 4.35, min inferred z is -3.87, and std is 1.01
 4.22 s (23.7 data/s) [100/100]
training: epoch 67: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.789047, min gradient is -8.000000, learning rate is 0.004448
Net1: layer conv2:max response is , min response is .
max gradient is 6.315570, min gradient is -8.000000, learning rate is 0.004448
Net1: layer conv1:max response is , min response is .
max gradient is 7.221884, min gradient is -8.000000, learning rate is 0.004448
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -5.194450, learning rate is 0.000465
Net2: layer deconv3:max response is 23.657070, min response is -26.380800.
max gradient is 8.000000, min gradient is -6.611518, learning rate is 0.000233
Net2: layer bn50:max response is 17.659824, min response is -3.516927.
max gradient is 7.310457, min gradient is -8.000000, learning rate is 0.000465
Net2: layer deconv2:max response is , min response is .
max gradient is 6.698485, min gradient is -8.000000, learning rate is 0.000233
Net2: layer bn49:max response is 7.871091, min response is -1.836498.
max gradient is 4.226050, min gradient is -8.000000, learning rate is 0.000465
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.297630, learning rate is 0.000233
max inferred z is 4.31, min inferred z is -4.72, and std is 1.01
 4.42 s (22.6 data/s) [100/100]
training: epoch 67: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.532487, min gradient is -8.000000, learning rate is 0.004448
Net1: layer conv2:max response is , min response is .
max gradient is 7.230904, min gradient is -8.000000, learning rate is 0.004448
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -2.885958, learning rate is 0.004448
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.349640, learning rate is 0.000465
Net2: layer deconv3:max response is 23.650200, min response is -29.626509.
max gradient is 4.606013, min gradient is -8.000000, learning rate is 0.000233
Net2: layer bn50:max response is 17.330135, min response is -3.369322.
max gradient is 3.842874, min gradient is -8.000000, learning rate is 0.000465
Net2: layer deconv2:max response is , min response is .
max gradient is 6.569893, min gradient is -8.000000, learning rate is 0.000233
Net2: layer bn49:max response is 7.555056, min response is -1.724712.
max gradient is 8.000000, min gradient is -5.258475, learning rate is 0.000465
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.990840, learning rate is 0.000233
max inferred z is 3.81, min inferred z is -4.03, and std is 1.01
 4.41 s (22.7 data/s) [100/100]
training: epoch 67: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.967241, min gradient is -8.000000, learning rate is 0.004448
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.874395, learning rate is 0.004448
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.027202, learning rate is 0.004448
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.270015, learning rate is 0.000465
Net2: layer deconv3:max response is 24.897764, min response is -27.154930.
max gradient is 5.447781, min gradient is -8.000000, learning rate is 0.000233
Net2: layer bn50:max response is 18.890408, min response is -3.900467.
max gradient is 2.958099, min gradient is -8.000000, learning rate is 0.000465
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.969950, learning rate is 0.000233
Net2: layer bn49:max response is 8.707212, min response is -1.711651.
max gradient is 7.635687, min gradient is -8.000000, learning rate is 0.000465
Net2: layer deconv1:max response is , min response is .
max gradient is 6.382109, min gradient is -8.000000, learning rate is 0.000233
max inferred z is 3.95, min inferred z is -3.93, and std is 1.01
 4.27 s (23.4 data/s) [100/100]
training: epoch 67: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.602442, min gradient is -8.000000, learning rate is 0.004448
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.423858, learning rate is 0.004448
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.863822, learning rate is 0.004448
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.798709, learning rate is 0.000465
Net2: layer deconv3:max response is 26.235231, min response is -30.042566.
max gradient is 4.953343, min gradient is -8.000000, learning rate is 0.000233
Net2: layer bn50:max response is 21.388472, min response is -3.264072.
max gradient is 2.523649, min gradient is -8.000000, learning rate is 0.000465
Net2: layer deconv2:max response is , min response is .
max gradient is 6.961792, min gradient is -8.000000, learning rate is 0.000233
Net2: layer bn49:max response is 7.955441, min response is -1.817007.
max gradient is 6.562501, min gradient is -8.000000, learning rate is 0.000465
Net2: layer deconv1:max response is , min response is .
max gradient is 7.652797, min gradient is -8.000000, learning rate is 0.000233
max inferred z is 3.87, min inferred z is -4.39, and std is 1.01
 4.23 s (23.6 data/s) [100/100]
training: epoch 67: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.177676, min gradient is -8.000000, learning rate is 0.004448
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.863446, learning rate is 0.004448
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.394481, learning rate is 0.004448
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.795783, learning rate is 0.000465
Net2: layer deconv3:max response is 24.564106, min response is -26.842089.
max gradient is 8.000000, min gradient is -6.611414, learning rate is 0.000233
Net2: layer bn50:max response is 17.468985, min response is -3.601477.
max gradient is 6.211699, min gradient is -8.000000, learning rate is 0.000465
Net2: layer deconv2:max response is , min response is .
max gradient is 7.844186, min gradient is -8.000000, learning rate is 0.000233
Net2: layer bn49:max response is 7.099142, min response is -1.866482.
max gradient is 5.077695, min gradient is -8.000000, learning rate is 0.000465
Net2: layer deconv1:max response is , min response is .
max gradient is 7.612591, min gradient is -8.000000, learning rate is 0.000233
max inferred z is 3.71, min inferred z is -3.78, and std is 1.01
 4.28 s (23.4 data/s) [100/100]
training: epoch 67: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.081403, min gradient is -8.000000, learning rate is 0.004448
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.662097, learning rate is 0.004448
Net1: layer conv1:max response is , min response is .
max gradient is 4.536207, min gradient is -8.000000, learning rate is 0.004448
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 7.930879, min gradient is -8.000000, learning rate is 0.000465
Net2: layer deconv3:max response is 27.664553, min response is -27.562918.
max gradient is 8.000000, min gradient is -7.380948, learning rate is 0.000233
Net2: layer bn50:max response is 19.884327, min response is -3.147479.
max gradient is 8.000000, min gradient is -3.546539, learning rate is 0.000465
Net2: layer deconv2:max response is , min response is .
max gradient is 6.016057, min gradient is -8.000000, learning rate is 0.000233
Net2: layer bn49:max response is 8.078824, min response is -1.857267.
max gradient is 4.039111, min gradient is -8.000000, learning rate is 0.000465
Net2: layer deconv1:max response is , min response is .
max gradient is 7.406622, min gradient is -8.000000, learning rate is 0.000233
max inferred z is 4.18, min inferred z is -3.81, and std is 1.01
 4.23 s (23.7 data/s) [100/100]
training: epoch 67: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.670227, min gradient is -8.000000, learning rate is 0.004448
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.715903, learning rate is 0.004448
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.171326, learning rate is 0.004448
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.877172, learning rate is 0.000465
Net2: layer deconv3:max response is 22.913559, min response is -28.093271.
max gradient is 6.587205, min gradient is -8.000000, learning rate is 0.000233
Net2: layer bn50:max response is 17.148193, min response is -3.597972.
max gradient is 5.566758, min gradient is -8.000000, learning rate is 0.000465
Net2: layer deconv2:max response is , min response is .
max gradient is 5.966490, min gradient is -8.000000, learning rate is 0.000233
Net2: layer bn49:max response is 9.063086, min response is -1.711717.
max gradient is 5.267377, min gradient is -8.000000, learning rate is 0.000465
Net2: layer deconv1:max response is , min response is .
max gradient is 7.809210, min gradient is -8.000000, learning rate is 0.000233
max inferred z is 3.80, min inferred z is -4.43, and std is 1.01
 4.32 s (23.2 data/s) [100/100]
training: epoch 67: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.329177, learning rate is 0.004448
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.797247, learning rate is 0.004448
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.101564, learning rate is 0.004448
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.294951, learning rate is 0.000465
Net2: layer deconv3:max response is 23.840216, min response is -24.589073.
max gradient is 6.550800, min gradient is -8.000000, learning rate is 0.000233
Net2: layer bn50:max response is 16.951279, min response is -3.289842.
max gradient is 4.370127, min gradient is -8.000000, learning rate is 0.000465
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.793129, learning rate is 0.000233
Net2: layer bn49:max response is 8.454023, min response is -1.741068.
max gradient is 8.000000, min gradient is -6.557335, learning rate is 0.000465
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.702084, learning rate is 0.000233
max inferred z is 3.94, min inferred z is -3.83, and std is 1.01
 4.37 s (22.9 data/s) [100/100]
Loss: 1.8821
Iteration 68 / 200
training: epoch 68: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.199175, min gradient is -8.000000, learning rate is 0.004448
Net1: layer conv2:max response is , min response is .
max gradient is 7.507302, min gradient is -8.000000, learning rate is 0.004448
Net1: layer conv1:max response is , min response is .
max gradient is 6.342720, min gradient is -8.000000, learning rate is 0.004448
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -1.908799, learning rate is 0.000463
Net2: layer deconv3:max response is 24.975153, min response is -25.901590.
max gradient is 8.000001, min gradient is -7.977791, learning rate is 0.000232
Net2: layer bn50:max response is 17.801090, min response is -3.168278.
max gradient is 8.000000, min gradient is -6.782449, learning rate is 0.000463
Net2: layer deconv2:max response is , min response is .
max gradient is 6.630141, min gradient is -8.000000, learning rate is 0.000232
Net2: layer bn49:max response is 8.037037, min response is -1.670248.
max gradient is 5.198886, min gradient is -8.000000, learning rate is 0.000463
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.717061, learning rate is 0.000232
max inferred z is 4.10, min inferred z is -4.50, and std is 0.99
 4.16 s (24.0 data/s) [100/100]
training: epoch 68: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.808865, learning rate is 0.004448
Net1: layer conv2:max response is , min response is .
max gradient is 6.179589, min gradient is -8.000000, learning rate is 0.004448
Net1: layer conv1:max response is , min response is .
max gradient is 4.588219, min gradient is -8.000000, learning rate is 0.004448
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 0.859627, min gradient is -8.000000, learning rate is 0.000463
Net2: layer deconv3:max response is 24.816547, min response is -29.286308.
max gradient is 8.000000, min gradient is -4.463292, learning rate is 0.000232
Net2: layer bn50:max response is 18.122425, min response is -4.114757.
max gradient is 8.000000, min gradient is -3.290664, learning rate is 0.000463
Net2: layer deconv2:max response is , min response is .
max gradient is 7.700043, min gradient is -8.000000, learning rate is 0.000232
Net2: layer bn49:max response is 7.957346, min response is -1.771667.
max gradient is 8.000000, min gradient is -5.631004, learning rate is 0.000463
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.502732, learning rate is 0.000232
max inferred z is 4.13, min inferred z is -4.08, and std is 0.99
 4.34 s (23.0 data/s) [100/100]
training: epoch 68: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.789030, learning rate is 0.004448
Net1: layer conv2:max response is , min response is .
max gradient is 7.052922, min gradient is -8.000000, learning rate is 0.004448
Net1: layer conv1:max response is , min response is .
max gradient is 5.701753, min gradient is -8.000000, learning rate is 0.004448
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 7.406812, min gradient is -8.000000, learning rate is 0.000463
Net2: layer deconv3:max response is 26.121063, min response is -25.365217.
max gradient is 8.000000, min gradient is -3.582547, learning rate is 0.000232
Net2: layer bn50:max response is 18.827581, min response is -3.728208.
max gradient is 2.930754, min gradient is -8.000000, learning rate is 0.000463
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.012206, learning rate is 0.000232
Net2: layer bn49:max response is 9.603715, min response is -1.671823.
max gradient is 3.557789, min gradient is -8.000000, learning rate is 0.000463
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.543122, learning rate is 0.000232
max inferred z is 4.04, min inferred z is -4.23, and std is 0.99
 4.38 s (22.8 data/s) [100/100]
training: epoch 68: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.488876, min gradient is -8.000000, learning rate is 0.004448
Net1: layer conv2:max response is , min response is .
max gradient is 7.186522, min gradient is -8.000000, learning rate is 0.004448
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -2.521906, learning rate is 0.004448
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.046207, learning rate is 0.000463
Net2: layer deconv3:max response is 25.692785, min response is -23.260925.
max gradient is 5.159420, min gradient is -8.000000, learning rate is 0.000232
Net2: layer bn50:max response is 17.364576, min response is -3.169024.
max gradient is 2.984929, min gradient is -8.000000, learning rate is 0.000463
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.043753, learning rate is 0.000232
Net2: layer bn49:max response is 7.453579, min response is -1.633967.
max gradient is 8.000000, min gradient is -5.542628, learning rate is 0.000463
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.706391, learning rate is 0.000232
max inferred z is 4.84, min inferred z is -4.47, and std is 0.99
 4.40 s (22.7 data/s) [100/100]
training: epoch 68: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.219440, min gradient is -8.000000, learning rate is 0.004448
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.938288, learning rate is 0.004448
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.861612, learning rate is 0.004448
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.572738, learning rate is 0.000463
Net2: layer deconv3:max response is 26.438061, min response is -32.666656.
max gradient is 3.794906, min gradient is -8.000000, learning rate is 0.000232
Net2: layer bn50:max response is 18.343821, min response is -3.634697.
max gradient is 2.336735, min gradient is -8.000000, learning rate is 0.000463
Net2: layer deconv2:max response is , min response is .
max gradient is 7.509557, min gradient is -8.000000, learning rate is 0.000232
Net2: layer bn49:max response is 9.184932, min response is -2.275201.
max gradient is 4.529919, min gradient is -8.000000, learning rate is 0.000463
Net2: layer deconv1:max response is , min response is .
max gradient is 7.365888, min gradient is -8.000000, learning rate is 0.000232
max inferred z is 4.41, min inferred z is -3.83, and std is 0.99
 4.38 s (22.8 data/s) [100/100]
training: epoch 68: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.666870, min gradient is -8.000000, learning rate is 0.004448
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.372332, learning rate is 0.004448
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.834058, learning rate is 0.004448
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.512893, learning rate is 0.000463
Net2: layer deconv3:max response is 25.008095, min response is -25.863737.
max gradient is 8.000000, min gradient is -5.806066, learning rate is 0.000232
Net2: layer bn50:max response is 16.885061, min response is -4.682897.
max gradient is 5.167588, min gradient is -8.000000, learning rate is 0.000463
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.836684, learning rate is 0.000232
Net2: layer bn49:max response is 10.368236, min response is -2.250876.
max gradient is 7.794059, min gradient is -8.000000, learning rate is 0.000463
Net2: layer deconv1:max response is , min response is .
max gradient is 7.530186, min gradient is -8.000000, learning rate is 0.000232
max inferred z is 3.94, min inferred z is -3.82, and std is 0.99
 4.42 s (22.6 data/s) [100/100]
training: epoch 68: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.757315, min gradient is -8.000000, learning rate is 0.004448
Net1: layer conv2:max response is , min response is .
max gradient is 6.795157, min gradient is -8.000000, learning rate is 0.004448
Net1: layer conv1:max response is , min response is .
max gradient is 2.955272, min gradient is -8.000000, learning rate is 0.004448
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -2.248802, min gradient is -8.000000, learning rate is 0.000463
Net2: layer deconv3:max response is 25.187122, min response is -30.379869.
max gradient is 8.000000, min gradient is -5.176678, learning rate is 0.000232
Net2: layer bn50:max response is 18.285561, min response is -3.436208.
max gradient is 8.000000, min gradient is -1.976023, learning rate is 0.000463
Net2: layer deconv2:max response is , min response is .
max gradient is 6.432893, min gradient is -8.000000, learning rate is 0.000232
Net2: layer bn49:max response is 8.407254, min response is -1.667419.
max gradient is 8.000000, min gradient is -7.890366, learning rate is 0.000463
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.872682, learning rate is 0.000232
max inferred z is 4.09, min inferred z is -4.54, and std is 0.99
 4.29 s (23.3 data/s) [100/100]
training: epoch 68: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.776781, min gradient is -8.000000, learning rate is 0.004448
Net1: layer conv2:max response is , min response is .
max gradient is 7.424798, min gradient is -8.000000, learning rate is 0.004448
Net1: layer conv1:max response is , min response is .
max gradient is 3.802171, min gradient is -8.000000, learning rate is 0.004448
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 0.993481, min gradient is -8.000000, learning rate is 0.000463
Net2: layer deconv3:max response is 27.476322, min response is -29.035097.
max gradient is 8.000000, min gradient is -4.315179, learning rate is 0.000232
Net2: layer bn50:max response is 19.780138, min response is -3.990500.
max gradient is 8.000000, min gradient is -2.456511, learning rate is 0.000463
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.869017, learning rate is 0.000232
Net2: layer bn49:max response is 9.343615, min response is -1.655902.
max gradient is 5.966851, min gradient is -8.000000, learning rate is 0.000463
Net2: layer deconv1:max response is , min response is .
max gradient is 7.861947, min gradient is -8.000000, learning rate is 0.000232
max inferred z is 4.08, min inferred z is -4.22, and std is 0.99
 4.26 s (23.5 data/s) [100/100]
training: epoch 68: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.821728, min gradient is -8.000000, learning rate is 0.004448
Net1: layer conv2:max response is , min response is .
max gradient is 6.852410, min gradient is -8.000000, learning rate is 0.004448
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.309355, learning rate is 0.004448
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.723676, learning rate is 0.000463
Net2: layer deconv3:max response is 24.003830, min response is -27.301292.
max gradient is 8.000000, min gradient is -6.670413, learning rate is 0.000232
Net2: layer bn50:max response is 17.737890, min response is -3.691601.
max gradient is 8.000000, min gradient is -4.592190, learning rate is 0.000463
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.791665, learning rate is 0.000232
Net2: layer bn49:max response is 7.776795, min response is -1.658813.
max gradient is 5.123169, min gradient is -8.000000, learning rate is 0.000463
Net2: layer deconv1:max response is , min response is .
max gradient is 6.841422, min gradient is -8.000000, learning rate is 0.000232
max inferred z is 3.91, min inferred z is -4.08, and std is 0.99
 4.35 s (23.0 data/s) [100/100]
training: epoch 68: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.373584, min gradient is -8.000000, learning rate is 0.004448
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.009033, learning rate is 0.004448
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.402078, learning rate is 0.004448
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.151289, learning rate is 0.000463
Net2: layer deconv3:max response is 24.542902, min response is -26.483585.
max gradient is 8.000000, min gradient is -7.099345, learning rate is 0.000232
Net2: layer bn50:max response is 17.895939, min response is -3.322490.
max gradient is 4.983077, min gradient is -8.000000, learning rate is 0.000463
Net2: layer deconv2:max response is , min response is .
max gradient is 7.558479, min gradient is -8.000000, learning rate is 0.000232
Net2: layer bn49:max response is 7.154291, min response is -1.680721.
max gradient is 8.000000, min gradient is -6.934443, learning rate is 0.000463
Net2: layer deconv1:max response is , min response is .
max gradient is 7.372841, min gradient is -8.000000, learning rate is 0.000232
max inferred z is 3.54, min inferred z is -3.69, and std is 0.99
 4.22 s (23.7 data/s) [100/100]
Loss: 1.8697
Iteration 69 / 200
training: epoch 69: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.599634, learning rate is 0.003692
Net1: layer conv2:max response is , min response is .
max gradient is 5.273153, min gradient is -8.000000, learning rate is 0.003692
Net1: layer conv1:max response is , min response is .
max gradient is 4.877697, min gradient is -8.000000, learning rate is 0.003692
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -5.601966, learning rate is 0.000461
Net2: layer deconv3:max response is 28.578152, min response is -25.999397.
max gradient is 5.412444, min gradient is -8.000000, learning rate is 0.000231
Net2: layer bn50:max response is 22.085224, min response is -3.731092.
max gradient is 8.000000, min gradient is -6.938865, learning rate is 0.000461
Net2: layer deconv2:max response is , min response is .
max gradient is 7.868127, min gradient is -8.000000, learning rate is 0.000231
Net2: layer bn49:max response is 8.451947, min response is -1.733620.
max gradient is 5.232257, min gradient is -8.000000, learning rate is 0.000461
Net2: layer deconv1:max response is , min response is .
max gradient is 7.546849, min gradient is -8.000000, learning rate is 0.000231
max inferred z is 3.82, min inferred z is -4.19, and std is 0.99
 4.17 s (24.0 data/s) [100/100]
training: epoch 69: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.915386, min gradient is -8.000000, learning rate is 0.003692
Net1: layer conv2:max response is , min response is .
max gradient is 6.560620, min gradient is -8.000000, learning rate is 0.003692
Net1: layer conv1:max response is , min response is .
max gradient is 6.198986, min gradient is -8.000000, learning rate is 0.003692
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -0.096948, min gradient is -8.000000, learning rate is 0.000461
Net2: layer deconv3:max response is 30.147356, min response is -24.588371.
max gradient is 8.000000, min gradient is -7.237866, learning rate is 0.000231
Net2: layer bn50:max response is 18.669851, min response is -3.202810.
max gradient is 5.712227, min gradient is -8.000000, learning rate is 0.000461
Net2: layer deconv2:max response is , min response is .
max gradient is 6.856462, min gradient is -8.000000, learning rate is 0.000231
Net2: layer bn49:max response is 8.140495, min response is -1.826089.
max gradient is 5.833342, min gradient is -8.000000, learning rate is 0.000461
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.323938, learning rate is 0.000231
max inferred z is 3.93, min inferred z is -4.43, and std is 0.99
 4.37 s (22.9 data/s) [100/100]
training: epoch 69: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000001, min gradient is -5.419208, learning rate is 0.003692
Net1: layer conv2:max response is , min response is .
max gradient is 5.659043, min gradient is -8.000000, learning rate is 0.003692
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.364871, learning rate is 0.003692
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -0.959569, learning rate is 0.000461
Net2: layer deconv3:max response is 27.545464, min response is -25.393543.
max gradient is 6.551959, min gradient is -8.000000, learning rate is 0.000231
Net2: layer bn50:max response is 19.266375, min response is -3.505587.
max gradient is 6.397993, min gradient is -8.000001, learning rate is 0.000461
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.707624, learning rate is 0.000231
Net2: layer bn49:max response is 8.987925, min response is -1.599695.
max gradient is 4.376109, min gradient is -8.000000, learning rate is 0.000461
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.566943, learning rate is 0.000231
max inferred z is 3.93, min inferred z is -4.05, and std is 0.99
 4.40 s (22.7 data/s) [100/100]
training: epoch 69: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.165639, min gradient is -8.000000, learning rate is 0.003692
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.750346, learning rate is 0.003692
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.935654, learning rate is 0.003692
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.988925, learning rate is 0.000461
Net2: layer deconv3:max response is 36.944519, min response is -28.625212.
max gradient is 6.575683, min gradient is -8.000000, learning rate is 0.000231
Net2: layer bn50:max response is 23.753742, min response is -2.989916.
max gradient is 3.219384, min gradient is -8.000000, learning rate is 0.000461
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.393584, learning rate is 0.000231
Net2: layer bn49:max response is 7.734564, min response is -1.687799.
max gradient is 8.000000, min gradient is -6.567073, learning rate is 0.000461
Net2: layer deconv1:max response is , min response is .
max gradient is 6.805969, min gradient is -8.000000, learning rate is 0.000231
max inferred z is 4.11, min inferred z is -4.01, and std is 0.99
 4.40 s (22.7 data/s) [100/100]
training: epoch 69: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.894975, min gradient is -8.000000, learning rate is 0.003692
Net1: layer conv2:max response is , min response is .
max gradient is 8.000001, min gradient is -6.549965, learning rate is 0.003692
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.250939, learning rate is 0.003692
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.924443, learning rate is 0.000461
Net2: layer deconv3:max response is 32.714550, min response is -25.944620.
max gradient is 7.739620, min gradient is -8.000000, learning rate is 0.000231
Net2: layer bn50:max response is 19.571831, min response is -3.501671.
max gradient is 3.007071, min gradient is -8.000000, learning rate is 0.000461
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.638148, learning rate is 0.000231
Net2: layer bn49:max response is 7.884813, min response is -1.750070.
max gradient is 8.000000, min gradient is -6.686614, learning rate is 0.000461
Net2: layer deconv1:max response is , min response is .
max gradient is 7.774032, min gradient is -8.000000, learning rate is 0.000231
max inferred z is 3.97, min inferred z is -4.00, and std is 0.99
 4.29 s (23.3 data/s) [100/100]
training: epoch 69: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.100582, learning rate is 0.003692
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.584571, learning rate is 0.003692
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -5.017024, learning rate is 0.003692
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.839139, learning rate is 0.000461
Net2: layer deconv3:max response is 31.652756, min response is -28.741381.
max gradient is 4.133004, min gradient is -8.000000, learning rate is 0.000231
Net2: layer bn50:max response is 20.242039, min response is -3.688271.
max gradient is 2.464588, min gradient is -8.000000, learning rate is 0.000461
Net2: layer deconv2:max response is , min response is .
max gradient is 7.127146, min gradient is -8.000000, learning rate is 0.000231
Net2: layer bn49:max response is 9.136604, min response is -1.819941.
max gradient is 7.551775, min gradient is -8.000000, learning rate is 0.000461
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.952754, learning rate is 0.000231
max inferred z is 4.08, min inferred z is -3.74, and std is 0.99
 4.19 s (23.9 data/s) [100/100]
training: epoch 69: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.907972, min gradient is -8.000000, learning rate is 0.003692
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.047789, learning rate is 0.003692
Net1: layer conv1:max response is , min response is .
max gradient is 4.208965, min gradient is -8.000000, learning rate is 0.003692
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -2.811777, learning rate is 0.000461
Net2: layer deconv3:max response is 24.702803, min response is -34.328392.
max gradient is 8.000000, min gradient is -6.545925, learning rate is 0.000231
Net2: layer bn50:max response is 16.757971, min response is -3.664510.
max gradient is 8.000000, min gradient is -4.691467, learning rate is 0.000461
Net2: layer deconv2:max response is , min response is .
max gradient is 6.782928, min gradient is -8.000000, learning rate is 0.000231
Net2: layer bn49:max response is 8.197843, min response is -2.070447.
max gradient is 7.454573, min gradient is -8.000000, learning rate is 0.000461
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.404097, learning rate is 0.000231
max inferred z is 4.07, min inferred z is -3.80, and std is 0.99
 4.32 s (23.2 data/s) [100/100]
training: epoch 69: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.486705, min gradient is -8.000000, learning rate is 0.003692
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.697184, learning rate is 0.003692
Net1: layer conv1:max response is , min response is .
max gradient is 4.768662, min gradient is -8.000000, learning rate is 0.003692
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 5.736179, min gradient is -8.000000, learning rate is 0.000461
Net2: layer deconv3:max response is 26.671404, min response is -29.123407.
max gradient is 8.000000, min gradient is -6.018664, learning rate is 0.000231
Net2: layer bn50:max response is 17.682180, min response is -3.473632.
max gradient is 8.000000, min gradient is -2.916638, learning rate is 0.000461
Net2: layer deconv2:max response is , min response is .
max gradient is 6.895908, min gradient is -8.000000, learning rate is 0.000231
Net2: layer bn49:max response is 7.695324, min response is -1.704914.
max gradient is 8.000000, min gradient is -7.104673, learning rate is 0.000461
Net2: layer deconv1:max response is , min response is .
max gradient is 7.483870, min gradient is -8.000000, learning rate is 0.000231
max inferred z is 4.13, min inferred z is -4.62, and std is 0.99
 4.28 s (23.4 data/s) [100/100]
training: epoch 69: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.660215, learning rate is 0.003692
Net1: layer conv2:max response is , min response is .
max gradient is 5.975888, min gradient is -8.000000, learning rate is 0.003692
Net1: layer conv1:max response is , min response is .
max gradient is 6.408423, min gradient is -8.000000, learning rate is 0.003692
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.803659, learning rate is 0.000461
Net2: layer deconv3:max response is 29.806274, min response is -26.408606.
max gradient is 6.900151, min gradient is -8.000000, learning rate is 0.000231
Net2: layer bn50:max response is 20.120018, min response is -3.361517.
max gradient is 8.000000, min gradient is -7.147426, learning rate is 0.000461
Net2: layer deconv2:max response is , min response is .
max gradient is 7.908570, min gradient is -8.000000, learning rate is 0.000231
Net2: layer bn49:max response is 8.027855, min response is -1.786565.
max gradient is 4.940157, min gradient is -8.000000, learning rate is 0.000461
Net2: layer deconv1:max response is , min response is .
max gradient is 7.452310, min gradient is -8.000000, learning rate is 0.000231
max inferred z is 4.23, min inferred z is -3.95, and std is 0.99
 4.24 s (23.6 data/s) [100/100]
training: epoch 69: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.676116, min gradient is -8.000000, learning rate is 0.003692
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.169124, learning rate is 0.003692
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.135035, learning rate is 0.003692
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.716706, learning rate is 0.000461
Net2: layer deconv3:max response is 30.557756, min response is -28.207497.
max gradient is 6.846431, min gradient is -8.000000, learning rate is 0.000231
Net2: layer bn50:max response is 20.195400, min response is -3.253489.
max gradient is 7.042941, min gradient is -8.000000, learning rate is 0.000461
Net2: layer deconv2:max response is , min response is .
max gradient is 7.038797, min gradient is -8.000000, learning rate is 0.000231
Net2: layer bn49:max response is 8.224699, min response is -1.823706.
max gradient is 6.129731, min gradient is -8.000000, learning rate is 0.000461
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.820309, learning rate is 0.000231
max inferred z is 3.79, min inferred z is -3.82, and std is 0.99
 4.35 s (23.0 data/s) [100/100]
Loss: 1.9096
Iteration 70 / 200
training: epoch 70: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.838760, min gradient is -8.000000, learning rate is 0.003692
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.443771, learning rate is 0.003692
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.014444, learning rate is 0.003692
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -0.873613, learning rate is 0.000459
Net2: layer deconv3:max response is 25.824703, min response is -27.107176.
max gradient is 8.000000, min gradient is -5.217991, learning rate is 0.000230
Net2: layer bn50:max response is 22.704378, min response is -3.697546.
max gradient is 8.000000, min gradient is -4.691846, learning rate is 0.000459
Net2: layer deconv2:max response is , min response is .
max gradient is 6.595786, min gradient is -8.000000, learning rate is 0.000230
Net2: layer bn49:max response is 8.456978, min response is -1.949365.
max gradient is 7.217006, min gradient is -8.000000, learning rate is 0.000459
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.026531, learning rate is 0.000230
max inferred z is 3.80, min inferred z is -3.77, and std is 1.01
 4.19 s (23.8 data/s) [100/100]
training: epoch 70: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.330443, min gradient is -8.000001, learning rate is 0.003692
Net1: layer conv2:max response is , min response is .
max gradient is 7.220247, min gradient is -8.000000, learning rate is 0.003692
Net1: layer conv1:max response is , min response is .
max gradient is 6.256391, min gradient is -8.000000, learning rate is 0.003692
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 0.523755, min gradient is -8.000000, learning rate is 0.000459
Net2: layer deconv3:max response is 28.816708, min response is -33.454735.
max gradient is 8.000000, min gradient is -5.487163, learning rate is 0.000230
Net2: layer bn50:max response is 17.665649, min response is -3.533083.
max gradient is 8.000000, min gradient is -3.708679, learning rate is 0.000459
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.388610, learning rate is 0.000230
Net2: layer bn49:max response is 8.081259, min response is -1.836084.
max gradient is 5.442760, min gradient is -8.000000, learning rate is 0.000459
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.038405, learning rate is 0.000230
max inferred z is 4.30, min inferred z is -4.65, and std is 1.01
 4.23 s (23.6 data/s) [100/100]
training: epoch 70: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.726287, learning rate is 0.003692
Net1: layer conv2:max response is , min response is .
max gradient is 6.256069, min gradient is -8.000000, learning rate is 0.003692
Net1: layer conv1:max response is , min response is .
max gradient is 7.458785, min gradient is -8.000000, learning rate is 0.003692
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 0.534270, learning rate is 0.000459
Net2: layer deconv3:max response is 25.548649, min response is -29.454628.
max gradient is 4.078263, min gradient is -8.000000, learning rate is 0.000230
Net2: layer bn50:max response is 16.732183, min response is -3.410026.
max gradient is 1.796701, min gradient is -8.000000, learning rate is 0.000459
Net2: layer deconv2:max response is , min response is .
max gradient is 6.237202, min gradient is -8.000000, learning rate is 0.000230
Net2: layer bn49:max response is 7.578004, min response is -1.933842.
max gradient is 8.000000, min gradient is -7.485540, learning rate is 0.000459
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.351793, learning rate is 0.000230
max inferred z is 3.76, min inferred z is -4.24, and std is 1.01
 4.27 s (23.4 data/s) [100/100]
training: epoch 70: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.826242, min gradient is -8.000000, learning rate is 0.003692
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.158226, learning rate is 0.003692
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -2.519022, learning rate is 0.003692
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.985806, learning rate is 0.000459
Net2: layer deconv3:max response is 23.580599, min response is -24.766687.
max gradient is 4.864896, min gradient is -8.000000, learning rate is 0.000230
Net2: layer bn50:max response is 16.003212, min response is -3.340063.
max gradient is 3.055965, min gradient is -8.000000, learning rate is 0.000459
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.367337, learning rate is 0.000230
Net2: layer bn49:max response is 7.460231, min response is -1.857473.
max gradient is 8.000000, min gradient is -5.153603, learning rate is 0.000459
Net2: layer deconv1:max response is , min response is .
max gradient is 6.963000, min gradient is -8.000000, learning rate is 0.000230
max inferred z is 4.12, min inferred z is -3.96, and std is 1.01
 4.21 s (23.7 data/s) [100/100]
training: epoch 70: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.449058, min gradient is -8.000000, learning rate is 0.003692
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.340408, learning rate is 0.003692
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.583044, learning rate is 0.003692
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.629791, learning rate is 0.000459
Net2: layer deconv3:max response is 26.967516, min response is -36.472878.
max gradient is 8.000000, min gradient is -7.696373, learning rate is 0.000230
Net2: layer bn50:max response is 18.135338, min response is -3.398195.
max gradient is 4.378502, min gradient is -8.000000, learning rate is 0.000459
Net2: layer deconv2:max response is , min response is .
max gradient is 7.266059, min gradient is -8.000000, learning rate is 0.000230
Net2: layer bn49:max response is 9.351132, min response is -1.959671.
max gradient is 5.878319, min gradient is -8.000000, learning rate is 0.000459
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.603365, learning rate is 0.000230
max inferred z is 4.38, min inferred z is -3.76, and std is 1.01
 4.30 s (23.2 data/s) [100/100]
training: epoch 70: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.284544, learning rate is 0.003692
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.296468, learning rate is 0.003692
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.574201, learning rate is 0.003692
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000001, min gradient is 4.547097, learning rate is 0.000459
Net2: layer deconv3:max response is 28.783714, min response is -30.517328.
max gradient is 7.609869, min gradient is -8.000000, learning rate is 0.000230
Net2: layer bn50:max response is 19.292936, min response is -3.358557.
max gradient is 8.000000, min gradient is -6.209273, learning rate is 0.000459
Net2: layer deconv2:max response is , min response is .
max gradient is 7.325277, min gradient is -8.000000, learning rate is 0.000230
Net2: layer bn49:max response is 8.652135, min response is -1.996494.
max gradient is 8.000000, min gradient is -6.304513, learning rate is 0.000459
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.615071, learning rate is 0.000230
max inferred z is 3.74, min inferred z is -4.07, and std is 1.01
 4.40 s (22.7 data/s) [100/100]
training: epoch 70: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.763395, min gradient is -8.000000, learning rate is 0.003692
Net1: layer conv2:max response is , min response is .
max gradient is 8.000001, min gradient is -7.123466, learning rate is 0.003692
Net1: layer conv1:max response is , min response is .
max gradient is 6.037558, min gradient is -8.000000, learning rate is 0.003692
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -3.769660, learning rate is 0.000459
Net2: layer deconv3:max response is 23.686094, min response is -32.759972.
max gradient is 3.226485, min gradient is -8.000000, learning rate is 0.000230
Net2: layer bn50:max response is 16.783558, min response is -3.670456.
max gradient is 8.000000, min gradient is -4.657518, learning rate is 0.000459
Net2: layer deconv2:max response is , min response is .
max gradient is 6.338380, min gradient is -8.000000, learning rate is 0.000230
Net2: layer bn49:max response is 7.784261, min response is -1.720181.
max gradient is 7.885569, min gradient is -8.000000, learning rate is 0.000459
Net2: layer deconv1:max response is , min response is .
max gradient is 7.816673, min gradient is -8.000000, learning rate is 0.000230
max inferred z is 3.72, min inferred z is -3.88, and std is 1.01
 4.45 s (22.5 data/s) [100/100]
training: epoch 70: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.067612, min gradient is -8.000000, learning rate is 0.003692
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.844359, learning rate is 0.003692
Net1: layer conv1:max response is , min response is .
max gradient is 3.415145, min gradient is -8.000000, learning rate is 0.003692
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -1.033031, min gradient is -8.000000, learning rate is 0.000459
Net2: layer deconv3:max response is 27.720678, min response is -27.992912.
max gradient is 8.000000, min gradient is -6.433804, learning rate is 0.000230
Net2: layer bn50:max response is 20.920767, min response is -3.118944.
max gradient is 8.000001, min gradient is -3.526918, learning rate is 0.000459
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.449266, learning rate is 0.000230
Net2: layer bn49:max response is 8.647268, min response is -1.846956.
max gradient is 6.258307, min gradient is -8.000000, learning rate is 0.000459
Net2: layer deconv1:max response is , min response is .
max gradient is 7.140214, min gradient is -8.000000, learning rate is 0.000230
max inferred z is 4.31, min inferred z is -4.05, and std is 1.01
 4.39 s (22.8 data/s) [100/100]
training: epoch 70: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.159141, min gradient is -8.000000, learning rate is 0.003692
Net1: layer conv2:max response is , min response is .
max gradient is 4.508264, min gradient is -8.000000, learning rate is 0.003692
Net1: layer conv1:max response is , min response is .
max gradient is 5.915711, min gradient is -8.000000, learning rate is 0.003692
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.049239, learning rate is 0.000459
Net2: layer deconv3:max response is 28.935314, min response is -25.369602.
max gradient is 6.009632, min gradient is -8.000000, learning rate is 0.000230
Net2: layer bn50:max response is 19.201571, min response is -3.553566.
max gradient is 8.000000, min gradient is -5.065825, learning rate is 0.000459
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.400967, learning rate is 0.000230
Net2: layer bn49:max response is 8.467205, min response is -1.641321.
max gradient is 6.269707, min gradient is -8.000000, learning rate is 0.000459
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.598721, learning rate is 0.000230
max inferred z is 3.74, min inferred z is -4.35, and std is 1.01
 4.32 s (23.1 data/s) [100/100]
training: epoch 70: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.421356, min gradient is -8.000000, learning rate is 0.003692
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.972658, learning rate is 0.003692
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -2.560419, learning rate is 0.003692
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.183732, learning rate is 0.000459
Net2: layer deconv3:max response is 29.026812, min response is -25.761694.
max gradient is 6.638202, min gradient is -8.000000, learning rate is 0.000230
Net2: layer bn50:max response is 18.699903, min response is -2.825163.
max gradient is 5.284426, min gradient is -8.000000, learning rate is 0.000459
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.603358, learning rate is 0.000230
Net2: layer bn49:max response is 9.142543, min response is -1.932714.
max gradient is 5.201909, min gradient is -8.000000, learning rate is 0.000459
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.820880, learning rate is 0.000230
max inferred z is 3.54, min inferred z is -3.77, and std is 1.01
 4.42 s (22.6 data/s) [100/100]
Loss: 1.8627
Iteration 71 / 200
training: epoch 71: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.567574, min gradient is -8.000000, learning rate is 0.003064
Net1: layer conv2:max response is , min response is .
max gradient is 7.217251, min gradient is -8.000000, learning rate is 0.003064
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.678100, learning rate is 0.003064
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -7.213383, learning rate is 0.000457
Net2: layer deconv3:max response is 27.965481, min response is -26.709879.
max gradient is 8.000000, min gradient is -7.172922, learning rate is 0.000229
Net2: layer bn50:max response is 20.149143, min response is -3.387597.
max gradient is 7.406201, min gradient is -8.000000, learning rate is 0.000457
Net2: layer deconv2:max response is , min response is .
max gradient is 5.776085, min gradient is -8.000000, learning rate is 0.000229
Net2: layer bn49:max response is 7.933526, min response is -1.872605.
max gradient is 5.986142, min gradient is -8.000000, learning rate is 0.000457
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.687217, learning rate is 0.000229
max inferred z is 3.99, min inferred z is -4.18, and std is 1.00
 4.18 s (23.9 data/s) [100/100]
training: epoch 71: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.174023, min gradient is -8.000000, learning rate is 0.003064
Net1: layer conv2:max response is , min response is .
max gradient is 5.803640, min gradient is -8.000000, learning rate is 0.003064
Net1: layer conv1:max response is , min response is .
max gradient is 5.885334, min gradient is -8.000000, learning rate is 0.003064
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 0.176645, min gradient is -8.000000, learning rate is 0.000457
Net2: layer deconv3:max response is 28.693993, min response is -29.880335.
max gradient is 8.000000, min gradient is -5.217902, learning rate is 0.000229
Net2: layer bn50:max response is 17.744215, min response is -3.012013.
max gradient is 7.615540, min gradient is -8.000000, learning rate is 0.000457
Net2: layer deconv2:max response is , min response is .
max gradient is 6.731075, min gradient is -8.000000, learning rate is 0.000229
Net2: layer bn49:max response is 9.025803, min response is -1.911964.
max gradient is 4.830879, min gradient is -8.000000, learning rate is 0.000457
Net2: layer deconv1:max response is , min response is .
max gradient is 6.373539, min gradient is -8.000000, learning rate is 0.000229
max inferred z is 3.69, min inferred z is -4.09, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
training: epoch 71: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.740644, min gradient is -8.000000, learning rate is 0.003064
Net1: layer conv2:max response is , min response is .
max gradient is 7.767288, min gradient is -8.000000, learning rate is 0.003064
Net1: layer conv1:max response is , min response is .
max gradient is 7.939877, min gradient is -8.000000, learning rate is 0.003064
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 6.297143, min gradient is -8.000000, learning rate is 0.000457
Net2: layer deconv3:max response is 23.786407, min response is -28.334671.
max gradient is 6.066411, min gradient is -8.000000, learning rate is 0.000229
Net2: layer bn50:max response is 16.280659, min response is -3.136669.
max gradient is 3.330117, min gradient is -8.000000, learning rate is 0.000457
Net2: layer deconv2:max response is , min response is .
max gradient is 7.922151, min gradient is -8.000000, learning rate is 0.000229
Net2: layer bn49:max response is 8.290773, min response is -1.596016.
max gradient is 5.955313, min gradient is -8.000000, learning rate is 0.000457
Net2: layer deconv1:max response is , min response is .
max gradient is 7.885972, min gradient is -8.000000, learning rate is 0.000229
max inferred z is 3.91, min inferred z is -3.87, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 71: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.349353, min gradient is -8.000000, learning rate is 0.003064
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.094417, learning rate is 0.003064
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.599417, learning rate is 0.003064
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.043583, learning rate is 0.000457
Net2: layer deconv3:max response is 30.363420, min response is -30.414902.
max gradient is 7.696673, min gradient is -8.000000, learning rate is 0.000229
Net2: layer bn50:max response is 20.156918, min response is -3.832124.
max gradient is 2.034012, min gradient is -8.000000, learning rate is 0.000457
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.862872, learning rate is 0.000229
Net2: layer bn49:max response is 8.807096, min response is -2.100093.
max gradient is 3.218611, min gradient is -8.000000, learning rate is 0.000457
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.684929, learning rate is 0.000229
max inferred z is 4.12, min inferred z is -3.56, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
training: epoch 71: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.815235, learning rate is 0.003064
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.726946, learning rate is 0.003064
Net1: layer conv1:max response is , min response is .
max gradient is 5.501434, min gradient is -8.000000, learning rate is 0.003064
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.984227, learning rate is 0.000457
Net2: layer deconv3:max response is 32.469742, min response is -29.234701.
max gradient is 5.483638, min gradient is -8.000000, learning rate is 0.000229
Net2: layer bn50:max response is 18.256001, min response is -3.325873.
max gradient is 7.296054, min gradient is -8.000000, learning rate is 0.000457
Net2: layer deconv2:max response is , min response is .
max gradient is 5.317692, min gradient is -8.000000, learning rate is 0.000229
Net2: layer bn49:max response is 9.319576, min response is -1.877847.
max gradient is 6.138974, min gradient is -8.000000, learning rate is 0.000457
Net2: layer deconv1:max response is , min response is .
max gradient is 6.572020, min gradient is -8.000000, learning rate is 0.000229
max inferred z is 3.94, min inferred z is -3.92, and std is 1.00
 4.38 s (22.9 data/s) [100/100]
training: epoch 71: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.992250, learning rate is 0.003064
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.863318, learning rate is 0.003064
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.436563, learning rate is 0.003064
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.073249, learning rate is 0.000457
Net2: layer deconv3:max response is 23.321699, min response is -27.269703.
max gradient is 6.013902, min gradient is -8.000000, learning rate is 0.000229
Net2: layer bn50:max response is 17.302582, min response is -3.335032.
max gradient is 3.764576, min gradient is -8.000000, learning rate is 0.000457
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.967710, learning rate is 0.000229
Net2: layer bn49:max response is 8.595860, min response is -2.026032.
max gradient is 6.171534, min gradient is -8.000000, learning rate is 0.000457
Net2: layer deconv1:max response is , min response is .
max gradient is 6.421254, min gradient is -8.000000, learning rate is 0.000229
max inferred z is 4.06, min inferred z is -4.05, and std is 1.00
 4.30 s (23.2 data/s) [100/100]
training: epoch 71: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.591081, min gradient is -8.000000, learning rate is 0.003064
Net1: layer conv2:max response is , min response is .
max gradient is 7.815089, min gradient is -8.000000, learning rate is 0.003064
Net1: layer conv1:max response is , min response is .
max gradient is 4.716965, min gradient is -8.000000, learning rate is 0.003064
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.184519, learning rate is 0.000457
Net2: layer deconv3:max response is 22.760874, min response is -30.441061.
max gradient is 7.048163, min gradient is -8.000000, learning rate is 0.000229
Net2: layer bn50:max response is 16.946548, min response is -3.289106.
max gradient is 8.000000, min gradient is -5.432828, learning rate is 0.000457
Net2: layer deconv2:max response is , min response is .
max gradient is 7.855068, min gradient is -8.000000, learning rate is 0.000229
Net2: layer bn49:max response is 9.675248, min response is -1.784444.
max gradient is 5.665364, min gradient is -8.000000, learning rate is 0.000457
Net2: layer deconv1:max response is , min response is .
max gradient is 7.755434, min gradient is -8.000000, learning rate is 0.000229
max inferred z is 3.88, min inferred z is -4.11, and std is 1.00
 4.28 s (23.3 data/s) [100/100]
training: epoch 71: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.223748, min gradient is -8.000000, learning rate is 0.003064
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.208666, learning rate is 0.003064
Net1: layer conv1:max response is , min response is .
max gradient is 4.007410, min gradient is -8.000000, learning rate is 0.003064
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -3.148673, learning rate is 0.000457
Net2: layer deconv3:max response is 23.279488, min response is -41.487995.
max gradient is 8.000000, min gradient is -6.270983, learning rate is 0.000229
Net2: layer bn50:max response is 17.135201, min response is -3.197894.
max gradient is 8.000000, min gradient is -3.515241, learning rate is 0.000457
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.314693, learning rate is 0.000229
Net2: layer bn49:max response is 8.418546, min response is -2.457362.
max gradient is 8.000001, min gradient is -7.120776, learning rate is 0.000457
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.228800, learning rate is 0.000229
max inferred z is 4.29, min inferred z is -4.19, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
training: epoch 71: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.568769, min gradient is -8.000000, learning rate is 0.003064
Net1: layer conv2:max response is , min response is .
max gradient is 5.525763, min gradient is -8.000000, learning rate is 0.003064
Net1: layer conv1:max response is , min response is .
max gradient is 6.662052, min gradient is -8.000000, learning rate is 0.003064
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -0.509069, learning rate is 0.000457
Net2: layer deconv3:max response is 23.079958, min response is -30.138872.
max gradient is 8.000001, min gradient is -7.420847, learning rate is 0.000229
Net2: layer bn50:max response is 16.493340, min response is -3.106917.
max gradient is 6.235327, min gradient is -8.000000, learning rate is 0.000457
Net2: layer deconv2:max response is , min response is .
max gradient is 6.650531, min gradient is -8.000000, learning rate is 0.000229
Net2: layer bn49:max response is 8.308668, min response is -1.708542.
max gradient is 8.000000, min gradient is -5.312335, learning rate is 0.000457
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.939849, learning rate is 0.000229
max inferred z is 3.86, min inferred z is -4.24, and std is 1.00
 4.28 s (23.4 data/s) [100/100]
training: epoch 71: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.602683, min gradient is -8.000000, learning rate is 0.003064
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.772410, learning rate is 0.003064
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.883274, learning rate is 0.003064
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -0.749121, learning rate is 0.000457
Net2: layer deconv3:max response is 25.571150, min response is -31.650951.
max gradient is 7.446742, min gradient is -8.000000, learning rate is 0.000229
Net2: layer bn50:max response is 18.901114, min response is -3.175075.
max gradient is 5.180288, min gradient is -8.000000, learning rate is 0.000457
Net2: layer deconv2:max response is , min response is .
max gradient is 7.490316, min gradient is -8.000000, learning rate is 0.000229
Net2: layer bn49:max response is 8.681250, min response is -1.977618.
max gradient is 5.085219, min gradient is -8.000000, learning rate is 0.000457
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.083969, learning rate is 0.000229
max inferred z is 3.99, min inferred z is -4.33, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
Loss: 1.8512
Iteration 72 / 200
training: epoch 72: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.699516, min gradient is -8.000000, learning rate is 0.003064
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.524768, learning rate is 0.003064
Net1: layer conv1:max response is , min response is .
max gradient is 3.672523, min gradient is -8.000000, learning rate is 0.003064
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -2.651900, min gradient is -8.000000, learning rate is 0.000455
Net2: layer deconv3:max response is 27.765284, min response is -30.576904.
max gradient is 8.000000, min gradient is -6.616246, learning rate is 0.000228
Net2: layer bn50:max response is 18.763901, min response is -3.658807.
max gradient is 8.000000, min gradient is -5.153589, learning rate is 0.000455
Net2: layer deconv2:max response is , min response is .
max gradient is 6.494743, min gradient is -8.000000, learning rate is 0.000228
Net2: layer bn49:max response is 8.610992, min response is -1.706732.
max gradient is 7.282829, min gradient is -8.000000, learning rate is 0.000455
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.485451, learning rate is 0.000228
max inferred z is 3.69, min inferred z is -4.27, and std is 1.01
 4.15 s (24.1 data/s) [100/100]
training: epoch 72: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.910071, min gradient is -8.000000, learning rate is 0.003064
Net1: layer conv2:max response is , min response is .
max gradient is 6.675120, min gradient is -8.000000, learning rate is 0.003064
Net1: layer conv1:max response is , min response is .
max gradient is 6.313212, min gradient is -8.000000, learning rate is 0.003064
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -0.571199, min gradient is -8.000000, learning rate is 0.000455
Net2: layer deconv3:max response is 28.470032, min response is -31.629961.
max gradient is 8.000000, min gradient is -6.367212, learning rate is 0.000228
Net2: layer bn50:max response is 19.464674, min response is -3.267567.
max gradient is 5.817213, min gradient is -8.000000, learning rate is 0.000455
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.936054, learning rate is 0.000228
Net2: layer bn49:max response is 8.833248, min response is -2.217390.
max gradient is 4.883246, min gradient is -8.000000, learning rate is 0.000455
Net2: layer deconv1:max response is , min response is .
max gradient is 6.427533, min gradient is -8.000000, learning rate is 0.000228
max inferred z is 3.89, min inferred z is -4.05, and std is 1.01
 4.22 s (23.7 data/s) [100/100]
training: epoch 72: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.694262, min gradient is -8.000000, learning rate is 0.003064
Net1: layer conv2:max response is , min response is .
max gradient is 5.621088, min gradient is -8.000000, learning rate is 0.003064
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.850111, learning rate is 0.003064
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -5.773192, learning rate is 0.000455
Net2: layer deconv3:max response is 26.374685, min response is -31.745672.
max gradient is 8.000000, min gradient is -7.536372, learning rate is 0.000228
Net2: layer bn50:max response is 19.210543, min response is -3.062894.
max gradient is 5.065510, min gradient is -8.000000, learning rate is 0.000455
Net2: layer deconv2:max response is , min response is .
max gradient is 7.164742, min gradient is -8.000000, learning rate is 0.000228
Net2: layer bn49:max response is 9.212963, min response is -1.777717.
max gradient is 8.000000, min gradient is -6.154194, learning rate is 0.000455
Net2: layer deconv1:max response is , min response is .
max gradient is 5.920172, min gradient is -8.000000, learning rate is 0.000228
max inferred z is 4.37, min inferred z is -4.08, and std is 1.01
 4.20 s (23.8 data/s) [100/100]
training: epoch 72: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.387974, min gradient is -8.000000, learning rate is 0.003064
Net1: layer conv2:max response is , min response is .
max gradient is 6.936379, min gradient is -8.000000, learning rate is 0.003064
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -2.694707, learning rate is 0.003064
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.397950, learning rate is 0.000455
Net2: layer deconv3:max response is 25.184975, min response is -35.184147.
max gradient is 7.344158, min gradient is -8.000000, learning rate is 0.000228
Net2: layer bn50:max response is 15.966311, min response is -3.327276.
max gradient is 2.623753, min gradient is -8.000000, learning rate is 0.000455
Net2: layer deconv2:max response is , min response is .
max gradient is 7.654747, min gradient is -8.000000, learning rate is 0.000228
Net2: layer bn49:max response is 10.623874, min response is -1.789279.
max gradient is 4.526248, min gradient is -8.000000, learning rate is 0.000455
Net2: layer deconv1:max response is , min response is .
max gradient is 7.377088, min gradient is -8.000000, learning rate is 0.000228
max inferred z is 4.05, min inferred z is -4.45, and std is 1.01
 4.46 s (22.4 data/s) [100/100]
training: epoch 72: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.655785, min gradient is -8.000000, learning rate is 0.003064
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.093005, learning rate is 0.003064
Net1: layer conv1:max response is , min response is .
max gradient is 6.448493, min gradient is -8.000000, learning rate is 0.003064
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.535964, learning rate is 0.000455
Net2: layer deconv3:max response is 24.651949, min response is -28.686420.
max gradient is 6.210442, min gradient is -8.000000, learning rate is 0.000228
Net2: layer bn50:max response is 16.036510, min response is -3.170930.
max gradient is 2.045048, min gradient is -8.000000, learning rate is 0.000455
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.176458, learning rate is 0.000228
Net2: layer bn49:max response is 10.142141, min response is -1.771672.
max gradient is 8.000000, min gradient is -6.333018, learning rate is 0.000455
Net2: layer deconv1:max response is , min response is .
max gradient is 7.509417, min gradient is -8.000000, learning rate is 0.000228
max inferred z is 3.93, min inferred z is -3.75, and std is 1.01
 4.43 s (22.6 data/s) [100/100]
training: epoch 72: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.442670, min gradient is -8.000000, learning rate is 0.003064
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.274349, learning rate is 0.003064
Net1: layer conv1:max response is , min response is .
max gradient is 6.385674, min gradient is -8.000000, learning rate is 0.003064
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.295989, learning rate is 0.000455
Net2: layer deconv3:max response is 27.003157, min response is -39.773216.
max gradient is 6.224801, min gradient is -8.000000, learning rate is 0.000228
Net2: layer bn50:max response is 18.317944, min response is -3.645823.
max gradient is 4.480613, min gradient is -8.000000, learning rate is 0.000455
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.796882, learning rate is 0.000228
Net2: layer bn49:max response is 8.776168, min response is -2.056554.
max gradient is 7.313695, min gradient is -8.000000, learning rate is 0.000455
Net2: layer deconv1:max response is , min response is .
max gradient is 5.755044, min gradient is -8.000000, learning rate is 0.000228
max inferred z is 4.00, min inferred z is -3.75, and std is 1.01
 4.34 s (23.1 data/s) [100/100]
training: epoch 72: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.330167, min gradient is -8.000000, learning rate is 0.003064
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.641529, learning rate is 0.003064
Net1: layer conv1:max response is , min response is .
max gradient is 6.111853, min gradient is -8.000000, learning rate is 0.003064
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.112969, learning rate is 0.000455
Net2: layer deconv3:max response is 29.519186, min response is -31.217953.
max gradient is 4.445275, min gradient is -8.000000, learning rate is 0.000228
Net2: layer bn50:max response is 20.275478, min response is -3.453193.
max gradient is 8.000000, min gradient is -3.641759, learning rate is 0.000455
Net2: layer deconv2:max response is , min response is .
max gradient is 7.436713, min gradient is -8.000000, learning rate is 0.000228
Net2: layer bn49:max response is 9.017317, min response is -1.850777.
max gradient is 7.995982, min gradient is -8.000000, learning rate is 0.000455
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.713626, learning rate is 0.000228
max inferred z is 3.60, min inferred z is -3.74, and std is 1.01
 4.38 s (22.9 data/s) [100/100]
training: epoch 72: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.971239, min gradient is -8.000000, learning rate is 0.003064
Net1: layer conv2:max response is , min response is .
max gradient is 7.764881, min gradient is -8.000001, learning rate is 0.003064
Net1: layer conv1:max response is , min response is .
max gradient is 3.319776, min gradient is -8.000000, learning rate is 0.003064
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -2.157480, min gradient is -8.000000, learning rate is 0.000455
Net2: layer deconv3:max response is 22.960911, min response is -28.992868.
max gradient is 8.000000, min gradient is -6.125676, learning rate is 0.000228
Net2: layer bn50:max response is 16.503780, min response is -3.392927.
max gradient is 8.000000, min gradient is -5.422099, learning rate is 0.000455
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.622169, learning rate is 0.000228
Net2: layer bn49:max response is 8.455298, min response is -1.687339.
max gradient is 7.242122, min gradient is -8.000000, learning rate is 0.000455
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.224927, learning rate is 0.000228
max inferred z is 3.73, min inferred z is -3.62, and std is 1.01
 4.39 s (22.8 data/s) [100/100]
training: epoch 72: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.163697, min gradient is -8.000000, learning rate is 0.003064
Net1: layer conv2:max response is , min response is .
max gradient is 5.038120, min gradient is -8.000000, learning rate is 0.003064
Net1: layer conv1:max response is , min response is .
max gradient is 4.843282, min gradient is -8.000000, learning rate is 0.003064
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.066551, learning rate is 0.000455
Net2: layer deconv3:max response is 30.136526, min response is -34.979118.
max gradient is 8.000001, min gradient is -6.200012, learning rate is 0.000228
Net2: layer bn50:max response is 16.802500, min response is -3.310433.
max gradient is 8.000000, min gradient is -3.627408, learning rate is 0.000455
Net2: layer deconv2:max response is , min response is .
max gradient is 6.858638, min gradient is -8.000000, learning rate is 0.000228
Net2: layer bn49:max response is 9.270630, min response is -1.982736.
max gradient is 8.000000, min gradient is -5.468513, learning rate is 0.000455
Net2: layer deconv1:max response is , min response is .
max gradient is 7.013117, min gradient is -8.000000, learning rate is 0.000228
max inferred z is 4.06, min inferred z is -3.87, and std is 1.01
 4.34 s (23.0 data/s) [100/100]
training: epoch 72: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.220380, min gradient is -8.000000, learning rate is 0.003064
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.494022, learning rate is 0.003064
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.091292, learning rate is 0.003064
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.311670, learning rate is 0.000455
Net2: layer deconv3:max response is 24.325411, min response is -28.315964.
max gradient is 7.653442, min gradient is -8.000000, learning rate is 0.000228
Net2: layer bn50:max response is 17.927427, min response is -3.092030.
max gradient is 3.411692, min gradient is -8.000000, learning rate is 0.000455
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.436658, learning rate is 0.000228
Net2: layer bn49:max response is 9.566813, min response is -1.781886.
max gradient is 5.413580, min gradient is -8.000000, learning rate is 0.000455
Net2: layer deconv1:max response is , min response is .
max gradient is 7.347619, min gradient is -8.000000, learning rate is 0.000228
max inferred z is 4.00, min inferred z is -4.31, and std is 1.01
 4.16 s (24.0 data/s) [100/100]
Loss: 1.762
Iteration 73 / 200
training: epoch 73: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.292173, min gradient is -8.000000, learning rate is 0.002543
Net1: layer conv2:max response is , min response is .
max gradient is 6.630096, min gradient is -8.000000, learning rate is 0.002543
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.949320, learning rate is 0.002543
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 6.023598, min gradient is -8.000000, learning rate is 0.000453
Net2: layer deconv3:max response is 26.263933, min response is -29.295219.
max gradient is 8.000000, min gradient is -7.413084, learning rate is 0.000227
Net2: layer bn50:max response is 18.051760, min response is -3.606998.
max gradient is 8.000000, min gradient is -5.022674, learning rate is 0.000453
Net2: layer deconv2:max response is , min response is .
max gradient is 7.324578, min gradient is -8.000000, learning rate is 0.000227
Net2: layer bn49:max response is 8.684757, min response is -1.833544.
max gradient is 8.000000, min gradient is -6.991561, learning rate is 0.000453
Net2: layer deconv1:max response is , min response is .
max gradient is 7.655434, min gradient is -8.000000, learning rate is 0.000227
max inferred z is 3.89, min inferred z is -3.72, and std is 1.00
 4.17 s (24.0 data/s) [100/100]
training: epoch 73: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.307880, min gradient is -8.000000, learning rate is 0.002543
Net1: layer conv2:max response is , min response is .
max gradient is 7.936841, min gradient is -8.000000, learning rate is 0.002543
Net1: layer conv1:max response is , min response is .
max gradient is 5.867637, min gradient is -8.000000, learning rate is 0.002543
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -4.083266, learning rate is 0.000453
Net2: layer deconv3:max response is 30.957157, min response is -31.991968.
max gradient is 8.000000, min gradient is -6.666132, learning rate is 0.000227
Net2: layer bn50:max response is 18.442032, min response is -3.307249.
max gradient is 6.432896, min gradient is -8.000000, learning rate is 0.000453
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.924323, learning rate is 0.000227
Net2: layer bn49:max response is 9.162800, min response is -2.029610.
max gradient is 8.000000, min gradient is -7.439234, learning rate is 0.000453
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.601330, learning rate is 0.000227
max inferred z is 4.15, min inferred z is -4.09, and std is 1.00
 4.23 s (23.6 data/s) [100/100]
training: epoch 73: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.934200, min gradient is -8.000000, learning rate is 0.002543
Net1: layer conv2:max response is , min response is .
max gradient is 7.098442, min gradient is -8.000000, learning rate is 0.002543
Net1: layer conv1:max response is , min response is .
max gradient is 7.060548, min gradient is -8.000000, learning rate is 0.002543
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.364563, learning rate is 0.000453
Net2: layer deconv3:max response is 27.676243, min response is -25.882105.
max gradient is 7.858596, min gradient is -8.000000, learning rate is 0.000227
Net2: layer bn50:max response is 16.242290, min response is -3.152672.
max gradient is 6.816800, min gradient is -8.000000, learning rate is 0.000453
Net2: layer deconv2:max response is , min response is .
max gradient is 7.374033, min gradient is -8.000000, learning rate is 0.000227
Net2: layer bn49:max response is 9.856855, min response is -2.029871.
max gradient is 8.000000, min gradient is -7.166903, learning rate is 0.000453
Net2: layer deconv1:max response is , min response is .
max gradient is 7.480983, min gradient is -8.000000, learning rate is 0.000227
max inferred z is 3.58, min inferred z is -3.71, and std is 1.00
 4.18 s (23.9 data/s) [100/100]
training: epoch 73: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.769262, min gradient is -8.000000, learning rate is 0.002543
Net1: layer conv2:max response is , min response is .
max gradient is 7.786440, min gradient is -8.000000, learning rate is 0.002543
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -2.608337, learning rate is 0.002543
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.584480, learning rate is 0.000453
Net2: layer deconv3:max response is 26.565884, min response is -29.909773.
max gradient is 5.101415, min gradient is -8.000000, learning rate is 0.000227
Net2: layer bn50:max response is 18.209105, min response is -3.131217.
max gradient is 2.018566, min gradient is -8.000000, learning rate is 0.000453
Net2: layer deconv2:max response is , min response is .
max gradient is 6.909277, min gradient is -8.000000, learning rate is 0.000227
Net2: layer bn49:max response is 8.508727, min response is -2.037071.
max gradient is 6.063426, min gradient is -8.000000, learning rate is 0.000453
Net2: layer deconv1:max response is , min response is .
max gradient is 7.654555, min gradient is -8.000000, learning rate is 0.000227
max inferred z is 4.89, min inferred z is -4.06, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 73: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.720040, min gradient is -8.000000, learning rate is 0.002543
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.736820, learning rate is 0.002543
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.556040, learning rate is 0.002543
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.366296, learning rate is 0.000453
Net2: layer deconv3:max response is 29.293512, min response is -33.506676.
max gradient is 4.692412, min gradient is -8.000000, learning rate is 0.000227
Net2: layer bn50:max response is 18.346914, min response is -3.272014.
max gradient is 2.489591, min gradient is -8.000000, learning rate is 0.000453
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.186082, learning rate is 0.000227
Net2: layer bn49:max response is 10.645080, min response is -2.283875.
max gradient is 8.000000, min gradient is -5.312431, learning rate is 0.000453
Net2: layer deconv1:max response is , min response is .
max gradient is 7.818956, min gradient is -8.000000, learning rate is 0.000227
max inferred z is 4.10, min inferred z is -3.85, and std is 1.00
 4.38 s (22.9 data/s) [100/100]
training: epoch 73: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.649331, min gradient is -8.000000, learning rate is 0.002543
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.744022, learning rate is 0.002543
Net1: layer conv1:max response is , min response is .
max gradient is 7.994502, min gradient is -8.000000, learning rate is 0.002543
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.780516, learning rate is 0.000453
Net2: layer deconv3:max response is 26.819111, min response is -34.484753.
max gradient is 7.065559, min gradient is -8.000000, learning rate is 0.000227
Net2: layer bn50:max response is 16.935490, min response is -2.988806.
max gradient is 7.007178, min gradient is -8.000000, learning rate is 0.000453
Net2: layer deconv2:max response is , min response is .
max gradient is 7.354692, min gradient is -8.000000, learning rate is 0.000227
Net2: layer bn49:max response is 9.628288, min response is -1.913027.
max gradient is 8.000000, min gradient is -7.368926, learning rate is 0.000453
Net2: layer deconv1:max response is , min response is .
max gradient is 7.465007, min gradient is -8.000000, learning rate is 0.000227
max inferred z is 3.86, min inferred z is -3.85, and std is 1.00
 4.41 s (22.7 data/s) [100/100]
training: epoch 73: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.954068, min gradient is -8.000000, learning rate is 0.002543
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.075352, learning rate is 0.002543
Net1: layer conv1:max response is , min response is .
max gradient is 7.706640, min gradient is -8.000000, learning rate is 0.002543
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 0.093807, learning rate is 0.000453
Net2: layer deconv3:max response is 24.637535, min response is -35.453346.
max gradient is 7.046622, min gradient is -8.000000, learning rate is 0.000227
Net2: layer bn50:max response is 15.751141, min response is -3.048933.
max gradient is 8.000000, min gradient is -6.722649, learning rate is 0.000453
Net2: layer deconv2:max response is , min response is .
max gradient is 5.945334, min gradient is -8.000000, learning rate is 0.000227
Net2: layer bn49:max response is 10.045984, min response is -1.977064.
max gradient is 6.622449, min gradient is -8.000000, learning rate is 0.000453
Net2: layer deconv1:max response is , min response is .
max gradient is 7.069704, min gradient is -8.000000, learning rate is 0.000227
max inferred z is 4.10, min inferred z is -4.35, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
training: epoch 73: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.069004, min gradient is -8.000000, learning rate is 0.002543
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.613697, learning rate is 0.002543
Net1: layer conv1:max response is , min response is .
max gradient is 3.916093, min gradient is -8.000000, learning rate is 0.002543
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 5.261931, min gradient is -8.000000, learning rate is 0.000453
Net2: layer deconv3:max response is 27.842978, min response is -33.891834.
max gradient is 6.735521, min gradient is -8.000000, learning rate is 0.000227
Net2: layer bn50:max response is 19.841278, min response is -3.278540.
max gradient is 8.000000, min gradient is -7.539217, learning rate is 0.000453
Net2: layer deconv2:max response is , min response is .
max gradient is 6.575940, min gradient is -8.000000, learning rate is 0.000227
Net2: layer bn49:max response is 10.547658, min response is -1.791990.
max gradient is 8.000000, min gradient is -7.063657, learning rate is 0.000453
Net2: layer deconv1:max response is , min response is .
max gradient is 6.795874, min gradient is -8.000000, learning rate is 0.000227
max inferred z is 4.71, min inferred z is -3.95, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 73: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.166386, min gradient is -8.000000, learning rate is 0.002543
Net1: layer conv2:max response is , min response is .
max gradient is 7.970830, min gradient is -8.000000, learning rate is 0.002543
Net1: layer conv1:max response is , min response is .
max gradient is 5.447992, min gradient is -8.000000, learning rate is 0.002543
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -1.332283, learning rate is 0.000453
Net2: layer deconv3:max response is 24.888594, min response is -33.870327.
max gradient is 5.515478, min gradient is -8.000001, learning rate is 0.000227
Net2: layer bn50:max response is 16.462246, min response is -3.120027.
max gradient is 8.000000, min gradient is -6.339362, learning rate is 0.000453
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.777204, learning rate is 0.000227
Net2: layer bn49:max response is 8.946613, min response is -1.862667.
max gradient is 5.869446, min gradient is -8.000000, learning rate is 0.000453
Net2: layer deconv1:max response is , min response is .
max gradient is 7.526455, min gradient is -8.000000, learning rate is 0.000227
max inferred z is 3.70, min inferred z is -3.52, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 73: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.534839, min gradient is -8.000000, learning rate is 0.002543
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.784788, learning rate is 0.002543
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.462514, learning rate is 0.002543
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -1.275266, learning rate is 0.000453
Net2: layer deconv3:max response is 31.495775, min response is -32.746006.
max gradient is 8.000000, min gradient is -5.473641, learning rate is 0.000227
Net2: layer bn50:max response is 21.359932, min response is -3.641657.
max gradient is 7.126903, min gradient is -8.000000, learning rate is 0.000453
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.932684, learning rate is 0.000227
Net2: layer bn49:max response is 8.940689, min response is -2.223569.
max gradient is 6.666966, min gradient is -8.000000, learning rate is 0.000453
Net2: layer deconv1:max response is , min response is .
max gradient is 7.394635, min gradient is -8.000000, learning rate is 0.000227
max inferred z is 3.96, min inferred z is -3.90, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
Loss: 1.7483
Iteration 74 / 200
training: epoch 74: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.672158, min gradient is -8.000000, learning rate is 0.002543
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.494996, learning rate is 0.002543
Net1: layer conv1:max response is , min response is .
max gradient is 4.539604, min gradient is -8.000000, learning rate is 0.002543
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 7.529603, min gradient is -8.000000, learning rate is 0.000451
Net2: layer deconv3:max response is 26.158504, min response is -35.937790.
max gradient is 8.000000, min gradient is -5.585478, learning rate is 0.000226
Net2: layer bn50:max response is 16.956631, min response is -3.045174.
max gradient is 8.000000, min gradient is -6.709579, learning rate is 0.000451
Net2: layer deconv2:max response is , min response is .
max gradient is 5.332650, min gradient is -8.000000, learning rate is 0.000226
Net2: layer bn49:max response is 10.047771, min response is -1.841391.
max gradient is 8.000000, min gradient is -7.629403, learning rate is 0.000451
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.447967, learning rate is 0.000226
max inferred z is 3.93, min inferred z is -3.90, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
training: epoch 74: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.463837, min gradient is -8.000000, learning rate is 0.002543
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.777709, learning rate is 0.002543
Net1: layer conv1:max response is , min response is .
max gradient is 7.663879, min gradient is -8.000000, learning rate is 0.002543
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 2.021573, min gradient is -8.000000, learning rate is 0.000451
Net2: layer deconv3:max response is 28.181385, min response is -38.679062.
max gradient is 8.000000, min gradient is -6.669522, learning rate is 0.000226
Net2: layer bn50:max response is 19.706432, min response is -3.412424.
max gradient is 8.000000, min gradient is -6.852984, learning rate is 0.000451
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.525707, learning rate is 0.000226
Net2: layer bn49:max response is 11.161608, min response is -1.949296.
max gradient is 7.425546, min gradient is -8.000000, learning rate is 0.000451
Net2: layer deconv1:max response is , min response is .
max gradient is 7.667626, min gradient is -8.000000, learning rate is 0.000226
max inferred z is 4.63, min inferred z is -3.71, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 74: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.815297, learning rate is 0.002543
Net1: layer conv2:max response is , min response is .
max gradient is 6.835104, min gradient is -8.000000, learning rate is 0.002543
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.774580, learning rate is 0.002543
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -0.944558, learning rate is 0.000451
Net2: layer deconv3:max response is 27.749449, min response is -35.460896.
max gradient is 7.200024, min gradient is -8.000000, learning rate is 0.000226
Net2: layer bn50:max response is 17.534515, min response is -3.001305.
max gradient is 2.930539, min gradient is -8.000000, learning rate is 0.000451
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.739012, learning rate is 0.000226
Net2: layer bn49:max response is 8.167523, min response is -1.861930.
max gradient is 5.511369, min gradient is -8.000000, learning rate is 0.000451
Net2: layer deconv1:max response is , min response is .
max gradient is 6.691226, min gradient is -8.000000, learning rate is 0.000226
max inferred z is 3.80, min inferred z is -3.67, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 74: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.882954, min gradient is -8.000000, learning rate is 0.002543
Net1: layer conv2:max response is , min response is .
max gradient is 5.883865, min gradient is -8.000000, learning rate is 0.002543
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -2.328604, learning rate is 0.002543
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.523203, learning rate is 0.000451
Net2: layer deconv3:max response is 30.110783, min response is -32.195972.
max gradient is 7.416343, min gradient is -8.000000, learning rate is 0.000226
Net2: layer bn50:max response is 20.462894, min response is -3.470411.
max gradient is 2.737996, min gradient is -8.000000, learning rate is 0.000451
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.774315, learning rate is 0.000226
Net2: layer bn49:max response is 8.408404, min response is -1.812968.
max gradient is 5.354531, min gradient is -8.000000, learning rate is 0.000451
Net2: layer deconv1:max response is , min response is .
max gradient is 7.928123, min gradient is -8.000000, learning rate is 0.000226
max inferred z is 4.02, min inferred z is -3.74, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 74: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.687770, min gradient is -8.000000, learning rate is 0.002543
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.481787, learning rate is 0.002543
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.004689, learning rate is 0.002543
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.159114, learning rate is 0.000451
Net2: layer deconv3:max response is 25.512987, min response is -40.242287.
max gradient is 8.000000, min gradient is -6.763885, learning rate is 0.000226
Net2: layer bn50:max response is 18.567719, min response is -3.451008.
max gradient is 2.857087, min gradient is -8.000000, learning rate is 0.000451
Net2: layer deconv2:max response is , min response is .
max gradient is 6.265404, min gradient is -8.000000, learning rate is 0.000226
Net2: layer bn49:max response is 9.203080, min response is -2.031399.
max gradient is 7.496444, min gradient is -8.000000, learning rate is 0.000451
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.309551, learning rate is 0.000226
max inferred z is 3.87, min inferred z is -4.25, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 74: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.460794, min gradient is -8.000000, learning rate is 0.002543
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.686542, learning rate is 0.002543
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.494456, learning rate is 0.002543
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.925841, learning rate is 0.000451
Net2: layer deconv3:max response is 25.939901, min response is -34.355453.
max gradient is 6.962168, min gradient is -8.000000, learning rate is 0.000226
Net2: layer bn50:max response is 17.595135, min response is -3.215427.
max gradient is 2.325818, min gradient is -8.000000, learning rate is 0.000451
Net2: layer deconv2:max response is , min response is .
max gradient is 6.875628, min gradient is -8.000000, learning rate is 0.000226
Net2: layer bn49:max response is 11.204468, min response is -1.815785.
max gradient is 8.000000, min gradient is -7.505256, learning rate is 0.000451
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.224393, learning rate is 0.000226
max inferred z is 3.96, min inferred z is -4.09, and std is 1.00
 4.30 s (23.2 data/s) [100/100]
training: epoch 74: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.631968, min gradient is -8.000000, learning rate is 0.002543
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.296248, learning rate is 0.002543
Net1: layer conv1:max response is , min response is .
max gradient is 6.274563, min gradient is -8.000000, learning rate is 0.002543
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.125815, learning rate is 0.000451
Net2: layer deconv3:max response is 28.356073, min response is -35.748589.
max gradient is 3.715534, min gradient is -8.000000, learning rate is 0.000226
Net2: layer bn50:max response is 22.394175, min response is -2.977821.
max gradient is 8.000000, min gradient is -6.158134, learning rate is 0.000451
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.935297, learning rate is 0.000226
Net2: layer bn49:max response is 9.111788, min response is -2.095798.
max gradient is 8.000000, min gradient is -5.951849, learning rate is 0.000451
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.710537, learning rate is 0.000226
max inferred z is 4.00, min inferred z is -3.71, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 74: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.430317, min gradient is -8.000000, learning rate is 0.002543
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.938592, learning rate is 0.002543
Net1: layer conv1:max response is , min response is .
max gradient is 5.228866, min gradient is -8.000000, learning rate is 0.002543
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -1.529809, learning rate is 0.000451
Net2: layer deconv3:max response is 27.695894, min response is -34.652328.
max gradient is 6.567414, min gradient is -8.000000, learning rate is 0.000226
Net2: layer bn50:max response is 17.726416, min response is -3.532911.
max gradient is 7.855865, min gradient is -8.000000, learning rate is 0.000451
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.804807, learning rate is 0.000226
Net2: layer bn49:max response is 9.034759, min response is -1.883783.
max gradient is 7.671967, min gradient is -8.000000, learning rate is 0.000451
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.837620, learning rate is 0.000226
max inferred z is 4.26, min inferred z is -4.09, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 74: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.254634, min gradient is -8.000000, learning rate is 0.002543
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.866001, learning rate is 0.002543
Net1: layer conv1:max response is , min response is .
max gradient is 5.414646, min gradient is -8.000000, learning rate is 0.002543
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 0.529821, learning rate is 0.000451
Net2: layer deconv3:max response is 29.021086, min response is -33.708084.
max gradient is 4.828444, min gradient is -8.000000, learning rate is 0.000226
Net2: layer bn50:max response is 17.424320, min response is -3.151189.
max gradient is 5.698999, min gradient is -8.000000, learning rate is 0.000451
Net2: layer deconv2:max response is , min response is .
max gradient is 6.967415, min gradient is -8.000000, learning rate is 0.000226
Net2: layer bn49:max response is 9.390473, min response is -1.877939.
max gradient is 4.871690, min gradient is -8.000000, learning rate is 0.000451
Net2: layer deconv1:max response is , min response is .
max gradient is 5.678749, min gradient is -8.000000, learning rate is 0.000226
max inferred z is 3.79, min inferred z is -3.69, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 74: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.855785, min gradient is -8.000001, learning rate is 0.002543
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.485549, learning rate is 0.002543
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.348464, learning rate is 0.002543
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.517898, learning rate is 0.000451
Net2: layer deconv3:max response is 22.875721, min response is -36.250134.
max gradient is 8.000000, min gradient is -6.360030, learning rate is 0.000226
Net2: layer bn50:max response is 18.439922, min response is -3.318120.
max gradient is 5.002269, min gradient is -8.000000, learning rate is 0.000451
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.844673, learning rate is 0.000226
Net2: layer bn49:max response is 10.721211, min response is -2.021264.
max gradient is 8.000000, min gradient is -7.243621, learning rate is 0.000451
Net2: layer deconv1:max response is , min response is .
max gradient is 7.156394, min gradient is -8.000000, learning rate is 0.000226
max inferred z is 3.94, min inferred z is -3.78, and std is 1.00
 4.30 s (23.2 data/s) [100/100]
Loss: 1.6738
Iteration 75 / 200
training: epoch 75: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.588869, min gradient is -8.000000, learning rate is 0.002111
Net1: layer conv2:max response is , min response is .
max gradient is 5.820430, min gradient is -8.000000, learning rate is 0.002111
Net1: layer conv1:max response is , min response is .
max gradient is 4.695742, min gradient is -8.000000, learning rate is 0.002111
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 1.625530, min gradient is -8.000000, learning rate is 0.000449
Net2: layer deconv3:max response is 25.519228, min response is -32.328156.
max gradient is 8.000000, min gradient is -7.265718, learning rate is 0.000225
Net2: layer bn50:max response is 18.565134, min response is -3.611916.
max gradient is 8.000000, min gradient is -5.316055, learning rate is 0.000449
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.123083, learning rate is 0.000225
Net2: layer bn49:max response is 9.799586, min response is -2.226827.
max gradient is 7.456890, min gradient is -8.000000, learning rate is 0.000449
Net2: layer deconv1:max response is , min response is .
max gradient is 7.356674, min gradient is -8.000000, learning rate is 0.000225
max inferred z is 4.06, min inferred z is -3.79, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 75: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.656016, min gradient is -8.000000, learning rate is 0.002111
Net1: layer conv2:max response is , min response is .
max gradient is 7.664861, min gradient is -8.000000, learning rate is 0.002111
Net1: layer conv1:max response is , min response is .
max gradient is 5.190485, min gradient is -8.000000, learning rate is 0.002111
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.376782, min gradient is -8.000000, learning rate is 0.000449
Net2: layer deconv3:max response is 26.544430, min response is -33.203350.
max gradient is 8.000000, min gradient is -7.576302, learning rate is 0.000225
Net2: layer bn50:max response is 18.188604, min response is -3.098037.
max gradient is 8.000000, min gradient is -2.266348, learning rate is 0.000449
Net2: layer deconv2:max response is , min response is .
max gradient is 7.572775, min gradient is -8.000000, learning rate is 0.000225
Net2: layer bn49:max response is 9.561618, min response is -2.008086.
max gradient is 6.416015, min gradient is -8.000000, learning rate is 0.000449
Net2: layer deconv1:max response is , min response is .
max gradient is 7.471596, min gradient is -8.000000, learning rate is 0.000225
max inferred z is 3.89, min inferred z is -4.10, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
training: epoch 75: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.928959, learning rate is 0.002111
Net1: layer conv2:max response is , min response is .
max gradient is 7.847177, min gradient is -8.000000, learning rate is 0.002111
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.031522, learning rate is 0.002111
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.964635, min gradient is -8.000000, learning rate is 0.000449
Net2: layer deconv3:max response is 27.334724, min response is -34.107368.
max gradient is 5.043121, min gradient is -8.000000, learning rate is 0.000225
Net2: layer bn50:max response is 17.745070, min response is -3.180120.
max gradient is 4.965952, min gradient is -8.000000, learning rate is 0.000449
Net2: layer deconv2:max response is , min response is .
max gradient is 7.399673, min gradient is -8.000000, learning rate is 0.000225
Net2: layer bn49:max response is 9.992303, min response is -2.527091.
max gradient is 4.435642, min gradient is -8.000000, learning rate is 0.000449
Net2: layer deconv1:max response is , min response is .
max gradient is 7.169044, min gradient is -8.000000, learning rate is 0.000225
max inferred z is 3.63, min inferred z is -3.75, and std is 1.00
 4.32 s (23.2 data/s) [100/100]
training: epoch 75: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.404762, min gradient is -8.000000, learning rate is 0.002111
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.599424, learning rate is 0.002111
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.101399, learning rate is 0.002111
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.885967, learning rate is 0.000449
Net2: layer deconv3:max response is 26.589539, min response is -33.254864.
max gradient is 5.166775, min gradient is -8.000000, learning rate is 0.000225
Net2: layer bn50:max response is 19.246231, min response is -3.320013.
max gradient is 1.623461, min gradient is -8.000001, learning rate is 0.000449
Net2: layer deconv2:max response is , min response is .
max gradient is 7.606936, min gradient is -8.000001, learning rate is 0.000225
Net2: layer bn49:max response is 9.478194, min response is -2.005325.
max gradient is 5.124135, min gradient is -8.000000, learning rate is 0.000449
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.419789, learning rate is 0.000225
max inferred z is 3.87, min inferred z is -3.61, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
training: epoch 75: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.472500, min gradient is -8.000000, learning rate is 0.002111
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.571052, learning rate is 0.002111
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -2.048664, learning rate is 0.002111
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.502360, learning rate is 0.000449
Net2: layer deconv3:max response is 24.718630, min response is -35.951496.
max gradient is 8.000000, min gradient is -6.386139, learning rate is 0.000225
Net2: layer bn50:max response is 15.776614, min response is -2.887859.
max gradient is 6.216276, min gradient is -8.000000, learning rate is 0.000449
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000001, min gradient is -7.502416, learning rate is 0.000225
Net2: layer bn49:max response is 9.395849, min response is -1.943630.
max gradient is 6.587481, min gradient is -8.000000, learning rate is 0.000449
Net2: layer deconv1:max response is , min response is .
max gradient is 6.543162, min gradient is -8.000000, learning rate is 0.000225
max inferred z is 3.78, min inferred z is -4.09, and std is 1.00
 4.41 s (22.7 data/s) [100/100]
training: epoch 75: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.392604, min gradient is -8.000000, learning rate is 0.002111
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.126447, learning rate is 0.002111
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.613268, learning rate is 0.002111
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.308067, learning rate is 0.000449
Net2: layer deconv3:max response is 27.849842, min response is -31.770638.
max gradient is 8.000000, min gradient is -7.448720, learning rate is 0.000225
Net2: layer bn50:max response is 19.660906, min response is -2.979333.
max gradient is 5.460451, min gradient is -8.000000, learning rate is 0.000449
Net2: layer deconv2:max response is , min response is .
max gradient is 5.709651, min gradient is -8.000000, learning rate is 0.000225
Net2: layer bn49:max response is 10.212694, min response is -1.971183.
max gradient is 8.000000, min gradient is -5.712481, learning rate is 0.000449
Net2: layer deconv1:max response is , min response is .
max gradient is 7.934471, min gradient is -8.000000, learning rate is 0.000225
max inferred z is 4.44, min inferred z is -4.02, and std is 1.00
 4.23 s (23.6 data/s) [100/100]
training: epoch 75: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.346364, min gradient is -8.000000, learning rate is 0.002111
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.639844, learning rate is 0.002111
Net1: layer conv1:max response is , min response is .
max gradient is 5.306948, min gradient is -8.000000, learning rate is 0.002111
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.618991, learning rate is 0.000449
Net2: layer deconv3:max response is 30.349005, min response is -35.854195.
max gradient is 8.000000, min gradient is -6.971447, learning rate is 0.000225
Net2: layer bn50:max response is 20.128256, min response is -3.694178.
max gradient is 5.845338, min gradient is -8.000000, learning rate is 0.000449
Net2: layer deconv2:max response is , min response is .
max gradient is 7.855093, min gradient is -8.000000, learning rate is 0.000225
Net2: layer bn49:max response is 10.613899, min response is -2.069301.
max gradient is 8.000000, min gradient is -4.864119, learning rate is 0.000449
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.696548, learning rate is 0.000225
max inferred z is 4.09, min inferred z is -3.79, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 75: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.532888, min gradient is -8.000000, learning rate is 0.002111
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.320984, learning rate is 0.002111
Net1: layer conv1:max response is , min response is .
max gradient is 3.173148, min gradient is -8.000000, learning rate is 0.002111
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.463348, learning rate is 0.000449
Net2: layer deconv3:max response is 27.342731, min response is -37.655167.
max gradient is 3.853780, min gradient is -8.000000, learning rate is 0.000225
Net2: layer bn50:max response is 17.160978, min response is -3.488644.
max gradient is 8.000000, min gradient is -2.788156, learning rate is 0.000449
Net2: layer deconv2:max response is , min response is .
max gradient is 6.686459, min gradient is -8.000000, learning rate is 0.000225
Net2: layer bn49:max response is 9.359177, min response is -2.233106.
max gradient is 8.000000, min gradient is -7.219659, learning rate is 0.000449
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.639405, learning rate is 0.000225
max inferred z is 4.56, min inferred z is -3.54, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
training: epoch 75: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.514873, min gradient is -8.000000, learning rate is 0.002111
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.419392, learning rate is 0.002111
Net1: layer conv1:max response is , min response is .
max gradient is 7.371643, min gradient is -8.000000, learning rate is 0.002111
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.840149, learning rate is 0.000449
Net2: layer deconv3:max response is 24.727671, min response is -43.222801.
max gradient is 8.000000, min gradient is -6.868891, learning rate is 0.000225
Net2: layer bn50:max response is 17.306705, min response is -4.328237.
max gradient is 6.032630, min gradient is -8.000000, learning rate is 0.000449
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.892316, learning rate is 0.000225
Net2: layer bn49:max response is 9.855146, min response is -2.178160.
max gradient is 8.000000, min gradient is -3.301930, learning rate is 0.000449
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.989251, learning rate is 0.000225
max inferred z is 4.42, min inferred z is -4.12, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 75: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.616072, min gradient is -8.000001, learning rate is 0.002111
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.703026, learning rate is 0.002111
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -4.724360, learning rate is 0.002111
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.163828, learning rate is 0.000449
Net2: layer deconv3:max response is 27.034477, min response is -38.294106.
max gradient is 8.000000, min gradient is -5.768321, learning rate is 0.000225
Net2: layer bn50:max response is 18.649540, min response is -3.374590.
max gradient is 3.238455, min gradient is -8.000000, learning rate is 0.000449
Net2: layer deconv2:max response is , min response is .
max gradient is 6.809340, min gradient is -8.000000, learning rate is 0.000225
Net2: layer bn49:max response is 12.118678, min response is -2.263342.
max gradient is 4.846571, min gradient is -8.000000, learning rate is 0.000449
Net2: layer deconv1:max response is , min response is .
max gradient is 6.955652, min gradient is -8.000000, learning rate is 0.000225
max inferred z is 4.48, min inferred z is -4.26, and std is 1.00
 4.21 s (23.8 data/s) [100/100]
Loss: 1.6176
Iteration 76 / 200
training: epoch 76: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.574507, min gradient is -8.000000, learning rate is 0.002111
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.966046, learning rate is 0.002111
Net1: layer conv1:max response is , min response is .
max gradient is 6.033927, min gradient is -8.000000, learning rate is 0.002111
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.154026, learning rate is 0.000447
Net2: layer deconv3:max response is 30.588728, min response is -36.787289.
max gradient is 7.435513, min gradient is -8.000000, learning rate is 0.000224
Net2: layer bn50:max response is 16.562052, min response is -3.352616.
max gradient is 8.000000, min gradient is -4.566096, learning rate is 0.000447
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.867028, learning rate is 0.000224
Net2: layer bn49:max response is 10.002419, min response is -1.958509.
max gradient is 8.000000, min gradient is -5.420726, learning rate is 0.000447
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000001, min gradient is -6.647010, learning rate is 0.000224
max inferred z is 3.68, min inferred z is -4.28, and std is 1.01
 4.16 s (24.0 data/s) [100/100]
training: epoch 76: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.206252, min gradient is -8.000000, learning rate is 0.002111
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.004481, learning rate is 0.002111
Net1: layer conv1:max response is , min response is .
max gradient is 6.067439, min gradient is -8.000000, learning rate is 0.002111
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -2.298614, min gradient is -8.000000, learning rate is 0.000447
Net2: layer deconv3:max response is 26.932396, min response is -33.600033.
max gradient is 8.000000, min gradient is -5.278551, learning rate is 0.000224
Net2: layer bn50:max response is 18.821163, min response is -3.423389.
max gradient is 8.000000, min gradient is -7.872220, learning rate is 0.000447
Net2: layer deconv2:max response is , min response is .
max gradient is 6.327647, min gradient is -8.000000, learning rate is 0.000224
Net2: layer bn49:max response is 10.223266, min response is -1.922270.
max gradient is 5.567633, min gradient is -8.000000, learning rate is 0.000447
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.098814, learning rate is 0.000224
max inferred z is 4.31, min inferred z is -3.97, and std is 1.01
 4.27 s (23.4 data/s) [100/100]
training: epoch 76: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.886621, learning rate is 0.002111
Net1: layer conv2:max response is , min response is .
max gradient is 6.927597, min gradient is -8.000001, learning rate is 0.002111
Net1: layer conv1:max response is , min response is .
max gradient is 6.815939, min gradient is -8.000000, learning rate is 0.002111
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 7.687607, min gradient is -8.000000, learning rate is 0.000447
Net2: layer deconv3:max response is 27.564299, min response is -33.751278.
max gradient is 6.465209, min gradient is -8.000000, learning rate is 0.000224
Net2: layer bn50:max response is 18.736069, min response is -3.688823.
max gradient is 8.000000, min gradient is -4.707964, learning rate is 0.000447
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.156872, learning rate is 0.000224
Net2: layer bn49:max response is 10.374151, min response is -2.141773.
max gradient is 8.000000, min gradient is -5.568442, learning rate is 0.000447
Net2: layer deconv1:max response is , min response is .
max gradient is 7.432734, min gradient is -8.000000, learning rate is 0.000224
max inferred z is 4.41, min inferred z is -4.08, and std is 1.01
 4.33 s (23.1 data/s) [100/100]
training: epoch 76: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.348232, min gradient is -8.000000, learning rate is 0.002111
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.880151, learning rate is 0.002111
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -2.124541, learning rate is 0.002111
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.510579, learning rate is 0.000447
Net2: layer deconv3:max response is 22.554136, min response is -33.487335.
max gradient is 8.000000, min gradient is -5.546242, learning rate is 0.000224
Net2: layer bn50:max response is 16.477373, min response is -2.895722.
max gradient is 3.620022, min gradient is -8.000000, learning rate is 0.000447
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.652725, learning rate is 0.000224
Net2: layer bn49:max response is 8.818285, min response is -1.982265.
max gradient is 6.312763, min gradient is -8.000000, learning rate is 0.000447
Net2: layer deconv1:max response is , min response is .
max gradient is 6.280671, min gradient is -8.000000, learning rate is 0.000224
max inferred z is 3.75, min inferred z is -4.00, and std is 1.01
 4.45 s (22.5 data/s) [100/100]
training: epoch 76: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.810045, min gradient is -8.000000, learning rate is 0.002111
Net1: layer conv2:max response is , min response is .
max gradient is 7.786450, min gradient is -8.000000, learning rate is 0.002111
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.980328, learning rate is 0.002111
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.055201, learning rate is 0.000447
Net2: layer deconv3:max response is 26.997690, min response is -34.885155.
max gradient is 6.793023, min gradient is -8.000000, learning rate is 0.000224
Net2: layer bn50:max response is 17.415585, min response is -3.172945.
max gradient is 4.662084, min gradient is -8.000000, learning rate is 0.000447
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.794663, learning rate is 0.000224
Net2: layer bn49:max response is 9.249564, min response is -1.937448.
max gradient is 8.000000, min gradient is -4.992969, learning rate is 0.000447
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.829019, learning rate is 0.000224
max inferred z is 4.25, min inferred z is -4.06, and std is 1.01
 4.32 s (23.2 data/s) [100/100]
training: epoch 76: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.598842, min gradient is -8.000000, learning rate is 0.002111
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.093407, learning rate is 0.002111
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.828505, learning rate is 0.002111
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.591329, learning rate is 0.000447
Net2: layer deconv3:max response is 23.999163, min response is -36.055313.
max gradient is 8.000000, min gradient is -5.188597, learning rate is 0.000224
Net2: layer bn50:max response is 16.996292, min response is -3.846126.
max gradient is 2.952396, min gradient is -8.000000, learning rate is 0.000447
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.846297, learning rate is 0.000224
Net2: layer bn49:max response is 9.497914, min response is -2.358500.
max gradient is 5.115182, min gradient is -8.000000, learning rate is 0.000447
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.116220, learning rate is 0.000224
max inferred z is 3.65, min inferred z is -3.61, and std is 1.01
 4.32 s (23.2 data/s) [100/100]
training: epoch 76: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.618911, min gradient is -8.000000, learning rate is 0.002111
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.419641, learning rate is 0.002111
Net1: layer conv1:max response is , min response is .
max gradient is 5.783677, min gradient is -8.000000, learning rate is 0.002111
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.602577, learning rate is 0.000447
Net2: layer deconv3:max response is 27.420895, min response is -39.357822.
max gradient is 4.793483, min gradient is -8.000000, learning rate is 0.000224
Net2: layer bn50:max response is 18.595154, min response is -3.840001.
max gradient is 8.000000, min gradient is -3.616076, learning rate is 0.000447
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.793762, learning rate is 0.000224
Net2: layer bn49:max response is 8.886624, min response is -2.085205.
max gradient is 8.000000, min gradient is -5.595873, learning rate is 0.000447
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.632564, learning rate is 0.000224
max inferred z is 3.81, min inferred z is -3.94, and std is 1.01
 4.38 s (22.8 data/s) [100/100]
training: epoch 76: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.851015, min gradient is -8.000000, learning rate is 0.002111
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.522837, learning rate is 0.002111
Net1: layer conv1:max response is , min response is .
max gradient is 3.597190, min gradient is -8.000000, learning rate is 0.002111
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.872175, learning rate is 0.000447
Net2: layer deconv3:max response is 24.273642, min response is -34.767666.
max gradient is 8.000000, min gradient is -3.358623, learning rate is 0.000224
Net2: layer bn50:max response is 15.130362, min response is -3.388578.
max gradient is 8.000000, min gradient is -6.766490, learning rate is 0.000447
Net2: layer deconv2:max response is , min response is .
max gradient is 7.382103, min gradient is -8.000000, learning rate is 0.000224
Net2: layer bn49:max response is 9.976344, min response is -1.806414.
max gradient is 8.000000, min gradient is -5.525649, learning rate is 0.000447
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.078101, learning rate is 0.000224
max inferred z is 3.81, min inferred z is -3.96, and std is 1.01
 4.18 s (23.9 data/s) [100/100]
training: epoch 76: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.619856, learning rate is 0.002111
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.563100, learning rate is 0.002111
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.712954, learning rate is 0.002111
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.186954, learning rate is 0.000447
Net2: layer deconv3:max response is 31.447807, min response is -32.830284.
max gradient is 3.484052, min gradient is -8.000000, learning rate is 0.000224
Net2: layer bn50:max response is 20.106691, min response is -2.726809.
max gradient is 8.000000, min gradient is -7.395311, learning rate is 0.000447
Net2: layer deconv2:max response is , min response is .
max gradient is 7.284520, min gradient is -8.000000, learning rate is 0.000224
Net2: layer bn49:max response is 8.825127, min response is -1.957597.
max gradient is 5.992230, min gradient is -8.000000, learning rate is 0.000447
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.559084, learning rate is 0.000224
max inferred z is 4.02, min inferred z is -4.05, and std is 1.01
 4.37 s (22.9 data/s) [100/100]
training: epoch 76: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.167531, min gradient is -8.000000, learning rate is 0.002111
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.449965, learning rate is 0.002111
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.088704, learning rate is 0.002111
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.918486, learning rate is 0.000447
Net2: layer deconv3:max response is 32.251854, min response is -33.389236.
max gradient is 8.000000, min gradient is -6.545809, learning rate is 0.000224
Net2: layer bn50:max response is 19.203966, min response is -3.353764.
max gradient is 4.824333, min gradient is -8.000000, learning rate is 0.000447
Net2: layer deconv2:max response is , min response is .
max gradient is 7.381725, min gradient is -8.000000, learning rate is 0.000224
Net2: layer bn49:max response is 8.329551, min response is -2.091657.
max gradient is 7.598026, min gradient is -8.000000, learning rate is 0.000447
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.506039, learning rate is 0.000224
max inferred z is 4.42, min inferred z is -4.01, and std is 1.01
 4.35 s (23.0 data/s) [100/100]
Loss: 1.5948
Iteration 77 / 200
training: epoch 77: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.143257, min gradient is -8.000000, learning rate is 0.001752
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.844748, learning rate is 0.001752
Net1: layer conv1:max response is , min response is .
max gradient is 6.532686, min gradient is -8.000000, learning rate is 0.001752
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 0.170277, learning rate is 0.000445
Net2: layer deconv3:max response is 25.536497, min response is -37.879845.
max gradient is 6.186666, min gradient is -8.000000, learning rate is 0.000223
Net2: layer bn50:max response is 18.813732, min response is -3.004266.
max gradient is 8.000000, min gradient is -4.614354, learning rate is 0.000445
Net2: layer deconv2:max response is , min response is .
max gradient is 7.496166, min gradient is -8.000000, learning rate is 0.000223
Net2: layer bn49:max response is 8.640228, min response is -1.869583.
max gradient is 8.000000, min gradient is -7.311820, learning rate is 0.000445
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.586939, learning rate is 0.000223
max inferred z is 3.94, min inferred z is -4.15, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 77: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.039857, min gradient is -8.000000, learning rate is 0.001752
Net1: layer conv2:max response is , min response is .
max gradient is 7.743299, min gradient is -8.000000, learning rate is 0.001752
Net1: layer conv1:max response is , min response is .
max gradient is 4.602442, min gradient is -8.000000, learning rate is 0.001752
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 3.417416, min gradient is -8.000000, learning rate is 0.000445
Net2: layer deconv3:max response is 27.317446, min response is -32.751690.
max gradient is 8.000000, min gradient is -3.860111, learning rate is 0.000223
Net2: layer bn50:max response is 18.214741, min response is -3.450596.
max gradient is 8.000000, min gradient is -7.623898, learning rate is 0.000445
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.630115, learning rate is 0.000223
Net2: layer bn49:max response is 8.991880, min response is -1.971830.
max gradient is 5.611729, min gradient is -8.000000, learning rate is 0.000445
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.435304, learning rate is 0.000223
max inferred z is 3.87, min inferred z is -3.87, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 77: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.975963, min gradient is -8.000000, learning rate is 0.001752
Net1: layer conv2:max response is , min response is .
max gradient is 6.919874, min gradient is -8.000000, learning rate is 0.001752
Net1: layer conv1:max response is , min response is .
max gradient is 5.941007, min gradient is -8.000000, learning rate is 0.001752
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.564265, learning rate is 0.000445
Net2: layer deconv3:max response is 26.222305, min response is -39.856773.
max gradient is 4.665462, min gradient is -8.000000, learning rate is 0.000223
Net2: layer bn50:max response is 17.266109, min response is -3.371388.
max gradient is 8.000000, min gradient is -7.509405, learning rate is 0.000445
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.635846, learning rate is 0.000223
Net2: layer bn49:max response is 9.565505, min response is -1.789064.
max gradient is 8.000000, min gradient is -7.052427, learning rate is 0.000445
Net2: layer deconv1:max response is , min response is .
max gradient is 7.565571, min gradient is -8.000000, learning rate is 0.000223
max inferred z is 4.04, min inferred z is -4.52, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 77: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.312185, min gradient is -8.000000, learning rate is 0.001752
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.242050, learning rate is 0.001752
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.019075, learning rate is 0.001752
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.367110, learning rate is 0.000445
Net2: layer deconv3:max response is 27.589808, min response is -33.534203.
max gradient is 8.000000, min gradient is -7.570719, learning rate is 0.000223
Net2: layer bn50:max response is 17.620813, min response is -3.158452.
max gradient is 4.361667, min gradient is -8.000000, learning rate is 0.000445
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.030752, learning rate is 0.000223
Net2: layer bn49:max response is 8.363461, min response is -1.960172.
max gradient is 6.939263, min gradient is -8.000000, learning rate is 0.000445
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.382680, learning rate is 0.000223
max inferred z is 4.46, min inferred z is -4.26, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 77: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.324454, min gradient is -8.000000, learning rate is 0.001752
Net1: layer conv2:max response is , min response is .
max gradient is 6.058722, min gradient is -8.000000, learning rate is 0.001752
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.349755, learning rate is 0.001752
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.751927, learning rate is 0.000445
Net2: layer deconv3:max response is 25.948534, min response is -32.721382.
max gradient is 5.376106, min gradient is -8.000000, learning rate is 0.000223
Net2: layer bn50:max response is 18.379019, min response is -3.265298.
max gradient is 7.294250, min gradient is -8.000000, learning rate is 0.000445
Net2: layer deconv2:max response is , min response is .
max gradient is 6.653647, min gradient is -8.000000, learning rate is 0.000223
Net2: layer bn49:max response is 8.847480, min response is -2.023902.
max gradient is 8.000000, min gradient is -4.581946, learning rate is 0.000445
Net2: layer deconv1:max response is , min response is .
max gradient is 6.599731, min gradient is -8.000000, learning rate is 0.000223
max inferred z is 4.15, min inferred z is -4.04, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 77: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.732511, min gradient is -8.000000, learning rate is 0.001752
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.766110, learning rate is 0.001752
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.331004, learning rate is 0.001752
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.208655, learning rate is 0.000445
Net2: layer deconv3:max response is 28.911932, min response is -34.411003.
max gradient is 8.000000, min gradient is -7.020396, learning rate is 0.000223
Net2: layer bn50:max response is 14.906938, min response is -3.084134.
max gradient is 3.020153, min gradient is -8.000000, learning rate is 0.000445
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.509067, learning rate is 0.000223
Net2: layer bn49:max response is 9.109815, min response is -1.959406.
max gradient is 6.816902, min gradient is -8.000000, learning rate is 0.000445
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.233830, learning rate is 0.000223
max inferred z is 4.15, min inferred z is -3.91, and std is 1.00
 4.22 s (23.7 data/s) [100/100]
training: epoch 77: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.726220, min gradient is -8.000000, learning rate is 0.001752
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.665870, learning rate is 0.001752
Net1: layer conv1:max response is , min response is .
max gradient is 6.565154, min gradient is -8.000000, learning rate is 0.001752
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.080136, learning rate is 0.000445
Net2: layer deconv3:max response is 28.447641, min response is -38.733723.
max gradient is 6.569106, min gradient is -8.000000, learning rate is 0.000223
Net2: layer bn50:max response is 17.657358, min response is -3.074951.
max gradient is 8.000000, min gradient is -4.240612, learning rate is 0.000445
Net2: layer deconv2:max response is , min response is .
max gradient is 6.944611, min gradient is -8.000000, learning rate is 0.000223
Net2: layer bn49:max response is 8.847928, min response is -2.036261.
max gradient is 8.000000, min gradient is -4.255226, learning rate is 0.000445
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.745806, learning rate is 0.000223
max inferred z is 3.65, min inferred z is -4.33, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 77: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.570859, min gradient is -8.000000, learning rate is 0.001752
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.581048, learning rate is 0.001752
Net1: layer conv1:max response is , min response is .
max gradient is 4.093133, min gradient is -8.000000, learning rate is 0.001752
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 3.621465, min gradient is -8.000000, learning rate is 0.000445
Net2: layer deconv3:max response is 25.809141, min response is -33.417767.
max gradient is 8.000000, min gradient is -4.530568, learning rate is 0.000223
Net2: layer bn50:max response is 15.918363, min response is -2.883179.
max gradient is 8.000000, min gradient is -7.668869, learning rate is 0.000445
Net2: layer deconv2:max response is , min response is .
max gradient is 7.928150, min gradient is -8.000000, learning rate is 0.000223
Net2: layer bn49:max response is 8.135907, min response is -1.733893.
max gradient is 7.304576, min gradient is -8.000000, learning rate is 0.000445
Net2: layer deconv1:max response is , min response is .
max gradient is 7.056084, min gradient is -8.000000, learning rate is 0.000223
max inferred z is 4.31, min inferred z is -3.69, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 77: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.421143, min gradient is -8.000000, learning rate is 0.001752
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.126670, learning rate is 0.001752
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.395892, learning rate is 0.001752
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.158200, learning rate is 0.000445
Net2: layer deconv3:max response is 28.214876, min response is -39.881596.
max gradient is 4.413833, min gradient is -8.000000, learning rate is 0.000223
Net2: layer bn50:max response is 24.606230, min response is -3.847839.
max gradient is 8.000000, min gradient is -6.843050, learning rate is 0.000445
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.894531, learning rate is 0.000223
Net2: layer bn49:max response is 8.878710, min response is -2.179333.
max gradient is 6.937445, min gradient is -8.000001, learning rate is 0.000445
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.174946, learning rate is 0.000223
max inferred z is 3.76, min inferred z is -3.96, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 77: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.412413, min gradient is -8.000000, learning rate is 0.001752
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.900427, learning rate is 0.001752
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.393756, learning rate is 0.001752
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.841563, min gradient is -8.000000, learning rate is 0.000445
Net2: layer deconv3:max response is 27.213894, min response is -34.396229.
max gradient is 8.000000, min gradient is -5.516294, learning rate is 0.000223
Net2: layer bn50:max response is 19.332933, min response is -3.374156.
max gradient is 8.000000, min gradient is -6.180601, learning rate is 0.000445
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.243299, learning rate is 0.000223
Net2: layer bn49:max response is 8.890712, min response is -1.895866.
max gradient is 6.814755, min gradient is -8.000000, learning rate is 0.000445
Net2: layer deconv1:max response is , min response is .
max gradient is 7.607095, min gradient is -8.000000, learning rate is 0.000223
max inferred z is 3.93, min inferred z is -3.87, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
Loss: 1.5692
Iteration 78 / 200
training: epoch 78: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.652801, min gradient is -8.000000, learning rate is 0.001752
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.855101, learning rate is 0.001752
Net1: layer conv1:max response is , min response is .
max gradient is 4.023913, min gradient is -8.000000, learning rate is 0.001752
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.498229, min gradient is -8.000000, learning rate is 0.000443
Net2: layer deconv3:max response is 27.319267, min response is -37.655323.
max gradient is 6.891808, min gradient is -8.000000, learning rate is 0.000222
Net2: layer bn50:max response is 20.021399, min response is -3.382995.
max gradient is 8.000000, min gradient is -5.189785, learning rate is 0.000443
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.963910, learning rate is 0.000222
Net2: layer bn49:max response is 9.315429, min response is -1.993482.
max gradient is 7.058669, min gradient is -8.000000, learning rate is 0.000443
Net2: layer deconv1:max response is , min response is .
max gradient is 7.787139, min gradient is -8.000000, learning rate is 0.000222
max inferred z is 4.10, min inferred z is -4.13, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 78: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.135048, min gradient is -8.000000, learning rate is 0.001752
Net1: layer conv2:max response is , min response is .
max gradient is 7.277721, min gradient is -8.000000, learning rate is 0.001752
Net1: layer conv1:max response is , min response is .
max gradient is 4.392703, min gradient is -8.000000, learning rate is 0.001752
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.569730, min gradient is -8.000000, learning rate is 0.000443
Net2: layer deconv3:max response is 27.875826, min response is -37.652596.
max gradient is 8.000000, min gradient is -4.475652, learning rate is 0.000222
Net2: layer bn50:max response is 18.017551, min response is -3.433967.
max gradient is 8.000000, min gradient is -6.363976, learning rate is 0.000443
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.891119, learning rate is 0.000222
Net2: layer bn49:max response is 11.003812, min response is -2.346591.
max gradient is 5.219172, min gradient is -8.000000, learning rate is 0.000443
Net2: layer deconv1:max response is , min response is .
max gradient is 7.666719, min gradient is -8.000000, learning rate is 0.000222
max inferred z is 3.85, min inferred z is -3.96, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 78: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.182678, min gradient is -8.000000, learning rate is 0.001752
Net1: layer conv2:max response is , min response is .
max gradient is 6.782118, min gradient is -8.000000, learning rate is 0.001752
Net1: layer conv1:max response is , min response is .
max gradient is 7.352109, min gradient is -8.000000, learning rate is 0.001752
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 0.510099, learning rate is 0.000443
Net2: layer deconv3:max response is 27.255793, min response is -35.683357.
max gradient is 5.469240, min gradient is -8.000000, learning rate is 0.000222
Net2: layer bn50:max response is 15.530744, min response is -2.969152.
max gradient is 7.009439, min gradient is -8.000000, learning rate is 0.000443
Net2: layer deconv2:max response is , min response is .
max gradient is 7.070151, min gradient is -8.000000, learning rate is 0.000222
Net2: layer bn49:max response is 9.657132, min response is -1.981289.
max gradient is 6.711111, min gradient is -8.000000, learning rate is 0.000443
Net2: layer deconv1:max response is , min response is .
max gradient is 7.415595, min gradient is -8.000000, learning rate is 0.000222
max inferred z is 4.27, min inferred z is -4.82, and std is 1.00
 4.43 s (22.6 data/s) [100/100]
training: epoch 78: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.831750, min gradient is -8.000000, learning rate is 0.001752
Net1: layer conv2:max response is , min response is .
max gradient is 6.929228, min gradient is -8.000000, learning rate is 0.001752
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -2.713947, learning rate is 0.001752
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -1.583120, learning rate is 0.000443
Net2: layer deconv3:max response is 24.369425, min response is -32.738483.
max gradient is 8.000000, min gradient is -4.131269, learning rate is 0.000222
Net2: layer bn50:max response is 16.183855, min response is -3.010781.
max gradient is 5.860922, min gradient is -8.000000, learning rate is 0.000443
Net2: layer deconv2:max response is , min response is .
max gradient is 7.380119, min gradient is -8.000000, learning rate is 0.000222
Net2: layer bn49:max response is 9.166853, min response is -1.875680.
max gradient is 5.902110, min gradient is -8.000000, learning rate is 0.000443
Net2: layer deconv1:max response is , min response is .
max gradient is 6.915467, min gradient is -8.000000, learning rate is 0.000222
max inferred z is 4.45, min inferred z is -4.11, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 78: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.354352, min gradient is -8.000000, learning rate is 0.001752
Net1: layer conv2:max response is , min response is .
max gradient is 7.133809, min gradient is -8.000000, learning rate is 0.001752
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -2.007686, learning rate is 0.001752
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.550902, learning rate is 0.000443
Net2: layer deconv3:max response is 25.519457, min response is -32.792503.
max gradient is 8.000000, min gradient is -7.472596, learning rate is 0.000222
Net2: layer bn50:max response is 16.575502, min response is -3.172736.
max gradient is 8.000000, min gradient is -7.091039, learning rate is 0.000443
Net2: layer deconv2:max response is , min response is .
max gradient is 7.830394, min gradient is -8.000000, learning rate is 0.000222
Net2: layer bn49:max response is 9.826947, min response is -1.964678.
max gradient is 7.920244, min gradient is -8.000000, learning rate is 0.000443
Net2: layer deconv1:max response is , min response is .
max gradient is 7.781736, min gradient is -8.000000, learning rate is 0.000222
max inferred z is 3.77, min inferred z is -4.49, and std is 1.00
 4.48 s (22.3 data/s) [100/100]
training: epoch 78: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.591523, min gradient is -8.000000, learning rate is 0.001752
Net1: layer conv2:max response is , min response is .
max gradient is 7.644693, min gradient is -8.000000, learning rate is 0.001752
Net1: layer conv1:max response is , min response is .
max gradient is 7.897904, min gradient is -8.000000, learning rate is 0.001752
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.187962, learning rate is 0.000443
Net2: layer deconv3:max response is 26.012484, min response is -36.295559.
max gradient is 8.000000, min gradient is -5.507478, learning rate is 0.000222
Net2: layer bn50:max response is 18.221764, min response is -3.125526.
max gradient is 7.897502, min gradient is -8.000000, learning rate is 0.000443
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.150240, learning rate is 0.000222
Net2: layer bn49:max response is 9.635757, min response is -1.915518.
max gradient is 5.392827, min gradient is -8.000000, learning rate is 0.000443
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.303463, learning rate is 0.000222
max inferred z is 3.80, min inferred z is -3.78, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 78: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.252522, min gradient is -8.000000, learning rate is 0.001752
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.047183, learning rate is 0.001752
Net1: layer conv1:max response is , min response is .
max gradient is 4.014850, min gradient is -8.000000, learning rate is 0.001752
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.717222, learning rate is 0.000443
Net2: layer deconv3:max response is 28.695921, min response is -39.169415.
max gradient is 7.063207, min gradient is -8.000000, learning rate is 0.000222
Net2: layer bn50:max response is 21.700583, min response is -3.942575.
max gradient is 8.000000, min gradient is -7.484169, learning rate is 0.000443
Net2: layer deconv2:max response is , min response is .
max gradient is 7.239295, min gradient is -8.000000, learning rate is 0.000222
Net2: layer bn49:max response is 8.661503, min response is -2.085903.
max gradient is 8.000000, min gradient is -7.251632, learning rate is 0.000443
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.494020, learning rate is 0.000222
max inferred z is 3.88, min inferred z is -3.85, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 78: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.648037, min gradient is -8.000000, learning rate is 0.001752
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.345720, learning rate is 0.001752
Net1: layer conv1:max response is , min response is .
max gradient is 3.566461, min gradient is -8.000000, learning rate is 0.001752
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -3.540301, learning rate is 0.000443
Net2: layer deconv3:max response is 26.668921, min response is -34.033955.
max gradient is 8.000000, min gradient is -7.016943, learning rate is 0.000222
Net2: layer bn50:max response is 22.064871, min response is -3.623702.
max gradient is 7.247770, min gradient is -8.000000, learning rate is 0.000443
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.380438, learning rate is 0.000222
Net2: layer bn49:max response is 11.050789, min response is -2.000992.
max gradient is 5.942531, min gradient is -8.000001, learning rate is 0.000443
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.747819, learning rate is 0.000222
max inferred z is 4.48, min inferred z is -5.04, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 78: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.760968, min gradient is -8.000000, learning rate is 0.001752
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.203301, learning rate is 0.001752
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.302474, learning rate is 0.001752
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.404058, learning rate is 0.000443
Net2: layer deconv3:max response is 29.455097, min response is -34.759449.
max gradient is 4.767071, min gradient is -8.000000, learning rate is 0.000222
Net2: layer bn50:max response is 17.648314, min response is -2.962725.
max gradient is 7.834275, min gradient is -8.000000, learning rate is 0.000443
Net2: layer deconv2:max response is , min response is .
max gradient is 6.494046, min gradient is -8.000000, learning rate is 0.000222
Net2: layer bn49:max response is 9.537604, min response is -1.863235.
max gradient is 8.000000, min gradient is -7.076682, learning rate is 0.000443
Net2: layer deconv1:max response is , min response is .
max gradient is 7.549065, min gradient is -8.000000, learning rate is 0.000222
max inferred z is 4.45, min inferred z is -4.50, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 78: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.396480, learning rate is 0.001752
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.092649, learning rate is 0.001752
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.456682, learning rate is 0.001752
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.941709, learning rate is 0.000443
Net2: layer deconv3:max response is 27.335814, min response is -36.625267.
max gradient is 8.000000, min gradient is -5.017937, learning rate is 0.000222
Net2: layer bn50:max response is 16.323427, min response is -2.862608.
max gradient is 7.488128, min gradient is -8.000000, learning rate is 0.000443
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.215919, learning rate is 0.000222
Net2: layer bn49:max response is 9.935880, min response is -1.936710.
max gradient is 5.730633, min gradient is -8.000000, learning rate is 0.000443
Net2: layer deconv1:max response is , min response is .
max gradient is 7.750004, min gradient is -8.000000, learning rate is 0.000222
max inferred z is 3.64, min inferred z is -3.99, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
Loss: 1.5848
Iteration 79 / 200
training: epoch 79: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.640671, min gradient is -8.000000, learning rate is 0.001454
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.337889, learning rate is 0.001454
Net1: layer conv1:max response is , min response is .
max gradient is 5.320841, min gradient is -8.000000, learning rate is 0.001454
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.353249, learning rate is 0.000441
Net2: layer deconv3:max response is 30.851646, min response is -36.225979.
max gradient is 4.895965, min gradient is -8.000000, learning rate is 0.000221
Net2: layer bn50:max response is 18.410261, min response is -3.777589.
max gradient is 8.000000, min gradient is -6.745414, learning rate is 0.000441
Net2: layer deconv2:max response is , min response is .
max gradient is 6.507337, min gradient is -8.000000, learning rate is 0.000221
Net2: layer bn49:max response is 11.739144, min response is -1.995180.
max gradient is 7.347864, min gradient is -8.000000, learning rate is 0.000441
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.643168, learning rate is 0.000221
max inferred z is 4.51, min inferred z is -3.66, and std is 1.00
 4.22 s (23.7 data/s) [100/100]
training: epoch 79: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.775267, min gradient is -8.000000, learning rate is 0.001454
Net1: layer conv2:max response is , min response is .
max gradient is 7.336854, min gradient is -8.000000, learning rate is 0.001454
Net1: layer conv1:max response is , min response is .
max gradient is 4.294405, min gradient is -8.000000, learning rate is 0.001454
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.441682, min gradient is -8.000000, learning rate is 0.000441
Net2: layer deconv3:max response is 29.655462, min response is -38.514065.
max gradient is 8.000000, min gradient is -6.245670, learning rate is 0.000221
Net2: layer bn50:max response is 17.163849, min response is -3.540849.
max gradient is 8.000001, min gradient is -6.755113, learning rate is 0.000441
Net2: layer deconv2:max response is , min response is .
max gradient is 7.511981, min gradient is -8.000000, learning rate is 0.000221
Net2: layer bn49:max response is 8.385820, min response is -1.937457.
max gradient is 8.000000, min gradient is -7.879055, learning rate is 0.000441
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.713290, learning rate is 0.000221
max inferred z is 3.81, min inferred z is -3.94, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
training: epoch 79: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.897763, min gradient is -8.000000, learning rate is 0.001454
Net1: layer conv2:max response is , min response is .
max gradient is 7.240215, min gradient is -8.000000, learning rate is 0.001454
Net1: layer conv1:max response is , min response is .
max gradient is 4.753245, min gradient is -8.000000, learning rate is 0.001454
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.172978, learning rate is 0.000441
Net2: layer deconv3:max response is 30.374414, min response is -32.039326.
max gradient is 5.498994, min gradient is -8.000000, learning rate is 0.000221
Net2: layer bn50:max response is 17.979618, min response is -3.052755.
max gradient is 8.000000, min gradient is -7.200468, learning rate is 0.000441
Net2: layer deconv2:max response is , min response is .
max gradient is 5.539865, min gradient is -8.000000, learning rate is 0.000221
Net2: layer bn49:max response is 11.199783, min response is -2.032885.
max gradient is 8.000000, min gradient is -4.876519, learning rate is 0.000441
Net2: layer deconv1:max response is , min response is .
max gradient is 7.179845, min gradient is -8.000000, learning rate is 0.000221
max inferred z is 3.77, min inferred z is -4.24, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 79: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.641143, min gradient is -8.000000, learning rate is 0.001454
Net1: layer conv2:max response is , min response is .
max gradient is 6.327203, min gradient is -8.000000, learning rate is 0.001454
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.988602, learning rate is 0.001454
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.483517, learning rate is 0.000441
Net2: layer deconv3:max response is 25.403065, min response is -33.105545.
max gradient is 8.000000, min gradient is -5.559801, learning rate is 0.000221
Net2: layer bn50:max response is 18.524132, min response is -3.058630.
max gradient is 6.530096, min gradient is -8.000000, learning rate is 0.000441
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.431425, learning rate is 0.000221
Net2: layer bn49:max response is 9.288961, min response is -1.956310.
max gradient is 3.472920, min gradient is -8.000000, learning rate is 0.000441
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.104578, learning rate is 0.000221
max inferred z is 3.97, min inferred z is -3.87, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 79: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.748484, min gradient is -8.000000, learning rate is 0.001454
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.712707, learning rate is 0.001454
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -2.783732, learning rate is 0.001454
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.794819, learning rate is 0.000441
Net2: layer deconv3:max response is 29.779186, min response is -42.188396.
max gradient is 4.797548, min gradient is -8.000000, learning rate is 0.000221
Net2: layer bn50:max response is 19.417633, min response is -3.463039.
max gradient is 6.648606, min gradient is -8.000000, learning rate is 0.000441
Net2: layer deconv2:max response is , min response is .
max gradient is 6.282689, min gradient is -8.000000, learning rate is 0.000221
Net2: layer bn49:max response is 11.438523, min response is -1.947089.
max gradient is 8.000000, min gradient is -5.745332, learning rate is 0.000441
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.385935, learning rate is 0.000221
max inferred z is 3.96, min inferred z is -3.56, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 79: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.093444, min gradient is -8.000000, learning rate is 0.001454
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.164032, learning rate is 0.001454
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.603447, learning rate is 0.001454
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.674150, learning rate is 0.000441
Net2: layer deconv3:max response is 25.881897, min response is -43.682201.
max gradient is 8.000000, min gradient is -4.192182, learning rate is 0.000221
Net2: layer bn50:max response is 16.401592, min response is -3.376080.
max gradient is 8.000000, min gradient is -4.942695, learning rate is 0.000441
Net2: layer deconv2:max response is , min response is .
max gradient is 7.709842, min gradient is -8.000000, learning rate is 0.000221
Net2: layer bn49:max response is 9.987746, min response is -1.829037.
max gradient is 8.000000, min gradient is -6.795974, learning rate is 0.000441
Net2: layer deconv1:max response is , min response is .
max gradient is 6.359459, min gradient is -8.000000, learning rate is 0.000221
max inferred z is 4.15, min inferred z is -4.09, and std is 1.00
 4.47 s (22.4 data/s) [100/100]
training: epoch 79: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.916415, learning rate is 0.001454
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.768765, learning rate is 0.001454
Net1: layer conv1:max response is , min response is .
max gradient is 2.956399, min gradient is -8.000000, learning rate is 0.001454
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.170849, learning rate is 0.000441
Net2: layer deconv3:max response is 27.789970, min response is -35.026150.
max gradient is 4.129355, min gradient is -8.000001, learning rate is 0.000221
Net2: layer bn50:max response is 16.848860, min response is -3.337787.
max gradient is 7.656680, min gradient is -8.000000, learning rate is 0.000441
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.199516, learning rate is 0.000221
Net2: layer bn49:max response is 9.476011, min response is -2.190904.
max gradient is 8.000000, min gradient is -7.655715, learning rate is 0.000441
Net2: layer deconv1:max response is , min response is .
max gradient is 5.930634, min gradient is -8.000000, learning rate is 0.000221
max inferred z is 3.80, min inferred z is -4.06, and std is 1.00
 4.41 s (22.7 data/s) [100/100]
training: epoch 79: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.962467, min gradient is -8.000000, learning rate is 0.001454
Net1: layer conv2:max response is , min response is .
max gradient is 7.758817, min gradient is -8.000000, learning rate is 0.001454
Net1: layer conv1:max response is , min response is .
max gradient is 4.188794, min gradient is -8.000000, learning rate is 0.001454
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.663082, learning rate is 0.000441
Net2: layer deconv3:max response is 28.401964, min response is -37.047329.
max gradient is 8.000000, min gradient is -4.938797, learning rate is 0.000221
Net2: layer bn50:max response is 18.035133, min response is -3.353436.
max gradient is 8.000000, min gradient is -4.735902, learning rate is 0.000441
Net2: layer deconv2:max response is , min response is .
max gradient is 7.431681, min gradient is -8.000000, learning rate is 0.000221
Net2: layer bn49:max response is 10.618264, min response is -1.951899.
max gradient is 8.000000, min gradient is -7.553528, learning rate is 0.000441
Net2: layer deconv1:max response is , min response is .
max gradient is 6.439158, min gradient is -8.000000, learning rate is 0.000221
max inferred z is 4.26, min inferred z is -3.99, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 79: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.125674, min gradient is -8.000000, learning rate is 0.001454
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.373831, learning rate is 0.001454
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.925403, learning rate is 0.001454
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.880804, learning rate is 0.000441
Net2: layer deconv3:max response is 25.866209, min response is -36.364658.
max gradient is 4.117503, min gradient is -8.000000, learning rate is 0.000221
Net2: layer bn50:max response is 17.988096, min response is -3.515279.
max gradient is 6.432534, min gradient is -8.000000, learning rate is 0.000441
Net2: layer deconv2:max response is , min response is .
max gradient is 6.215076, min gradient is -8.000000, learning rate is 0.000221
Net2: layer bn49:max response is 11.209273, min response is -2.002947.
max gradient is 8.000000, min gradient is -7.279677, learning rate is 0.000441
Net2: layer deconv1:max response is , min response is .
max gradient is 7.261462, min gradient is -8.000000, learning rate is 0.000221
max inferred z is 3.92, min inferred z is -3.94, and std is 1.00
 4.43 s (22.6 data/s) [100/100]
training: epoch 79: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.578641, learning rate is 0.001454
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.384806, learning rate is 0.001454
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.670188, learning rate is 0.001454
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 0.937279, learning rate is 0.000441
Net2: layer deconv3:max response is 29.600988, min response is -34.391430.
max gradient is 8.000000, min gradient is -6.569248, learning rate is 0.000221
Net2: layer bn50:max response is 16.009573, min response is -4.040905.
max gradient is 5.509097, min gradient is -8.000000, learning rate is 0.000441
Net2: layer deconv2:max response is , min response is .
max gradient is 7.950687, min gradient is -8.000000, learning rate is 0.000221
Net2: layer bn49:max response is 9.725874, min response is -2.212770.
max gradient is 6.327686, min gradient is -8.000000, learning rate is 0.000441
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.493234, learning rate is 0.000221
max inferred z is 3.79, min inferred z is -3.94, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
Loss: 1.6087
Iteration 80 / 200
training: epoch 80: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.983449, min gradient is -8.000000, learning rate is 0.001454
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.625021, learning rate is 0.001454
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.760903, learning rate is 0.001454
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 0.647898, learning rate is 0.000440
Net2: layer deconv3:max response is 26.545248, min response is -38.601086.
max gradient is 5.199313, min gradient is -8.000000, learning rate is 0.000220
Net2: layer bn50:max response is 21.412115, min response is -3.822508.
max gradient is 8.000000, min gradient is -4.916034, learning rate is 0.000440
Net2: layer deconv2:max response is , min response is .
max gradient is 5.946434, min gradient is -8.000000, learning rate is 0.000220
Net2: layer bn49:max response is 8.684773, min response is -1.954928.
max gradient is 8.000000, min gradient is -5.759317, learning rate is 0.000440
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.969450, learning rate is 0.000220
max inferred z is 4.26, min inferred z is -3.96, and std is 1.00
 4.21 s (23.7 data/s) [100/100]
training: epoch 80: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.673647, min gradient is -8.000000, learning rate is 0.001454
Net1: layer conv2:max response is , min response is .
max gradient is 6.205553, min gradient is -8.000000, learning rate is 0.001454
Net1: layer conv1:max response is , min response is .
max gradient is 3.584625, min gradient is -8.000000, learning rate is 0.001454
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -4.218313, min gradient is -8.000000, learning rate is 0.000440
Net2: layer deconv3:max response is 23.550783, min response is -35.444572.
max gradient is 8.000000, min gradient is -6.928769, learning rate is 0.000220
Net2: layer bn50:max response is 16.837469, min response is -3.211923.
max gradient is 8.000000, min gradient is -7.397388, learning rate is 0.000440
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.986560, learning rate is 0.000220
Net2: layer bn49:max response is 9.972538, min response is -1.772965.
max gradient is 4.860487, min gradient is -8.000000, learning rate is 0.000440
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.275966, learning rate is 0.000220
max inferred z is 3.92, min inferred z is -4.48, and std is 1.00
 4.30 s (23.3 data/s) [100/100]
training: epoch 80: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.403112, min gradient is -8.000000, learning rate is 0.001454
Net1: layer conv2:max response is , min response is .
max gradient is 6.610116, min gradient is -8.000000, learning rate is 0.001454
Net1: layer conv1:max response is , min response is .
max gradient is 5.090346, min gradient is -8.000000, learning rate is 0.001454
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 3.976735, min gradient is -8.000000, learning rate is 0.000440
Net2: layer deconv3:max response is 31.514566, min response is -37.799809.
max gradient is 4.453628, min gradient is -8.000000, learning rate is 0.000220
Net2: layer bn50:max response is 19.248585, min response is -3.371708.
max gradient is 7.189376, min gradient is -8.000000, learning rate is 0.000440
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.133055, learning rate is 0.000220
Net2: layer bn49:max response is 10.025912, min response is -1.970563.
max gradient is 6.490797, min gradient is -8.000000, learning rate is 0.000440
Net2: layer deconv1:max response is , min response is .
max gradient is 6.624884, min gradient is -8.000000, learning rate is 0.000220
max inferred z is 4.25, min inferred z is -3.96, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 80: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.867040, min gradient is -8.000000, learning rate is 0.001454
Net1: layer conv2:max response is , min response is .
max gradient is 5.752079, min gradient is -8.000000, learning rate is 0.001454
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -2.961352, learning rate is 0.001454
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.785146, learning rate is 0.000440
Net2: layer deconv3:max response is 28.362671, min response is -40.899502.
max gradient is 8.000000, min gradient is -6.393723, learning rate is 0.000220
Net2: layer bn50:max response is 19.590418, min response is -3.166489.
max gradient is 5.075255, min gradient is -8.000000, learning rate is 0.000440
Net2: layer deconv2:max response is , min response is .
max gradient is 7.825510, min gradient is -8.000000, learning rate is 0.000220
Net2: layer bn49:max response is 9.677428, min response is -1.923017.
max gradient is 8.000000, min gradient is -5.669440, learning rate is 0.000440
Net2: layer deconv1:max response is , min response is .
max gradient is 7.810852, min gradient is -8.000000, learning rate is 0.000220
max inferred z is 4.01, min inferred z is -3.71, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 80: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.798550, learning rate is 0.001454
Net1: layer conv2:max response is , min response is .
max gradient is 6.013146, min gradient is -8.000000, learning rate is 0.001454
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.399989, learning rate is 0.001454
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.240505, learning rate is 0.000440
Net2: layer deconv3:max response is 31.258522, min response is -36.995506.
max gradient is 4.938002, min gradient is -8.000000, learning rate is 0.000220
Net2: layer bn50:max response is 20.819799, min response is -3.837062.
max gradient is 8.000000, min gradient is -7.290799, learning rate is 0.000440
Net2: layer deconv2:max response is , min response is .
max gradient is 5.330802, min gradient is -8.000000, learning rate is 0.000220
Net2: layer bn49:max response is 10.371264, min response is -2.050856.
max gradient is 8.000000, min gradient is -7.493970, learning rate is 0.000440
Net2: layer deconv1:max response is , min response is .
max gradient is 7.421220, min gradient is -8.000000, learning rate is 0.000220
max inferred z is 4.72, min inferred z is -4.25, and std is 1.00
 4.45 s (22.4 data/s) [100/100]
training: epoch 80: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.919633, min gradient is -8.000000, learning rate is 0.001454
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.881076, learning rate is 0.001454
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.440205, learning rate is 0.001454
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.321317, learning rate is 0.000440
Net2: layer deconv3:max response is 28.934698, min response is -32.481689.
max gradient is 8.000000, min gradient is -5.294060, learning rate is 0.000220
Net2: layer bn50:max response is 19.655088, min response is -3.184317.
max gradient is 7.720747, min gradient is -8.000000, learning rate is 0.000440
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.763697, learning rate is 0.000220
Net2: layer bn49:max response is 8.606333, min response is -1.883746.
max gradient is 5.984708, min gradient is -8.000000, learning rate is 0.000440
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.569746, learning rate is 0.000220
max inferred z is 4.18, min inferred z is -4.17, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
training: epoch 80: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.800562, learning rate is 0.001454
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.579353, learning rate is 0.001454
Net1: layer conv1:max response is , min response is .
max gradient is 5.837017, min gradient is -8.000001, learning rate is 0.001454
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.543246, learning rate is 0.000440
Net2: layer deconv3:max response is 26.343998, min response is -33.258324.
max gradient is 4.777320, min gradient is -8.000000, learning rate is 0.000220
Net2: layer bn50:max response is 20.788858, min response is -3.452262.
max gradient is 8.000000, min gradient is -6.440593, learning rate is 0.000440
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.397106, learning rate is 0.000220
Net2: layer bn49:max response is 10.442444, min response is -1.841517.
max gradient is 8.000000, min gradient is -5.261302, learning rate is 0.000440
Net2: layer deconv1:max response is , min response is .
max gradient is 7.296243, min gradient is -8.000000, learning rate is 0.000220
max inferred z is 3.78, min inferred z is -3.59, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
training: epoch 80: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.764255, min gradient is -8.000000, learning rate is 0.001454
Net1: layer conv2:max response is , min response is .
max gradient is 5.822109, min gradient is -8.000000, learning rate is 0.001454
Net1: layer conv1:max response is , min response is .
max gradient is 4.920227, min gradient is -8.000000, learning rate is 0.001454
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -1.721083, min gradient is -8.000000, learning rate is 0.000440
Net2: layer deconv3:max response is 27.095591, min response is -35.906658.
max gradient is 8.000000, min gradient is -4.521966, learning rate is 0.000220
Net2: layer bn50:max response is 17.517462, min response is -3.226228.
max gradient is 8.000000, min gradient is -6.935467, learning rate is 0.000440
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.981734, learning rate is 0.000220
Net2: layer bn49:max response is 9.099055, min response is -2.159742.
max gradient is 5.933365, min gradient is -8.000000, learning rate is 0.000440
Net2: layer deconv1:max response is , min response is .
max gradient is 7.152509, min gradient is -8.000000, learning rate is 0.000220
max inferred z is 4.16, min inferred z is -4.80, and std is 1.00
 4.43 s (22.6 data/s) [100/100]
training: epoch 80: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.259653, min gradient is -8.000000, learning rate is 0.001454
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.935922, learning rate is 0.001454
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.074078, learning rate is 0.001454
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.919058, learning rate is 0.000440
Net2: layer deconv3:max response is 28.853821, min response is -34.298885.
max gradient is 4.840848, min gradient is -8.000000, learning rate is 0.000220
Net2: layer bn50:max response is 19.370073, min response is -3.183726.
max gradient is 7.368986, min gradient is -8.000000, learning rate is 0.000440
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.259952, learning rate is 0.000220
Net2: layer bn49:max response is 10.517918, min response is -2.056897.
max gradient is 8.000000, min gradient is -6.948744, learning rate is 0.000440
Net2: layer deconv1:max response is , min response is .
max gradient is 7.502728, min gradient is -8.000000, learning rate is 0.000220
max inferred z is 3.67, min inferred z is -4.82, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 80: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.793339, learning rate is 0.001454
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.425408, learning rate is 0.001454
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.095203, learning rate is 0.001454
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 1.490890, min gradient is -3.858571, learning rate is 0.000440
Net2: layer deconv3:max response is 30.996483, min response is -38.678909.
max gradient is 8.000000, min gradient is -6.488593, learning rate is 0.000220
Net2: layer bn50:max response is 23.275963, min response is -4.086994.
max gradient is 8.000000, min gradient is -5.833805, learning rate is 0.000440
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.025211, learning rate is 0.000220
Net2: layer bn49:max response is 9.299290, min response is -1.999110.
max gradient is 5.989243, min gradient is -8.000000, learning rate is 0.000440
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.867214, learning rate is 0.000220
max inferred z is 3.66, min inferred z is -4.33, and std is 1.00
 4.34 s (23.1 data/s) [100/100]
Loss: 1.5657
Iteration 81 / 200
training: epoch 81: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.010120, learning rate is 0.001207
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.982912, learning rate is 0.001207
Net1: layer conv1:max response is , min response is .
max gradient is 2.986613, min gradient is -8.000000, learning rate is 0.001207
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -1.878680, min gradient is -8.000000, learning rate is 0.000438
Net2: layer deconv3:max response is 29.077358, min response is -36.707783.
max gradient is 4.184494, min gradient is -8.000000, learning rate is 0.000219
Net2: layer bn50:max response is 18.891054, min response is -3.316257.
max gradient is 8.000000, min gradient is -6.359619, learning rate is 0.000438
Net2: layer deconv2:max response is , min response is .
max gradient is 6.184372, min gradient is -8.000000, learning rate is 0.000219
Net2: layer bn49:max response is 10.178172, min response is -2.086074.
max gradient is 8.000000, min gradient is -5.401663, learning rate is 0.000438
Net2: layer deconv1:max response is , min response is .
max gradient is 6.932554, min gradient is -8.000000, learning rate is 0.000219
max inferred z is 4.11, min inferred z is -3.83, and std is 0.99
 4.26 s (23.5 data/s) [100/100]
training: epoch 81: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.332388, min gradient is -8.000000, learning rate is 0.001207
Net1: layer conv2:max response is , min response is .
max gradient is 6.425758, min gradient is -8.000000, learning rate is 0.001207
Net1: layer conv1:max response is , min response is .
max gradient is 3.673227, min gradient is -8.000000, learning rate is 0.001207
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -4.950932, min gradient is -8.000000, learning rate is 0.000438
Net2: layer deconv3:max response is 26.846653, min response is -32.379959.
max gradient is 8.000000, min gradient is -6.868740, learning rate is 0.000219
Net2: layer bn50:max response is 19.922600, min response is -3.628729.
max gradient is 6.918649, min gradient is -8.000000, learning rate is 0.000438
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.226023, learning rate is 0.000219
Net2: layer bn49:max response is 10.645487, min response is -2.307157.
max gradient is 8.000000, min gradient is -7.269129, learning rate is 0.000438
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.847291, learning rate is 0.000219
max inferred z is 4.09, min inferred z is -3.93, and std is 0.99
 4.36 s (22.9 data/s) [100/100]
training: epoch 81: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.318874, min gradient is -8.000000, learning rate is 0.001207
Net1: layer conv2:max response is , min response is .
max gradient is 7.095650, min gradient is -8.000000, learning rate is 0.001207
Net1: layer conv1:max response is , min response is .
max gradient is 6.717046, min gradient is -8.000000, learning rate is 0.001207
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 1.258797, min gradient is -8.000000, learning rate is 0.000438
Net2: layer deconv3:max response is 27.176954, min response is -35.856819.
max gradient is 6.564045, min gradient is -8.000000, learning rate is 0.000219
Net2: layer bn50:max response is 17.987663, min response is -3.536325.
max gradient is 8.000000, min gradient is -5.118684, learning rate is 0.000438
Net2: layer deconv2:max response is , min response is .
max gradient is 7.359714, min gradient is -8.000000, learning rate is 0.000219
Net2: layer bn49:max response is 10.649457, min response is -1.958156.
max gradient is 8.000000, min gradient is -5.717640, learning rate is 0.000438
Net2: layer deconv1:max response is , min response is .
max gradient is 6.021460, min gradient is -8.000000, learning rate is 0.000219
max inferred z is 4.49, min inferred z is -4.00, and std is 0.99
 4.36 s (22.9 data/s) [100/100]
training: epoch 81: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.376178, min gradient is -8.000000, learning rate is 0.001207
Net1: layer conv2:max response is , min response is .
max gradient is 5.923077, min gradient is -8.000000, learning rate is 0.001207
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -2.672076, learning rate is 0.001207
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 2.527322, min gradient is -8.000000, learning rate is 0.000438
Net2: layer deconv3:max response is 26.518719, min response is -36.170444.
max gradient is 8.000000, min gradient is -7.359818, learning rate is 0.000219
Net2: layer bn50:max response is 24.665257, min response is -4.039901.
max gradient is 4.982015, min gradient is -8.000000, learning rate is 0.000438
Net2: layer deconv2:max response is , min response is .
max gradient is 7.757620, min gradient is -8.000000, learning rate is 0.000219
Net2: layer bn49:max response is 8.565483, min response is -2.190906.
max gradient is 4.201990, min gradient is -8.000000, learning rate is 0.000438
Net2: layer deconv1:max response is , min response is .
max gradient is 7.114540, min gradient is -8.000000, learning rate is 0.000219
max inferred z is 3.73, min inferred z is -4.19, and std is 0.99
 4.29 s (23.3 data/s) [100/100]
training: epoch 81: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.580966, learning rate is 0.001207
Net1: layer conv2:max response is , min response is .
max gradient is 5.065729, min gradient is -8.000000, learning rate is 0.001207
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.205696, learning rate is 0.001207
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.132762, learning rate is 0.000438
Net2: layer deconv3:max response is 32.716270, min response is -33.228317.
max gradient is 3.916695, min gradient is -8.000000, learning rate is 0.000219
Net2: layer bn50:max response is 16.922207, min response is -3.188302.
max gradient is 6.994467, min gradient is -8.000000, learning rate is 0.000438
Net2: layer deconv2:max response is , min response is .
max gradient is 7.109601, min gradient is -8.000000, learning rate is 0.000219
Net2: layer bn49:max response is 9.344594, min response is -2.014879.
max gradient is 8.000000, min gradient is -7.489919, learning rate is 0.000438
Net2: layer deconv1:max response is , min response is .
max gradient is 6.949228, min gradient is -8.000000, learning rate is 0.000219
max inferred z is 3.81, min inferred z is -4.18, and std is 0.99
 4.28 s (23.4 data/s) [100/100]
training: epoch 81: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.602687, min gradient is -8.000000, learning rate is 0.001207
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.550826, learning rate is 0.001207
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.601372, learning rate is 0.001207
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.365734, learning rate is 0.000438
Net2: layer deconv3:max response is 32.542961, min response is -42.615665.
max gradient is 8.000000, min gradient is -6.445052, learning rate is 0.000219
Net2: layer bn50:max response is 17.991379, min response is -3.465067.
max gradient is 8.000000, min gradient is -6.283281, learning rate is 0.000438
Net2: layer deconv2:max response is , min response is .
max gradient is 7.316243, min gradient is -8.000000, learning rate is 0.000219
Net2: layer bn49:max response is 10.829638, min response is -1.933436.
max gradient is 5.969570, min gradient is -8.000000, learning rate is 0.000438
Net2: layer deconv1:max response is , min response is .
max gradient is 7.125579, min gradient is -8.000000, learning rate is 0.000219
max inferred z is 3.48, min inferred z is -4.00, and std is 0.99
 4.30 s (23.3 data/s) [100/100]
training: epoch 81: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.694528, min gradient is -8.000000, learning rate is 0.001207
Net1: layer conv2:max response is , min response is .
max gradient is 6.829971, min gradient is -8.000000, learning rate is 0.001207
Net1: layer conv1:max response is , min response is .
max gradient is 4.492420, min gradient is -8.000000, learning rate is 0.001207
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.366734, learning rate is 0.000438
Net2: layer deconv3:max response is 30.342205, min response is -37.350578.
max gradient is 5.987936, min gradient is -8.000000, learning rate is 0.000219
Net2: layer bn50:max response is 20.525314, min response is -3.185970.
max gradient is 8.000000, min gradient is -6.476558, learning rate is 0.000438
Net2: layer deconv2:max response is , min response is .
max gradient is 7.092813, min gradient is -8.000000, learning rate is 0.000219
Net2: layer bn49:max response is 9.591012, min response is -2.057301.
max gradient is 8.000000, min gradient is -5.510966, learning rate is 0.000438
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.400629, learning rate is 0.000219
max inferred z is 3.73, min inferred z is -4.00, and std is 0.99
 4.35 s (23.0 data/s) [100/100]
training: epoch 81: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.152184, min gradient is -8.000000, learning rate is 0.001207
Net1: layer conv2:max response is , min response is .
max gradient is 7.385576, min gradient is -8.000000, learning rate is 0.001207
Net1: layer conv1:max response is , min response is .
max gradient is 3.199315, min gradient is -8.000000, learning rate is 0.001207
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.059613, learning rate is 0.000438
Net2: layer deconv3:max response is 37.083229, min response is -39.543720.
max gradient is 7.699777, min gradient is -8.000000, learning rate is 0.000219
Net2: layer bn50:max response is 21.544378, min response is -3.621437.
max gradient is 8.000000, min gradient is -4.810188, learning rate is 0.000438
Net2: layer deconv2:max response is , min response is .
max gradient is 7.679465, min gradient is -8.000000, learning rate is 0.000219
Net2: layer bn49:max response is 9.822750, min response is -2.326509.
max gradient is 8.000000, min gradient is -6.379026, learning rate is 0.000438
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.438555, learning rate is 0.000219
max inferred z is 3.76, min inferred z is -4.43, and std is 0.99
 4.33 s (23.1 data/s) [100/100]
training: epoch 81: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.195279, min gradient is -8.000000, learning rate is 0.001207
Net1: layer conv2:max response is , min response is .
max gradient is 6.205877, min gradient is -8.000000, learning rate is 0.001207
Net1: layer conv1:max response is , min response is .
max gradient is 7.471910, min gradient is -8.000000, learning rate is 0.001207
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.188360, learning rate is 0.000438
Net2: layer deconv3:max response is 38.304890, min response is -39.106056.
max gradient is 6.776815, min gradient is -8.000000, learning rate is 0.000219
Net2: layer bn50:max response is 19.082560, min response is -3.377012.
max gradient is 5.377547, min gradient is -8.000000, learning rate is 0.000438
Net2: layer deconv2:max response is , min response is .
max gradient is 7.802620, min gradient is -8.000000, learning rate is 0.000219
Net2: layer bn49:max response is 10.688873, min response is -1.933700.
max gradient is 8.000000, min gradient is -7.689490, learning rate is 0.000438
Net2: layer deconv1:max response is , min response is .
max gradient is 6.921878, min gradient is -8.000000, learning rate is 0.000219
max inferred z is 4.08, min inferred z is -3.64, and std is 0.99
 4.42 s (22.6 data/s) [100/100]
training: epoch 81: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.885635, min gradient is -8.000000, learning rate is 0.001207
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.867913, learning rate is 0.001207
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -5.451581, learning rate is 0.001207
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.647082, learning rate is 0.000438
Net2: layer deconv3:max response is 26.906546, min response is -36.259148.
max gradient is 8.000000, min gradient is -7.436533, learning rate is 0.000219
Net2: layer bn50:max response is 17.335485, min response is -3.780986.
max gradient is 4.655191, min gradient is -8.000000, learning rate is 0.000438
Net2: layer deconv2:max response is , min response is .
max gradient is 7.137802, min gradient is -8.000000, learning rate is 0.000219
Net2: layer bn49:max response is 10.131449, min response is -1.975670.
max gradient is 8.000000, min gradient is -7.351944, learning rate is 0.000438
Net2: layer deconv1:max response is , min response is .
max gradient is 7.991353, min gradient is -8.000000, learning rate is 0.000219
max inferred z is 4.54, min inferred z is -3.62, and std is 0.99
 4.43 s (22.6 data/s) [100/100]
Loss: 1.5986
Iteration 82 / 200
training: epoch 82: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.362137, learning rate is 0.001207
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.888273, learning rate is 0.001207
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.905463, learning rate is 0.001207
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.208032, learning rate is 0.000436
Net2: layer deconv3:max response is 30.941666, min response is -37.252151.
max gradient is 6.546363, min gradient is -8.000000, learning rate is 0.000218
Net2: layer bn50:max response is 17.876127, min response is -3.349005.
max gradient is 8.000000, min gradient is -4.231261, learning rate is 0.000436
Net2: layer deconv2:max response is , min response is .
max gradient is 6.983087, min gradient is -8.000000, learning rate is 0.000218
Net2: layer bn49:max response is 10.524145, min response is -2.314290.
max gradient is 8.000000, min gradient is -6.706952, learning rate is 0.000436
Net2: layer deconv1:max response is , min response is .
max gradient is 7.492884, min gradient is -8.000000, learning rate is 0.000218
max inferred z is 3.56, min inferred z is -3.83, and std is 1.00
 4.11 s (24.3 data/s) [100/100]
training: epoch 82: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.703674, min gradient is -8.000000, learning rate is 0.001207
Net1: layer conv2:max response is , min response is .
max gradient is 6.789786, min gradient is -8.000000, learning rate is 0.001207
Net1: layer conv1:max response is , min response is .
max gradient is 4.253782, min gradient is -8.000000, learning rate is 0.001207
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.746629, min gradient is -8.000000, learning rate is 0.000436
Net2: layer deconv3:max response is 37.384243, min response is -34.180908.
max gradient is 8.000000, min gradient is -5.997344, learning rate is 0.000218
Net2: layer bn50:max response is 18.691767, min response is -3.772583.
max gradient is 8.000000, min gradient is -7.470711, learning rate is 0.000436
Net2: layer deconv2:max response is , min response is .
max gradient is 7.707950, min gradient is -8.000000, learning rate is 0.000218
Net2: layer bn49:max response is 9.731521, min response is -2.067147.
max gradient is 5.917118, min gradient is -8.000000, learning rate is 0.000436
Net2: layer deconv1:max response is , min response is .
max gradient is 7.378860, min gradient is -8.000000, learning rate is 0.000218
max inferred z is 4.46, min inferred z is -4.20, and std is 1.00
 4.12 s (24.3 data/s) [100/100]
training: epoch 82: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.311148, min gradient is -8.000000, learning rate is 0.001207
Net1: layer conv2:max response is , min response is .
max gradient is 7.140433, min gradient is -8.000000, learning rate is 0.001207
Net1: layer conv1:max response is , min response is .
max gradient is 4.361135, min gradient is -8.000000, learning rate is 0.001207
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.322068, min gradient is -8.000000, learning rate is 0.000436
Net2: layer deconv3:max response is 28.067537, min response is -41.119755.
max gradient is 4.625644, min gradient is -8.000000, learning rate is 0.000218
Net2: layer bn50:max response is 17.088293, min response is -3.320925.
max gradient is 7.934783, min gradient is -8.000000, learning rate is 0.000436
Net2: layer deconv2:max response is , min response is .
max gradient is 6.977648, min gradient is -8.000000, learning rate is 0.000218
Net2: layer bn49:max response is 9.314062, min response is -2.088626.
max gradient is 8.000000, min gradient is -7.025903, learning rate is 0.000436
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.332330, learning rate is 0.000218
max inferred z is 3.96, min inferred z is -3.81, and std is 1.00
 4.14 s (24.2 data/s) [100/100]
training: epoch 82: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.306074, min gradient is -8.000000, learning rate is 0.001207
Net1: layer conv2:max response is , min response is .
max gradient is 5.497482, min gradient is -8.000000, learning rate is 0.001207
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -2.637192, learning rate is 0.001207
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -2.550835, min gradient is -8.000000, learning rate is 0.000436
Net2: layer deconv3:max response is 28.068090, min response is -32.686455.
max gradient is 8.000000, min gradient is -7.420579, learning rate is 0.000218
Net2: layer bn50:max response is 20.569048, min response is -4.170356.
max gradient is 4.889539, min gradient is -8.000001, learning rate is 0.000436
Net2: layer deconv2:max response is , min response is .
max gradient is 7.972663, min gradient is -8.000000, learning rate is 0.000218
Net2: layer bn49:max response is 9.125469, min response is -2.337879.
max gradient is 5.352013, min gradient is -8.000000, learning rate is 0.000436
Net2: layer deconv1:max response is , min response is .
max gradient is 7.630904, min gradient is -8.000000, learning rate is 0.000218
max inferred z is 4.15, min inferred z is -3.75, and std is 1.00
 4.30 s (23.3 data/s) [100/100]
training: epoch 82: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.952106, min gradient is -8.000000, learning rate is 0.001207
Net1: layer conv2:max response is , min response is .
max gradient is 5.645500, min gradient is -8.000000, learning rate is 0.001207
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -3.028481, learning rate is 0.001207
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.997815, learning rate is 0.000436
Net2: layer deconv3:max response is 34.240063, min response is -36.233246.
max gradient is 6.638377, min gradient is -8.000000, learning rate is 0.000218
Net2: layer bn50:max response is 20.620451, min response is -3.963982.
max gradient is 8.000000, min gradient is -5.439269, learning rate is 0.000436
Net2: layer deconv2:max response is , min response is .
max gradient is 7.826641, min gradient is -8.000000, learning rate is 0.000218
Net2: layer bn49:max response is 9.282649, min response is -2.021293.
max gradient is 8.000000, min gradient is -5.319091, learning rate is 0.000436
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.481335, learning rate is 0.000218
max inferred z is 3.94, min inferred z is -4.08, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 82: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.744170, min gradient is -8.000000, learning rate is 0.001207
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.872135, learning rate is 0.001207
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.388868, learning rate is 0.001207
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -4.529278, min gradient is -8.000000, learning rate is 0.000436
Net2: layer deconv3:max response is 29.266634, min response is -41.537102.
max gradient is 8.000000, min gradient is -6.871092, learning rate is 0.000218
Net2: layer bn50:max response is 20.400066, min response is -3.243379.
max gradient is 6.175341, min gradient is -8.000000, learning rate is 0.000436
Net2: layer deconv2:max response is , min response is .
max gradient is 7.774045, min gradient is -8.000000, learning rate is 0.000218
Net2: layer bn49:max response is 9.714354, min response is -2.192185.
max gradient is 5.342727, min gradient is -8.000000, learning rate is 0.000436
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.125995, learning rate is 0.000218
max inferred z is 4.02, min inferred z is -4.31, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 82: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.343576, min gradient is -8.000000, learning rate is 0.001207
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.879823, learning rate is 0.001207
Net1: layer conv1:max response is , min response is .
max gradient is 4.096057, min gradient is -8.000000, learning rate is 0.001207
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.656303, learning rate is 0.000436
Net2: layer deconv3:max response is 32.135368, min response is -32.467121.
max gradient is 5.800040, min gradient is -8.000000, learning rate is 0.000218
Net2: layer bn50:max response is 19.008871, min response is -3.366519.
max gradient is 8.000000, min gradient is -5.895773, learning rate is 0.000436
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.244893, learning rate is 0.000218
Net2: layer bn49:max response is 10.832472, min response is -1.987056.
max gradient is 8.000000, min gradient is -4.667732, learning rate is 0.000436
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.167953, learning rate is 0.000218
max inferred z is 3.74, min inferred z is -3.91, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 82: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.129704, min gradient is -8.000000, learning rate is 0.001207
Net1: layer conv2:max response is , min response is .
max gradient is 6.005900, min gradient is -8.000000, learning rate is 0.001207
Net1: layer conv1:max response is , min response is .
max gradient is 4.288033, min gradient is -8.000000, learning rate is 0.001207
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -0.373799, min gradient is -8.000000, learning rate is 0.000436
Net2: layer deconv3:max response is 32.594318, min response is -37.907200.
max gradient is 8.000000, min gradient is -6.688700, learning rate is 0.000218
Net2: layer bn50:max response is 20.364866, min response is -3.828060.
max gradient is 8.000000, min gradient is -6.413538, learning rate is 0.000436
Net2: layer deconv2:max response is , min response is .
max gradient is 7.252731, min gradient is -8.000000, learning rate is 0.000218
Net2: layer bn49:max response is 12.065752, min response is -2.129635.
max gradient is 7.814724, min gradient is -8.000000, learning rate is 0.000436
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.032099, learning rate is 0.000218
max inferred z is 4.09, min inferred z is -3.93, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 82: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.150594, min gradient is -8.000000, learning rate is 0.001207
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.732780, learning rate is 0.001207
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.504545, learning rate is 0.001207
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.290415, learning rate is 0.000436
Net2: layer deconv3:max response is 34.245598, min response is -44.225056.
max gradient is 5.443771, min gradient is -8.000001, learning rate is 0.000218
Net2: layer bn50:max response is 17.744282, min response is -3.019249.
max gradient is 8.000000, min gradient is -7.904227, learning rate is 0.000436
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.042833, learning rate is 0.000218
Net2: layer bn49:max response is 10.505172, min response is -1.862314.
max gradient is 5.277820, min gradient is -8.000000, learning rate is 0.000436
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.493635, learning rate is 0.000218
max inferred z is 3.99, min inferred z is -3.92, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 82: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.589626, min gradient is -8.000000, learning rate is 0.001207
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.593071, learning rate is 0.001207
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.823113, learning rate is 0.001207
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -2.195932, learning rate is 0.000436
Net2: layer deconv3:max response is 26.646414, min response is -46.794849.
max gradient is 7.037691, min gradient is -8.000000, learning rate is 0.000218
Net2: layer bn50:max response is 18.123720, min response is -3.809786.
max gradient is 5.094001, min gradient is -8.000000, learning rate is 0.000436
Net2: layer deconv2:max response is , min response is .
max gradient is 6.810013, min gradient is -8.000000, learning rate is 0.000218
Net2: layer bn49:max response is 9.509520, min response is -1.859696.
max gradient is 8.000000, min gradient is -7.442572, learning rate is 0.000436
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.188616, learning rate is 0.000218
max inferred z is 3.95, min inferred z is -4.15, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
Loss: 1.5696
Iteration 83 / 200
training: epoch 83: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.595713, min gradient is -8.000000, learning rate is 0.001002
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.408078, learning rate is 0.001002
Net1: layer conv1:max response is , min response is .
max gradient is 5.152390, min gradient is -8.000000, learning rate is 0.001002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.068877, learning rate is 0.000434
Net2: layer deconv3:max response is 31.726114, min response is -38.185837.
max gradient is 6.919423, min gradient is -8.000000, learning rate is 0.000217
Net2: layer bn50:max response is 19.842564, min response is -3.386582.
max gradient is 8.000000, min gradient is -4.535593, learning rate is 0.000434
Net2: layer deconv2:max response is , min response is .
max gradient is 7.364478, min gradient is -8.000000, learning rate is 0.000217
Net2: layer bn49:max response is 8.498081, min response is -2.038619.
max gradient is 8.000000, min gradient is -7.234503, learning rate is 0.000434
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.302259, learning rate is 0.000217
max inferred z is 3.76, min inferred z is -4.07, and std is 1.00
 4.17 s (24.0 data/s) [100/100]
training: epoch 83: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.927833, min gradient is -8.000000, learning rate is 0.001002
Net1: layer conv2:max response is , min response is .
max gradient is 7.004341, min gradient is -8.000000, learning rate is 0.001002
Net1: layer conv1:max response is , min response is .
max gradient is 3.931366, min gradient is -8.000000, learning rate is 0.001002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -3.397062, min gradient is -8.000000, learning rate is 0.000434
Net2: layer deconv3:max response is 30.660469, min response is -43.801968.
max gradient is 8.000000, min gradient is -5.287755, learning rate is 0.000217
Net2: layer bn50:max response is 19.992922, min response is -3.596304.
max gradient is 7.139782, min gradient is -8.000000, learning rate is 0.000434
Net2: layer deconv2:max response is , min response is .
max gradient is 7.731098, min gradient is -8.000000, learning rate is 0.000217
Net2: layer bn49:max response is 10.286160, min response is -2.153927.
max gradient is 8.000000, min gradient is -6.852957, learning rate is 0.000434
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.008993, learning rate is 0.000217
max inferred z is 4.23, min inferred z is -3.62, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 83: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.799558, min gradient is -8.000000, learning rate is 0.001002
Net1: layer conv2:max response is , min response is .
max gradient is 6.760938, min gradient is -8.000000, learning rate is 0.001002
Net1: layer conv1:max response is , min response is .
max gradient is 5.685578, min gradient is -8.000000, learning rate is 0.001002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.441071, learning rate is 0.000434
Net2: layer deconv3:max response is 28.864904, min response is -39.112812.
max gradient is 5.912664, min gradient is -8.000000, learning rate is 0.000217
Net2: layer bn50:max response is 16.884449, min response is -3.281936.
max gradient is 8.000000, min gradient is -7.904022, learning rate is 0.000434
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.416099, learning rate is 0.000217
Net2: layer bn49:max response is 9.941056, min response is -2.088088.
max gradient is 7.591393, min gradient is -8.000000, learning rate is 0.000434
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.360245, learning rate is 0.000217
max inferred z is 3.60, min inferred z is -3.62, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 83: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.988555, learning rate is 0.001002
Net1: layer conv2:max response is , min response is .
max gradient is 6.518912, min gradient is -8.000000, learning rate is 0.001002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -2.543689, learning rate is 0.001002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.962527, learning rate is 0.000434
Net2: layer deconv3:max response is 34.561749, min response is -38.729156.
max gradient is 7.152455, min gradient is -8.000000, learning rate is 0.000217
Net2: layer bn50:max response is 26.069639, min response is -4.410840.
max gradient is 4.701272, min gradient is -8.000000, learning rate is 0.000434
Net2: layer deconv2:max response is , min response is .
max gradient is 5.963508, min gradient is -8.000000, learning rate is 0.000217
Net2: layer bn49:max response is 9.753340, min response is -2.150759.
max gradient is 7.603152, min gradient is -8.000000, learning rate is 0.000434
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.766728, learning rate is 0.000217
max inferred z is 4.38, min inferred z is -3.64, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 83: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.466894, min gradient is -8.000000, learning rate is 0.001002
Net1: layer conv2:max response is , min response is .
max gradient is 7.945066, min gradient is -8.000000, learning rate is 0.001002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -2.683172, learning rate is 0.001002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.927157, learning rate is 0.000434
Net2: layer deconv3:max response is 26.617455, min response is -35.101616.
max gradient is 6.767109, min gradient is -8.000000, learning rate is 0.000217
Net2: layer bn50:max response is 18.939232, min response is -3.435725.
max gradient is 7.686283, min gradient is -8.000000, learning rate is 0.000434
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.706412, learning rate is 0.000217
Net2: layer bn49:max response is 10.122327, min response is -1.963138.
max gradient is 6.284044, min gradient is -8.000000, learning rate is 0.000434
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.105309, learning rate is 0.000217
max inferred z is 3.97, min inferred z is -3.59, and std is 1.00
 4.23 s (23.7 data/s) [100/100]
training: epoch 83: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.101638, min gradient is -8.000000, learning rate is 0.001002
Net1: layer conv2:max response is , min response is .
max gradient is 7.491040, min gradient is -8.000000, learning rate is 0.001002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.669939, learning rate is 0.001002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 6.290079, min gradient is -1.969965, learning rate is 0.000434
Net2: layer deconv3:max response is 27.617411, min response is -33.271637.
max gradient is 8.000000, min gradient is -6.823735, learning rate is 0.000217
Net2: layer bn50:max response is 17.272423, min response is -3.483067.
max gradient is 7.997434, min gradient is -8.000000, learning rate is 0.000434
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.658337, learning rate is 0.000217
Net2: layer bn49:max response is 9.794915, min response is -1.762332.
max gradient is 8.000000, min gradient is -6.322561, learning rate is 0.000434
Net2: layer deconv1:max response is , min response is .
max gradient is 7.458097, min gradient is -8.000000, learning rate is 0.000217
max inferred z is 3.99, min inferred z is -4.01, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 83: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.092215, min gradient is -8.000000, learning rate is 0.001002
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.250439, learning rate is 0.001002
Net1: layer conv1:max response is , min response is .
max gradient is 3.700485, min gradient is -8.000000, learning rate is 0.001002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.175274, learning rate is 0.000434
Net2: layer deconv3:max response is 34.342087, min response is -36.146324.
max gradient is 6.487128, min gradient is -8.000000, learning rate is 0.000217
Net2: layer bn50:max response is 19.331200, min response is -3.451349.
max gradient is 8.000000, min gradient is -5.988568, learning rate is 0.000434
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.288037, learning rate is 0.000217
Net2: layer bn49:max response is 9.922222, min response is -1.905891.
max gradient is 8.000000, min gradient is -6.550803, learning rate is 0.000434
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.958206, learning rate is 0.000217
max inferred z is 4.21, min inferred z is -4.09, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 83: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.395335, min gradient is -8.000000, learning rate is 0.001002
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.808182, learning rate is 0.001002
Net1: layer conv1:max response is , min response is .
max gradient is 3.346289, min gradient is -8.000000, learning rate is 0.001002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -4.996478, min gradient is -8.000000, learning rate is 0.000434
Net2: layer deconv3:max response is 34.935562, min response is -36.996994.
max gradient is 8.000000, min gradient is -4.763704, learning rate is 0.000217
Net2: layer bn50:max response is 19.233765, min response is -3.875877.
max gradient is 5.679547, min gradient is -8.000001, learning rate is 0.000434
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.883942, learning rate is 0.000217
Net2: layer bn49:max response is 9.501863, min response is -1.936185.
max gradient is 5.765288, min gradient is -8.000000, learning rate is 0.000434
Net2: layer deconv1:max response is , min response is .
max gradient is 7.641773, min gradient is -8.000000, learning rate is 0.000217
max inferred z is 3.57, min inferred z is -4.11, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 83: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.446991, learning rate is 0.001002
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.613009, learning rate is 0.001002
Net1: layer conv1:max response is , min response is .
max gradient is 4.730577, min gradient is -8.000000, learning rate is 0.001002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.617881, learning rate is 0.000434
Net2: layer deconv3:max response is 33.505646, min response is -37.297363.
max gradient is 6.347283, min gradient is -8.000000, learning rate is 0.000217
Net2: layer bn50:max response is 20.164558, min response is -3.891244.
max gradient is 8.000000, min gradient is -5.758479, learning rate is 0.000434
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.944767, learning rate is 0.000217
Net2: layer bn49:max response is 8.614192, min response is -1.995083.
max gradient is 8.000000, min gradient is -4.859977, learning rate is 0.000434
Net2: layer deconv1:max response is , min response is .
max gradient is 7.573941, min gradient is -8.000000, learning rate is 0.000217
max inferred z is 4.21, min inferred z is -4.46, and std is 1.00
 4.41 s (22.7 data/s) [100/100]
training: epoch 83: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.134424, min gradient is -8.000000, learning rate is 0.001002
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.422141, learning rate is 0.001002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.350813, learning rate is 0.001002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.117027, min gradient is -8.000000, learning rate is 0.000434
Net2: layer deconv3:max response is 32.141277, min response is -32.987480.
max gradient is 8.000000, min gradient is -5.632050, learning rate is 0.000217
Net2: layer bn50:max response is 17.444090, min response is -3.374720.
max gradient is 6.917124, min gradient is -8.000000, learning rate is 0.000434
Net2: layer deconv2:max response is , min response is .
max gradient is 7.809942, min gradient is -8.000000, learning rate is 0.000217
Net2: layer bn49:max response is 10.278368, min response is -2.256646.
max gradient is 5.949783, min gradient is -8.000000, learning rate is 0.000434
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.093163, learning rate is 0.000217
max inferred z is 4.07, min inferred z is -4.37, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
Loss: 1.6306
Iteration 84 / 200
training: epoch 84: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.741385, min gradient is -8.000000, learning rate is 0.001002
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.621552, learning rate is 0.001002
Net1: layer conv1:max response is , min response is .
max gradient is 5.997469, min gradient is -8.000000, learning rate is 0.001002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 0.941921, learning rate is 0.000432
Net2: layer deconv3:max response is 34.369930, min response is -35.519161.
max gradient is 6.889795, min gradient is -8.000000, learning rate is 0.000216
Net2: layer bn50:max response is 22.246899, min response is -3.935458.
max gradient is 8.000000, min gradient is -7.496870, learning rate is 0.000432
Net2: layer deconv2:max response is , min response is .
max gradient is 7.219654, min gradient is -8.000000, learning rate is 0.000216
Net2: layer bn49:max response is 10.039353, min response is -2.022241.
max gradient is 6.930547, min gradient is -8.000000, learning rate is 0.000432
Net2: layer deconv1:max response is , min response is .
max gradient is 7.577801, min gradient is -8.000000, learning rate is 0.000216
max inferred z is 4.14, min inferred z is -3.87, and std is 1.00
 4.30 s (23.3 data/s) [100/100]
training: epoch 84: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.985620, min gradient is -8.000000, learning rate is 0.001002
Net1: layer conv2:max response is , min response is .
max gradient is 7.378359, min gradient is -8.000000, learning rate is 0.001002
Net1: layer conv1:max response is , min response is .
max gradient is 5.010360, min gradient is -8.000000, learning rate is 0.001002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.341366, min gradient is -8.000000, learning rate is 0.000432
Net2: layer deconv3:max response is 34.643574, min response is -34.874981.
max gradient is 8.000000, min gradient is -5.575098, learning rate is 0.000216
Net2: layer bn50:max response is 20.861414, min response is -3.685579.
max gradient is 8.000000, min gradient is -6.218334, learning rate is 0.000432
Net2: layer deconv2:max response is , min response is .
max gradient is 7.973882, min gradient is -8.000000, learning rate is 0.000216
Net2: layer bn49:max response is 10.207249, min response is -2.018520.
max gradient is 8.000000, min gradient is -5.213255, learning rate is 0.000432
Net2: layer deconv1:max response is , min response is .
max gradient is 7.601371, min gradient is -8.000000, learning rate is 0.000216
max inferred z is 4.02, min inferred z is -4.02, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
training: epoch 84: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.412068, min gradient is -8.000000, learning rate is 0.001002
Net1: layer conv2:max response is , min response is .
max gradient is 7.195457, min gradient is -8.000000, learning rate is 0.001002
Net1: layer conv1:max response is , min response is .
max gradient is 5.737149, min gradient is -8.000000, learning rate is 0.001002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 2.277907, min gradient is -8.000000, learning rate is 0.000432
Net2: layer deconv3:max response is 28.259373, min response is -32.700531.
max gradient is 7.007224, min gradient is -8.000000, learning rate is 0.000216
Net2: layer bn50:max response is 20.389965, min response is -4.099548.
max gradient is 8.000000, min gradient is -7.792760, learning rate is 0.000432
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.816630, learning rate is 0.000216
Net2: layer bn49:max response is 9.052433, min response is -1.951604.
max gradient is 7.699428, min gradient is -8.000000, learning rate is 0.000432
Net2: layer deconv1:max response is , min response is .
max gradient is 6.172918, min gradient is -8.000000, learning rate is 0.000216
max inferred z is 4.17, min inferred z is -3.76, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 84: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.012267, min gradient is -8.000000, learning rate is 0.001002
Net1: layer conv2:max response is , min response is .
max gradient is 6.895017, min gradient is -8.000000, learning rate is 0.001002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.052098, learning rate is 0.001002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.649726, min gradient is -8.000000, learning rate is 0.000432
Net2: layer deconv3:max response is 33.105484, min response is -42.437901.
max gradient is 8.000000, min gradient is -6.970632, learning rate is 0.000216
Net2: layer bn50:max response is 17.620359, min response is -3.220210.
max gradient is 5.622838, min gradient is -8.000000, learning rate is 0.000432
Net2: layer deconv2:max response is , min response is .
max gradient is 6.608098, min gradient is -8.000000, learning rate is 0.000216
Net2: layer bn49:max response is 10.086299, min response is -2.263990.
max gradient is 6.133707, min gradient is -8.000000, learning rate is 0.000432
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.528518, learning rate is 0.000216
max inferred z is 4.41, min inferred z is -3.74, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 84: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.206962, min gradient is -8.000000, learning rate is 0.001002
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.957468, learning rate is 0.001002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.249153, learning rate is 0.001002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 5.922056, min gradient is 0.248804, learning rate is 0.000432
Net2: layer deconv3:max response is 40.091278, min response is -31.069553.
max gradient is 5.852984, min gradient is -8.000000, learning rate is 0.000216
Net2: layer bn50:max response is 21.417553, min response is -3.218620.
max gradient is 8.000000, min gradient is -6.165293, learning rate is 0.000432
Net2: layer deconv2:max response is , min response is .
max gradient is 6.419571, min gradient is -8.000000, learning rate is 0.000216
Net2: layer bn49:max response is 9.853839, min response is -1.860057.
max gradient is 8.000000, min gradient is -4.862008, learning rate is 0.000432
Net2: layer deconv1:max response is , min response is .
max gradient is 6.330301, min gradient is -8.000000, learning rate is 0.000216
max inferred z is 3.89, min inferred z is -3.91, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 84: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.578770, min gradient is -8.000000, learning rate is 0.001002
Net1: layer conv2:max response is , min response is .
max gradient is 7.678321, min gradient is -8.000000, learning rate is 0.001002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.142507, learning rate is 0.001002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.633641, min gradient is -8.000000, learning rate is 0.000432
Net2: layer deconv3:max response is 31.577847, min response is -33.120682.
max gradient is 8.000000, min gradient is -5.214732, learning rate is 0.000216
Net2: layer bn50:max response is 20.302197, min response is -3.658509.
max gradient is 8.000000, min gradient is -5.630883, learning rate is 0.000432
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.109196, learning rate is 0.000216
Net2: layer bn49:max response is 9.084609, min response is -1.956058.
max gradient is 6.603929, min gradient is -8.000000, learning rate is 0.000432
Net2: layer deconv1:max response is , min response is .
max gradient is 5.482031, min gradient is -8.000000, learning rate is 0.000216
max inferred z is 4.01, min inferred z is -3.61, and std is 1.00
 4.30 s (23.3 data/s) [100/100]
training: epoch 84: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.326380, min gradient is -8.000000, learning rate is 0.001002
Net1: layer conv2:max response is , min response is .
max gradient is 8.000001, min gradient is -7.836641, learning rate is 0.001002
Net1: layer conv1:max response is , min response is .
max gradient is 4.098056, min gradient is -8.000000, learning rate is 0.001002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.707056, learning rate is 0.000432
Net2: layer deconv3:max response is 30.657221, min response is -36.533165.
max gradient is 3.941505, min gradient is -8.000000, learning rate is 0.000216
Net2: layer bn50:max response is 24.829283, min response is -5.073734.
max gradient is 7.349055, min gradient is -8.000000, learning rate is 0.000432
Net2: layer deconv2:max response is , min response is .
max gradient is 7.367599, min gradient is -8.000000, learning rate is 0.000216
Net2: layer bn49:max response is 8.571122, min response is -2.140011.
max gradient is 6.775915, min gradient is -8.000000, learning rate is 0.000432
Net2: layer deconv1:max response is , min response is .
max gradient is 6.828886, min gradient is -8.000000, learning rate is 0.000216
max inferred z is 4.45, min inferred z is -4.12, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 84: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.621914, min gradient is -8.000001, learning rate is 0.001002
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.312678, learning rate is 0.001002
Net1: layer conv1:max response is , min response is .
max gradient is 4.803953, min gradient is -8.000000, learning rate is 0.001002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -1.228562, min gradient is -8.000000, learning rate is 0.000432
Net2: layer deconv3:max response is 36.326889, min response is -34.681293.
max gradient is 8.000000, min gradient is -5.429834, learning rate is 0.000216
Net2: layer bn50:max response is 19.050211, min response is -3.424604.
max gradient is 8.000000, min gradient is -7.973478, learning rate is 0.000432
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.236604, learning rate is 0.000216
Net2: layer bn49:max response is 9.561332, min response is -1.887024.
max gradient is 7.250163, min gradient is -8.000000, learning rate is 0.000432
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.124212, learning rate is 0.000216
max inferred z is 3.68, min inferred z is -3.82, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 84: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.568557, min gradient is -8.000000, learning rate is 0.001002
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.434970, learning rate is 0.001002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.131382, learning rate is 0.001002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.100982, learning rate is 0.000432
Net2: layer deconv3:max response is 34.514721, min response is -33.557682.
max gradient is 6.135162, min gradient is -8.000000, learning rate is 0.000216
Net2: layer bn50:max response is 19.127405, min response is -3.480849.
max gradient is 8.000000, min gradient is -5.254719, learning rate is 0.000432
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.088132, learning rate is 0.000216
Net2: layer bn49:max response is 8.913323, min response is -1.872929.
max gradient is 8.000000, min gradient is -6.898260, learning rate is 0.000432
Net2: layer deconv1:max response is , min response is .
max gradient is 7.739555, min gradient is -8.000001, learning rate is 0.000216
max inferred z is 3.81, min inferred z is -3.81, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 84: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.680465, min gradient is -8.000000, learning rate is 0.001002
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.271331, learning rate is 0.001002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.722934, learning rate is 0.001002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.294220, min gradient is -8.000000, learning rate is 0.000432
Net2: layer deconv3:max response is 32.873108, min response is -39.534996.
max gradient is 8.000000, min gradient is -5.386135, learning rate is 0.000216
Net2: layer bn50:max response is 18.467569, min response is -3.507376.
max gradient is 5.877461, min gradient is -8.000000, learning rate is 0.000432
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.831227, learning rate is 0.000216
Net2: layer bn49:max response is 10.536641, min response is -2.109869.
max gradient is 3.559963, min gradient is -8.000000, learning rate is 0.000432
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.889746, learning rate is 0.000216
max inferred z is 4.08, min inferred z is -3.92, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
Loss: 1.5903
Iteration 85 / 200
training: epoch 85: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.677984, min gradient is -8.000000, learning rate is 0.000832
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.315893, learning rate is 0.000832
Net1: layer conv1:max response is , min response is .
max gradient is 4.153057, min gradient is -8.000000, learning rate is 0.000832
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.427772, min gradient is -8.000000, learning rate is 0.000430
Net2: layer deconv3:max response is 31.343725, min response is -38.215698.
max gradient is 6.340201, min gradient is -8.000000, learning rate is 0.000215
Net2: layer bn50:max response is 22.748154, min response is -4.583465.
max gradient is 8.000000, min gradient is -5.124237, learning rate is 0.000430
Net2: layer deconv2:max response is , min response is .
max gradient is 7.026310, min gradient is -8.000000, learning rate is 0.000215
Net2: layer bn49:max response is 9.381734, min response is -2.086972.
max gradient is 8.000000, min gradient is -2.831701, learning rate is 0.000430
Net2: layer deconv1:max response is , min response is .
max gradient is 7.517148, min gradient is -8.000000, learning rate is 0.000215
max inferred z is 3.87, min inferred z is -3.80, and std is 1.00
 4.17 s (24.0 data/s) [100/100]
training: epoch 85: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.099537, min gradient is -8.000000, learning rate is 0.000832
Net1: layer conv2:max response is , min response is .
max gradient is 7.074790, min gradient is -8.000000, learning rate is 0.000832
Net1: layer conv1:max response is , min response is .
max gradient is 4.242086, min gradient is -8.000000, learning rate is 0.000832
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.910165, min gradient is -8.000000, learning rate is 0.000430
Net2: layer deconv3:max response is 29.212492, min response is -33.743515.
max gradient is 8.000000, min gradient is -6.970376, learning rate is 0.000215
Net2: layer bn50:max response is 18.284815, min response is -3.715124.
max gradient is 6.954411, min gradient is -8.000000, learning rate is 0.000430
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.336285, learning rate is 0.000215
Net2: layer bn49:max response is 8.918029, min response is -1.938311.
max gradient is 7.082343, min gradient is -8.000000, learning rate is 0.000430
Net2: layer deconv1:max response is , min response is .
max gradient is 5.937874, min gradient is -8.000000, learning rate is 0.000215
max inferred z is 4.18, min inferred z is -4.02, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 85: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.814112, min gradient is -8.000000, learning rate is 0.000832
Net1: layer conv2:max response is , min response is .
max gradient is 7.147141, min gradient is -8.000000, learning rate is 0.000832
Net1: layer conv1:max response is , min response is .
max gradient is 5.855502, min gradient is -8.000000, learning rate is 0.000832
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.447368, learning rate is 0.000430
Net2: layer deconv3:max response is 37.779739, min response is -30.958815.
max gradient is 6.591478, min gradient is -8.000000, learning rate is 0.000215
Net2: layer bn50:max response is 20.443768, min response is -3.483022.
max gradient is 7.375134, min gradient is -8.000000, learning rate is 0.000430
Net2: layer deconv2:max response is , min response is .
max gradient is 6.472988, min gradient is -8.000000, learning rate is 0.000215
Net2: layer bn49:max response is 9.183973, min response is -2.079396.
max gradient is 6.918856, min gradient is -8.000000, learning rate is 0.000430
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.107927, learning rate is 0.000215
max inferred z is 4.43, min inferred z is -4.04, and std is 1.00
 4.46 s (22.4 data/s) [100/100]
training: epoch 85: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.414814, min gradient is -8.000000, learning rate is 0.000832
Net1: layer conv2:max response is , min response is .
max gradient is 7.926284, min gradient is -8.000000, learning rate is 0.000832
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.418504, learning rate is 0.000832
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.032032, min gradient is -8.000000, learning rate is 0.000430
Net2: layer deconv3:max response is 31.430418, min response is -31.276295.
max gradient is 8.000000, min gradient is -6.707685, learning rate is 0.000215
Net2: layer bn50:max response is 18.266071, min response is -3.533635.
max gradient is 7.390574, min gradient is -8.000000, learning rate is 0.000430
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.959167, learning rate is 0.000215
Net2: layer bn49:max response is 8.699138, min response is -2.024087.
max gradient is 8.000000, min gradient is -6.231503, learning rate is 0.000430
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.111209, learning rate is 0.000215
max inferred z is 4.12, min inferred z is -3.99, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 85: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.276036, min gradient is -8.000000, learning rate is 0.000832
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.814524, learning rate is 0.000832
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.713695, learning rate is 0.000832
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.822129, learning rate is 0.000430
Net2: layer deconv3:max response is 31.199310, min response is -32.413658.
max gradient is 7.139159, min gradient is -8.000000, learning rate is 0.000215
Net2: layer bn50:max response is 19.414820, min response is -3.744484.
max gradient is 7.078016, min gradient is -8.000000, learning rate is 0.000430
Net2: layer deconv2:max response is , min response is .
max gradient is 7.748713, min gradient is -8.000000, learning rate is 0.000215
Net2: layer bn49:max response is 9.490073, min response is -2.029276.
max gradient is 8.000000, min gradient is -5.336929, learning rate is 0.000430
Net2: layer deconv1:max response is , min response is .
max gradient is 6.740044, min gradient is -8.000000, learning rate is 0.000215
max inferred z is 3.89, min inferred z is -3.97, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 85: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.236505, min gradient is -8.000000, learning rate is 0.000832
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.068371, learning rate is 0.000832
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.032615, learning rate is 0.000832
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.961940, min gradient is -8.000001, learning rate is 0.000430
Net2: layer deconv3:max response is 31.675373, min response is -28.343470.
max gradient is 8.000001, min gradient is -7.140152, learning rate is 0.000215
Net2: layer bn50:max response is 18.126999, min response is -3.604150.
max gradient is 7.224053, min gradient is -8.000000, learning rate is 0.000430
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.871851, learning rate is 0.000215
Net2: layer bn49:max response is 8.434021, min response is -2.005389.
max gradient is 8.000000, min gradient is -6.583526, learning rate is 0.000430
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.761898, learning rate is 0.000215
max inferred z is 4.08, min inferred z is -3.81, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
training: epoch 85: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.788152, min gradient is -8.000000, learning rate is 0.000832
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.490918, learning rate is 0.000832
Net1: layer conv1:max response is , min response is .
max gradient is 5.636491, min gradient is -8.000000, learning rate is 0.000832
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.836466, learning rate is 0.000430
Net2: layer deconv3:max response is 34.890034, min response is -36.831589.
max gradient is 5.706559, min gradient is -8.000000, learning rate is 0.000215
Net2: layer bn50:max response is 19.443108, min response is -3.530165.
max gradient is 7.166966, min gradient is -8.000000, learning rate is 0.000430
Net2: layer deconv2:max response is , min response is .
max gradient is 7.633661, min gradient is -8.000000, learning rate is 0.000215
Net2: layer bn49:max response is 11.670154, min response is -2.052265.
max gradient is 7.120896, min gradient is -8.000000, learning rate is 0.000430
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.681378, learning rate is 0.000215
max inferred z is 4.25, min inferred z is -4.27, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 85: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.646308, min gradient is -8.000000, learning rate is 0.000832
Net1: layer conv2:max response is , min response is .
max gradient is 7.199984, min gradient is -8.000000, learning rate is 0.000832
Net1: layer conv1:max response is , min response is .
max gradient is 4.038012, min gradient is -8.000000, learning rate is 0.000832
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.716324, min gradient is -8.000000, learning rate is 0.000430
Net2: layer deconv3:max response is 31.294806, min response is -34.107586.
max gradient is 8.000000, min gradient is -7.989636, learning rate is 0.000215
Net2: layer bn50:max response is 19.801222, min response is -3.598424.
max gradient is 6.905480, min gradient is -8.000000, learning rate is 0.000430
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.963155, learning rate is 0.000215
Net2: layer bn49:max response is 9.762531, min response is -1.888432.
max gradient is 6.656061, min gradient is -8.000000, learning rate is 0.000430
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.529178, learning rate is 0.000215
max inferred z is 3.91, min inferred z is -3.52, and std is 1.00
 4.30 s (23.3 data/s) [100/100]
training: epoch 85: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.304148, min gradient is -8.000000, learning rate is 0.000832
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.316966, learning rate is 0.000832
Net1: layer conv1:max response is , min response is .
max gradient is 5.165665, min gradient is -8.000000, learning rate is 0.000832
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.123305, learning rate is 0.000430
Net2: layer deconv3:max response is 37.576401, min response is -43.142151.
max gradient is 6.475307, min gradient is -8.000000, learning rate is 0.000215
Net2: layer bn50:max response is 19.367849, min response is -3.770020.
max gradient is 7.970153, min gradient is -8.000000, learning rate is 0.000430
Net2: layer deconv2:max response is , min response is .
max gradient is 6.975938, min gradient is -8.000000, learning rate is 0.000215
Net2: layer bn49:max response is 10.921681, min response is -2.569213.
max gradient is 8.000000, min gradient is -7.499138, learning rate is 0.000430
Net2: layer deconv1:max response is , min response is .
max gradient is 6.943201, min gradient is -8.000000, learning rate is 0.000215
max inferred z is 3.80, min inferred z is -4.30, and std is 1.00
 4.30 s (23.3 data/s) [100/100]
training: epoch 85: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.376760, min gradient is -8.000000, learning rate is 0.000832
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.685780, learning rate is 0.000832
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -5.915202, learning rate is 0.000832
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.227647, min gradient is -8.000000, learning rate is 0.000430
Net2: layer deconv3:max response is 28.953447, min response is -31.924831.
max gradient is 8.000000, min gradient is -6.553597, learning rate is 0.000215
Net2: layer bn50:max response is 23.301565, min response is -4.701402.
max gradient is 8.000000, min gradient is -6.691725, learning rate is 0.000430
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.944639, learning rate is 0.000215
Net2: layer bn49:max response is 9.355955, min response is -2.237101.
max gradient is 8.000000, min gradient is -5.910426, learning rate is 0.000430
Net2: layer deconv1:max response is , min response is .
max gradient is 5.985600, min gradient is -8.000000, learning rate is 0.000215
max inferred z is 4.51, min inferred z is -3.89, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
Loss: 1.5065
Iteration 86 / 200
training: epoch 86: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.293122, min gradient is -8.000000, learning rate is 0.000832
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.211405, learning rate is 0.000832
Net1: layer conv1:max response is , min response is .
max gradient is 7.642203, min gradient is -8.000001, learning rate is 0.000832
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.881161, learning rate is 0.000428
Net2: layer deconv3:max response is 40.592567, min response is -38.791187.
max gradient is 6.558774, min gradient is -8.000000, learning rate is 0.000214
Net2: layer bn50:max response is 22.326262, min response is -3.912942.
max gradient is 8.000000, min gradient is -7.575161, learning rate is 0.000428
Net2: layer deconv2:max response is , min response is .
max gradient is 6.920634, min gradient is -8.000000, learning rate is 0.000214
Net2: layer bn49:max response is 10.846283, min response is -1.965157.
max gradient is 8.000000, min gradient is -7.333994, learning rate is 0.000428
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.344309, learning rate is 0.000214
max inferred z is 4.04, min inferred z is -3.35, and std is 0.99
 4.30 s (23.2 data/s) [100/100]
training: epoch 86: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.471269, min gradient is -8.000000, learning rate is 0.000832
Net1: layer conv2:max response is , min response is .
max gradient is 7.945858, min gradient is -8.000000, learning rate is 0.000832
Net1: layer conv1:max response is , min response is .
max gradient is 3.942909, min gradient is -8.000000, learning rate is 0.000832
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.292294, min gradient is -8.000000, learning rate is 0.000428
Net2: layer deconv3:max response is 36.760735, min response is -29.448076.
max gradient is 8.000000, min gradient is -6.571759, learning rate is 0.000214
Net2: layer bn50:max response is 22.590485, min response is -4.334039.
max gradient is 7.525220, min gradient is -8.000000, learning rate is 0.000428
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.769448, learning rate is 0.000214
Net2: layer bn49:max response is 9.057042, min response is -2.160439.
max gradient is 8.000000, min gradient is -6.134977, learning rate is 0.000428
Net2: layer deconv1:max response is , min response is .
max gradient is 7.342278, min gradient is -8.000000, learning rate is 0.000214
max inferred z is 3.90, min inferred z is -4.28, and std is 0.99
 4.35 s (23.0 data/s) [100/100]
training: epoch 86: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.942064, min gradient is -8.000000, learning rate is 0.000832
Net1: layer conv2:max response is , min response is .
max gradient is 7.520032, min gradient is -8.000000, learning rate is 0.000832
Net1: layer conv1:max response is , min response is .
max gradient is 5.570740, min gradient is -8.000000, learning rate is 0.000832
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.221115, learning rate is 0.000428
Net2: layer deconv3:max response is 30.719940, min response is -29.519222.
max gradient is 5.098086, min gradient is -8.000000, learning rate is 0.000214
Net2: layer bn50:max response is 17.147491, min response is -3.479228.
max gradient is 6.806247, min gradient is -8.000000, learning rate is 0.000428
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.544190, learning rate is 0.000214
Net2: layer bn49:max response is 9.750545, min response is -2.096524.
max gradient is 8.000000, min gradient is -5.548679, learning rate is 0.000428
Net2: layer deconv1:max response is , min response is .
max gradient is 7.408558, min gradient is -8.000000, learning rate is 0.000214
max inferred z is 4.23, min inferred z is -3.88, and std is 0.99
 4.38 s (22.8 data/s) [100/100]
training: epoch 86: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.539766, min gradient is -8.000000, learning rate is 0.000832
Net1: layer conv2:max response is , min response is .
max gradient is 7.243244, min gradient is -8.000000, learning rate is 0.000832
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.752200, learning rate is 0.000832
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.943165, min gradient is -8.000000, learning rate is 0.000428
Net2: layer deconv3:max response is 34.565540, min response is -30.786800.
max gradient is 8.000000, min gradient is -6.660634, learning rate is 0.000214
Net2: layer bn50:max response is 19.668472, min response is -3.975029.
max gradient is 6.400400, min gradient is -8.000000, learning rate is 0.000428
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.122915, learning rate is 0.000214
Net2: layer bn49:max response is 10.378173, min response is -2.181752.
max gradient is 6.347254, min gradient is -8.000000, learning rate is 0.000428
Net2: layer deconv1:max response is , min response is .
max gradient is 7.903324, min gradient is -8.000000, learning rate is 0.000214
max inferred z is 3.80, min inferred z is -4.16, and std is 0.99
 4.37 s (22.9 data/s) [100/100]
training: epoch 86: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.239236, min gradient is -8.000000, learning rate is 0.000832
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.895477, learning rate is 0.000832
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.752164, learning rate is 0.000832
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.686368, learning rate is 0.000428
Net2: layer deconv3:max response is 33.739052, min response is -27.102415.
max gradient is 6.476656, min gradient is -8.000000, learning rate is 0.000214
Net2: layer bn50:max response is 18.015202, min response is -3.749675.
max gradient is 8.000000, min gradient is -6.248062, learning rate is 0.000428
Net2: layer deconv2:max response is , min response is .
max gradient is 7.681379, min gradient is -8.000000, learning rate is 0.000214
Net2: layer bn49:max response is 10.393347, min response is -2.087683.
max gradient is 8.000000, min gradient is -5.262982, learning rate is 0.000428
Net2: layer deconv1:max response is , min response is .
max gradient is 5.325247, min gradient is -8.000000, learning rate is 0.000214
max inferred z is 4.12, min inferred z is -4.36, and std is 0.99
 4.40 s (22.7 data/s) [100/100]
training: epoch 86: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.048627, min gradient is -8.000000, learning rate is 0.000832
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.588762, learning rate is 0.000832
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.992826, learning rate is 0.000832
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.367140, learning rate is 0.000428
Net2: layer deconv3:max response is 38.153633, min response is -30.460859.
max gradient is 7.375504, min gradient is -8.000000, learning rate is 0.000214
Net2: layer bn50:max response is 20.285341, min response is -3.744395.
max gradient is 5.622867, min gradient is -8.000000, learning rate is 0.000428
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.685068, learning rate is 0.000214
Net2: layer bn49:max response is 9.296758, min response is -2.027897.
max gradient is 7.359261, min gradient is -8.000000, learning rate is 0.000428
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.292295, learning rate is 0.000214
max inferred z is 4.03, min inferred z is -4.13, and std is 0.99
 4.22 s (23.7 data/s) [100/100]
training: epoch 86: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.085571, min gradient is -8.000000, learning rate is 0.000832
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.826963, learning rate is 0.000832
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.423056, learning rate is 0.000832
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.680233, learning rate is 0.000428
Net2: layer deconv3:max response is 28.477800, min response is -30.794559.
max gradient is 6.879709, min gradient is -8.000000, learning rate is 0.000214
Net2: layer bn50:max response is 21.635921, min response is -4.498987.
max gradient is 8.000000, min gradient is -7.033262, learning rate is 0.000428
Net2: layer deconv2:max response is , min response is .
max gradient is 7.659027, min gradient is -8.000000, learning rate is 0.000214
Net2: layer bn49:max response is 10.138747, min response is -2.203330.
max gradient is 8.000000, min gradient is -4.850875, learning rate is 0.000428
Net2: layer deconv1:max response is , min response is .
max gradient is 7.857989, min gradient is -8.000000, learning rate is 0.000214
max inferred z is 4.02, min inferred z is -4.31, and std is 0.99
 4.38 s (22.9 data/s) [100/100]
training: epoch 86: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.411297, min gradient is -8.000000, learning rate is 0.000832
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.956061, learning rate is 0.000832
Net1: layer conv1:max response is , min response is .
max gradient is 3.548529, min gradient is -8.000000, learning rate is 0.000832
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -2.740012, min gradient is -8.000000, learning rate is 0.000428
Net2: layer deconv3:max response is 27.559469, min response is -29.162664.
max gradient is 8.000000, min gradient is -7.004215, learning rate is 0.000214
Net2: layer bn50:max response is 16.683664, min response is -3.827660.
max gradient is 5.595705, min gradient is -8.000000, learning rate is 0.000428
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.526880, learning rate is 0.000214
Net2: layer bn49:max response is 10.793146, min response is -2.161300.
max gradient is 7.467412, min gradient is -8.000000, learning rate is 0.000428
Net2: layer deconv1:max response is , min response is .
max gradient is 6.154840, min gradient is -8.000000, learning rate is 0.000214
max inferred z is 3.84, min inferred z is -3.62, and std is 0.99
 4.30 s (23.2 data/s) [100/100]
training: epoch 86: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.650619, min gradient is -8.000000, learning rate is 0.000832
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.856013, learning rate is 0.000832
Net1: layer conv1:max response is , min response is .
max gradient is 6.634809, min gradient is -8.000000, learning rate is 0.000832
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.825837, learning rate is 0.000428
Net2: layer deconv3:max response is 33.235191, min response is -31.158031.
max gradient is 7.251086, min gradient is -8.000000, learning rate is 0.000214
Net2: layer bn50:max response is 19.787830, min response is -3.462672.
max gradient is 8.000000, min gradient is -6.576707, learning rate is 0.000428
Net2: layer deconv2:max response is , min response is .
max gradient is 7.862873, min gradient is -8.000000, learning rate is 0.000214
Net2: layer bn49:max response is 9.585628, min response is -2.007519.
max gradient is 8.000000, min gradient is -5.625334, learning rate is 0.000428
Net2: layer deconv1:max response is , min response is .
max gradient is 7.387093, min gradient is -8.000000, learning rate is 0.000214
max inferred z is 3.61, min inferred z is -4.02, and std is 0.99
 4.33 s (23.1 data/s) [100/100]
training: epoch 86: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.868701, min gradient is -8.000001, learning rate is 0.000832
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.602173, learning rate is 0.000832
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.608997, learning rate is 0.000832
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -0.734469, min gradient is -8.000000, learning rate is 0.000428
Net2: layer deconv3:max response is 37.262028, min response is -31.271971.
max gradient is 8.000001, min gradient is -7.938223, learning rate is 0.000214
Net2: layer bn50:max response is 22.443436, min response is -3.655299.
max gradient is 5.852546, min gradient is -8.000000, learning rate is 0.000428
Net2: layer deconv2:max response is , min response is .
max gradient is 7.039245, min gradient is -8.000000, learning rate is 0.000214
Net2: layer bn49:max response is 10.005908, min response is -2.246945.
max gradient is 8.000000, min gradient is -6.691551, learning rate is 0.000428
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.840405, learning rate is 0.000214
max inferred z is 3.67, min inferred z is -3.77, and std is 0.99
 4.39 s (22.8 data/s) [100/100]
Loss: 1.4508
Iteration 87 / 200
training: epoch 87: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.693156, min gradient is -8.000000, learning rate is 0.000690
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.803282, learning rate is 0.000690
Net1: layer conv1:max response is , min response is .
max gradient is 7.661030, min gradient is -8.000000, learning rate is 0.000690
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.731205, learning rate is 0.000426
Net2: layer deconv3:max response is 36.778545, min response is -31.989326.
max gradient is 7.264225, min gradient is -8.000000, learning rate is 0.000213
Net2: layer bn50:max response is 23.193731, min response is -4.394459.
max gradient is 8.000000, min gradient is -6.473745, learning rate is 0.000426
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.696731, learning rate is 0.000213
Net2: layer bn49:max response is 9.012922, min response is -2.131236.
max gradient is 8.000000, min gradient is -4.129969, learning rate is 0.000426
Net2: layer deconv1:max response is , min response is .
max gradient is 7.458640, min gradient is -8.000000, learning rate is 0.000213
max inferred z is 3.46, min inferred z is -3.74, and std is 1.01
 4.17 s (24.0 data/s) [100/100]
training: epoch 87: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.230448, min gradient is -8.000000, learning rate is 0.000690
Net1: layer conv2:max response is , min response is .
max gradient is 7.678875, min gradient is -8.000000, learning rate is 0.000690
Net1: layer conv1:max response is , min response is .
max gradient is 3.844875, min gradient is -8.000000, learning rate is 0.000690
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -3.894459, min gradient is -8.000000, learning rate is 0.000426
Net2: layer deconv3:max response is 32.619915, min response is -32.549236.
max gradient is 7.834791, min gradient is -8.000000, learning rate is 0.000213
Net2: layer bn50:max response is 18.215727, min response is -3.986375.
max gradient is 5.543801, min gradient is -8.000000, learning rate is 0.000426
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.671951, learning rate is 0.000213
Net2: layer bn49:max response is 9.632913, min response is -2.066301.
max gradient is 5.759058, min gradient is -8.000000, learning rate is 0.000426
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.803651, learning rate is 0.000213
max inferred z is 3.80, min inferred z is -4.25, and std is 1.01
 4.41 s (22.7 data/s) [100/100]
training: epoch 87: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.263906, min gradient is -8.000000, learning rate is 0.000690
Net1: layer conv2:max response is , min response is .
max gradient is 7.601127, min gradient is -8.000000, learning rate is 0.000690
Net1: layer conv1:max response is , min response is .
max gradient is 5.235933, min gradient is -8.000000, learning rate is 0.000690
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.517394, learning rate is 0.000426
Net2: layer deconv3:max response is 30.686462, min response is -31.228655.
max gradient is 6.666834, min gradient is -8.000000, learning rate is 0.000213
Net2: layer bn50:max response is 19.123867, min response is -3.659651.
max gradient is 7.764444, min gradient is -8.000000, learning rate is 0.000426
Net2: layer deconv2:max response is , min response is .
max gradient is 6.061912, min gradient is -8.000000, learning rate is 0.000213
Net2: layer bn49:max response is 9.735929, min response is -2.124244.
max gradient is 8.000000, min gradient is -2.846740, learning rate is 0.000426
Net2: layer deconv1:max response is , min response is .
max gradient is 6.716774, min gradient is -8.000001, learning rate is 0.000213
max inferred z is 4.17, min inferred z is -4.29, and std is 1.01
 4.19 s (23.9 data/s) [100/100]
training: epoch 87: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.417325, min gradient is -8.000000, learning rate is 0.000690
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.694329, learning rate is 0.000690
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.635733, learning rate is 0.000690
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -3.579036, min gradient is -8.000001, learning rate is 0.000426
Net2: layer deconv3:max response is 31.190321, min response is -31.468731.
max gradient is 8.000000, min gradient is -7.081347, learning rate is 0.000213
Net2: layer bn50:max response is 17.226555, min response is -3.300249.
max gradient is 8.000000, min gradient is -7.799311, learning rate is 0.000426
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.936403, learning rate is 0.000213
Net2: layer bn49:max response is 13.049365, min response is -2.030340.
max gradient is 6.603416, min gradient is -8.000000, learning rate is 0.000426
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.964433, learning rate is 0.000213
max inferred z is 3.92, min inferred z is -3.95, and std is 1.01
 4.24 s (23.6 data/s) [100/100]
training: epoch 87: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.443826, min gradient is -8.000000, learning rate is 0.000690
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.985396, learning rate is 0.000690
Net1: layer conv1:max response is , min response is .
max gradient is 6.982316, min gradient is -8.000000, learning rate is 0.000690
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000001, min gradient is 5.440134, learning rate is 0.000426
Net2: layer deconv3:max response is 38.193348, min response is -32.184387.
max gradient is 8.000000, min gradient is -7.503413, learning rate is 0.000213
Net2: layer bn50:max response is 19.516077, min response is -4.630226.
max gradient is 8.000000, min gradient is -6.678402, learning rate is 0.000426
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.331134, learning rate is 0.000213
Net2: layer bn49:max response is 9.599791, min response is -2.331253.
max gradient is 8.000000, min gradient is -3.860621, learning rate is 0.000426
Net2: layer deconv1:max response is , min response is .
max gradient is 7.201421, min gradient is -8.000000, learning rate is 0.000213
max inferred z is 4.04, min inferred z is -3.78, and std is 1.01
 4.30 s (23.3 data/s) [100/100]
training: epoch 87: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.213127, min gradient is -8.000000, learning rate is 0.000690
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.340284, learning rate is 0.000690
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.989376, learning rate is 0.000690
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.607629, learning rate is 0.000426
Net2: layer deconv3:max response is 42.828278, min response is -29.455284.
max gradient is 7.417024, min gradient is -8.000000, learning rate is 0.000213
Net2: layer bn50:max response is 20.642397, min response is -4.153457.
max gradient is 5.705905, min gradient is -8.000000, learning rate is 0.000426
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.626253, learning rate is 0.000213
Net2: layer bn49:max response is 10.670502, min response is -2.025152.
max gradient is 5.943012, min gradient is -8.000000, learning rate is 0.000426
Net2: layer deconv1:max response is , min response is .
max gradient is 7.845098, min gradient is -8.000000, learning rate is 0.000213
max inferred z is 3.91, min inferred z is -4.23, and std is 1.01
 4.37 s (22.9 data/s) [100/100]
training: epoch 87: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.374511, min gradient is -8.000000, learning rate is 0.000690
Net1: layer conv2:max response is , min response is .
max gradient is 7.804932, min gradient is -8.000000, learning rate is 0.000690
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.863525, learning rate is 0.000690
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.048345, learning rate is 0.000426
Net2: layer deconv3:max response is 36.135765, min response is -30.226671.
max gradient is 8.000000, min gradient is -7.168098, learning rate is 0.000213
Net2: layer bn50:max response is 19.190956, min response is -3.742827.
max gradient is 8.000000, min gradient is -4.781056, learning rate is 0.000426
Net2: layer deconv2:max response is , min response is .
max gradient is 6.878883, min gradient is -8.000000, learning rate is 0.000213
Net2: layer bn49:max response is 10.483319, min response is -2.046177.
max gradient is 8.000000, min gradient is -3.796419, learning rate is 0.000426
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.530247, learning rate is 0.000213
max inferred z is 3.79, min inferred z is -3.72, and std is 1.01
 4.18 s (24.0 data/s) [100/100]
training: epoch 87: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.826325, min gradient is -8.000000, learning rate is 0.000690
Net1: layer conv2:max response is , min response is .
max gradient is 7.919422, min gradient is -8.000000, learning rate is 0.000690
Net1: layer conv1:max response is , min response is .
max gradient is 4.027974, min gradient is -8.000000, learning rate is 0.000690
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -3.428796, min gradient is -8.000000, learning rate is 0.000426
Net2: layer deconv3:max response is 37.696365, min response is -30.203621.
max gradient is 8.000001, min gradient is -6.291251, learning rate is 0.000213
Net2: layer bn50:max response is 20.214378, min response is -4.435466.
max gradient is 7.451501, min gradient is -8.000000, learning rate is 0.000426
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.465966, learning rate is 0.000213
Net2: layer bn49:max response is 9.721988, min response is -2.375839.
max gradient is 7.646599, min gradient is -8.000000, learning rate is 0.000426
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.237907, learning rate is 0.000213
max inferred z is 4.28, min inferred z is -4.27, and std is 1.01
 4.34 s (23.0 data/s) [100/100]
training: epoch 87: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.962665, min gradient is -8.000000, learning rate is 0.000690
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.029218, learning rate is 0.000690
Net1: layer conv1:max response is , min response is .
max gradient is 5.437295, min gradient is -8.000000, learning rate is 0.000690
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.020881, learning rate is 0.000426
Net2: layer deconv3:max response is 40.550381, min response is -37.536762.
max gradient is 3.531136, min gradient is -8.000000, learning rate is 0.000213
Net2: layer bn50:max response is 21.986177, min response is -4.552227.
max gradient is 7.572012, min gradient is -8.000000, learning rate is 0.000426
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.825446, learning rate is 0.000213
Net2: layer bn49:max response is 11.882138, min response is -2.023888.
max gradient is 5.869377, min gradient is -8.000000, learning rate is 0.000426
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.497693, learning rate is 0.000213
max inferred z is 3.93, min inferred z is -4.20, and std is 1.01
 4.39 s (22.8 data/s) [100/100]
training: epoch 87: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.203015, min gradient is -8.000000, learning rate is 0.000690
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.173097, learning rate is 0.000690
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.065955, learning rate is 0.000690
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -1.687592, learning rate is 0.000426
Net2: layer deconv3:max response is 28.723318, min response is -34.016090.
max gradient is 8.000000, min gradient is -4.869535, learning rate is 0.000213
Net2: layer bn50:max response is 18.928829, min response is -3.916094.
max gradient is 8.000000, min gradient is -5.734817, learning rate is 0.000426
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.606517, learning rate is 0.000213
Net2: layer bn49:max response is 12.390090, min response is -2.098999.
max gradient is 8.000000, min gradient is -7.983238, learning rate is 0.000426
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.745181, learning rate is 0.000213
max inferred z is 3.83, min inferred z is -3.89, and std is 1.01
 4.39 s (22.8 data/s) [100/100]
Loss: 1.426
Iteration 88 / 200
training: epoch 88: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.393055, min gradient is -8.000000, learning rate is 0.000690
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.700699, learning rate is 0.000690
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.583038, learning rate is 0.000690
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.762069, learning rate is 0.000424
Net2: layer deconv3:max response is 32.985966, min response is -27.594231.
max gradient is 6.774701, min gradient is -8.000000, learning rate is 0.000212
Net2: layer bn50:max response is 17.049946, min response is -3.713435.
max gradient is 8.000000, min gradient is -5.735177, learning rate is 0.000424
Net2: layer deconv2:max response is , min response is .
max gradient is 6.051924, min gradient is -8.000000, learning rate is 0.000212
Net2: layer bn49:max response is 10.293322, min response is -2.371868.
max gradient is 8.000000, min gradient is -3.875064, learning rate is 0.000424
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.385261, learning rate is 0.000212
max inferred z is 3.74, min inferred z is -3.71, and std is 1.00
 4.16 s (24.0 data/s) [100/100]
training: epoch 88: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.720305, min gradient is -8.000000, learning rate is 0.000690
Net1: layer conv2:max response is , min response is .
max gradient is 7.729679, min gradient is -8.000000, learning rate is 0.000690
Net1: layer conv1:max response is , min response is .
max gradient is 4.736784, min gradient is -8.000000, learning rate is 0.000690
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.683761, learning rate is 0.000424
Net2: layer deconv3:max response is 34.118504, min response is -31.111984.
max gradient is 7.599215, min gradient is -8.000000, learning rate is 0.000212
Net2: layer bn50:max response is 17.749453, min response is -3.347499.
max gradient is 5.470868, min gradient is -8.000000, learning rate is 0.000424
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.557147, learning rate is 0.000212
Net2: layer bn49:max response is 10.103385, min response is -2.322899.
max gradient is 6.587986, min gradient is -8.000000, learning rate is 0.000424
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.563714, learning rate is 0.000212
max inferred z is 4.19, min inferred z is -3.85, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 88: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.998552, min gradient is -8.000000, learning rate is 0.000690
Net1: layer conv2:max response is , min response is .
max gradient is 7.545644, min gradient is -8.000000, learning rate is 0.000690
Net1: layer conv1:max response is , min response is .
max gradient is 6.213754, min gradient is -8.000000, learning rate is 0.000690
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.570479, learning rate is 0.000424
Net2: layer deconv3:max response is 49.620464, min response is -30.570272.
max gradient is 7.342082, min gradient is -8.000000, learning rate is 0.000212
Net2: layer bn50:max response is 23.059162, min response is -3.944677.
max gradient is 8.000000, min gradient is -5.837104, learning rate is 0.000424
Net2: layer deconv2:max response is , min response is .
max gradient is 7.295272, min gradient is -8.000000, learning rate is 0.000212
Net2: layer bn49:max response is 9.928661, min response is -2.048930.
max gradient is 8.000000, min gradient is -5.295622, learning rate is 0.000424
Net2: layer deconv1:max response is , min response is .
max gradient is 6.788177, min gradient is -8.000000, learning rate is 0.000212
max inferred z is 4.02, min inferred z is -4.23, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 88: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.300951, min gradient is -8.000000, learning rate is 0.000690
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.806325, learning rate is 0.000690
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.190334, learning rate is 0.000690
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.935905, learning rate is 0.000424
Net2: layer deconv3:max response is 33.507282, min response is -27.279154.
max gradient is 8.000000, min gradient is -6.413691, learning rate is 0.000212
Net2: layer bn50:max response is 16.758001, min response is -3.440060.
max gradient is 7.348668, min gradient is -8.000000, learning rate is 0.000424
Net2: layer deconv2:max response is , min response is .
max gradient is 6.317697, min gradient is -8.000000, learning rate is 0.000212
Net2: layer bn49:max response is 9.304339, min response is -1.890126.
max gradient is 6.218987, min gradient is -8.000000, learning rate is 0.000424
Net2: layer deconv1:max response is , min response is .
max gradient is 7.618589, min gradient is -8.000000, learning rate is 0.000212
max inferred z is 3.79, min inferred z is -3.82, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 88: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.377151, min gradient is -8.000000, learning rate is 0.000690
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.830373, learning rate is 0.000690
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.074172, learning rate is 0.000690
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.168617, learning rate is 0.000424
Net2: layer deconv3:max response is 32.713005, min response is -30.141556.
max gradient is 5.366681, min gradient is -8.000000, learning rate is 0.000212
Net2: layer bn50:max response is 19.055378, min response is -3.999706.
max gradient is 5.923399, min gradient is -8.000000, learning rate is 0.000424
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.839627, learning rate is 0.000212
Net2: layer bn49:max response is 10.580278, min response is -2.280365.
max gradient is 8.000000, min gradient is -4.198390, learning rate is 0.000424
Net2: layer deconv1:max response is , min response is .
max gradient is 6.848094, min gradient is -8.000000, learning rate is 0.000212
max inferred z is 3.67, min inferred z is -3.77, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 88: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.562743, min gradient is -8.000000, learning rate is 0.000690
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.534626, learning rate is 0.000690
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.285535, learning rate is 0.000690
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.333218, learning rate is 0.000424
Net2: layer deconv3:max response is 35.987835, min response is -30.532286.
max gradient is 8.000000, min gradient is -7.088778, learning rate is 0.000212
Net2: layer bn50:max response is 20.127798, min response is -4.328956.
max gradient is 8.000000, min gradient is -7.777475, learning rate is 0.000424
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.767702, learning rate is 0.000212
Net2: layer bn49:max response is 10.105784, min response is -2.211811.
max gradient is 6.554767, min gradient is -8.000000, learning rate is 0.000424
Net2: layer deconv1:max response is , min response is .
max gradient is 7.801014, min gradient is -8.000000, learning rate is 0.000212
max inferred z is 3.70, min inferred z is -4.35, and std is 1.00
 4.30 s (23.2 data/s) [100/100]
training: epoch 88: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.798320, min gradient is -8.000000, learning rate is 0.000690
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.879391, learning rate is 0.000690
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.798048, learning rate is 0.000690
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000001, min gradient is 5.909295, learning rate is 0.000424
Net2: layer deconv3:max response is 34.916588, min response is -28.346203.
max gradient is 6.342168, min gradient is -8.000000, learning rate is 0.000212
Net2: layer bn50:max response is 19.046528, min response is -4.218149.
max gradient is 7.331099, min gradient is -8.000000, learning rate is 0.000424
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.703414, learning rate is 0.000212
Net2: layer bn49:max response is 9.794700, min response is -2.137841.
max gradient is 8.000000, min gradient is -5.441381, learning rate is 0.000424
Net2: layer deconv1:max response is , min response is .
max gradient is 6.357874, min gradient is -8.000000, learning rate is 0.000212
max inferred z is 3.82, min inferred z is -4.05, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 88: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.720803, min gradient is -8.000000, learning rate is 0.000690
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.924253, learning rate is 0.000690
Net1: layer conv1:max response is , min response is .
max gradient is 4.528930, min gradient is -8.000000, learning rate is 0.000690
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.515127, learning rate is 0.000424
Net2: layer deconv3:max response is 30.810513, min response is -27.056469.
max gradient is 8.000000, min gradient is -6.796793, learning rate is 0.000212
Net2: layer bn50:max response is 19.080296, min response is -3.491829.
max gradient is 8.000000, min gradient is -6.213785, learning rate is 0.000424
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.135706, learning rate is 0.000212
Net2: layer bn49:max response is 9.955490, min response is -2.011493.
max gradient is 7.585368, min gradient is -8.000000, learning rate is 0.000424
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.438706, learning rate is 0.000212
max inferred z is 3.98, min inferred z is -4.38, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
training: epoch 88: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.712589, min gradient is -8.000000, learning rate is 0.000690
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.433955, learning rate is 0.000690
Net1: layer conv1:max response is , min response is .
max gradient is 6.388395, min gradient is -8.000000, learning rate is 0.000690
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.026993, learning rate is 0.000424
Net2: layer deconv3:max response is 39.023800, min response is -30.178423.
max gradient is 8.000000, min gradient is -7.840070, learning rate is 0.000212
Net2: layer bn50:max response is 19.586287, min response is -4.121935.
max gradient is 8.000000, min gradient is -6.523986, learning rate is 0.000424
Net2: layer deconv2:max response is , min response is .
max gradient is 6.468740, min gradient is -8.000000, learning rate is 0.000212
Net2: layer bn49:max response is 9.630795, min response is -2.064207.
max gradient is 8.000000, min gradient is -2.894501, learning rate is 0.000424
Net2: layer deconv1:max response is , min response is .
max gradient is 6.999588, min gradient is -8.000000, learning rate is 0.000212
max inferred z is 3.88, min inferred z is -4.20, and std is 1.00
 4.23 s (23.7 data/s) [100/100]
training: epoch 88: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.137933, min gradient is -8.000000, learning rate is 0.000690
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.306595, learning rate is 0.000690
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.790060, learning rate is 0.000690
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.562126, learning rate is 0.000424
Net2: layer deconv3:max response is 37.586094, min response is -27.696646.
max gradient is 7.383655, min gradient is -8.000000, learning rate is 0.000212
Net2: layer bn50:max response is 19.719206, min response is -3.736526.
max gradient is 6.455774, min gradient is -8.000000, learning rate is 0.000424
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.139532, learning rate is 0.000212
Net2: layer bn49:max response is 9.782297, min response is -2.278769.
max gradient is 3.745614, min gradient is -8.000000, learning rate is 0.000424
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.382633, learning rate is 0.000212
max inferred z is 3.82, min inferred z is -4.11, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
Loss: 1.4109
Iteration 89 / 200
training: epoch 89: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.778341, min gradient is -8.000000, learning rate is 0.000573
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.111364, learning rate is 0.000573
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.443570, learning rate is 0.000573
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.877082, learning rate is 0.000422
Net2: layer deconv3:max response is 41.674553, min response is -32.237129.
max gradient is 8.000000, min gradient is -6.540523, learning rate is 0.000211
Net2: layer bn50:max response is 21.791765, min response is -4.036966.
max gradient is 8.000000, min gradient is -5.746844, learning rate is 0.000422
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.366831, learning rate is 0.000211
Net2: layer bn49:max response is 11.340659, min response is -2.145268.
max gradient is 8.000000, min gradient is -3.289081, learning rate is 0.000422
Net2: layer deconv1:max response is , min response is .
max gradient is 7.923194, min gradient is -8.000000, learning rate is 0.000211
max inferred z is 3.94, min inferred z is -4.42, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 89: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.208499, min gradient is -8.000000, learning rate is 0.000573
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.787994, learning rate is 0.000573
Net1: layer conv1:max response is , min response is .
max gradient is 5.019191, min gradient is -8.000000, learning rate is 0.000573
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.757155, learning rate is 0.000422
Net2: layer deconv3:max response is 38.516205, min response is -27.804871.
max gradient is 8.000000, min gradient is -7.813829, learning rate is 0.000211
Net2: layer bn50:max response is 19.314085, min response is -3.936954.
max gradient is 5.237005, min gradient is -8.000000, learning rate is 0.000422
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.945740, learning rate is 0.000211
Net2: layer bn49:max response is 9.774706, min response is -1.958448.
max gradient is 6.749542, min gradient is -8.000000, learning rate is 0.000422
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.036002, learning rate is 0.000211
max inferred z is 4.09, min inferred z is -3.94, and std is 1.00
 4.19 s (23.9 data/s) [100/100]
training: epoch 89: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.516098, min gradient is -8.000000, learning rate is 0.000573
Net1: layer conv2:max response is , min response is .
max gradient is 7.265506, min gradient is -8.000000, learning rate is 0.000573
Net1: layer conv1:max response is , min response is .
max gradient is 5.867019, min gradient is -8.000000, learning rate is 0.000573
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.426673, learning rate is 0.000422
Net2: layer deconv3:max response is 39.922363, min response is -29.535402.
max gradient is 7.861789, min gradient is -8.000000, learning rate is 0.000211
Net2: layer bn50:max response is 20.891479, min response is -4.079257.
max gradient is 8.000000, min gradient is -7.898118, learning rate is 0.000422
Net2: layer deconv2:max response is , min response is .
max gradient is 6.879227, min gradient is -8.000000, learning rate is 0.000211
Net2: layer bn49:max response is 10.696258, min response is -2.248349.
max gradient is 8.000000, min gradient is -5.516284, learning rate is 0.000422
Net2: layer deconv1:max response is , min response is .
max gradient is 7.509646, min gradient is -8.000000, learning rate is 0.000211
max inferred z is 3.87, min inferred z is -3.80, and std is 1.00
 4.17 s (24.0 data/s) [100/100]
training: epoch 89: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.685905, min gradient is -8.000000, learning rate is 0.000573
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.518099, learning rate is 0.000573
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.953847, learning rate is 0.000573
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -6.679906, learning rate is 0.000422
Net2: layer deconv3:max response is 34.938442, min response is -28.739410.
max gradient is 8.000000, min gradient is -6.677376, learning rate is 0.000211
Net2: layer bn50:max response is 17.297192, min response is -3.978533.
max gradient is 8.000000, min gradient is -5.448526, learning rate is 0.000422
Net2: layer deconv2:max response is , min response is .
max gradient is 7.341097, min gradient is -8.000000, learning rate is 0.000211
Net2: layer bn49:max response is 9.958860, min response is -1.996905.
max gradient is 6.806504, min gradient is -8.000000, learning rate is 0.000422
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.869814, learning rate is 0.000211
max inferred z is 3.69, min inferred z is -4.54, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 89: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.706966, min gradient is -8.000000, learning rate is 0.000573
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.309328, learning rate is 0.000573
Net1: layer conv1:max response is , min response is .
max gradient is 7.689614, min gradient is -8.000000, learning rate is 0.000573
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.748937, learning rate is 0.000422
Net2: layer deconv3:max response is 36.130669, min response is -25.763344.
max gradient is 5.843033, min gradient is -8.000000, learning rate is 0.000211
Net2: layer bn50:max response is 17.039553, min response is -3.280013.
max gradient is 7.244018, min gradient is -8.000001, learning rate is 0.000422
Net2: layer deconv2:max response is , min response is .
max gradient is 6.929486, min gradient is -8.000000, learning rate is 0.000211
Net2: layer bn49:max response is 8.918287, min response is -2.101136.
max gradient is 8.000000, min gradient is -7.100818, learning rate is 0.000422
Net2: layer deconv1:max response is , min response is .
max gradient is 6.385380, min gradient is -8.000000, learning rate is 0.000211
max inferred z is 3.97, min inferred z is -4.33, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
training: epoch 89: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.962657, min gradient is -8.000000, learning rate is 0.000573
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.589049, learning rate is 0.000573
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.427597, learning rate is 0.000573
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.418832, learning rate is 0.000422
Net2: layer deconv3:max response is 36.781971, min response is -30.606134.
max gradient is 8.000000, min gradient is -5.158858, learning rate is 0.000211
Net2: layer bn50:max response is 19.282015, min response is -3.531689.
max gradient is 8.000000, min gradient is -5.976673, learning rate is 0.000422
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.238393, learning rate is 0.000211
Net2: layer bn49:max response is 9.334035, min response is -1.979293.
max gradient is 7.760609, min gradient is -8.000000, learning rate is 0.000422
Net2: layer deconv1:max response is , min response is .
max gradient is 7.769611, min gradient is -8.000000, learning rate is 0.000211
max inferred z is 3.88, min inferred z is -4.09, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 89: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.208752, min gradient is -8.000000, learning rate is 0.000573
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.626816, learning rate is 0.000573
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.808943, learning rate is 0.000573
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.084328, learning rate is 0.000422
Net2: layer deconv3:max response is 39.517212, min response is -35.501278.
max gradient is 4.697599, min gradient is -8.000000, learning rate is 0.000211
Net2: layer bn50:max response is 22.222290, min response is -4.663190.
max gradient is 6.713038, min gradient is -8.000000, learning rate is 0.000422
Net2: layer deconv2:max response is , min response is .
max gradient is 7.031541, min gradient is -8.000000, learning rate is 0.000211
Net2: layer bn49:max response is 10.088247, min response is -2.538696.
max gradient is 8.000000, min gradient is -6.217545, learning rate is 0.000422
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.972674, learning rate is 0.000211
max inferred z is 3.71, min inferred z is -3.80, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 89: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.041149, min gradient is -8.000000, learning rate is 0.000573
Net1: layer conv2:max response is , min response is .
max gradient is 7.627371, min gradient is -8.000000, learning rate is 0.000573
Net1: layer conv1:max response is , min response is .
max gradient is 5.562240, min gradient is -8.000000, learning rate is 0.000573
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.832774, learning rate is 0.000422
Net2: layer deconv3:max response is 39.228523, min response is -34.770027.
max gradient is 8.000000, min gradient is -6.699597, learning rate is 0.000211
Net2: layer bn50:max response is 21.418629, min response is -4.501578.
max gradient is 8.000000, min gradient is -7.968391, learning rate is 0.000422
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.214769, learning rate is 0.000211
Net2: layer bn49:max response is 12.841554, min response is -2.290174.
max gradient is 7.308528, min gradient is -8.000000, learning rate is 0.000422
Net2: layer deconv1:max response is , min response is .
max gradient is 7.986331, min gradient is -8.000000, learning rate is 0.000211
max inferred z is 3.73, min inferred z is -4.32, and std is 1.00
 4.19 s (23.9 data/s) [100/100]
training: epoch 89: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.636091, min gradient is -8.000000, learning rate is 0.000573
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.341137, learning rate is 0.000573
Net1: layer conv1:max response is , min response is .
max gradient is 5.959518, min gradient is -8.000000, learning rate is 0.000573
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.556390, learning rate is 0.000422
Net2: layer deconv3:max response is 37.871792, min response is -34.707714.
max gradient is 7.874048, min gradient is -8.000000, learning rate is 0.000211
Net2: layer bn50:max response is 20.669802, min response is -4.880113.
max gradient is 8.000000, min gradient is -7.539958, learning rate is 0.000422
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.614007, learning rate is 0.000211
Net2: layer bn49:max response is 10.991372, min response is -2.205177.
max gradient is 8.000000, min gradient is -6.202436, learning rate is 0.000422
Net2: layer deconv1:max response is , min response is .
max gradient is 7.304984, min gradient is -8.000000, learning rate is 0.000211
max inferred z is 4.08, min inferred z is -4.41, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 89: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.654054, min gradient is -8.000000, learning rate is 0.000573
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.538376, learning rate is 0.000573
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.122335, learning rate is 0.000573
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.409911, learning rate is 0.000422
Net2: layer deconv3:max response is 32.506432, min response is -31.186094.
max gradient is 8.000000, min gradient is -5.874510, learning rate is 0.000211
Net2: layer bn50:max response is 19.044798, min response is -4.125164.
max gradient is 8.000000, min gradient is -6.206010, learning rate is 0.000422
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.341920, learning rate is 0.000211
Net2: layer bn49:max response is 8.866031, min response is -2.062852.
max gradient is 5.424087, min gradient is -8.000000, learning rate is 0.000422
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.652694, learning rate is 0.000211
max inferred z is 4.46, min inferred z is -3.98, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
Loss: 1.4237
Iteration 90 / 200
training: epoch 90: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.274003, min gradient is -8.000000, learning rate is 0.000573
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.856902, learning rate is 0.000573
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.692833, learning rate is 0.000573
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.603560, learning rate is 0.000420
Net2: layer deconv3:max response is 42.917912, min response is -30.599499.
max gradient is 4.841725, min gradient is -8.000000, learning rate is 0.000210
Net2: layer bn50:max response is 20.063669, min response is -4.008523.
max gradient is 6.785561, min gradient is -8.000000, learning rate is 0.000420
Net2: layer deconv2:max response is , min response is .
max gradient is 7.890114, min gradient is -8.000000, learning rate is 0.000210
Net2: layer bn49:max response is 10.288060, min response is -2.311675.
max gradient is 8.000000, min gradient is -6.455369, learning rate is 0.000420
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.684322, learning rate is 0.000210
max inferred z is 3.94, min inferred z is -4.06, and std is 1.00
 4.28 s (23.3 data/s) [100/100]
training: epoch 90: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.102554, min gradient is -8.000000, learning rate is 0.000573
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.263877, learning rate is 0.000573
Net1: layer conv1:max response is , min response is .
max gradient is 4.157202, min gradient is -8.000000, learning rate is 0.000573
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.248075, learning rate is 0.000420
Net2: layer deconv3:max response is 41.303883, min response is -32.122482.
max gradient is 8.000000, min gradient is -5.789351, learning rate is 0.000210
Net2: layer bn50:max response is 21.382364, min response is -4.398282.
max gradient is 8.000000, min gradient is -5.545196, learning rate is 0.000420
Net2: layer deconv2:max response is , min response is .
max gradient is 6.654865, min gradient is -8.000000, learning rate is 0.000210
Net2: layer bn49:max response is 11.616456, min response is -1.934010.
max gradient is 8.000000, min gradient is -6.927593, learning rate is 0.000420
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.917908, learning rate is 0.000210
max inferred z is 4.49, min inferred z is -4.10, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
training: epoch 90: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.558024, min gradient is -8.000000, learning rate is 0.000573
Net1: layer conv2:max response is , min response is .
max gradient is 6.698975, min gradient is -8.000000, learning rate is 0.000573
Net1: layer conv1:max response is , min response is .
max gradient is 5.654335, min gradient is -8.000000, learning rate is 0.000573
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.570828, learning rate is 0.000420
Net2: layer deconv3:max response is 42.168644, min response is -32.472553.
max gradient is 5.188118, min gradient is -8.000000, learning rate is 0.000210
Net2: layer bn50:max response is 20.746332, min response is -4.170233.
max gradient is 6.206916, min gradient is -8.000000, learning rate is 0.000420
Net2: layer deconv2:max response is , min response is .
max gradient is 7.843822, min gradient is -8.000000, learning rate is 0.000210
Net2: layer bn49:max response is 10.480547, min response is -2.280706.
max gradient is 5.607476, min gradient is -8.000000, learning rate is 0.000420
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.846355, learning rate is 0.000210
max inferred z is 3.98, min inferred z is -4.34, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 90: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.031116, min gradient is -8.000000, learning rate is 0.000573
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.432528, learning rate is 0.000573
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.514911, learning rate is 0.000573
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.469331, learning rate is 0.000420
Net2: layer deconv3:max response is 39.378635, min response is -29.132830.
max gradient is 8.000000, min gradient is -5.561044, learning rate is 0.000210
Net2: layer bn50:max response is 19.038425, min response is -3.594683.
max gradient is 8.000000, min gradient is -6.514862, learning rate is 0.000420
Net2: layer deconv2:max response is , min response is .
max gradient is 7.621026, min gradient is -8.000000, learning rate is 0.000210
Net2: layer bn49:max response is 12.119993, min response is -2.207327.
max gradient is 6.384800, min gradient is -8.000000, learning rate is 0.000420
Net2: layer deconv1:max response is , min response is .
max gradient is 7.421358, min gradient is -8.000000, learning rate is 0.000210
max inferred z is 4.49, min inferred z is -3.78, and std is 1.00
 4.34 s (23.1 data/s) [100/100]
training: epoch 90: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.722462, min gradient is -8.000000, learning rate is 0.000573
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.305793, learning rate is 0.000573
Net1: layer conv1:max response is , min response is .
max gradient is 6.196965, min gradient is -8.000000, learning rate is 0.000573
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.989490, learning rate is 0.000420
Net2: layer deconv3:max response is 35.895699, min response is -31.935207.
max gradient is 6.257284, min gradient is -8.000000, learning rate is 0.000210
Net2: layer bn50:max response is 19.477188, min response is -3.806870.
max gradient is 6.340944, min gradient is -8.000000, learning rate is 0.000420
Net2: layer deconv2:max response is , min response is .
max gradient is 6.358931, min gradient is -8.000000, learning rate is 0.000210
Net2: layer bn49:max response is 10.107621, min response is -1.884127.
max gradient is 7.960280, min gradient is -8.000000, learning rate is 0.000420
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.845910, learning rate is 0.000210
max inferred z is 3.72, min inferred z is -4.29, and std is 1.00
 4.18 s (23.9 data/s) [100/100]
training: epoch 90: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.638176, min gradient is -8.000000, learning rate is 0.000573
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.972311, learning rate is 0.000573
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.551789, learning rate is 0.000573
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.325692, learning rate is 0.000420
Net2: layer deconv3:max response is 41.073204, min response is -29.950190.
max gradient is 8.000000, min gradient is -5.286547, learning rate is 0.000210
Net2: layer bn50:max response is 19.438499, min response is -4.141754.
max gradient is 7.202935, min gradient is -8.000000, learning rate is 0.000420
Net2: layer deconv2:max response is , min response is .
max gradient is 7.804997, min gradient is -8.000000, learning rate is 0.000210
Net2: layer bn49:max response is 9.768795, min response is -2.104303.
max gradient is 8.000000, min gradient is -7.167635, learning rate is 0.000420
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.273044, learning rate is 0.000210
max inferred z is 4.63, min inferred z is -4.38, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 90: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.698816, min gradient is -8.000000, learning rate is 0.000573
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.298451, learning rate is 0.000573
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.910393, learning rate is 0.000573
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.981859, learning rate is 0.000420
Net2: layer deconv3:max response is 46.348328, min response is -33.607204.
max gradient is 6.675526, min gradient is -8.000000, learning rate is 0.000210
Net2: layer bn50:max response is 21.871279, min response is -4.482092.
max gradient is 7.965535, min gradient is -8.000000, learning rate is 0.000420
Net2: layer deconv2:max response is , min response is .
max gradient is 7.897500, min gradient is -8.000000, learning rate is 0.000210
Net2: layer bn49:max response is 10.382314, min response is -2.132930.
max gradient is 8.000000, min gradient is -7.861775, learning rate is 0.000420
Net2: layer deconv1:max response is , min response is .
max gradient is 6.371129, min gradient is -8.000000, learning rate is 0.000210
max inferred z is 4.04, min inferred z is -3.88, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 90: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.747323, min gradient is -8.000000, learning rate is 0.000573
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.023326, learning rate is 0.000573
Net1: layer conv1:max response is , min response is .
max gradient is 5.967599, min gradient is -8.000000, learning rate is 0.000573
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.128263, learning rate is 0.000420
Net2: layer deconv3:max response is 34.909626, min response is -41.422363.
max gradient is 8.000000, min gradient is -6.989967, learning rate is 0.000210
Net2: layer bn50:max response is 24.444799, min response is -4.534775.
max gradient is 8.000000, min gradient is -7.654737, learning rate is 0.000420
Net2: layer deconv2:max response is , min response is .
max gradient is 6.945505, min gradient is -8.000000, learning rate is 0.000210
Net2: layer bn49:max response is 10.486667, min response is -2.094665.
max gradient is 5.605515, min gradient is -8.000000, learning rate is 0.000420
Net2: layer deconv1:max response is , min response is .
max gradient is 7.289732, min gradient is -8.000000, learning rate is 0.000210
max inferred z is 4.04, min inferred z is -4.37, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
training: epoch 90: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.567277, min gradient is -8.000000, learning rate is 0.000573
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.252620, learning rate is 0.000573
Net1: layer conv1:max response is , min response is .
max gradient is 5.303669, min gradient is -8.000000, learning rate is 0.000573
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.382120, learning rate is 0.000420
Net2: layer deconv3:max response is 38.382015, min response is -31.418367.
max gradient is 6.443490, min gradient is -8.000000, learning rate is 0.000210
Net2: layer bn50:max response is 17.043734, min response is -4.050298.
max gradient is 6.193668, min gradient is -8.000000, learning rate is 0.000420
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.553919, learning rate is 0.000210
Net2: layer bn49:max response is 9.751328, min response is -2.001752.
max gradient is 8.000000, min gradient is -4.975322, learning rate is 0.000420
Net2: layer deconv1:max response is , min response is .
max gradient is 7.727768, min gradient is -8.000000, learning rate is 0.000210
max inferred z is 3.82, min inferred z is -3.80, and std is 1.00
 4.34 s (23.1 data/s) [100/100]
training: epoch 90: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.513205, min gradient is -8.000000, learning rate is 0.000573
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.100295, learning rate is 0.000573
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.451348, learning rate is 0.000573
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.190304, learning rate is 0.000420
Net2: layer deconv3:max response is 39.894730, min response is -30.422276.
max gradient is 8.000000, min gradient is -5.130069, learning rate is 0.000210
Net2: layer bn50:max response is 18.916721, min response is -4.004492.
max gradient is 8.000000, min gradient is -6.234692, learning rate is 0.000420
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.761388, learning rate is 0.000210
Net2: layer bn49:max response is 9.134991, min response is -2.442997.
max gradient is 7.992959, min gradient is -8.000000, learning rate is 0.000420
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.503701, learning rate is 0.000210
max inferred z is 3.58, min inferred z is -4.16, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
Loss: 1.3681
Iteration 91 / 200
training: epoch 91: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.079618, min gradient is -8.000000, learning rate is 0.000476
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.245103, learning rate is 0.000476
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.979474, learning rate is 0.000476
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.393879, learning rate is 0.000418
Net2: layer deconv3:max response is 39.830727, min response is -28.774935.
max gradient is 4.503699, min gradient is -8.000000, learning rate is 0.000209
Net2: layer bn50:max response is 19.024765, min response is -3.397372.
max gradient is 7.139091, min gradient is -8.000000, learning rate is 0.000418
Net2: layer deconv2:max response is , min response is .
max gradient is 7.828883, min gradient is -8.000000, learning rate is 0.000209
Net2: layer bn49:max response is 10.280552, min response is -2.053517.
max gradient is 7.929176, min gradient is -8.000000, learning rate is 0.000418
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.916094, learning rate is 0.000209
max inferred z is 3.82, min inferred z is -3.77, and std is 1.00
 4.18 s (23.9 data/s) [100/100]
training: epoch 91: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.490716, min gradient is -8.000000, learning rate is 0.000476
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.864135, learning rate is 0.000476
Net1: layer conv1:max response is , min response is .
max gradient is 3.666042, min gradient is -8.000000, learning rate is 0.000476
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -0.228566, learning rate is 0.000418
Net2: layer deconv3:max response is 35.309628, min response is -32.912445.
max gradient is 8.000000, min gradient is -4.457657, learning rate is 0.000209
Net2: layer bn50:max response is 18.606348, min response is -4.018040.
max gradient is 8.000000, min gradient is -6.204665, learning rate is 0.000418
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.362817, learning rate is 0.000209
Net2: layer bn49:max response is 10.654888, min response is -2.175987.
max gradient is 7.628011, min gradient is -8.000000, learning rate is 0.000418
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.597938, learning rate is 0.000209
max inferred z is 3.93, min inferred z is -3.94, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 91: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.348528, min gradient is -8.000000, learning rate is 0.000476
Net1: layer conv2:max response is , min response is .
max gradient is 6.948645, min gradient is -8.000000, learning rate is 0.000476
Net1: layer conv1:max response is , min response is .
max gradient is 5.299192, min gradient is -8.000000, learning rate is 0.000476
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.952862, learning rate is 0.000418
Net2: layer deconv3:max response is 34.209057, min response is -36.559822.
max gradient is 4.822708, min gradient is -8.000000, learning rate is 0.000209
Net2: layer bn50:max response is 23.166376, min response is -4.974065.
max gradient is 6.586652, min gradient is -8.000000, learning rate is 0.000418
Net2: layer deconv2:max response is , min response is .
max gradient is 6.849928, min gradient is -8.000000, learning rate is 0.000209
Net2: layer bn49:max response is 10.546643, min response is -2.337927.
max gradient is 8.000000, min gradient is -7.736508, learning rate is 0.000418
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.912419, learning rate is 0.000209
max inferred z is 3.68, min inferred z is -3.84, and std is 1.00
 4.23 s (23.6 data/s) [100/100]
training: epoch 91: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.173399, min gradient is -8.000000, learning rate is 0.000476
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.606942, learning rate is 0.000476
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -3.710100, learning rate is 0.000476
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.019042, learning rate is 0.000418
Net2: layer deconv3:max response is 40.638683, min response is -33.143124.
max gradient is 8.000000, min gradient is -4.461481, learning rate is 0.000209
Net2: layer bn50:max response is 20.727564, min response is -4.415956.
max gradient is 8.000000, min gradient is -6.875353, learning rate is 0.000418
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.696722, learning rate is 0.000209
Net2: layer bn49:max response is 10.212144, min response is -2.293678.
max gradient is 7.074979, min gradient is -8.000000, learning rate is 0.000418
Net2: layer deconv1:max response is , min response is .
max gradient is 7.013563, min gradient is -8.000000, learning rate is 0.000209
max inferred z is 4.32, min inferred z is -4.23, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 91: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.341873, min gradient is -8.000000, learning rate is 0.000476
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.263441, learning rate is 0.000476
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.159667, learning rate is 0.000476
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.375598, learning rate is 0.000418
Net2: layer deconv3:max response is 41.276329, min response is -31.753069.
max gradient is 6.776391, min gradient is -8.000000, learning rate is 0.000209
Net2: layer bn50:max response is 20.017149, min response is -3.935150.
max gradient is 6.963739, min gradient is -8.000000, learning rate is 0.000418
Net2: layer deconv2:max response is , min response is .
max gradient is 5.765161, min gradient is -8.000000, learning rate is 0.000209
Net2: layer bn49:max response is 10.546229, min response is -2.205928.
max gradient is 8.000000, min gradient is -5.955077, learning rate is 0.000418
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.660947, learning rate is 0.000209
max inferred z is 3.86, min inferred z is -3.83, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 91: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.467755, min gradient is -8.000000, learning rate is 0.000476
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.776008, learning rate is 0.000476
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.403851, learning rate is 0.000476
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.573307, learning rate is 0.000418
Net2: layer deconv3:max response is 53.038651, min response is -32.882500.
max gradient is 8.000000, min gradient is -5.227764, learning rate is 0.000209
Net2: layer bn50:max response is 25.322632, min response is -4.125279.
max gradient is 8.000000, min gradient is -7.230897, learning rate is 0.000418
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.755227, learning rate is 0.000209
Net2: layer bn49:max response is 11.037859, min response is -2.338569.
max gradient is 4.216022, min gradient is -8.000000, learning rate is 0.000418
Net2: layer deconv1:max response is , min response is .
max gradient is 5.747478, min gradient is -8.000000, learning rate is 0.000209
max inferred z is 3.51, min inferred z is -3.80, and std is 1.00
 4.44 s (22.5 data/s) [100/100]
training: epoch 91: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.152654, min gradient is -8.000000, learning rate is 0.000476
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.752798, learning rate is 0.000476
Net1: layer conv1:max response is , min response is .
max gradient is 6.378902, min gradient is -8.000000, learning rate is 0.000476
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.422141, learning rate is 0.000418
Net2: layer deconv3:max response is 43.806217, min response is -32.271381.
max gradient is 7.556019, min gradient is -8.000000, learning rate is 0.000209
Net2: layer bn50:max response is 20.257086, min response is -4.264227.
max gradient is 6.278191, min gradient is -8.000000, learning rate is 0.000418
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.790104, learning rate is 0.000209
Net2: layer bn49:max response is 10.950629, min response is -2.161544.
max gradient is 8.000000, min gradient is -3.669737, learning rate is 0.000418
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.829418, learning rate is 0.000209
max inferred z is 3.79, min inferred z is -4.06, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 91: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.827752, min gradient is -8.000000, learning rate is 0.000476
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.524061, learning rate is 0.000476
Net1: layer conv1:max response is , min response is .
max gradient is 6.856832, min gradient is -8.000000, learning rate is 0.000476
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.269736, learning rate is 0.000418
Net2: layer deconv3:max response is 37.598423, min response is -33.824612.
max gradient is 8.000000, min gradient is -6.602344, learning rate is 0.000209
Net2: layer bn50:max response is 18.151461, min response is -4.332137.
max gradient is 8.000000, min gradient is -7.337987, learning rate is 0.000418
Net2: layer deconv2:max response is , min response is .
max gradient is 6.479766, min gradient is -8.000000, learning rate is 0.000209
Net2: layer bn49:max response is 10.724071, min response is -2.422425.
max gradient is 7.594904, min gradient is -8.000000, learning rate is 0.000418
Net2: layer deconv1:max response is , min response is .
max gradient is 6.473244, min gradient is -8.000000, learning rate is 0.000209
max inferred z is 4.21, min inferred z is -3.89, and std is 1.00
 4.43 s (22.6 data/s) [100/100]
training: epoch 91: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.380765, min gradient is -8.000000, learning rate is 0.000476
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.440299, learning rate is 0.000476
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.823501, learning rate is 0.000476
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.867275, learning rate is 0.000418
Net2: layer deconv3:max response is 36.777248, min response is -36.417698.
max gradient is 8.000000, min gradient is -7.266320, learning rate is 0.000209
Net2: layer bn50:max response is 18.050152, min response is -3.954082.
max gradient is 8.000000, min gradient is -6.954986, learning rate is 0.000418
Net2: layer deconv2:max response is , min response is .
max gradient is 7.442952, min gradient is -8.000000, learning rate is 0.000209
Net2: layer bn49:max response is 12.109055, min response is -2.042455.
max gradient is 8.000000, min gradient is -5.964482, learning rate is 0.000418
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.471589, learning rate is 0.000209
max inferred z is 4.04, min inferred z is -4.02, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 91: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.299395, min gradient is -8.000000, learning rate is 0.000476
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.063107, learning rate is 0.000476
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.605878, learning rate is 0.000476
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.020027, learning rate is 0.000418
Net2: layer deconv3:max response is 36.087391, min response is -37.128136.
max gradient is 7.793123, min gradient is -8.000000, learning rate is 0.000209
Net2: layer bn50:max response is 22.255573, min response is -4.995502.
max gradient is 6.329342, min gradient is -8.000000, learning rate is 0.000418
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.178412, learning rate is 0.000209
Net2: layer bn49:max response is 12.577988, min response is -2.439374.
max gradient is 3.786843, min gradient is -8.000000, learning rate is 0.000418
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.288504, learning rate is 0.000209
max inferred z is 3.70, min inferred z is -3.80, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
Loss: 1.3676
Iteration 92 / 200
training: epoch 92: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.893538, min gradient is -8.000000, learning rate is 0.000476
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.894840, learning rate is 0.000476
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.816872, learning rate is 0.000476
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.930445, learning rate is 0.000416
Net2: layer deconv3:max response is 35.355610, min response is -35.346096.
max gradient is 8.000000, min gradient is -7.455090, learning rate is 0.000208
Net2: layer bn50:max response is 19.791143, min response is -4.690764.
max gradient is 8.000000, min gradient is -5.475267, learning rate is 0.000416
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.617250, learning rate is 0.000208
Net2: layer bn49:max response is 10.476584, min response is -2.176880.
max gradient is 8.000000, min gradient is -2.856836, learning rate is 0.000416
Net2: layer deconv1:max response is , min response is .
max gradient is 7.447943, min gradient is -8.000000, learning rate is 0.000208
max inferred z is 3.75, min inferred z is -4.23, and std is 1.00
 4.17 s (24.0 data/s) [100/100]
training: epoch 92: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.487036, min gradient is -8.000000, learning rate is 0.000476
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.586817, learning rate is 0.000476
Net1: layer conv1:max response is , min response is .
max gradient is 5.514489, min gradient is -8.000000, learning rate is 0.000476
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.568730, learning rate is 0.000416
Net2: layer deconv3:max response is 39.434902, min response is -30.122742.
max gradient is 6.871069, min gradient is -8.000000, learning rate is 0.000208
Net2: layer bn50:max response is 18.769825, min response is -3.611261.
max gradient is 5.985524, min gradient is -8.000000, learning rate is 0.000416
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.838847, learning rate is 0.000208
Net2: layer bn49:max response is 9.930342, min response is -2.060426.
max gradient is 4.790446, min gradient is -8.000000, learning rate is 0.000416
Net2: layer deconv1:max response is , min response is .
max gradient is 6.318146, min gradient is -8.000000, learning rate is 0.000208
max inferred z is 4.11, min inferred z is -3.49, and std is 1.00
 4.17 s (24.0 data/s) [100/100]
training: epoch 92: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.722651, min gradient is -8.000000, learning rate is 0.000476
Net1: layer conv2:max response is , min response is .
max gradient is 7.048975, min gradient is -8.000000, learning rate is 0.000476
Net1: layer conv1:max response is , min response is .
max gradient is 5.368981, min gradient is -8.000000, learning rate is 0.000476
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.882843, learning rate is 0.000416
Net2: layer deconv3:max response is 39.053425, min response is -37.426895.
max gradient is 8.000000, min gradient is -7.093309, learning rate is 0.000208
Net2: layer bn50:max response is 21.132624, min response is -4.324083.
max gradient is 8.000000, min gradient is -5.462301, learning rate is 0.000416
Net2: layer deconv2:max response is , min response is .
max gradient is 7.727764, min gradient is -8.000000, learning rate is 0.000208
Net2: layer bn49:max response is 10.826836, min response is -2.493298.
max gradient is 8.000000, min gradient is -4.208403, learning rate is 0.000416
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.479218, learning rate is 0.000208
max inferred z is 3.81, min inferred z is -3.81, and std is 1.00
 4.41 s (22.7 data/s) [100/100]
training: epoch 92: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.665334, min gradient is -8.000000, learning rate is 0.000476
Net1: layer conv2:max response is , min response is .
max gradient is 7.911486, min gradient is -8.000000, learning rate is 0.000476
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.721472, learning rate is 0.000476
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.040328, learning rate is 0.000416
Net2: layer deconv3:max response is 43.158180, min response is -31.695042.
max gradient is 7.436712, min gradient is -8.000000, learning rate is 0.000208
Net2: layer bn50:max response is 20.137779, min response is -3.931529.
max gradient is 6.531498, min gradient is -8.000000, learning rate is 0.000416
Net2: layer deconv2:max response is , min response is .
max gradient is 6.839438, min gradient is -8.000000, learning rate is 0.000208
Net2: layer bn49:max response is 10.546045, min response is -2.086346.
max gradient is 4.031942, min gradient is -8.000000, learning rate is 0.000416
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.271797, learning rate is 0.000208
max inferred z is 4.07, min inferred z is -3.97, and std is 1.00
 4.30 s (23.3 data/s) [100/100]
training: epoch 92: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.356831, min gradient is -8.000000, learning rate is 0.000476
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.777519, learning rate is 0.000476
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -4.798987, learning rate is 0.000476
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.941101, learning rate is 0.000416
Net2: layer deconv3:max response is 38.487385, min response is -30.539835.
max gradient is 6.848444, min gradient is -8.000000, learning rate is 0.000208
Net2: layer bn50:max response is 17.992308, min response is -4.341448.
max gradient is 7.032365, min gradient is -8.000000, learning rate is 0.000416
Net2: layer deconv2:max response is , min response is .
max gradient is 7.343516, min gradient is -8.000000, learning rate is 0.000208
Net2: layer bn49:max response is 10.379584, min response is -2.405435.
max gradient is 8.000000, min gradient is -6.279796, learning rate is 0.000416
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.765810, learning rate is 0.000208
max inferred z is 4.14, min inferred z is -4.64, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 92: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.508239, min gradient is -8.000000, learning rate is 0.000476
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.016078, learning rate is 0.000476
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.998073, learning rate is 0.000476
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.059773, learning rate is 0.000416
Net2: layer deconv3:max response is 36.769039, min response is -34.187187.
max gradient is 8.000000, min gradient is -5.162468, learning rate is 0.000208
Net2: layer bn50:max response is 18.875748, min response is -4.121478.
max gradient is 8.000000, min gradient is -5.564240, learning rate is 0.000416
Net2: layer deconv2:max response is , min response is .
max gradient is 7.280620, min gradient is -8.000000, learning rate is 0.000208
Net2: layer bn49:max response is 13.239727, min response is -2.295940.
max gradient is 7.532648, min gradient is -8.000000, learning rate is 0.000416
Net2: layer deconv1:max response is , min response is .
max gradient is 7.212793, min gradient is -8.000000, learning rate is 0.000208
max inferred z is 3.88, min inferred z is -3.65, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 92: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.817335, min gradient is -8.000000, learning rate is 0.000476
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.412658, learning rate is 0.000476
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.504111, learning rate is 0.000476
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.986807, learning rate is 0.000416
Net2: layer deconv3:max response is 43.634914, min response is -31.756184.
max gradient is 8.000000, min gradient is -7.261979, learning rate is 0.000208
Net2: layer bn50:max response is 19.859505, min response is -3.881710.
max gradient is 8.000000, min gradient is -5.655897, learning rate is 0.000416
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.918349, learning rate is 0.000208
Net2: layer bn49:max response is 11.801586, min response is -2.269615.
max gradient is 8.000000, min gradient is -6.879104, learning rate is 0.000416
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.786616, learning rate is 0.000208
max inferred z is 4.12, min inferred z is -3.85, and std is 1.00
 4.43 s (22.6 data/s) [100/100]
training: epoch 92: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.188459, min gradient is -8.000000, learning rate is 0.000476
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.216650, learning rate is 0.000476
Net1: layer conv1:max response is , min response is .
max gradient is 5.826745, min gradient is -8.000000, learning rate is 0.000476
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.503890, learning rate is 0.000416
Net2: layer deconv3:max response is 34.689938, min response is -33.798794.
max gradient is 8.000000, min gradient is -7.766383, learning rate is 0.000208
Net2: layer bn50:max response is 21.716257, min response is -4.542060.
max gradient is 5.411463, min gradient is -8.000000, learning rate is 0.000416
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.997157, learning rate is 0.000208
Net2: layer bn49:max response is 11.073657, min response is -2.287999.
max gradient is 3.542455, min gradient is -8.000000, learning rate is 0.000416
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.682150, learning rate is 0.000208
max inferred z is 4.04, min inferred z is -4.60, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 92: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.663176, min gradient is -8.000000, learning rate is 0.000476
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.447407, learning rate is 0.000476
Net1: layer conv1:max response is , min response is .
max gradient is 7.820628, min gradient is -8.000000, learning rate is 0.000476
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.782590, learning rate is 0.000416
Net2: layer deconv3:max response is 32.062973, min response is -34.096748.
max gradient is 6.639698, min gradient is -8.000000, learning rate is 0.000208
Net2: layer bn50:max response is 18.425957, min response is -4.273334.
max gradient is 7.213665, min gradient is -8.000000, learning rate is 0.000416
Net2: layer deconv2:max response is , min response is .
max gradient is 7.083915, min gradient is -8.000000, learning rate is 0.000208
Net2: layer bn49:max response is 11.414586, min response is -2.168986.
max gradient is 8.000000, min gradient is -4.164708, learning rate is 0.000416
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.301930, learning rate is 0.000208
max inferred z is 4.20, min inferred z is -4.44, and std is 1.00
 4.34 s (23.1 data/s) [100/100]
training: epoch 92: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.799984, min gradient is -8.000000, learning rate is 0.000476
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.980129, learning rate is 0.000476
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.836396, learning rate is 0.000476
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -2.345177, learning rate is 0.000416
Net2: layer deconv3:max response is 41.993046, min response is -33.234200.
max gradient is 8.000000, min gradient is -7.486022, learning rate is 0.000208
Net2: layer bn50:max response is 19.568563, min response is -4.558012.
max gradient is 8.000000, min gradient is -7.941755, learning rate is 0.000416
Net2: layer deconv2:max response is , min response is .
max gradient is 7.951735, min gradient is -8.000000, learning rate is 0.000208
Net2: layer bn49:max response is 10.508193, min response is -2.419416.
max gradient is 3.644085, min gradient is -8.000000, learning rate is 0.000416
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.742637, learning rate is 0.000208
max inferred z is 4.35, min inferred z is -4.18, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
Loss: 1.3195
Iteration 93 / 200
training: epoch 93: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.988428, min gradient is -8.000001, learning rate is 0.000395
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.874372, learning rate is 0.000395
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.718410, learning rate is 0.000395
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.301937, learning rate is 0.000414
Net2: layer deconv3:max response is 39.349800, min response is -32.439865.
max gradient is 7.936790, min gradient is -8.000000, learning rate is 0.000207
Net2: layer bn50:max response is 18.252132, min response is -4.192760.
max gradient is 8.000000, min gradient is -5.123498, learning rate is 0.000414
Net2: layer deconv2:max response is , min response is .
max gradient is 7.395817, min gradient is -8.000000, learning rate is 0.000207
Net2: layer bn49:max response is 12.126557, min response is -1.978209.
max gradient is 8.000000, min gradient is -6.058673, learning rate is 0.000414
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.277757, learning rate is 0.000207
max inferred z is 4.35, min inferred z is -4.00, and std is 0.99
 4.18 s (23.9 data/s) [100/100]
training: epoch 93: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.868835, min gradient is -8.000000, learning rate is 0.000395
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.321277, learning rate is 0.000395
Net1: layer conv1:max response is , min response is .
max gradient is 5.297116, min gradient is -8.000000, learning rate is 0.000395
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.377891, learning rate is 0.000414
Net2: layer deconv3:max response is 36.532696, min response is -36.818230.
max gradient is 7.367924, min gradient is -8.000000, learning rate is 0.000207
Net2: layer bn50:max response is 18.878489, min response is -4.521131.
max gradient is 6.384453, min gradient is -8.000000, learning rate is 0.000414
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.106230, learning rate is 0.000207
Net2: layer bn49:max response is 10.482506, min response is -2.170442.
max gradient is 5.133783, min gradient is -8.000000, learning rate is 0.000414
Net2: layer deconv1:max response is , min response is .
max gradient is 7.017408, min gradient is -8.000000, learning rate is 0.000207
max inferred z is 4.03, min inferred z is -4.07, and std is 0.99
 4.27 s (23.4 data/s) [100/100]
training: epoch 93: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.941275, min gradient is -8.000000, learning rate is 0.000395
Net1: layer conv2:max response is , min response is .
max gradient is 7.077714, min gradient is -8.000000, learning rate is 0.000395
Net1: layer conv1:max response is , min response is .
max gradient is 5.334715, min gradient is -8.000000, learning rate is 0.000395
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.830907, learning rate is 0.000414
Net2: layer deconv3:max response is 36.597397, min response is -38.894325.
max gradient is 6.449639, min gradient is -8.000000, learning rate is 0.000207
Net2: layer bn50:max response is 20.177837, min response is -4.521500.
max gradient is 8.000000, min gradient is -7.856415, learning rate is 0.000414
Net2: layer deconv2:max response is , min response is .
max gradient is 7.382516, min gradient is -8.000000, learning rate is 0.000207
Net2: layer bn49:max response is 11.899981, min response is -2.099488.
max gradient is 8.000000, min gradient is -6.100766, learning rate is 0.000414
Net2: layer deconv1:max response is , min response is .
max gradient is 7.768466, min gradient is -8.000000, learning rate is 0.000207
max inferred z is 4.23, min inferred z is -4.11, and std is 0.99
 4.37 s (22.9 data/s) [100/100]
training: epoch 93: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.432046, min gradient is -8.000000, learning rate is 0.000395
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.077893, learning rate is 0.000395
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.790920, learning rate is 0.000395
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.035609, learning rate is 0.000414
Net2: layer deconv3:max response is 43.603107, min response is -32.693890.
max gradient is 8.000000, min gradient is -5.532977, learning rate is 0.000207
Net2: layer bn50:max response is 19.928293, min response is -3.869409.
max gradient is 8.000000, min gradient is -7.732439, learning rate is 0.000414
Net2: layer deconv2:max response is , min response is .
max gradient is 6.290617, min gradient is -8.000000, learning rate is 0.000207
Net2: layer bn49:max response is 11.957132, min response is -2.164374.
max gradient is 3.905465, min gradient is -8.000000, learning rate is 0.000414
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.767857, learning rate is 0.000207
max inferred z is 4.08, min inferred z is -4.80, and std is 0.99
 4.16 s (24.0 data/s) [100/100]
training: epoch 93: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.854527, min gradient is -8.000000, learning rate is 0.000395
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.868727, learning rate is 0.000395
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.230938, learning rate is 0.000395
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.642627, learning rate is 0.000414
Net2: layer deconv3:max response is 34.590855, min response is -30.152811.
max gradient is 5.622031, min gradient is -8.000000, learning rate is 0.000207
Net2: layer bn50:max response is 16.282211, min response is -3.750271.
max gradient is 6.761186, min gradient is -8.000000, learning rate is 0.000414
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.506010, learning rate is 0.000207
Net2: layer bn49:max response is 10.418447, min response is -2.324016.
max gradient is 8.000000, min gradient is -4.232070, learning rate is 0.000414
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.349920, learning rate is 0.000207
max inferred z is 4.20, min inferred z is -3.98, and std is 0.99
 4.39 s (22.8 data/s) [100/100]
training: epoch 93: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.932249, min gradient is -8.000000, learning rate is 0.000395
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.371387, learning rate is 0.000395
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.678408, learning rate is 0.000395
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.748292, learning rate is 0.000414
Net2: layer deconv3:max response is 36.220177, min response is -36.703506.
max gradient is 8.000000, min gradient is -7.476975, learning rate is 0.000207
Net2: layer bn50:max response is 19.016247, min response is -3.881891.
max gradient is 8.000000, min gradient is -7.992071, learning rate is 0.000414
Net2: layer deconv2:max response is , min response is .
max gradient is 5.783232, min gradient is -8.000000, learning rate is 0.000207
Net2: layer bn49:max response is 11.352790, min response is -2.505948.
max gradient is 6.307421, min gradient is -8.000000, learning rate is 0.000414
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.721507, learning rate is 0.000207
max inferred z is 4.14, min inferred z is -4.75, and std is 0.99
 4.35 s (23.0 data/s) [100/100]
training: epoch 93: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.188723, min gradient is -8.000000, learning rate is 0.000395
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.034380, learning rate is 0.000395
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.345882, learning rate is 0.000395
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.162453, learning rate is 0.000414
Net2: layer deconv3:max response is 36.458199, min response is -38.477345.
max gradient is 6.889199, min gradient is -8.000000, learning rate is 0.000207
Net2: layer bn50:max response is 18.828737, min response is -4.511972.
max gradient is 8.000000, min gradient is -7.290530, learning rate is 0.000414
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.969427, learning rate is 0.000207
Net2: layer bn49:max response is 10.383190, min response is -2.117352.
max gradient is 8.000000, min gradient is -6.799376, learning rate is 0.000414
Net2: layer deconv1:max response is , min response is .
max gradient is 6.359625, min gradient is -8.000000, learning rate is 0.000207
max inferred z is 3.54, min inferred z is -3.41, and std is 0.99
 4.38 s (22.8 data/s) [100/100]
training: epoch 93: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.316244, min gradient is -8.000000, learning rate is 0.000395
Net1: layer conv2:max response is , min response is .
max gradient is 7.169601, min gradient is -8.000000, learning rate is 0.000395
Net1: layer conv1:max response is , min response is .
max gradient is 6.436361, min gradient is -8.000000, learning rate is 0.000395
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.272875, learning rate is 0.000414
Net2: layer deconv3:max response is 42.778820, min response is -30.596375.
max gradient is 7.197000, min gradient is -8.000000, learning rate is 0.000207
Net2: layer bn50:max response is 22.010576, min response is -4.020911.
max gradient is 7.506722, min gradient is -8.000000, learning rate is 0.000414
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.342318, learning rate is 0.000207
Net2: layer bn49:max response is 11.195491, min response is -2.187711.
max gradient is 3.937974, min gradient is -8.000000, learning rate is 0.000414
Net2: layer deconv1:max response is , min response is .
max gradient is 7.546454, min gradient is -8.000000, learning rate is 0.000207
max inferred z is 4.41, min inferred z is -4.11, and std is 0.99
 4.40 s (22.7 data/s) [100/100]
training: epoch 93: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.409692, min gradient is -8.000000, learning rate is 0.000395
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.792284, learning rate is 0.000395
Net1: layer conv1:max response is , min response is .
max gradient is 5.889058, min gradient is -8.000000, learning rate is 0.000395
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.285240, learning rate is 0.000414
Net2: layer deconv3:max response is 37.228813, min response is -39.352306.
max gradient is 6.825741, min gradient is -8.000000, learning rate is 0.000207
Net2: layer bn50:max response is 21.791218, min response is -5.049094.
max gradient is 8.000000, min gradient is -7.161337, learning rate is 0.000414
Net2: layer deconv2:max response is , min response is .
max gradient is 6.814911, min gradient is -8.000000, learning rate is 0.000207
Net2: layer bn49:max response is 13.725658, min response is -2.288649.
max gradient is 8.000000, min gradient is -6.743730, learning rate is 0.000414
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.739130, learning rate is 0.000207
max inferred z is 4.10, min inferred z is -4.60, and std is 0.99
 4.45 s (22.5 data/s) [100/100]
training: epoch 93: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.855947, min gradient is -8.000000, learning rate is 0.000395
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.873516, learning rate is 0.000395
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.460686, learning rate is 0.000395
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.335364, learning rate is 0.000414
Net2: layer deconv3:max response is 36.131817, min response is -41.988224.
max gradient is 8.000000, min gradient is -6.265319, learning rate is 0.000207
Net2: layer bn50:max response is 22.495432, min response is -5.496000.
max gradient is 8.000000, min gradient is -7.680641, learning rate is 0.000414
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.077639, learning rate is 0.000207
Net2: layer bn49:max response is 13.796064, min response is -2.259342.
max gradient is 5.922598, min gradient is -8.000000, learning rate is 0.000414
Net2: layer deconv1:max response is , min response is .
max gradient is 6.926147, min gradient is -8.000000, learning rate is 0.000207
max inferred z is 3.46, min inferred z is -4.44, and std is 0.99
 4.37 s (22.9 data/s) [100/100]
Loss: 1.2903
Iteration 94 / 200
training: epoch 94: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.410379, min gradient is -8.000000, learning rate is 0.000395
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.810153, learning rate is 0.000395
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.760899, learning rate is 0.000395
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.146194, learning rate is 0.000412
Net2: layer deconv3:max response is 39.230930, min response is -31.160677.
max gradient is 5.663521, min gradient is -8.000000, learning rate is 0.000206
Net2: layer bn50:max response is 17.710230, min response is -3.947987.
max gradient is 8.000000, min gradient is -7.101285, learning rate is 0.000412
Net2: layer deconv2:max response is , min response is .
max gradient is 5.646412, min gradient is -8.000001, learning rate is 0.000206
Net2: layer bn49:max response is 11.046230, min response is -2.275120.
max gradient is 8.000000, min gradient is -6.250054, learning rate is 0.000412
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.876660, learning rate is 0.000206
max inferred z is 4.27, min inferred z is -3.43, and std is 1.00
 4.17 s (24.0 data/s) [100/100]
training: epoch 94: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.235447, min gradient is -8.000000, learning rate is 0.000395
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.822474, learning rate is 0.000395
Net1: layer conv1:max response is , min response is .
max gradient is 5.169269, min gradient is -8.000000, learning rate is 0.000395
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.076229, learning rate is 0.000412
Net2: layer deconv3:max response is 46.397629, min response is -37.341450.
max gradient is 8.000000, min gradient is -5.156673, learning rate is 0.000206
Net2: layer bn50:max response is 21.881979, min response is -4.475239.
max gradient is 8.000000, min gradient is -7.973758, learning rate is 0.000412
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.398726, learning rate is 0.000206
Net2: layer bn49:max response is 11.132909, min response is -2.261434.
max gradient is 6.782706, min gradient is -8.000000, learning rate is 0.000412
Net2: layer deconv1:max response is , min response is .
max gradient is 7.376132, min gradient is -8.000000, learning rate is 0.000206
max inferred z is 3.45, min inferred z is -4.43, and std is 1.00
 4.19 s (23.8 data/s) [100/100]
training: epoch 94: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.599538, min gradient is -8.000000, learning rate is 0.000395
Net1: layer conv2:max response is , min response is .
max gradient is 6.893622, min gradient is -8.000000, learning rate is 0.000395
Net1: layer conv1:max response is , min response is .
max gradient is 5.647131, min gradient is -8.000000, learning rate is 0.000395
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.228566, learning rate is 0.000412
Net2: layer deconv3:max response is 51.980682, min response is -35.636478.
max gradient is 5.208153, min gradient is -8.000000, learning rate is 0.000206
Net2: layer bn50:max response is 24.011429, min response is -4.049792.
max gradient is 8.000000, min gradient is -7.889103, learning rate is 0.000412
Net2: layer deconv2:max response is , min response is .
max gradient is 6.902599, min gradient is -8.000000, learning rate is 0.000206
Net2: layer bn49:max response is 12.065420, min response is -2.254453.
max gradient is 8.000000, min gradient is -6.934628, learning rate is 0.000412
Net2: layer deconv1:max response is , min response is .
max gradient is 7.731702, min gradient is -8.000000, learning rate is 0.000206
max inferred z is 3.76, min inferred z is -4.31, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 94: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.647614, min gradient is -8.000000, learning rate is 0.000395
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.243297, learning rate is 0.000395
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.256168, learning rate is 0.000395
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.340223, learning rate is 0.000412
Net2: layer deconv3:max response is 39.471951, min response is -38.190525.
max gradient is 8.000000, min gradient is -5.040023, learning rate is 0.000206
Net2: layer bn50:max response is 19.565489, min response is -4.497110.
max gradient is 8.000000, min gradient is -7.253260, learning rate is 0.000412
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.250168, learning rate is 0.000206
Net2: layer bn49:max response is 13.465778, min response is -2.478730.
max gradient is 4.896305, min gradient is -8.000000, learning rate is 0.000412
Net2: layer deconv1:max response is , min response is .
max gradient is 6.870320, min gradient is -8.000000, learning rate is 0.000206
max inferred z is 4.02, min inferred z is -3.81, and std is 1.00
 4.23 s (23.6 data/s) [100/100]
training: epoch 94: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.183493, min gradient is -8.000000, learning rate is 0.000395
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.269374, learning rate is 0.000395
Net1: layer conv1:max response is , min response is .
max gradient is 7.865934, min gradient is -8.000000, learning rate is 0.000395
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.110362, learning rate is 0.000412
Net2: layer deconv3:max response is 47.406612, min response is -34.908249.
max gradient is 5.984152, min gradient is -8.000000, learning rate is 0.000206
Net2: layer bn50:max response is 21.296259, min response is -3.882597.
max gradient is 7.821558, min gradient is -8.000000, learning rate is 0.000412
Net2: layer deconv2:max response is , min response is .
max gradient is 5.767805, min gradient is -8.000000, learning rate is 0.000206
Net2: layer bn49:max response is 10.947936, min response is -2.698430.
max gradient is 8.000000, min gradient is -4.954987, learning rate is 0.000412
Net2: layer deconv1:max response is , min response is .
max gradient is 7.913265, min gradient is -8.000000, learning rate is 0.000206
max inferred z is 4.04, min inferred z is -4.41, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 94: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.258978, min gradient is -8.000000, learning rate is 0.000395
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.777734, learning rate is 0.000395
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -6.789306, learning rate is 0.000395
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.994070, learning rate is 0.000412
Net2: layer deconv3:max response is 32.225517, min response is -33.784916.
max gradient is 7.347323, min gradient is -8.000000, learning rate is 0.000206
Net2: layer bn50:max response is 17.912510, min response is -4.565392.
max gradient is 6.687482, min gradient is -8.000000, learning rate is 0.000412
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.204098, learning rate is 0.000206
Net2: layer bn49:max response is 11.901503, min response is -2.249376.
max gradient is 4.904879, min gradient is -8.000000, learning rate is 0.000412
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.165950, learning rate is 0.000206
max inferred z is 4.48, min inferred z is -4.40, and std is 1.00
 4.28 s (23.4 data/s) [100/100]
training: epoch 94: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.732310, min gradient is -8.000000, learning rate is 0.000395
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.151230, learning rate is 0.000395
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.043954, learning rate is 0.000395
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.641242, learning rate is 0.000412
Net2: layer deconv3:max response is 42.360703, min response is -37.919556.
max gradient is 7.857090, min gradient is -8.000000, learning rate is 0.000206
Net2: layer bn50:max response is 19.881054, min response is -4.668462.
max gradient is 8.000000, min gradient is -6.181241, learning rate is 0.000412
Net2: layer deconv2:max response is , min response is .
max gradient is 6.809451, min gradient is -8.000000, learning rate is 0.000206
Net2: layer bn49:max response is 12.293302, min response is -2.230411.
max gradient is 8.000000, min gradient is -4.278233, learning rate is 0.000412
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.072204, learning rate is 0.000206
max inferred z is 3.88, min inferred z is -4.43, and std is 1.00
 4.46 s (22.4 data/s) [100/100]
training: epoch 94: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.791648, min gradient is -8.000000, learning rate is 0.000395
Net1: layer conv2:max response is , min response is .
max gradient is 8.000001, min gradient is -7.292100, learning rate is 0.000395
Net1: layer conv1:max response is , min response is .
max gradient is 5.857176, min gradient is -8.000000, learning rate is 0.000395
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.154601, learning rate is 0.000412
Net2: layer deconv3:max response is 42.818676, min response is -33.236519.
max gradient is 8.000000, min gradient is -6.316228, learning rate is 0.000206
Net2: layer bn50:max response is 19.989912, min response is -4.308453.
max gradient is 8.000000, min gradient is -7.983004, learning rate is 0.000412
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000001, min gradient is -7.757507, learning rate is 0.000206
Net2: layer bn49:max response is 12.187347, min response is -2.412020.
max gradient is 3.815243, min gradient is -8.000000, learning rate is 0.000412
Net2: layer deconv1:max response is , min response is .
max gradient is 5.013893, min gradient is -8.000000, learning rate is 0.000206
max inferred z is 3.86, min inferred z is -4.50, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 94: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.156456, min gradient is -8.000000, learning rate is 0.000395
Net1: layer conv2:max response is , min response is .
max gradient is 8.000001, min gradient is -6.639407, learning rate is 0.000395
Net1: layer conv1:max response is , min response is .
max gradient is 6.637173, min gradient is -8.000000, learning rate is 0.000395
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.658174, learning rate is 0.000412
Net2: layer deconv3:max response is 32.596508, min response is -37.903660.
max gradient is 7.021990, min gradient is -8.000000, learning rate is 0.000206
Net2: layer bn50:max response is 18.726677, min response is -4.896464.
max gradient is 8.000000, min gradient is -7.323545, learning rate is 0.000412
Net2: layer deconv2:max response is , min response is .
max gradient is 6.333177, min gradient is -8.000000, learning rate is 0.000206
Net2: layer bn49:max response is 12.313706, min response is -2.220092.
max gradient is 8.000000, min gradient is -5.483567, learning rate is 0.000412
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.490787, learning rate is 0.000206
max inferred z is 3.81, min inferred z is -3.85, and std is 1.00
 4.16 s (24.1 data/s) [100/100]
training: epoch 94: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.951871, min gradient is -8.000000, learning rate is 0.000395
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.231609, learning rate is 0.000395
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.797437, learning rate is 0.000395
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.530912, learning rate is 0.000412
Net2: layer deconv3:max response is 38.494221, min response is -32.939323.
max gradient is 8.000000, min gradient is -7.709281, learning rate is 0.000206
Net2: layer bn50:max response is 21.603430, min response is -4.028348.
max gradient is 6.589214, min gradient is -8.000000, learning rate is 0.000412
Net2: layer deconv2:max response is , min response is .
max gradient is 5.450683, min gradient is -8.000000, learning rate is 0.000206
Net2: layer bn49:max response is 10.586731, min response is -2.389513.
max gradient is 7.865720, min gradient is -8.000000, learning rate is 0.000412
Net2: layer deconv1:max response is , min response is .
max gradient is 7.717101, min gradient is -8.000001, learning rate is 0.000206
max inferred z is 3.78, min inferred z is -4.02, and std is 1.00
 4.22 s (23.7 data/s) [100/100]
Loss: 1.2747
Iteration 95 / 200
training: epoch 95: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.049557, min gradient is -8.000000, learning rate is 0.000328
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.239971, learning rate is 0.000328
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.848446, learning rate is 0.000328
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.229427, learning rate is 0.000410
Net2: layer deconv3:max response is 38.141888, min response is -38.145367.
max gradient is 6.348698, min gradient is -8.000000, learning rate is 0.000205
Net2: layer bn50:max response is 19.597178, min response is -4.832776.
max gradient is 8.000000, min gradient is -6.680794, learning rate is 0.000410
Net2: layer deconv2:max response is , min response is .
max gradient is 6.400439, min gradient is -8.000000, learning rate is 0.000205
Net2: layer bn49:max response is 10.241076, min response is -2.457173.
max gradient is 8.000000, min gradient is -5.943917, learning rate is 0.000410
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.847676, learning rate is 0.000205
max inferred z is 3.70, min inferred z is -4.02, and std is 1.00
 4.30 s (23.2 data/s) [100/100]
training: epoch 95: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.516448, min gradient is -8.000000, learning rate is 0.000328
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.344793, learning rate is 0.000328
Net1: layer conv1:max response is , min response is .
max gradient is 5.612420, min gradient is -8.000000, learning rate is 0.000328
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.867018, learning rate is 0.000410
Net2: layer deconv3:max response is 38.451603, min response is -41.177486.
max gradient is 7.366700, min gradient is -8.000000, learning rate is 0.000205
Net2: layer bn50:max response is 19.261929, min response is -3.651559.
max gradient is 8.000000, min gradient is -7.408276, learning rate is 0.000410
Net2: layer deconv2:max response is , min response is .
max gradient is 7.529117, min gradient is -8.000001, learning rate is 0.000205
Net2: layer bn49:max response is 12.875792, min response is -2.892089.
max gradient is 6.649014, min gradient is -8.000000, learning rate is 0.000410
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.519500, learning rate is 0.000205
max inferred z is 3.86, min inferred z is -3.84, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 95: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.753147, min gradient is -8.000000, learning rate is 0.000328
Net1: layer conv2:max response is , min response is .
max gradient is 6.194832, min gradient is -8.000000, learning rate is 0.000328
Net1: layer conv1:max response is , min response is .
max gradient is 5.876387, min gradient is -8.000000, learning rate is 0.000328
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.691963, learning rate is 0.000410
Net2: layer deconv3:max response is 51.618881, min response is -42.275875.
max gradient is 6.954706, min gradient is -8.000000, learning rate is 0.000205
Net2: layer bn50:max response is 22.722086, min response is -5.629650.
max gradient is 7.491423, min gradient is -8.000000, learning rate is 0.000410
Net2: layer deconv2:max response is , min response is .
max gradient is 7.416921, min gradient is -8.000000, learning rate is 0.000205
Net2: layer bn49:max response is 14.552712, min response is -2.684216.
max gradient is 8.000000, min gradient is -6.773149, learning rate is 0.000410
Net2: layer deconv1:max response is , min response is .
max gradient is 6.963068, min gradient is -8.000000, learning rate is 0.000205
max inferred z is 4.26, min inferred z is -4.14, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 95: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.127098, min gradient is -8.000000, learning rate is 0.000328
Net1: layer conv2:max response is , min response is .
max gradient is 7.774078, min gradient is -8.000000, learning rate is 0.000328
Net1: layer conv1:max response is , min response is .
max gradient is 7.462829, min gradient is -8.000000, learning rate is 0.000328
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 5.576625, min gradient is -8.000000, learning rate is 0.000410
Net2: layer deconv3:max response is 36.847263, min response is -31.655107.
max gradient is 8.000000, min gradient is -7.965679, learning rate is 0.000205
Net2: layer bn50:max response is 17.658451, min response is -3.932097.
max gradient is 8.000000, min gradient is -7.950703, learning rate is 0.000410
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.162904, learning rate is 0.000205
Net2: layer bn49:max response is 11.769137, min response is -2.024025.
max gradient is 5.340876, min gradient is -8.000000, learning rate is 0.000410
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.859205, learning rate is 0.000205
max inferred z is 4.18, min inferred z is -3.79, and std is 1.00
 4.21 s (23.8 data/s) [100/100]
training: epoch 95: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.436563, min gradient is -8.000000, learning rate is 0.000328
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.660158, learning rate is 0.000328
Net1: layer conv1:max response is , min response is .
max gradient is 7.608225, min gradient is -8.000000, learning rate is 0.000328
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.317765, learning rate is 0.000410
Net2: layer deconv3:max response is 42.072159, min response is -36.713146.
max gradient is 7.162054, min gradient is -8.000000, learning rate is 0.000205
Net2: layer bn50:max response is 18.977993, min response is -4.484704.
max gradient is 8.000000, min gradient is -6.644580, learning rate is 0.000410
Net2: layer deconv2:max response is , min response is .
max gradient is 7.028610, min gradient is -8.000000, learning rate is 0.000205
Net2: layer bn49:max response is 10.345552, min response is -2.310875.
max gradient is 8.000000, min gradient is -5.180020, learning rate is 0.000410
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.253844, learning rate is 0.000205
max inferred z is 4.95, min inferred z is -4.82, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 95: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.632911, min gradient is -8.000000, learning rate is 0.000328
Net1: layer conv2:max response is , min response is .
max gradient is 8.000001, min gradient is -5.887377, learning rate is 0.000328
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.721975, learning rate is 0.000328
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.404968, learning rate is 0.000410
Net2: layer deconv3:max response is 36.479229, min response is -41.980797.
max gradient is 7.994513, min gradient is -8.000000, learning rate is 0.000205
Net2: layer bn50:max response is 20.921318, min response is -5.272699.
max gradient is 6.505409, min gradient is -8.000000, learning rate is 0.000410
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.358671, learning rate is 0.000205
Net2: layer bn49:max response is 11.297330, min response is -2.626570.
max gradient is 5.924817, min gradient is -8.000000, learning rate is 0.000410
Net2: layer deconv1:max response is , min response is .
max gradient is 7.902802, min gradient is -8.000001, learning rate is 0.000205
max inferred z is 4.78, min inferred z is -4.58, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 95: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.179494, min gradient is -8.000000, learning rate is 0.000328
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.084688, learning rate is 0.000328
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.242476, learning rate is 0.000328
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.975406, learning rate is 0.000410
Net2: layer deconv3:max response is 36.570480, min response is -40.558079.
max gradient is 7.474115, min gradient is -8.000000, learning rate is 0.000205
Net2: layer bn50:max response is 21.184332, min response is -5.001397.
max gradient is 8.000000, min gradient is -6.685893, learning rate is 0.000410
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.337984, learning rate is 0.000205
Net2: layer bn49:max response is 11.423288, min response is -2.297084.
max gradient is 8.000000, min gradient is -4.687655, learning rate is 0.000410
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.756710, learning rate is 0.000205
max inferred z is 3.93, min inferred z is -3.82, and std is 1.00
 4.43 s (22.6 data/s) [100/100]
training: epoch 95: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.917583, min gradient is -8.000000, learning rate is 0.000328
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.564792, learning rate is 0.000328
Net1: layer conv1:max response is , min response is .
max gradient is 6.680318, min gradient is -8.000000, learning rate is 0.000328
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.032219, learning rate is 0.000410
Net2: layer deconv3:max response is 41.404633, min response is -32.497559.
max gradient is 7.423417, min gradient is -8.000000, learning rate is 0.000205
Net2: layer bn50:max response is 18.771009, min response is -3.893580.
max gradient is 5.173481, min gradient is -8.000000, learning rate is 0.000410
Net2: layer deconv2:max response is , min response is .
max gradient is 7.488331, min gradient is -8.000000, learning rate is 0.000205
Net2: layer bn49:max response is 10.956738, min response is -2.128844.
max gradient is 3.087884, min gradient is -8.000000, learning rate is 0.000410
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.365036, learning rate is 0.000205
max inferred z is 3.89, min inferred z is -3.74, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 95: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.522000, min gradient is -8.000000, learning rate is 0.000328
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.948127, learning rate is 0.000328
Net1: layer conv1:max response is , min response is .
max gradient is 6.202028, min gradient is -8.000000, learning rate is 0.000328
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.062438, learning rate is 0.000410
Net2: layer deconv3:max response is 39.106636, min response is -40.400200.
max gradient is 7.403362, min gradient is -8.000000, learning rate is 0.000205
Net2: layer bn50:max response is 21.510841, min response is -4.329643.
max gradient is 8.000000, min gradient is -5.032700, learning rate is 0.000410
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.848868, learning rate is 0.000205
Net2: layer bn49:max response is 10.523485, min response is -2.272274.
max gradient is 8.000000, min gradient is -3.284727, learning rate is 0.000410
Net2: layer deconv1:max response is , min response is .
max gradient is 7.803162, min gradient is -8.000000, learning rate is 0.000205
max inferred z is 4.18, min inferred z is -3.77, and std is 1.00
 4.30 s (23.2 data/s) [100/100]
training: epoch 95: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.086248, min gradient is -8.000000, learning rate is 0.000328
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.934096, learning rate is 0.000328
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.829359, learning rate is 0.000328
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.736993, learning rate is 0.000410
Net2: layer deconv3:max response is 33.229172, min response is -33.489422.
max gradient is 7.623100, min gradient is -8.000000, learning rate is 0.000205
Net2: layer bn50:max response is 18.959274, min response is -4.665458.
max gradient is 5.638392, min gradient is -8.000000, learning rate is 0.000410
Net2: layer deconv2:max response is , min response is .
max gradient is 6.363818, min gradient is -8.000000, learning rate is 0.000205
Net2: layer bn49:max response is 11.012079, min response is -2.416511.
max gradient is 3.160111, min gradient is -8.000000, learning rate is 0.000410
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.457490, learning rate is 0.000205
max inferred z is 4.00, min inferred z is -4.13, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
Loss: 1.2751
Iteration 96 / 200
training: epoch 96: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.933206, min gradient is -8.000000, learning rate is 0.000328
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.106184, learning rate is 0.000328
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.253972, learning rate is 0.000328
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.146955, learning rate is 0.000408
Net2: layer deconv3:max response is 43.233402, min response is -36.517235.
max gradient is 5.736372, min gradient is -8.000000, learning rate is 0.000204
Net2: layer bn50:max response is 19.981615, min response is -4.528672.
max gradient is 8.000000, min gradient is -7.649658, learning rate is 0.000408
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.905715, learning rate is 0.000204
Net2: layer bn49:max response is 11.272629, min response is -2.029381.
max gradient is 8.000000, min gradient is -5.653937, learning rate is 0.000408
Net2: layer deconv1:max response is , min response is .
max gradient is 6.948653, min gradient is -8.000000, learning rate is 0.000204
max inferred z is 4.09, min inferred z is -3.94, and std is 1.00
 4.23 s (23.7 data/s) [100/100]
training: epoch 96: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.193916, min gradient is -8.000000, learning rate is 0.000328
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.661286, learning rate is 0.000328
Net1: layer conv1:max response is , min response is .
max gradient is 5.497380, min gradient is -8.000000, learning rate is 0.000328
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.759168, learning rate is 0.000408
Net2: layer deconv3:max response is 37.270443, min response is -39.491180.
max gradient is 8.000000, min gradient is -4.614608, learning rate is 0.000204
Net2: layer bn50:max response is 20.865646, min response is -5.115048.
max gradient is 8.000000, min gradient is -6.137634, learning rate is 0.000408
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.020236, learning rate is 0.000204
Net2: layer bn49:max response is 12.213796, min response is -2.374418.
max gradient is 7.403286, min gradient is -8.000000, learning rate is 0.000408
Net2: layer deconv1:max response is , min response is .
max gradient is 6.572578, min gradient is -8.000000, learning rate is 0.000204
max inferred z is 4.00, min inferred z is -4.33, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 96: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.852987, min gradient is -8.000000, learning rate is 0.000328
Net1: layer conv2:max response is , min response is .
max gradient is 5.951205, min gradient is -8.000000, learning rate is 0.000328
Net1: layer conv1:max response is , min response is .
max gradient is 6.451569, min gradient is -8.000000, learning rate is 0.000328
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.437259, learning rate is 0.000408
Net2: layer deconv3:max response is 45.090336, min response is -44.267120.
max gradient is 5.373982, min gradient is -8.000000, learning rate is 0.000204
Net2: layer bn50:max response is 23.861172, min response is -4.773901.
max gradient is 6.459592, min gradient is -8.000000, learning rate is 0.000408
Net2: layer deconv2:max response is , min response is .
max gradient is 5.386761, min gradient is -8.000000, learning rate is 0.000204
Net2: layer bn49:max response is 11.603168, min response is -2.206843.
max gradient is 5.760110, min gradient is -8.000000, learning rate is 0.000408
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.934726, learning rate is 0.000204
max inferred z is 3.94, min inferred z is -3.92, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 96: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.001084, min gradient is -8.000000, learning rate is 0.000328
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.331166, learning rate is 0.000328
Net1: layer conv1:max response is , min response is .
max gradient is 6.943321, min gradient is -8.000000, learning rate is 0.000328
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.331467, learning rate is 0.000408
Net2: layer deconv3:max response is 40.150757, min response is -39.391369.
max gradient is 8.000000, min gradient is -3.890096, learning rate is 0.000204
Net2: layer bn50:max response is 18.677309, min response is -4.975783.
max gradient is 8.000000, min gradient is -6.503894, learning rate is 0.000408
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.401088, learning rate is 0.000204
Net2: layer bn49:max response is 13.462938, min response is -2.353435.
max gradient is 8.000000, min gradient is -6.098734, learning rate is 0.000408
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.821484, learning rate is 0.000204
max inferred z is 3.68, min inferred z is -4.06, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 96: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.899647, min gradient is -8.000000, learning rate is 0.000328
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.135136, learning rate is 0.000328
Net1: layer conv1:max response is , min response is .
max gradient is 5.904249, min gradient is -8.000000, learning rate is 0.000328
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.070899, learning rate is 0.000408
Net2: layer deconv3:max response is 48.662243, min response is -45.652264.
max gradient is 4.142305, min gradient is -8.000000, learning rate is 0.000204
Net2: layer bn50:max response is 24.543056, min response is -5.935674.
max gradient is 7.376237, min gradient is -8.000000, learning rate is 0.000408
Net2: layer deconv2:max response is , min response is .
max gradient is 4.520423, min gradient is -8.000000, learning rate is 0.000204
Net2: layer bn49:max response is 14.191510, min response is -2.684757.
max gradient is 8.000000, min gradient is -7.555652, learning rate is 0.000408
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.625273, learning rate is 0.000204
max inferred z is 3.78, min inferred z is -4.07, and std is 1.00
 4.23 s (23.7 data/s) [100/100]
training: epoch 96: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.266293, min gradient is -8.000000, learning rate is 0.000328
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.151985, learning rate is 0.000328
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.609387, learning rate is 0.000328
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.677815, learning rate is 0.000408
Net2: layer deconv3:max response is 34.720802, min response is -35.552952.
max gradient is 8.000000, min gradient is -5.407538, learning rate is 0.000204
Net2: layer bn50:max response is 20.504625, min response is -4.461688.
max gradient is 7.837729, min gradient is -8.000000, learning rate is 0.000408
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.861457, learning rate is 0.000204
Net2: layer bn49:max response is 13.869151, min response is -2.460401.
max gradient is 8.000000, min gradient is -7.570455, learning rate is 0.000408
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.883756, learning rate is 0.000204
max inferred z is 4.24, min inferred z is -3.69, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 96: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.159896, min gradient is -8.000000, learning rate is 0.000328
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.388917, learning rate is 0.000328
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.940503, learning rate is 0.000328
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.145078, learning rate is 0.000408
Net2: layer deconv3:max response is 37.228539, min response is -32.701393.
max gradient is 4.244023, min gradient is -8.000000, learning rate is 0.000204
Net2: layer bn50:max response is 19.443615, min response is -3.669725.
max gradient is 7.169865, min gradient is -8.000000, learning rate is 0.000408
Net2: layer deconv2:max response is , min response is .
max gradient is 5.014208, min gradient is -8.000000, learning rate is 0.000204
Net2: layer bn49:max response is 10.377743, min response is -2.830732.
max gradient is 8.000000, min gradient is -6.617877, learning rate is 0.000408
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.072941, learning rate is 0.000204
max inferred z is 3.67, min inferred z is -3.80, and std is 1.00
 4.22 s (23.7 data/s) [100/100]
training: epoch 96: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.212224, learning rate is 0.000328
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.963248, learning rate is 0.000328
Net1: layer conv1:max response is , min response is .
max gradient is 6.982238, min gradient is -8.000000, learning rate is 0.000328
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.189699, learning rate is 0.000408
Net2: layer deconv3:max response is 40.011948, min response is -42.170132.
max gradient is 8.000000, min gradient is -4.979604, learning rate is 0.000204
Net2: layer bn50:max response is 24.131348, min response is -4.970894.
max gradient is 8.000000, min gradient is -5.863356, learning rate is 0.000408
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.067235, learning rate is 0.000204
Net2: layer bn49:max response is 10.161417, min response is -2.217810.
max gradient is 8.000000, min gradient is -6.219495, learning rate is 0.000408
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.988354, learning rate is 0.000204
max inferred z is 3.75, min inferred z is -3.90, and std is 1.00
 4.25 s (23.6 data/s) [100/100]
training: epoch 96: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.439781, min gradient is -8.000000, learning rate is 0.000328
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.902290, learning rate is 0.000328
Net1: layer conv1:max response is , min response is .
max gradient is 5.871409, min gradient is -8.000000, learning rate is 0.000328
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000001, min gradient is 7.340303, learning rate is 0.000408
Net2: layer deconv3:max response is 43.186749, min response is -37.494263.
max gradient is 4.089638, min gradient is -8.000000, learning rate is 0.000204
Net2: layer bn50:max response is 23.857172, min response is -5.018432.
max gradient is 6.716118, min gradient is -8.000000, learning rate is 0.000408
Net2: layer deconv2:max response is , min response is .
max gradient is 4.301726, min gradient is -8.000001, learning rate is 0.000204
Net2: layer bn49:max response is 11.546533, min response is -2.508157.
max gradient is 8.000000, min gradient is -7.128723, learning rate is 0.000408
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.920321, learning rate is 0.000204
max inferred z is 3.99, min inferred z is -3.90, and std is 1.00
 4.21 s (23.7 data/s) [100/100]
training: epoch 96: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.581553, min gradient is -8.000000, learning rate is 0.000328
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.108806, learning rate is 0.000328
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.654737, learning rate is 0.000328
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.044314, learning rate is 0.000408
Net2: layer deconv3:max response is 52.256100, min response is -43.622856.
max gradient is 8.000000, min gradient is -7.971757, learning rate is 0.000204
Net2: layer bn50:max response is 23.770395, min response is -4.766084.
max gradient is 4.505959, min gradient is -8.000000, learning rate is 0.000408
Net2: layer deconv2:max response is , min response is .
max gradient is 6.918939, min gradient is -8.000000, learning rate is 0.000204
Net2: layer bn49:max response is 12.257700, min response is -2.337042.
max gradient is 8.000000, min gradient is -7.183104, learning rate is 0.000408
Net2: layer deconv1:max response is , min response is .
max gradient is 6.962566, min gradient is -8.000000, learning rate is 0.000204
max inferred z is 4.14, min inferred z is -3.94, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
Loss: 1.3579
Iteration 97 / 200
training: epoch 97: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.633516, min gradient is -8.000000, learning rate is 0.000272
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.934619, learning rate is 0.000272
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.629943, learning rate is 0.000272
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.086174, learning rate is 0.000406
Net2: layer deconv3:max response is 38.903496, min response is -37.414211.
max gradient is 5.989649, min gradient is -8.000000, learning rate is 0.000203
Net2: layer bn50:max response is 20.773252, min response is -3.998581.
max gradient is 8.000000, min gradient is -4.625350, learning rate is 0.000406
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.548920, learning rate is 0.000203
Net2: layer bn49:max response is 11.399270, min response is -2.535973.
max gradient is 8.000000, min gradient is -3.680510, learning rate is 0.000406
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.950273, learning rate is 0.000203
max inferred z is 4.58, min inferred z is -3.97, and std is 1.00
 4.22 s (23.7 data/s) [100/100]
training: epoch 97: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.229124, min gradient is -8.000000, learning rate is 0.000272
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.444590, learning rate is 0.000272
Net1: layer conv1:max response is , min response is .
max gradient is 5.217256, min gradient is -8.000000, learning rate is 0.000272
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.227016, learning rate is 0.000406
Net2: layer deconv3:max response is 41.576344, min response is -40.498390.
max gradient is 8.000000, min gradient is -6.762853, learning rate is 0.000203
Net2: layer bn50:max response is 23.560650, min response is -4.191763.
max gradient is 8.000000, min gradient is -5.626668, learning rate is 0.000406
Net2: layer deconv2:max response is , min response is .
max gradient is 7.161676, min gradient is -8.000000, learning rate is 0.000203
Net2: layer bn49:max response is 11.140059, min response is -2.344964.
max gradient is 8.000000, min gradient is -7.917665, learning rate is 0.000406
Net2: layer deconv1:max response is , min response is .
max gradient is 7.341059, min gradient is -8.000001, learning rate is 0.000203
max inferred z is 4.66, min inferred z is -3.88, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 97: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.899579, learning rate is 0.000272
Net1: layer conv2:max response is , min response is .
max gradient is 6.190291, min gradient is -8.000000, learning rate is 0.000272
Net1: layer conv1:max response is , min response is .
max gradient is 5.839846, min gradient is -8.000000, learning rate is 0.000272
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.157137, learning rate is 0.000406
Net2: layer deconv3:max response is 41.354069, min response is -40.123222.
max gradient is 5.157544, min gradient is -8.000000, learning rate is 0.000203
Net2: layer bn50:max response is 21.354757, min response is -4.706583.
max gradient is 6.494513, min gradient is -8.000000, learning rate is 0.000406
Net2: layer deconv2:max response is , min response is .
max gradient is 6.001586, min gradient is -8.000000, learning rate is 0.000203
Net2: layer bn49:max response is 13.047719, min response is -2.312535.
max gradient is 8.000000, min gradient is -5.970997, learning rate is 0.000406
Net2: layer deconv1:max response is , min response is .
max gradient is 7.992373, min gradient is -8.000000, learning rate is 0.000203
max inferred z is 3.74, min inferred z is -3.86, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 97: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.904576, min gradient is -8.000000, learning rate is 0.000272
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.764537, learning rate is 0.000272
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.872258, learning rate is 0.000272
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.874183, learning rate is 0.000406
Net2: layer deconv3:max response is 38.299473, min response is -36.678596.
max gradient is 7.946556, min gradient is -8.000000, learning rate is 0.000203
Net2: layer bn50:max response is 21.992332, min response is -3.920247.
max gradient is 4.547249, min gradient is -8.000000, learning rate is 0.000406
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.719796, learning rate is 0.000203
Net2: layer bn49:max response is 10.940625, min response is -2.333201.
max gradient is 6.771493, min gradient is -8.000000, learning rate is 0.000406
Net2: layer deconv1:max response is , min response is .
max gradient is 7.945920, min gradient is -8.000000, learning rate is 0.000203
max inferred z is 4.05, min inferred z is -4.35, and std is 1.00
 4.32 s (23.2 data/s) [100/100]
training: epoch 97: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.973464, min gradient is -8.000000, learning rate is 0.000272
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.823531, learning rate is 0.000272
Net1: layer conv1:max response is , min response is .
max gradient is 6.801025, min gradient is -8.000000, learning rate is 0.000272
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.755673, learning rate is 0.000406
Net2: layer deconv3:max response is 47.595398, min response is -47.116100.
max gradient is 7.324189, min gradient is -8.000000, learning rate is 0.000203
Net2: layer bn50:max response is 24.352592, min response is -5.805110.
max gradient is 8.000000, min gradient is -5.297895, learning rate is 0.000406
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.600614, learning rate is 0.000203
Net2: layer bn49:max response is 13.006914, min response is -3.057213.
max gradient is 8.000000, min gradient is -4.521321, learning rate is 0.000406
Net2: layer deconv1:max response is , min response is .
max gradient is 6.223798, min gradient is -8.000000, learning rate is 0.000203
max inferred z is 4.11, min inferred z is -3.79, and std is 1.00
 4.34 s (23.1 data/s) [100/100]
training: epoch 97: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.416757, min gradient is -8.000000, learning rate is 0.000272
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.220496, learning rate is 0.000272
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.380353, learning rate is 0.000272
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.494849, learning rate is 0.000406
Net2: layer deconv3:max response is 38.531235, min response is -35.480743.
max gradient is 7.293394, min gradient is -8.000000, learning rate is 0.000203
Net2: layer bn50:max response is 20.334208, min response is -4.504701.
max gradient is 5.359723, min gradient is -8.000000, learning rate is 0.000406
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.947160, learning rate is 0.000203
Net2: layer bn49:max response is 11.401905, min response is -2.369811.
max gradient is 4.377714, min gradient is -8.000000, learning rate is 0.000406
Net2: layer deconv1:max response is , min response is .
max gradient is 6.990440, min gradient is -8.000000, learning rate is 0.000203
max inferred z is 4.50, min inferred z is -4.36, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 97: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.583194, min gradient is -8.000000, learning rate is 0.000272
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.564584, learning rate is 0.000272
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.956583, learning rate is 0.000272
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.465494, learning rate is 0.000406
Net2: layer deconv3:max response is 44.749210, min response is -46.646416.
max gradient is 5.556993, min gradient is -8.000000, learning rate is 0.000203
Net2: layer bn50:max response is 24.858438, min response is -5.972003.
max gradient is 8.000000, min gradient is -5.383502, learning rate is 0.000406
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.770011, learning rate is 0.000203
Net2: layer bn49:max response is 14.019121, min response is -2.789949.
max gradient is 8.000000, min gradient is -3.105403, learning rate is 0.000406
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.590580, learning rate is 0.000203
max inferred z is 3.95, min inferred z is -3.71, and std is 1.00
 4.43 s (22.6 data/s) [100/100]
training: epoch 97: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.518085, learning rate is 0.000272
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.769595, learning rate is 0.000272
Net1: layer conv1:max response is , min response is .
max gradient is 6.902044, min gradient is -8.000000, learning rate is 0.000272
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.090963, learning rate is 0.000406
Net2: layer deconv3:max response is 41.983452, min response is -35.204090.
max gradient is 6.723985, min gradient is -8.000000, learning rate is 0.000203
Net2: layer bn50:max response is 20.450188, min response is -4.285280.
max gradient is 3.945307, min gradient is -8.000000, learning rate is 0.000406
Net2: layer deconv2:max response is , min response is .
max gradient is 7.910405, min gradient is -8.000000, learning rate is 0.000203
Net2: layer bn49:max response is 10.515099, min response is -2.610011.
max gradient is 5.191123, min gradient is -8.000000, learning rate is 0.000406
Net2: layer deconv1:max response is , min response is .
max gradient is 7.193111, min gradient is -8.000000, learning rate is 0.000203
max inferred z is 4.23, min inferred z is -3.79, and std is 1.00
 4.30 s (23.3 data/s) [100/100]
training: epoch 97: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.391226, min gradient is -8.000000, learning rate is 0.000272
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.436697, learning rate is 0.000272
Net1: layer conv1:max response is , min response is .
max gradient is 6.120836, min gradient is -8.000000, learning rate is 0.000272
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.242405, learning rate is 0.000406
Net2: layer deconv3:max response is 42.288383, min response is -41.698265.
max gradient is 8.000000, min gradient is -7.976247, learning rate is 0.000203
Net2: layer bn50:max response is 23.082355, min response is -4.359766.
max gradient is 8.000001, min gradient is -5.039418, learning rate is 0.000406
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.554534, learning rate is 0.000203
Net2: layer bn49:max response is 10.113312, min response is -2.392727.
max gradient is 8.000000, min gradient is -5.866813, learning rate is 0.000406
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.061525, learning rate is 0.000203
max inferred z is 4.09, min inferred z is -4.13, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
training: epoch 97: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.158810, min gradient is -8.000000, learning rate is 0.000272
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.214569, learning rate is 0.000272
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.292582, learning rate is 0.000272
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.857570, learning rate is 0.000406
Net2: layer deconv3:max response is 41.147339, min response is -42.871284.
max gradient is 8.000000, min gradient is -6.706968, learning rate is 0.000203
Net2: layer bn50:max response is 22.643684, min response is -5.436234.
max gradient is 8.000000, min gradient is -7.202759, learning rate is 0.000406
Net2: layer deconv2:max response is , min response is .
max gradient is 7.105230, min gradient is -8.000000, learning rate is 0.000203
Net2: layer bn49:max response is 11.052462, min response is -2.327117.
max gradient is 6.652128, min gradient is -8.000000, learning rate is 0.000406
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.698580, learning rate is 0.000203
max inferred z is 4.45, min inferred z is -3.88, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
Loss: 1.2629
Iteration 98 / 200
training: epoch 98: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.801322, min gradient is -8.000000, learning rate is 0.000272
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.259912, learning rate is 0.000272
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.451119, learning rate is 0.000272
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.285778, learning rate is 0.000404
Net2: layer deconv3:max response is 39.408978, min response is -38.081867.
max gradient is 6.939735, min gradient is -8.000000, learning rate is 0.000202
Net2: layer bn50:max response is 19.933392, min response is -3.831332.
max gradient is 7.953310, min gradient is -8.000000, learning rate is 0.000404
Net2: layer deconv2:max response is , min response is .
max gradient is 6.780216, min gradient is -8.000000, learning rate is 0.000202
Net2: layer bn49:max response is 10.445489, min response is -2.447515.
max gradient is 8.000000, min gradient is -6.160992, learning rate is 0.000404
Net2: layer deconv1:max response is , min response is .
max gradient is 7.352756, min gradient is -8.000000, learning rate is 0.000202
max inferred z is 3.98, min inferred z is -4.24, and std is 1.00
 4.23 s (23.6 data/s) [100/100]
training: epoch 98: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.170443, min gradient is -8.000000, learning rate is 0.000272
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.611805, learning rate is 0.000272
Net1: layer conv1:max response is , min response is .
max gradient is 5.040438, min gradient is -8.000000, learning rate is 0.000272
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000001, min gradient is 6.405214, learning rate is 0.000404
Net2: layer deconv3:max response is 37.871807, min response is -33.878613.
max gradient is 7.418246, min gradient is -8.000000, learning rate is 0.000202
Net2: layer bn50:max response is 22.645302, min response is -4.498194.
max gradient is 5.675958, min gradient is -8.000000, learning rate is 0.000404
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.150212, learning rate is 0.000202
Net2: layer bn49:max response is 11.757228, min response is -2.310450.
max gradient is 5.713747, min gradient is -8.000000, learning rate is 0.000404
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.912054, learning rate is 0.000202
max inferred z is 3.87, min inferred z is -3.98, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 98: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.660042, min gradient is -8.000000, learning rate is 0.000272
Net1: layer conv2:max response is , min response is .
max gradient is 6.838753, min gradient is -8.000000, learning rate is 0.000272
Net1: layer conv1:max response is , min response is .
max gradient is 5.860301, min gradient is -8.000000, learning rate is 0.000272
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000001, min gradient is 7.607887, learning rate is 0.000404
Net2: layer deconv3:max response is 47.762203, min response is -46.283970.
max gradient is 8.000000, min gradient is -7.126771, learning rate is 0.000202
Net2: layer bn50:max response is 24.311409, min response is -4.972004.
max gradient is 8.000000, min gradient is -5.126952, learning rate is 0.000404
Net2: layer deconv2:max response is , min response is .
max gradient is 6.921813, min gradient is -8.000000, learning rate is 0.000202
Net2: layer bn49:max response is 10.969089, min response is -2.264385.
max gradient is 8.000001, min gradient is -3.816000, learning rate is 0.000404
Net2: layer deconv1:max response is , min response is .
max gradient is 7.612915, min gradient is -8.000000, learning rate is 0.000202
max inferred z is 3.91, min inferred z is -3.95, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 98: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.585673, min gradient is -8.000000, learning rate is 0.000272
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.663219, learning rate is 0.000272
Net1: layer conv1:max response is , min response is .
max gradient is 7.514881, min gradient is -8.000000, learning rate is 0.000272
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.442285, learning rate is 0.000404
Net2: layer deconv3:max response is 46.682392, min response is -38.912670.
max gradient is 6.901603, min gradient is -8.000001, learning rate is 0.000202
Net2: layer bn50:max response is 26.603558, min response is -4.186933.
max gradient is 5.491445, min gradient is -8.000000, learning rate is 0.000404
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.912951, learning rate is 0.000202
Net2: layer bn49:max response is 12.302477, min response is -2.811020.
max gradient is 3.819442, min gradient is -8.000000, learning rate is 0.000404
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.162613, learning rate is 0.000202
max inferred z is 3.78, min inferred z is -4.01, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
training: epoch 98: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.689727, min gradient is -8.000000, learning rate is 0.000272
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.282260, learning rate is 0.000272
Net1: layer conv1:max response is , min response is .
max gradient is 7.394821, min gradient is -8.000000, learning rate is 0.000272
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.646441, learning rate is 0.000404
Net2: layer deconv3:max response is 37.774143, min response is -34.486996.
max gradient is 4.610368, min gradient is -8.000000, learning rate is 0.000202
Net2: layer bn50:max response is 24.019899, min response is -3.738338.
max gradient is 7.712029, min gradient is -8.000000, learning rate is 0.000404
Net2: layer deconv2:max response is , min response is .
max gradient is 5.833259, min gradient is -8.000000, learning rate is 0.000202
Net2: layer bn49:max response is 10.748965, min response is -2.603697.
max gradient is 8.000000, min gradient is -4.773317, learning rate is 0.000404
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.478035, learning rate is 0.000202
max inferred z is 3.67, min inferred z is -3.98, and std is 1.00
 4.36 s (23.0 data/s) [100/100]
training: epoch 98: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.161999, min gradient is -8.000000, learning rate is 0.000272
Net1: layer conv2:max response is , min response is .
max gradient is 7.999999, min gradient is -5.275762, learning rate is 0.000272
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.650957, learning rate is 0.000272
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.881768, learning rate is 0.000404
Net2: layer deconv3:max response is 39.500946, min response is -38.588955.
max gradient is 8.000000, min gradient is -4.062038, learning rate is 0.000202
Net2: layer bn50:max response is 20.331121, min response is -4.671565.
max gradient is 8.000000, min gradient is -6.407138, learning rate is 0.000404
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.300075, learning rate is 0.000202
Net2: layer bn49:max response is 12.058522, min response is -2.458764.
max gradient is 6.075063, min gradient is -8.000000, learning rate is 0.000404
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.214950, learning rate is 0.000202
max inferred z is 3.70, min inferred z is -3.72, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 98: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.477299, min gradient is -8.000000, learning rate is 0.000272
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.814528, learning rate is 0.000272
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.150662, learning rate is 0.000272
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.095012, learning rate is 0.000404
Net2: layer deconv3:max response is 44.393326, min response is -40.327625.
max gradient is 5.992161, min gradient is -8.000000, learning rate is 0.000202
Net2: layer bn50:max response is 23.028379, min response is -4.015523.
max gradient is 8.000000, min gradient is -6.043203, learning rate is 0.000404
Net2: layer deconv2:max response is , min response is .
max gradient is 4.014317, min gradient is -8.000000, learning rate is 0.000202
Net2: layer bn49:max response is 12.180551, min response is -2.540033.
max gradient is 8.000000, min gradient is -6.539262, learning rate is 0.000404
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.496952, learning rate is 0.000202
max inferred z is 3.81, min inferred z is -4.69, and std is 1.00
 4.44 s (22.5 data/s) [100/100]
training: epoch 98: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.671819, learning rate is 0.000272
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.922329, learning rate is 0.000272
Net1: layer conv1:max response is , min response is .
max gradient is 5.484857, min gradient is -8.000000, learning rate is 0.000272
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.649946, learning rate is 0.000404
Net2: layer deconv3:max response is 45.390095, min response is -39.015907.
max gradient is 8.000000, min gradient is -6.261901, learning rate is 0.000202
Net2: layer bn50:max response is 24.338888, min response is -4.414917.
max gradient is 5.677512, min gradient is -8.000000, learning rate is 0.000404
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.346171, learning rate is 0.000202
Net2: layer bn49:max response is 13.211983, min response is -2.492026.
max gradient is 6.522926, min gradient is -8.000000, learning rate is 0.000404
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.574903, learning rate is 0.000202
max inferred z is 3.99, min inferred z is -4.42, and std is 1.00
 4.36 s (23.0 data/s) [100/100]
training: epoch 98: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.440424, min gradient is -8.000000, learning rate is 0.000272
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.666116, learning rate is 0.000272
Net1: layer conv1:max response is , min response is .
max gradient is 5.234169, min gradient is -8.000000, learning rate is 0.000272
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.002992, learning rate is 0.000404
Net2: layer deconv3:max response is 45.277149, min response is -41.155724.
max gradient is 5.542864, min gradient is -8.000000, learning rate is 0.000202
Net2: layer bn50:max response is 26.608820, min response is -4.426072.
max gradient is 7.891562, min gradient is -8.000000, learning rate is 0.000404
Net2: layer deconv2:max response is , min response is .
max gradient is 6.212111, min gradient is -8.000000, learning rate is 0.000202
Net2: layer bn49:max response is 12.437793, min response is -2.392525.
max gradient is 6.442493, min gradient is -8.000000, learning rate is 0.000404
Net2: layer deconv1:max response is , min response is .
max gradient is 7.796502, min gradient is -8.000000, learning rate is 0.000202
max inferred z is 4.05, min inferred z is -4.02, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
training: epoch 98: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.518160, min gradient is -8.000000, learning rate is 0.000272
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.575166, learning rate is 0.000272
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.555048, learning rate is 0.000272
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.209155, learning rate is 0.000404
Net2: layer deconv3:max response is 36.789337, min response is -34.661720.
max gradient is 8.000000, min gradient is -6.395443, learning rate is 0.000202
Net2: layer bn50:max response is 22.987453, min response is -4.165951.
max gradient is 8.000000, min gradient is -7.174738, learning rate is 0.000404
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.175822, learning rate is 0.000202
Net2: layer bn49:max response is 11.563362, min response is -2.362229.
max gradient is 6.956371, min gradient is -8.000000, learning rate is 0.000404
Net2: layer deconv1:max response is , min response is .
max gradient is 6.159693, min gradient is -8.000000, learning rate is 0.000202
max inferred z is 3.86, min inferred z is -3.72, and std is 1.00
 4.32 s (23.2 data/s) [100/100]
Loss: 1.2277
Iteration 99 / 200
training: epoch 99: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.281812, min gradient is -8.000000, learning rate is 0.000226
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.829823, learning rate is 0.000226
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.032333, learning rate is 0.000226
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.155142, learning rate is 0.000402
Net2: layer deconv3:max response is 40.695419, min response is -36.361153.
max gradient is 4.589027, min gradient is -8.000000, learning rate is 0.000201
Net2: layer bn50:max response is 19.577799, min response is -3.760351.
max gradient is 7.069787, min gradient is -8.000000, learning rate is 0.000402
Net2: layer deconv2:max response is , min response is .
max gradient is 5.158607, min gradient is -8.000000, learning rate is 0.000201
Net2: layer bn49:max response is 10.671464, min response is -2.120568.
max gradient is 8.000000, min gradient is -6.551768, learning rate is 0.000402
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.099261, learning rate is 0.000201
max inferred z is 3.71, min inferred z is -3.56, and std is 1.00
 4.36 s (23.0 data/s) [100/100]
training: epoch 99: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.981867, min gradient is -8.000000, learning rate is 0.000226
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.655640, learning rate is 0.000226
Net1: layer conv1:max response is , min response is .
max gradient is 5.272183, min gradient is -8.000000, learning rate is 0.000226
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.823921, learning rate is 0.000402
Net2: layer deconv3:max response is 38.136677, min response is -35.600716.
max gradient is 8.000000, min gradient is -5.980254, learning rate is 0.000201
Net2: layer bn50:max response is 24.202436, min response is -4.898864.
max gradient is 6.211786, min gradient is -8.000000, learning rate is 0.000402
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.225656, learning rate is 0.000201
Net2: layer bn49:max response is 11.525339, min response is -2.395095.
max gradient is 7.136277, min gradient is -8.000000, learning rate is 0.000402
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.552611, learning rate is 0.000201
max inferred z is 3.50, min inferred z is -4.08, and std is 1.00
 4.18 s (23.9 data/s) [100/100]
training: epoch 99: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.551118, min gradient is -8.000000, learning rate is 0.000226
Net1: layer conv2:max response is , min response is .
max gradient is 6.561215, min gradient is -8.000000, learning rate is 0.000226
Net1: layer conv1:max response is , min response is .
max gradient is 5.360207, min gradient is -8.000000, learning rate is 0.000226
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000001, min gradient is 7.170936, learning rate is 0.000402
Net2: layer deconv3:max response is 46.734200, min response is -43.026703.
max gradient is 6.105050, min gradient is -8.000000, learning rate is 0.000201
Net2: layer bn50:max response is 22.395855, min response is -5.034836.
max gradient is 8.000000, min gradient is -5.906207, learning rate is 0.000402
Net2: layer deconv2:max response is , min response is .
max gradient is 6.784212, min gradient is -8.000000, learning rate is 0.000201
Net2: layer bn49:max response is 11.320861, min response is -2.445131.
max gradient is 8.000001, min gradient is -7.450164, learning rate is 0.000402
Net2: layer deconv1:max response is , min response is .
max gradient is 6.052464, min gradient is -8.000000, learning rate is 0.000201
max inferred z is 3.87, min inferred z is -4.25, and std is 1.00
 4.30 s (23.3 data/s) [100/100]
training: epoch 99: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.603897, min gradient is -8.000000, learning rate is 0.000226
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.239823, learning rate is 0.000226
Net1: layer conv1:max response is , min response is .
max gradient is 7.588224, min gradient is -8.000000, learning rate is 0.000226
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 7.985842, min gradient is 3.404861, learning rate is 0.000402
Net2: layer deconv3:max response is 36.373287, min response is -34.969452.
max gradient is 8.000000, min gradient is -6.054417, learning rate is 0.000201
Net2: layer bn50:max response is 19.491388, min response is -4.620196.
max gradient is 7.763415, min gradient is -8.000000, learning rate is 0.000402
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.481531, learning rate is 0.000201
Net2: layer bn49:max response is 10.394458, min response is -2.381874.
max gradient is 5.925813, min gradient is -8.000000, learning rate is 0.000402
Net2: layer deconv1:max response is , min response is .
max gradient is 5.119248, min gradient is -8.000000, learning rate is 0.000201
max inferred z is 3.61, min inferred z is -3.73, and std is 1.00
 4.23 s (23.7 data/s) [100/100]
training: epoch 99: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.461303, min gradient is -8.000000, learning rate is 0.000226
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.669713, learning rate is 0.000226
Net1: layer conv1:max response is , min response is .
max gradient is 7.577063, min gradient is -8.000000, learning rate is 0.000226
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.256109, learning rate is 0.000402
Net2: layer deconv3:max response is 39.124176, min response is -36.136204.
max gradient is 5.590888, min gradient is -8.000000, learning rate is 0.000201
Net2: layer bn50:max response is 20.780134, min response is -4.382640.
max gradient is 6.798236, min gradient is -8.000000, learning rate is 0.000402
Net2: layer deconv2:max response is , min response is .
max gradient is 5.694275, min gradient is -8.000000, learning rate is 0.000201
Net2: layer bn49:max response is 10.599602, min response is -2.253826.
max gradient is 8.000000, min gradient is -6.316290, learning rate is 0.000402
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.831280, learning rate is 0.000201
max inferred z is 4.13, min inferred z is -4.05, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 99: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.145561, min gradient is -8.000000, learning rate is 0.000226
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.386918, learning rate is 0.000226
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.082549, learning rate is 0.000226
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.687348, learning rate is 0.000402
Net2: layer deconv3:max response is 41.125561, min response is -39.530499.
max gradient is 8.000000, min gradient is -5.017389, learning rate is 0.000201
Net2: layer bn50:max response is 20.981112, min response is -4.364871.
max gradient is 8.000000, min gradient is -6.642967, learning rate is 0.000402
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.429393, learning rate is 0.000201
Net2: layer bn49:max response is 12.089151, min response is -2.557513.
max gradient is 7.266829, min gradient is -8.000000, learning rate is 0.000402
Net2: layer deconv1:max response is , min response is .
max gradient is 5.186961, min gradient is -8.000000, learning rate is 0.000201
max inferred z is 4.01, min inferred z is -4.05, and std is 1.00
 4.26 s (23.4 data/s) [100/100]
training: epoch 99: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.263195, min gradient is -8.000000, learning rate is 0.000226
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.213205, learning rate is 0.000226
Net1: layer conv1:max response is , min response is .
max gradient is 6.238188, min gradient is -8.000000, learning rate is 0.000226
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.372084, learning rate is 0.000402
Net2: layer deconv3:max response is 44.347244, min response is -37.713554.
max gradient is 5.115716, min gradient is -8.000000, learning rate is 0.000201
Net2: layer bn50:max response is 22.991787, min response is -4.509908.
max gradient is 7.740949, min gradient is -8.000000, learning rate is 0.000402
Net2: layer deconv2:max response is , min response is .
max gradient is 5.238202, min gradient is -8.000000, learning rate is 0.000201
Net2: layer bn49:max response is 12.882906, min response is -2.185449.
max gradient is 7.728998, min gradient is -8.000000, learning rate is 0.000402
Net2: layer deconv1:max response is , min response is .
max gradient is 6.661170, min gradient is -8.000000, learning rate is 0.000201
max inferred z is 4.21, min inferred z is -3.70, and std is 1.00
 4.28 s (23.4 data/s) [100/100]
training: epoch 99: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.203852, learning rate is 0.000226
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.246725, learning rate is 0.000226
Net1: layer conv1:max response is , min response is .
max gradient is 5.625221, min gradient is -8.000000, learning rate is 0.000226
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.026120, learning rate is 0.000402
Net2: layer deconv3:max response is 38.842403, min response is -37.287834.
max gradient is 8.000000, min gradient is -7.191193, learning rate is 0.000201
Net2: layer bn50:max response is 22.639309, min response is -4.909706.
max gradient is 7.241696, min gradient is -8.000000, learning rate is 0.000402
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.465922, learning rate is 0.000201
Net2: layer bn49:max response is 11.645266, min response is -2.544999.
max gradient is 6.863651, min gradient is -8.000000, learning rate is 0.000402
Net2: layer deconv1:max response is , min response is .
max gradient is 7.012503, min gradient is -8.000000, learning rate is 0.000201
max inferred z is 4.14, min inferred z is -4.01, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
training: epoch 99: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.193679, min gradient is -8.000000, learning rate is 0.000226
Net1: layer conv2:max response is , min response is .
max gradient is 7.545163, min gradient is -8.000000, learning rate is 0.000226
Net1: layer conv1:max response is , min response is .
max gradient is 6.480682, min gradient is -8.000001, learning rate is 0.000226
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.264396, learning rate is 0.000402
Net2: layer deconv3:max response is 41.904636, min response is -35.055008.
max gradient is 6.458949, min gradient is -8.000000, learning rate is 0.000201
Net2: layer bn50:max response is 20.235470, min response is -3.625236.
max gradient is 8.000000, min gradient is -6.103691, learning rate is 0.000402
Net2: layer deconv2:max response is , min response is .
max gradient is 7.067440, min gradient is -8.000000, learning rate is 0.000201
Net2: layer bn49:max response is 10.911568, min response is -2.149913.
max gradient is 8.000000, min gradient is -7.289163, learning rate is 0.000402
Net2: layer deconv1:max response is , min response is .
max gradient is 7.920650, min gradient is -8.000000, learning rate is 0.000201
max inferred z is 4.29, min inferred z is -4.32, and std is 1.00
 4.47 s (22.4 data/s) [100/100]
training: epoch 99: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.983063, min gradient is -8.000000, learning rate is 0.000226
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.406356, learning rate is 0.000226
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.715548, learning rate is 0.000226
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.207504, learning rate is 0.000402
Net2: layer deconv3:max response is 42.279350, min response is -40.284657.
max gradient is 8.000000, min gradient is -6.437876, learning rate is 0.000201
Net2: layer bn50:max response is 20.769848, min response is -5.407688.
max gradient is 6.922979, min gradient is -8.000000, learning rate is 0.000402
Net2: layer deconv2:max response is , min response is .
max gradient is 7.899607, min gradient is -8.000000, learning rate is 0.000201
Net2: layer bn49:max response is 14.529124, min response is -2.461324.
max gradient is 4.967309, min gradient is -8.000000, learning rate is 0.000402
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.574148, learning rate is 0.000201
max inferred z is 3.80, min inferred z is -3.75, and std is 1.00
 4.36 s (23.0 data/s) [100/100]
Loss: 1.214
Iteration 100 / 200
training: epoch 100: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.890097, min gradient is -8.000000, learning rate is 0.000226
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.256700, learning rate is 0.000226
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.218274, learning rate is 0.000226
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.857368, learning rate is 0.000400
Net2: layer deconv3:max response is 44.004219, min response is -40.881561.
max gradient is 6.117629, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.194475, min response is -5.053678.
max gradient is 7.481629, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.458618, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 13.245783, min response is -2.710290.
max gradient is 8.000000, min gradient is -6.198306, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.186758, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.17, min inferred z is -3.85, and std is 1.01
 4.27 s (23.4 data/s) [100/100]
training: epoch 100: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.170646, min gradient is -8.000000, learning rate is 0.000226
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.657101, learning rate is 0.000226
Net1: layer conv1:max response is , min response is .
max gradient is 5.142174, min gradient is -8.000000, learning rate is 0.000226
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.242690, learning rate is 0.000400
Net2: layer deconv3:max response is 56.589504, min response is -56.448151.
max gradient is 8.000000, min gradient is -6.606151, learning rate is 0.000200
Net2: layer bn50:max response is 28.558031, min response is -5.531361.
max gradient is 6.029385, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.145061, learning rate is 0.000200
Net2: layer bn49:max response is 14.094382, min response is -2.862050.
max gradient is 3.324513, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.946836, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.26, min inferred z is -4.01, and std is 1.01
 4.18 s (23.9 data/s) [100/100]
training: epoch 100: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.340407, min gradient is -8.000000, learning rate is 0.000226
Net1: layer conv2:max response is , min response is .
max gradient is 7.040009, min gradient is -8.000000, learning rate is 0.000226
Net1: layer conv1:max response is , min response is .
max gradient is 5.388789, min gradient is -8.000000, learning rate is 0.000226
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.343945, learning rate is 0.000400
Net2: layer deconv3:max response is 45.804665, min response is -45.436630.
max gradient is 6.668717, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 24.288673, min response is -5.648493.
max gradient is 8.000000, min gradient is -5.391895, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.043172, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 10.854110, min response is -2.788303.
max gradient is 8.000000, min gradient is -5.763840, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.641774, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.33, min inferred z is -3.75, and std is 1.01
 4.25 s (23.5 data/s) [100/100]
training: epoch 100: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.404126, min gradient is -8.000000, learning rate is 0.000226
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.572000, learning rate is 0.000226
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.013048, learning rate is 0.000226
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.502462, learning rate is 0.000400
Net2: layer deconv3:max response is 45.711681, min response is -43.936096.
max gradient is 8.000000, min gradient is -6.705585, learning rate is 0.000200
Net2: layer bn50:max response is 23.018610, min response is -4.845611.
max gradient is 5.382514, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.808512, learning rate is 0.000200
Net2: layer bn49:max response is 11.943791, min response is -2.860793.
max gradient is 3.601122, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.718531, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.90, min inferred z is -4.06, and std is 1.01
 4.31 s (23.2 data/s) [100/100]
training: epoch 100: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.942155, learning rate is 0.000226
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.451540, learning rate is 0.000226
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.373798, learning rate is 0.000226
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.593352, learning rate is 0.000400
Net2: layer deconv3:max response is 35.855087, min response is -34.664295.
max gradient is 6.422045, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.017141, min response is -3.676132.
max gradient is 8.000000, min gradient is -6.524171, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.881660, learning rate is 0.000200
Net2: layer bn49:max response is 9.643458, min response is -2.293458.
max gradient is 8.000000, min gradient is -4.463929, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.362615, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.07, min inferred z is -4.25, and std is 1.01
 4.18 s (23.9 data/s) [100/100]
training: epoch 100: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.529907, min gradient is -8.000000, learning rate is 0.000226
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.376058, learning rate is 0.000226
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.520289, learning rate is 0.000226
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 7.803071, min gradient is 5.196226, learning rate is 0.000400
Net2: layer deconv3:max response is 46.546673, min response is -45.927868.
max gradient is 8.000000, min gradient is -7.238222, learning rate is 0.000200
Net2: layer bn50:max response is 23.498493, min response is -5.324535.
max gradient is 5.886245, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.311877, learning rate is 0.000200
Net2: layer bn49:max response is 13.015738, min response is -2.484181.
max gradient is 2.732311, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.173318, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.59, min inferred z is -4.19, and std is 1.01
 4.30 s (23.3 data/s) [100/100]
training: epoch 100: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.011052, min gradient is -8.000000, learning rate is 0.000226
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.913421, learning rate is 0.000226
Net1: layer conv1:max response is , min response is .
max gradient is 7.716305, min gradient is -8.000000, learning rate is 0.000226
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.323327, learning rate is 0.000400
Net2: layer deconv3:max response is 49.066463, min response is -46.792061.
max gradient is 6.005478, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.342022, min response is -4.867579.
max gradient is 8.000000, min gradient is -6.932342, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.515285, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 11.370116, min response is -2.598368.
max gradient is 8.000001, min gradient is -6.069400, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.815006, learning rate is 0.000200
max inferred z is 3.85, min inferred z is -4.06, and std is 1.01
 4.38 s (22.8 data/s) [100/100]
training: epoch 100: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -6.803432, learning rate is 0.000226
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.800165, learning rate is 0.000226
Net1: layer conv1:max response is , min response is .
max gradient is 4.815423, min gradient is -8.000000, learning rate is 0.000226
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.215224, learning rate is 0.000400
Net2: layer deconv3:max response is 37.954720, min response is -37.372307.
max gradient is 8.000000, min gradient is -5.903769, learning rate is 0.000200
Net2: layer bn50:max response is 18.623631, min response is -4.210658.
max gradient is 8.000000, min gradient is -7.804972, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.209154, learning rate is 0.000200
Net2: layer bn49:max response is 10.215120, min response is -2.358547.
max gradient is 7.520452, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.288566, learning rate is 0.000200
max inferred z is 4.24, min inferred z is -3.60, and std is 1.01
 4.40 s (22.7 data/s) [100/100]
training: epoch 100: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.759814, min gradient is -8.000000, learning rate is 0.000226
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.421527, learning rate is 0.000226
Net1: layer conv1:max response is , min response is .
max gradient is 4.423584, min gradient is -8.000000, learning rate is 0.000226
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.983195, learning rate is 0.000400
Net2: layer deconv3:max response is 43.404739, min response is -41.799858.
max gradient is 4.927799, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.180826, min response is -5.061035.
max gradient is 6.816683, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.913953, learning rate is 0.000200
Net2: layer bn49:max response is 13.159408, min response is -3.227098.
max gradient is 8.000000, min gradient is -7.880778, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.393808, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.07, min inferred z is -4.84, and std is 1.01
 4.29 s (23.3 data/s) [100/100]
training: epoch 100: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.280213, min gradient is -8.000000, learning rate is 0.000226
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.359282, learning rate is 0.000226
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.175485, learning rate is 0.000226
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.090930, learning rate is 0.000400
Net2: layer deconv3:max response is 37.990879, min response is -38.984791.
max gradient is 8.000000, min gradient is -3.680140, learning rate is 0.000200
Net2: layer bn50:max response is 18.786188, min response is -4.045635.
max gradient is 8.000000, min gradient is -6.188144, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.916751, learning rate is 0.000200
Net2: layer bn49:max response is 11.558208, min response is -2.410624.
max gradient is 7.668212, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.852381, learning rate is 0.000200
max inferred z is 3.98, min inferred z is -3.81, and std is 1.01
 4.27 s (23.4 data/s) [100/100]
Loss: 1.2108
Iteration 101 / 200
training: epoch 101: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.244353, min gradient is -8.000000, learning rate is 0.000187
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.187945, learning rate is 0.000187
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.507936, learning rate is 0.000187
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.602323, learning rate is 0.000400
Net2: layer deconv3:max response is 49.986099, min response is -47.153755.
max gradient is 4.819062, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.589605, min response is -5.845193.
max gradient is 6.841678, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.978516, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 15.372468, min response is -2.787334.
max gradient is 8.000000, min gradient is -6.137850, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.440505, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.97, min inferred z is -3.99, and std is 1.00
 4.23 s (23.6 data/s) [100/100]
training: epoch 101: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.352899, min gradient is -8.000000, learning rate is 0.000187
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.000911, learning rate is 0.000187
Net1: layer conv1:max response is , min response is .
max gradient is 5.541806, min gradient is -8.000000, learning rate is 0.000187
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.782712, learning rate is 0.000400
Net2: layer deconv3:max response is 42.148411, min response is -41.167072.
max gradient is 8.000000, min gradient is -6.440064, learning rate is 0.000200
Net2: layer bn50:max response is 22.114321, min response is -4.038541.
max gradient is 7.485399, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.136669, learning rate is 0.000200
Net2: layer bn49:max response is 11.581979, min response is -2.260867.
max gradient is 8.000000, min gradient is -7.513955, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.269849, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.86, min inferred z is -3.54, and std is 1.00
 4.34 s (23.1 data/s) [100/100]
training: epoch 101: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.476509, min gradient is -8.000000, learning rate is 0.000187
Net1: layer conv2:max response is , min response is .
max gradient is 6.746728, min gradient is -8.000000, learning rate is 0.000187
Net1: layer conv1:max response is , min response is .
max gradient is 5.164667, min gradient is -8.000000, learning rate is 0.000187
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.683072, learning rate is 0.000400
Net2: layer deconv3:max response is 56.040871, min response is -52.378502.
max gradient is 6.294400, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 26.094454, min response is -5.303989.
max gradient is 8.000000, min gradient is -7.795289, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.683718, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 11.112144, min response is -2.413827.
max gradient is 8.000000, min gradient is -6.064146, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.288483, learning rate is 0.000200
max inferred z is 4.32, min inferred z is -4.20, and std is 1.00
 4.28 s (23.4 data/s) [100/100]
training: epoch 101: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.821887, min gradient is -8.000000, learning rate is 0.000187
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.256520, learning rate is 0.000187
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.191235, learning rate is 0.000187
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.224200, learning rate is 0.000400
Net2: layer deconv3:max response is 44.435875, min response is -42.885166.
max gradient is 8.000000, min gradient is -6.465198, learning rate is 0.000200
Net2: layer bn50:max response is 23.730856, min response is -4.694852.
max gradient is 6.235658, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.739377, learning rate is 0.000200
Net2: layer bn49:max response is 11.889865, min response is -2.368309.
max gradient is 4.368407, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.106913, learning rate is 0.000200
max inferred z is 3.97, min inferred z is -3.72, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
training: epoch 101: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.799246, learning rate is 0.000187
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.557647, learning rate is 0.000187
Net1: layer conv1:max response is , min response is .
max gradient is 7.323472, min gradient is -8.000000, learning rate is 0.000187
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.361178, learning rate is 0.000400
Net2: layer deconv3:max response is 37.601761, min response is -37.373009.
max gradient is 6.817120, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.878315, min response is -4.541939.
max gradient is 8.000000, min gradient is -5.388109, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.906074, min gradient is -8.000001, learning rate is 0.000200
Net2: layer bn49:max response is 10.124870, min response is -2.487432.
max gradient is 8.000000, min gradient is -5.199299, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.418112, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.18, min inferred z is -4.29, and std is 1.00
 4.44 s (22.5 data/s) [100/100]
training: epoch 101: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.408630, min gradient is -8.000000, learning rate is 0.000187
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.027257, learning rate is 0.000187
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.381328, learning rate is 0.000187
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000001, min gradient is 6.174837, learning rate is 0.000400
Net2: layer deconv3:max response is 46.299259, min response is -45.116352.
max gradient is 8.000000, min gradient is -6.383987, learning rate is 0.000200
Net2: layer bn50:max response is 22.762569, min response is -5.006087.
max gradient is 5.398267, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.669920, learning rate is 0.000200
Net2: layer bn49:max response is 11.630346, min response is -2.262143.
max gradient is 3.295119, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.107028, learning rate is 0.000200
max inferred z is 3.99, min inferred z is -4.09, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 101: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.156284, min gradient is -8.000000, learning rate is 0.000187
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.589240, learning rate is 0.000187
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.133283, learning rate is 0.000187
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.817230, learning rate is 0.000400
Net2: layer deconv3:max response is 53.193935, min response is -52.049652.
max gradient is 8.000000, min gradient is -7.728484, learning rate is 0.000200
Net2: layer bn50:max response is 25.108503, min response is -5.269481.
max gradient is 8.000000, min gradient is -4.755862, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.554701, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 12.308543, min response is -2.500497.
max gradient is 8.000000, min gradient is -3.022051, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.231867, learning rate is 0.000200
max inferred z is 4.28, min inferred z is -4.64, and std is 1.00
 4.19 s (23.8 data/s) [100/100]
training: epoch 101: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.263052, learning rate is 0.000187
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.335071, learning rate is 0.000187
Net1: layer conv1:max response is , min response is .
max gradient is 5.297549, min gradient is -8.000000, learning rate is 0.000187
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.107137, learning rate is 0.000400
Net2: layer deconv3:max response is 44.151188, min response is -43.212025.
max gradient is 7.169405, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.597599, min response is -4.918734.
max gradient is 5.146079, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.832366, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 11.115358, min response is -2.286779.
max gradient is 2.752447, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.728424, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.08, min inferred z is -4.01, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 101: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.552152, min gradient is -8.000000, learning rate is 0.000187
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.370496, learning rate is 0.000187
Net1: layer conv1:max response is , min response is .
max gradient is 4.808760, min gradient is -8.000000, learning rate is 0.000187
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.516096, learning rate is 0.000400
Net2: layer deconv3:max response is 44.536942, min response is -45.213001.
max gradient is 8.000000, min gradient is -7.327940, learning rate is 0.000200
Net2: layer bn50:max response is 24.935387, min response is -4.827568.
max gradient is 8.000000, min gradient is -4.987498, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.418558, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 12.368047, min response is -2.581288.
max gradient is 8.000000, min gradient is -3.177792, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.918888, learning rate is 0.000200
max inferred z is 4.21, min inferred z is -4.03, and std is 1.00
 4.36 s (23.0 data/s) [100/100]
training: epoch 101: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.455026, min gradient is -8.000000, learning rate is 0.000187
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.051795, learning rate is 0.000187
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.660933, learning rate is 0.000187
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.923341, learning rate is 0.000400
Net2: layer deconv3:max response is 44.602409, min response is -41.200264.
max gradient is 6.934887, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.896111, min response is -4.992712.
max gradient is 3.990488, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.816501, learning rate is 0.000200
Net2: layer bn49:max response is 12.686538, min response is -2.879972.
max gradient is 3.772101, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.342511, learning rate is 0.000200
max inferred z is 4.39, min inferred z is -3.94, and std is 1.00
 4.23 s (23.6 data/s) [100/100]
Loss: 1.1553
Iteration 102 / 200
training: epoch 102: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.021212, min gradient is -8.000000, learning rate is 0.000187
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.026291, learning rate is 0.000187
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.764669, learning rate is 0.000187
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.469529, learning rate is 0.000400
Net2: layer deconv3:max response is 60.683235, min response is -59.309422.
max gradient is 8.000000, min gradient is -5.824255, learning rate is 0.000200
Net2: layer bn50:max response is 28.808485, min response is -5.909369.
max gradient is 8.000000, min gradient is -7.852709, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.151973, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 12.587420, min response is -2.808276.
max gradient is 8.000000, min gradient is -6.320310, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.033443, learning rate is 0.000200
max inferred z is 3.88, min inferred z is -4.12, and std is 1.00
 4.12 s (24.3 data/s) [100/100]
training: epoch 102: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.193212, min gradient is -8.000000, learning rate is 0.000187
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.776089, learning rate is 0.000187
Net1: layer conv1:max response is , min response is .
max gradient is 4.890204, min gradient is -8.000000, learning rate is 0.000187
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.408919, learning rate is 0.000400
Net2: layer deconv3:max response is 46.279972, min response is -46.354591.
max gradient is 4.822409, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 28.336672, min response is -4.314226.
max gradient is 8.000000, min gradient is -7.062104, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.869644, learning rate is 0.000200
Net2: layer bn49:max response is 15.304762, min response is -3.433173.
max gradient is 8.000001, min gradient is -7.108195, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.996801, learning rate is 0.000200
max inferred z is 3.65, min inferred z is -4.30, and std is 1.00
 4.14 s (24.2 data/s) [100/100]
training: epoch 102: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.840098, learning rate is 0.000187
Net1: layer conv2:max response is , min response is .
max gradient is 7.142102, min gradient is -8.000000, learning rate is 0.000187
Net1: layer conv1:max response is , min response is .
max gradient is 4.910115, min gradient is -8.000000, learning rate is 0.000187
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.845233, learning rate is 0.000400
Net2: layer deconv3:max response is 44.925510, min response is -47.107658.
max gradient is 8.000000, min gradient is -2.806022, learning rate is 0.000200
Net2: layer bn50:max response is 21.426577, min response is -4.365361.
max gradient is 8.000000, min gradient is -6.343148, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.714622, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 11.736183, min response is -2.256658.
max gradient is 6.623149, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.797720, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.01, min inferred z is -3.86, and std is 1.00
 4.15 s (24.1 data/s) [100/100]
training: epoch 102: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.624074, min gradient is -8.000000, learning rate is 0.000187
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.356357, learning rate is 0.000187
Net1: layer conv1:max response is , min response is .
max gradient is 6.399764, min gradient is -8.000000, learning rate is 0.000187
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.252195, learning rate is 0.000400
Net2: layer deconv3:max response is 54.792316, min response is -52.467072.
max gradient is 4.132001, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 25.157518, min response is -5.028167.
max gradient is 8.000000, min gradient is -7.616534, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.589042, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 11.654730, min response is -2.430973.
max gradient is 8.000000, min gradient is -6.443522, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.239981, learning rate is 0.000200
max inferred z is 4.76, min inferred z is -3.89, and std is 1.00
 4.17 s (24.0 data/s) [100/100]
training: epoch 102: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.692430, learning rate is 0.000187
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.659362, learning rate is 0.000187
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.674527, learning rate is 0.000187
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.313690, learning rate is 0.000400
Net2: layer deconv3:max response is 46.976444, min response is -46.362354.
max gradient is 8.000000, min gradient is -4.269808, learning rate is 0.000200
Net2: layer bn50:max response is 22.471546, min response is -5.423934.
max gradient is 8.000001, min gradient is -7.120249, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.829309, learning rate is 0.000200
Net2: layer bn49:max response is 12.020361, min response is -2.555111.
max gradient is 8.000000, min gradient is -6.499522, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.658730, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.14, min inferred z is -3.76, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
training: epoch 102: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.953627, min gradient is -8.000000, learning rate is 0.000187
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.520978, learning rate is 0.000187
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.972927, learning rate is 0.000187
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.525831, learning rate is 0.000400
Net2: layer deconv3:max response is 44.919704, min response is -43.993958.
max gradient is 4.073496, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.207258, min response is -5.097442.
max gradient is 7.309815, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.470161, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 13.128602, min response is -2.328905.
max gradient is 8.000000, min gradient is -6.776406, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.874409, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.94, min inferred z is -3.87, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 102: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.980944, min gradient is -8.000000, learning rate is 0.000187
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.068656, learning rate is 0.000187
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.129674, learning rate is 0.000187
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 7.656693, min gradient is -2.048352, learning rate is 0.000400
Net2: layer deconv3:max response is 47.196934, min response is -47.986588.
max gradient is 8.000000, min gradient is -3.754140, learning rate is 0.000200
Net2: layer bn50:max response is 22.528622, min response is -4.611473.
max gradient is 8.000000, min gradient is -6.621500, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.373740, learning rate is 0.000200
Net2: layer bn49:max response is 11.405514, min response is -2.612508.
max gradient is 6.653864, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.708280, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.98, min inferred z is -4.02, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 102: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.459368, learning rate is 0.000187
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.519875, learning rate is 0.000187
Net1: layer conv1:max response is , min response is .
max gradient is 4.843619, min gradient is -8.000000, learning rate is 0.000187
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.518427, learning rate is 0.000400
Net2: layer deconv3:max response is 41.311089, min response is -39.912025.
max gradient is 5.374818, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.966328, min response is -4.185216.
max gradient is 8.000000, min gradient is -6.037752, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.349399, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 9.695899, min response is -2.414736.
max gradient is 6.763043, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.506279, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.86, min inferred z is -3.49, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 102: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.805075, min gradient is -8.000000, learning rate is 0.000187
Net1: layer conv2:max response is , min response is .
max gradient is 7.932199, min gradient is -8.000000, learning rate is 0.000187
Net1: layer conv1:max response is , min response is .
max gradient is 4.283464, min gradient is -8.000000, learning rate is 0.000187
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.455513, learning rate is 0.000400
Net2: layer deconv3:max response is 50.053745, min response is -50.995491.
max gradient is 8.000000, min gradient is -7.618826, learning rate is 0.000200
Net2: layer bn50:max response is 23.931683, min response is -4.998624.
max gradient is 5.072851, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.160741, learning rate is 0.000200
Net2: layer bn49:max response is 14.075496, min response is -2.456454.
max gradient is 7.439638, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.957234, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.41, min inferred z is -3.84, and std is 1.00
 4.21 s (23.7 data/s) [100/100]
training: epoch 102: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.160097, min gradient is -8.000000, learning rate is 0.000187
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.241005, learning rate is 0.000187
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.048937, learning rate is 0.000187
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000001, min gradient is 6.899253, learning rate is 0.000400
Net2: layer deconv3:max response is 53.834824, min response is -51.741627.
max gradient is 4.805452, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 24.888330, min response is -5.539741.
max gradient is 7.099159, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.641830, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 11.464956, min response is -2.485493.
max gradient is 8.000000, min gradient is -7.016148, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.827668, learning rate is 0.000200
max inferred z is 3.96, min inferred z is -3.75, and std is 1.00
 4.32 s (23.2 data/s) [100/100]
Loss: 1.1705
Iteration 103 / 200
training: epoch 103: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.528682, min gradient is -8.000000, learning rate is 0.000155
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.137700, learning rate is 0.000155
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.080062, learning rate is 0.000155
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.481450, learning rate is 0.000400
Net2: layer deconv3:max response is 48.610073, min response is -47.727234.
max gradient is 8.000000, min gradient is -5.716376, learning rate is 0.000200
Net2: layer bn50:max response is 22.761017, min response is -4.657234.
max gradient is 8.000000, min gradient is -6.112757, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.412611, learning rate is 0.000200
Net2: layer bn49:max response is 11.063091, min response is -2.435238.
max gradient is 5.378784, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.776576, learning rate is 0.000200
max inferred z is 4.47, min inferred z is -3.77, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
training: epoch 103: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.657044, min gradient is -8.000000, learning rate is 0.000155
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.447128, learning rate is 0.000155
Net1: layer conv1:max response is , min response is .
max gradient is 4.727414, min gradient is -8.000000, learning rate is 0.000155
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.451282, learning rate is 0.000400
Net2: layer deconv3:max response is 40.220924, min response is -39.332150.
max gradient is 5.603256, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.312359, min response is -4.489826.
max gradient is 6.724502, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.007959, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 10.430484, min response is -2.417099.
max gradient is 8.000000, min gradient is -6.263031, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.510321, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.34, min inferred z is -3.52, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 103: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.533790, min gradient is -8.000000, learning rate is 0.000155
Net1: layer conv2:max response is , min response is .
max gradient is 7.708056, min gradient is -8.000000, learning rate is 0.000155
Net1: layer conv1:max response is , min response is .
max gradient is 5.335773, min gradient is -8.000000, learning rate is 0.000155
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.089969, learning rate is 0.000400
Net2: layer deconv3:max response is 38.147884, min response is -37.828362.
max gradient is 8.000000, min gradient is -5.985566, learning rate is 0.000200
Net2: layer bn50:max response is 20.471727, min response is -3.723542.
max gradient is 8.000000, min gradient is -7.193076, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.891735, learning rate is 0.000200
Net2: layer bn49:max response is 11.200446, min response is -2.291545.
max gradient is 7.239315, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.118244, learning rate is 0.000200
max inferred z is 3.52, min inferred z is -3.84, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 103: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.631023, min gradient is -8.000000, learning rate is 0.000155
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.755442, learning rate is 0.000155
Net1: layer conv1:max response is , min response is .
max gradient is 6.779120, min gradient is -8.000000, learning rate is 0.000155
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.348158, learning rate is 0.000400
Net2: layer deconv3:max response is 48.404484, min response is -46.309772.
max gradient is 4.953067, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.472404, min response is -4.710550.
max gradient is 7.591216, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.129059, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 11.749893, min response is -2.160009.
max gradient is 8.000000, min gradient is -6.948703, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.540942, learning rate is 0.000200
max inferred z is 3.91, min inferred z is -3.79, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 103: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.964993, min gradient is -8.000000, learning rate is 0.000155
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.452730, learning rate is 0.000155
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.712460, learning rate is 0.000155
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.140681, learning rate is 0.000400
Net2: layer deconv3:max response is 47.371876, min response is -49.267578.
max gradient is 8.000000, min gradient is -7.284236, learning rate is 0.000200
Net2: layer bn50:max response is 22.181400, min response is -4.812429.
max gradient is 4.867481, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.793004, learning rate is 0.000200
Net2: layer bn49:max response is 11.133037, min response is -2.410787.
max gradient is 3.892143, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.855031, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.00, min inferred z is -4.33, and std is 1.00
 4.47 s (22.3 data/s) [100/100]
training: epoch 103: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.135683, min gradient is -8.000000, learning rate is 0.000155
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.802343, learning rate is 0.000155
Net1: layer conv1:max response is , min response is .
max gradient is 7.886113, min gradient is -8.000000, learning rate is 0.000155
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.151355, learning rate is 0.000400
Net2: layer deconv3:max response is 44.168171, min response is -45.658806.
max gradient is 8.000000, min gradient is -7.934868, learning rate is 0.000200
Net2: layer bn50:max response is 23.299238, min response is -4.335224.
max gradient is 8.000000, min gradient is -5.059053, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.949408, learning rate is 0.000200
Net2: layer bn49:max response is 11.285079, min response is -2.200790.
max gradient is 8.000000, min gradient is -4.069677, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.055691, learning rate is 0.000200
max inferred z is 4.61, min inferred z is -4.03, and std is 1.00
 4.32 s (23.2 data/s) [100/100]
training: epoch 103: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.680900, min gradient is -8.000000, learning rate is 0.000155
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.427858, learning rate is 0.000155
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.814281, learning rate is 0.000155
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.297824, learning rate is 0.000400
Net2: layer deconv3:max response is 51.782833, min response is -53.239925.
max gradient is 6.877931, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.912670, min response is -5.133297.
max gradient is 6.114445, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.643344, learning rate is 0.000200
Net2: layer bn49:max response is 12.193583, min response is -2.414636.
max gradient is 4.326786, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.609117, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.10, min inferred z is -4.01, and std is 1.00
 4.19 s (23.9 data/s) [100/100]
training: epoch 103: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.342859, learning rate is 0.000155
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.553900, learning rate is 0.000155
Net1: layer conv1:max response is , min response is .
max gradient is 5.755978, min gradient is -8.000000, learning rate is 0.000155
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.878390, learning rate is 0.000400
Net2: layer deconv3:max response is 42.314381, min response is -41.071766.
max gradient is 4.085362, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.678778, min response is -4.072186.
max gradient is 7.898793, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.167140, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 11.630118, min response is -2.570044.
max gradient is 7.763546, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.647909, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.84, min inferred z is -3.62, and std is 1.00
 4.28 s (23.4 data/s) [100/100]
training: epoch 103: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.565527, min gradient is -8.000000, learning rate is 0.000155
Net1: layer conv2:max response is , min response is .
max gradient is 7.335177, min gradient is -8.000000, learning rate is 0.000155
Net1: layer conv1:max response is , min response is .
max gradient is 5.521178, min gradient is -8.000000, learning rate is 0.000155
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.687765, learning rate is 0.000400
Net2: layer deconv3:max response is 46.439377, min response is -49.106724.
max gradient is 5.524998, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.439661, min response is -4.746923.
max gradient is 8.000000, min gradient is -4.489362, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.340127, learning rate is 0.000200
Net2: layer bn49:max response is 12.349379, min response is -2.218357.
max gradient is 8.000000, min gradient is -5.576706, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.174688, learning rate is 0.000200
max inferred z is 4.25, min inferred z is -4.03, and std is 1.00
 4.46 s (22.4 data/s) [100/100]
training: epoch 103: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.147541, min gradient is -8.000000, learning rate is 0.000155
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.011567, learning rate is 0.000155
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.567233, learning rate is 0.000155
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.273156, learning rate is 0.000400
Net2: layer deconv3:max response is 45.308815, min response is -45.092857.
max gradient is 8.000000, min gradient is -4.132508, learning rate is 0.000200
Net2: layer bn50:max response is 22.972919, min response is -4.880445.
max gradient is 5.908258, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.877471, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 12.953735, min response is -2.346730.
max gradient is 4.235415, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.170043, learning rate is 0.000200
max inferred z is 4.80, min inferred z is -4.05, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
Loss: 1.1898
Iteration 104 / 200
training: epoch 104: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.136095, min gradient is -8.000000, learning rate is 0.000155
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.987041, learning rate is 0.000155
Net1: layer conv1:max response is , min response is .
max gradient is 6.197823, min gradient is -8.000000, learning rate is 0.000155
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.707054, learning rate is 0.000400
Net2: layer deconv3:max response is 43.215820, min response is -43.229237.
max gradient is 5.544626, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.293203, min response is -4.744464.
max gradient is 8.000000, min gradient is -5.852914, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000001, min gradient is -6.108873, learning rate is 0.000200
Net2: layer bn49:max response is 13.579971, min response is -2.611193.
max gradient is 8.000000, min gradient is -6.357725, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.271664, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.15, min inferred z is -3.76, and std is 1.01
 4.31 s (23.2 data/s) [100/100]
training: epoch 104: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.481094, min gradient is -8.000000, learning rate is 0.000155
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.519187, learning rate is 0.000155
Net1: layer conv1:max response is , min response is .
max gradient is 5.060635, min gradient is -8.000000, learning rate is 0.000155
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.636575, learning rate is 0.000400
Net2: layer deconv3:max response is 39.982456, min response is -40.844948.
max gradient is 8.000000, min gradient is -6.806033, learning rate is 0.000200
Net2: layer bn50:max response is 20.665344, min response is -3.970528.
max gradient is 5.467382, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.293629, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 10.746026, min response is -2.405480.
max gradient is 4.108356, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.818829, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.90, min inferred z is -3.73, and std is 1.01
 4.33 s (23.1 data/s) [100/100]
training: epoch 104: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.410095, min gradient is -8.000000, learning rate is 0.000155
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.865468, learning rate is 0.000155
Net1: layer conv1:max response is , min response is .
max gradient is 5.794660, min gradient is -8.000000, learning rate is 0.000155
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.565386, learning rate is 0.000400
Net2: layer deconv3:max response is 51.660049, min response is -52.415939.
max gradient is 7.531199, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 24.044878, min response is -5.128580.
max gradient is 8.000000, min gradient is -5.955780, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.802117, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 12.707497, min response is -2.837334.
max gradient is 8.000000, min gradient is -3.602475, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.057390, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.82, min inferred z is -3.97, and std is 1.01
 4.34 s (23.1 data/s) [100/100]
training: epoch 104: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.428836, min gradient is -8.000000, learning rate is 0.000155
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.814949, learning rate is 0.000155
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.674116, learning rate is 0.000155
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.211719, learning rate is 0.000400
Net2: layer deconv3:max response is 43.284847, min response is -46.238697.
max gradient is 8.000000, min gradient is -5.402014, learning rate is 0.000200
Net2: layer bn50:max response is 20.674826, min response is -4.821674.
max gradient is 8.000000, min gradient is -5.365087, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.675226, learning rate is 0.000200
Net2: layer bn49:max response is 11.468565, min response is -2.448264.
max gradient is 3.978906, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.874714, learning rate is 0.000200
max inferred z is 3.79, min inferred z is -4.09, and std is 1.01
 4.24 s (23.6 data/s) [100/100]
training: epoch 104: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.620987, min gradient is -8.000000, learning rate is 0.000155
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.646038, learning rate is 0.000155
Net1: layer conv1:max response is , min response is .
max gradient is 7.471409, min gradient is -8.000000, learning rate is 0.000155
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.672276, learning rate is 0.000400
Net2: layer deconv3:max response is 51.772568, min response is -44.887306.
max gradient is 8.000000, min gradient is -5.764289, learning rate is 0.000200
Net2: layer bn50:max response is 28.348846, min response is -4.761662.
max gradient is 4.215482, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.589712, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 14.122816, min response is -2.432168.
max gradient is 8.000000, min gradient is -7.920588, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.212692, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.85, min inferred z is -3.89, and std is 1.01
 4.32 s (23.1 data/s) [100/100]
training: epoch 104: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.915760, min gradient is -8.000000, learning rate is 0.000155
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.712784, learning rate is 0.000155
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.003835, learning rate is 0.000155
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.965480, learning rate is 0.000400
Net2: layer deconv3:max response is 43.516953, min response is -44.836258.
max gradient is 4.435395, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.916180, min response is -4.262595.
max gradient is 6.937570, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.543410, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 10.604887, min response is -2.117063.
max gradient is 8.000000, min gradient is -5.184193, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 4.708898, min gradient is -8.000001, learning rate is 0.000200
max inferred z is 4.81, min inferred z is -4.21, and std is 1.01
 4.38 s (22.8 data/s) [100/100]
training: epoch 104: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.581739, min gradient is -8.000000, learning rate is 0.000155
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.020168, learning rate is 0.000155
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.724500, learning rate is 0.000155
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.101326, learning rate is 0.000400
Net2: layer deconv3:max response is 43.019501, min response is -46.349632.
max gradient is 8.000000, min gradient is -3.098884, learning rate is 0.000200
Net2: layer bn50:max response is 19.387156, min response is -5.134831.
max gradient is 8.000000, min gradient is -7.117535, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.361823, learning rate is 0.000200
Net2: layer bn49:max response is 11.370849, min response is -2.466989.
max gradient is 6.900430, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.925399, learning rate is 0.000200
max inferred z is 4.03, min inferred z is -3.85, and std is 1.01
 4.24 s (23.6 data/s) [100/100]
training: epoch 104: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.985442, learning rate is 0.000155
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.452850, learning rate is 0.000155
Net1: layer conv1:max response is , min response is .
max gradient is 5.349063, min gradient is -8.000000, learning rate is 0.000155
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.571602, learning rate is 0.000400
Net2: layer deconv3:max response is 62.783512, min response is -62.186371.
max gradient is 4.548021, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 27.164742, min response is -5.951301.
max gradient is 7.873593, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.689850, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 13.933557, min response is -2.754189.
max gradient is 8.000000, min gradient is -6.410807, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.994347, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.97, min inferred z is -4.03, and std is 1.01
 4.36 s (22.9 data/s) [100/100]
training: epoch 104: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.452620, min gradient is -8.000000, learning rate is 0.000155
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.641542, learning rate is 0.000155
Net1: layer conv1:max response is , min response is .
max gradient is 6.703644, min gradient is -8.000000, learning rate is 0.000155
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -4.276834, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 37.661545, min response is -41.703857.
max gradient is 8.000000, min gradient is -3.740853, learning rate is 0.000200
Net2: layer bn50:max response is 19.507145, min response is -4.047395.
max gradient is 8.000000, min gradient is -7.475436, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.237996, learning rate is 0.000200
Net2: layer bn49:max response is 10.968942, min response is -2.481740.
max gradient is 7.272202, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.820946, learning rate is 0.000200
max inferred z is 3.70, min inferred z is -3.97, and std is 1.01
 4.28 s (23.4 data/s) [100/100]
training: epoch 104: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.413119, min gradient is -8.000000, learning rate is 0.000155
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.047321, learning rate is 0.000155
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.219295, learning rate is 0.000155
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.626886, learning rate is 0.000400
Net2: layer deconv3:max response is 47.101357, min response is -46.968578.
max gradient is 7.068676, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.406860, min response is -4.628949.
max gradient is 8.000000, min gradient is -6.233987, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.632451, learning rate is 0.000200
Net2: layer bn49:max response is 12.069899, min response is -2.380770.
max gradient is 8.000000, min gradient is -7.953455, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.870066, learning rate is 0.000200
max inferred z is 4.01, min inferred z is -4.70, and std is 1.01
 4.32 s (23.1 data/s) [100/100]
Loss: 1.2746
Iteration 105 / 200
training: epoch 105: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.667555, min gradient is -8.000000, learning rate is 0.000129
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.860826, learning rate is 0.000129
Net1: layer conv1:max response is , min response is .
max gradient is 7.135492, min gradient is -8.000000, learning rate is 0.000129
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.345518, learning rate is 0.000400
Net2: layer deconv3:max response is 43.488853, min response is -45.003471.
max gradient is 3.201211, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.920313, min response is -4.072295.
max gradient is 6.520166, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.518008, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 11.751807, min response is -2.611646.
max gradient is 8.000000, min gradient is -6.123105, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.647703, learning rate is 0.000200
max inferred z is 3.97, min inferred z is -3.82, and std is 0.99
 4.30 s (23.3 data/s) [100/100]
training: epoch 105: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.210982, min gradient is -8.000000, learning rate is 0.000129
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.029187, learning rate is 0.000129
Net1: layer conv1:max response is , min response is .
max gradient is 4.841434, min gradient is -8.000000, learning rate is 0.000129
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.971763, learning rate is 0.000400
Net2: layer deconv3:max response is 48.645576, min response is -50.139599.
max gradient is 8.000001, min gradient is -3.781898, learning rate is 0.000200
Net2: layer bn50:max response is 21.349047, min response is -5.072912.
max gradient is 8.000000, min gradient is -7.590302, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.664297, learning rate is 0.000200
Net2: layer bn49:max response is 13.053061, min response is -2.176151.
max gradient is 7.758219, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.736307, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.28, min inferred z is -4.26, and std is 0.99
 4.50 s (22.2 data/s) [100/100]
training: epoch 105: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.692776, min gradient is -8.000000, learning rate is 0.000129
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.031297, learning rate is 0.000129
Net1: layer conv1:max response is , min response is .
max gradient is 6.718852, min gradient is -8.000000, learning rate is 0.000129
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.715100, learning rate is 0.000400
Net2: layer deconv3:max response is 45.971878, min response is -46.718452.
max gradient is 5.227075, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.171856, min response is -4.603887.
max gradient is 8.000000, min gradient is -5.209485, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.140348, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 11.919439, min response is -2.399729.
max gradient is 8.000000, min gradient is -4.005270, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.911384, learning rate is 0.000200
max inferred z is 4.12, min inferred z is -3.90, and std is 0.99
 4.43 s (22.6 data/s) [100/100]
training: epoch 105: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.823653, min gradient is -8.000000, learning rate is 0.000129
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.373614, learning rate is 0.000129
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.942828, learning rate is 0.000129
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.684526, learning rate is 0.000400
Net2: layer deconv3:max response is 44.991070, min response is -43.811871.
max gradient is 8.000000, min gradient is -6.335734, learning rate is 0.000200
Net2: layer bn50:max response is 21.958561, min response is -4.759428.
max gradient is 6.275207, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.431797, learning rate is 0.000200
Net2: layer bn49:max response is 11.120237, min response is -2.240481.
max gradient is 4.239194, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.797318, learning rate is 0.000200
max inferred z is 3.69, min inferred z is -3.83, and std is 0.99
 4.22 s (23.7 data/s) [100/100]
training: epoch 105: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.841306, learning rate is 0.000129
Net1: layer conv2:max response is , min response is .
max gradient is 6.127089, min gradient is -8.000000, learning rate is 0.000129
Net1: layer conv1:max response is , min response is .
max gradient is 7.761012, min gradient is -8.000000, learning rate is 0.000129
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.833705, learning rate is 0.000400
Net2: layer deconv3:max response is 40.825752, min response is -42.548256.
max gradient is 4.454906, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.051624, min response is -3.783205.
max gradient is 6.054207, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.492571, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 11.025163, min response is -2.290566.
max gradient is 8.000000, min gradient is -5.042069, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.968164, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.58, min inferred z is -3.72, and std is 0.99
 4.24 s (23.6 data/s) [100/100]
training: epoch 105: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.942200, min gradient is -8.000000, learning rate is 0.000129
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.996637, learning rate is 0.000129
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.685450, learning rate is 0.000129
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.436476, learning rate is 0.000400
Net2: layer deconv3:max response is 39.379284, min response is -42.998898.
max gradient is 8.000000, min gradient is -6.466232, learning rate is 0.000200
Net2: layer bn50:max response is 20.312374, min response is -4.400828.
max gradient is 8.000000, min gradient is -7.129733, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.677434, learning rate is 0.000200
Net2: layer bn49:max response is 11.876870, min response is -2.527784.
max gradient is 6.000258, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.869308, learning rate is 0.000200
max inferred z is 4.09, min inferred z is -3.72, and std is 0.99
 4.19 s (23.9 data/s) [100/100]
training: epoch 105: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.245442, min gradient is -8.000000, learning rate is 0.000129
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.549534, learning rate is 0.000129
Net1: layer conv1:max response is , min response is .
max gradient is 7.921605, min gradient is -8.000000, learning rate is 0.000129
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.581680, learning rate is 0.000400
Net2: layer deconv3:max response is 52.533684, min response is -53.145348.
max gradient is 4.193441, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.840368, min response is -4.661458.
max gradient is 8.000000, min gradient is -6.205318, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.004566, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 11.963147, min response is -2.201649.
max gradient is 8.000000, min gradient is -4.722219, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.396636, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.78, min inferred z is -4.05, and std is 0.99
 4.22 s (23.7 data/s) [100/100]
training: epoch 105: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.121980, learning rate is 0.000129
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.884759, learning rate is 0.000129
Net1: layer conv1:max response is , min response is .
max gradient is 5.602562, min gradient is -8.000000, learning rate is 0.000129
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.269033, learning rate is 0.000400
Net2: layer deconv3:max response is 43.592670, min response is -46.360046.
max gradient is 8.000000, min gradient is -5.313047, learning rate is 0.000200
Net2: layer bn50:max response is 19.997183, min response is -5.336116.
max gradient is 6.537272, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.593735, learning rate is 0.000200
Net2: layer bn49:max response is 11.823668, min response is -2.484587.
max gradient is 6.203844, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.404040, learning rate is 0.000200
max inferred z is 4.11, min inferred z is -3.79, and std is 0.99
 4.26 s (23.5 data/s) [100/100]
training: epoch 105: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.678785, min gradient is -8.000000, learning rate is 0.000129
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.219854, learning rate is 0.000129
Net1: layer conv1:max response is , min response is .
max gradient is 5.522270, min gradient is -8.000000, learning rate is 0.000129
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.589767, learning rate is 0.000400
Net2: layer deconv3:max response is 50.408417, min response is -49.722244.
max gradient is 3.500857, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.962385, min response is -4.424569.
max gradient is 7.039688, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.883641, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 11.833726, min response is -2.715893.
max gradient is 8.000000, min gradient is -6.519652, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.557863, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.05, min inferred z is -4.16, and std is 0.99
 4.23 s (23.6 data/s) [100/100]
training: epoch 105: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.761916, min gradient is -8.000000, learning rate is 0.000129
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.337668, learning rate is 0.000129
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.661226, learning rate is 0.000129
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.030199, learning rate is 0.000400
Net2: layer deconv3:max response is 39.400497, min response is -42.166321.
max gradient is 8.000000, min gradient is -4.434876, learning rate is 0.000200
Net2: layer bn50:max response is 20.350872, min response is -4.175974.
max gradient is 8.000000, min gradient is -7.420962, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.719349, learning rate is 0.000200
Net2: layer bn49:max response is 11.725262, min response is -2.450010.
max gradient is 6.897911, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.664888, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.58, min inferred z is -4.05, and std is 0.99
 4.30 s (23.3 data/s) [100/100]
Loss: 1.1763
Iteration 106 / 200
training: epoch 106: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.643332, min gradient is -8.000000, learning rate is 0.000129
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.480244, learning rate is 0.000129
Net1: layer conv1:max response is , min response is .
max gradient is 6.398130, min gradient is -8.000000, learning rate is 0.000129
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.856094, learning rate is 0.000400
Net2: layer deconv3:max response is 49.742569, min response is -49.442104.
max gradient is 5.048483, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.410349, min response is -4.267534.
max gradient is 7.219949, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 4.991605, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 10.341498, min response is -2.153637.
max gradient is 8.000000, min gradient is -5.759723, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.781273, learning rate is 0.000200
max inferred z is 3.81, min inferred z is -4.36, and std is 1.00
 4.17 s (24.0 data/s) [100/100]
training: epoch 106: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.473168, min gradient is -8.000000, learning rate is 0.000129
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.639391, learning rate is 0.000129
Net1: layer conv1:max response is , min response is .
max gradient is 5.755272, min gradient is -8.000000, learning rate is 0.000129
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.668502, learning rate is 0.000400
Net2: layer deconv3:max response is 51.075062, min response is -47.742275.
max gradient is 8.000000, min gradient is -3.653745, learning rate is 0.000200
Net2: layer bn50:max response is 27.062300, min response is -5.005738.
max gradient is 8.000001, min gradient is -6.258946, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.422707, learning rate is 0.000200
Net2: layer bn49:max response is 11.952808, min response is -2.748470.
max gradient is 6.294248, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.225218, learning rate is 0.000200
max inferred z is 3.66, min inferred z is -3.71, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
training: epoch 106: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.368711, min gradient is -8.000000, learning rate is 0.000129
Net1: layer conv2:max response is , min response is .
max gradient is 7.724978, min gradient is -8.000000, learning rate is 0.000129
Net1: layer conv1:max response is , min response is .
max gradient is 5.981040, min gradient is -8.000000, learning rate is 0.000129
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.776019, learning rate is 0.000400
Net2: layer deconv3:max response is 46.379047, min response is -49.390923.
max gradient is 4.443844, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.697498, min response is -3.887334.
max gradient is 7.645450, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.928926, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 10.772547, min response is -2.511925.
max gradient is 8.000000, min gradient is -6.253873, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.644011, learning rate is 0.000200
max inferred z is 4.33, min inferred z is -3.74, and std is 1.00
 4.43 s (22.6 data/s) [100/100]
training: epoch 106: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.222111, min gradient is -8.000000, learning rate is 0.000129
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.271630, learning rate is 0.000129
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.993622, learning rate is 0.000129
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 7.858883, min gradient is 4.100159, learning rate is 0.000400
Net2: layer deconv3:max response is 55.612320, min response is -57.558865.
max gradient is 8.000000, min gradient is -5.030942, learning rate is 0.000200
Net2: layer bn50:max response is 24.526808, min response is -5.180809.
max gradient is 7.721734, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.244556, learning rate is 0.000200
Net2: layer bn49:max response is 12.693338, min response is -2.718544.
max gradient is 7.488926, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.764356, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.70, min inferred z is -3.48, and std is 1.00
 4.34 s (23.1 data/s) [100/100]
training: epoch 106: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.805370, min gradient is -8.000000, learning rate is 0.000129
Net1: layer conv2:max response is , min response is .
max gradient is 6.713972, min gradient is -8.000000, learning rate is 0.000129
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.149701, learning rate is 0.000129
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.708558, learning rate is 0.000400
Net2: layer deconv3:max response is 54.129742, min response is -52.536957.
max gradient is 4.325171, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.493654, min response is -5.854941.
max gradient is 8.000000, min gradient is -7.900057, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.939891, learning rate is 0.000200
Net2: layer bn49:max response is 13.265602, min response is -2.752388.
max gradient is 8.000000, min gradient is -6.120012, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.718626, learning rate is 0.000200
max inferred z is 4.40, min inferred z is -4.36, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 106: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.194808, min gradient is -8.000000, learning rate is 0.000129
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.220588, learning rate is 0.000129
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.128697, learning rate is 0.000129
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.463110, learning rate is 0.000400
Net2: layer deconv3:max response is 45.414639, min response is -49.330017.
max gradient is 8.000000, min gradient is -2.509164, learning rate is 0.000200
Net2: layer bn50:max response is 20.626806, min response is -4.812372.
max gradient is 8.000000, min gradient is -7.216393, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.698054, learning rate is 0.000200
Net2: layer bn49:max response is 11.226607, min response is -2.548885.
max gradient is 6.658366, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.222847, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.69, min inferred z is -4.44, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
training: epoch 106: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.715886, min gradient is -8.000000, learning rate is 0.000129
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.570828, learning rate is 0.000129
Net1: layer conv1:max response is , min response is .
max gradient is 7.419452, min gradient is -8.000000, learning rate is 0.000129
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.622374, learning rate is 0.000400
Net2: layer deconv3:max response is 40.956699, min response is -42.054108.
max gradient is 2.747974, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.123970, min response is -5.000522.
max gradient is 7.116621, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.871873, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 11.316059, min response is -2.550203.
max gradient is 8.000000, min gradient is -6.713217, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.002381, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.60, min inferred z is -3.96, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
training: epoch 106: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.478687, learning rate is 0.000129
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.758260, learning rate is 0.000129
Net1: layer conv1:max response is , min response is .
max gradient is 5.715904, min gradient is -8.000000, learning rate is 0.000129
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.659609, learning rate is 0.000400
Net2: layer deconv3:max response is 49.178738, min response is -51.544643.
max gradient is 8.000000, min gradient is -3.092281, learning rate is 0.000200
Net2: layer bn50:max response is 25.776506, min response is -5.081082.
max gradient is 8.000000, min gradient is -6.382870, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.113909, learning rate is 0.000200
Net2: layer bn49:max response is 11.701662, min response is -2.495602.
max gradient is 6.927155, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.480933, learning rate is 0.000200
max inferred z is 4.36, min inferred z is -4.00, and std is 1.00
 4.22 s (23.7 data/s) [100/100]
training: epoch 106: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.088134, min gradient is -8.000000, learning rate is 0.000129
Net1: layer conv2:max response is , min response is .
max gradient is 7.982119, min gradient is -8.000000, learning rate is 0.000129
Net1: layer conv1:max response is , min response is .
max gradient is 5.108963, min gradient is -8.000000, learning rate is 0.000129
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.836056, learning rate is 0.000400
Net2: layer deconv3:max response is 47.420357, min response is -46.204861.
max gradient is 3.310868, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.498417, min response is -4.480463.
max gradient is 7.907934, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.078752, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 11.353724, min response is -2.222601.
max gradient is 8.000000, min gradient is -6.956320, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.941922, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.20, min inferred z is -3.79, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 106: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.260616, min gradient is -8.000000, learning rate is 0.000129
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.369144, learning rate is 0.000129
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.078291, learning rate is 0.000129
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.172537, learning rate is 0.000400
Net2: layer deconv3:max response is 44.852566, min response is -46.276863.
max gradient is 8.000000, min gradient is -2.989393, learning rate is 0.000200
Net2: layer bn50:max response is 22.176888, min response is -4.318408.
max gradient is 8.000000, min gradient is -6.395977, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.233160, learning rate is 0.000200
Net2: layer bn49:max response is 13.136781, min response is -2.689631.
max gradient is 8.000000, min gradient is -7.588778, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.038239, learning rate is 0.000200
max inferred z is 3.86, min inferred z is -4.34, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
Loss: 1.1449
Iteration 107 / 200
training: epoch 107: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.987574, min gradient is -8.000000, learning rate is 0.000107
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.611218, learning rate is 0.000107
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.453078, learning rate is 0.000107
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.844499, learning rate is 0.000400
Net2: layer deconv3:max response is 50.016895, min response is -50.934822.
max gradient is 3.059859, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.139240, min response is -4.564306.
max gradient is 7.145471, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.743406, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 11.920240, min response is -2.489128.
max gradient is 8.000000, min gradient is -6.762517, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.980564, learning rate is 0.000200
max inferred z is 3.82, min inferred z is -4.51, and std is 1.01
 4.30 s (23.3 data/s) [100/100]
training: epoch 107: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.596224, min gradient is -8.000000, learning rate is 0.000107
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.517612, learning rate is 0.000107
Net1: layer conv1:max response is , min response is .
max gradient is 5.302110, min gradient is -8.000000, learning rate is 0.000107
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.640679, learning rate is 0.000400
Net2: layer deconv3:max response is 48.507900, min response is -50.227509.
max gradient is 8.000000, min gradient is -4.326453, learning rate is 0.000200
Net2: layer bn50:max response is 20.720928, min response is -5.219967.
max gradient is 8.000000, min gradient is -6.499799, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.431933, learning rate is 0.000200
Net2: layer bn49:max response is 13.721820, min response is -2.804516.
max gradient is 6.876245, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.339279, learning rate is 0.000200
max inferred z is 4.02, min inferred z is -4.20, and std is 1.01
 4.32 s (23.2 data/s) [100/100]
training: epoch 107: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.805573, min gradient is -8.000000, learning rate is 0.000107
Net1: layer conv2:max response is , min response is .
max gradient is 7.503020, min gradient is -8.000000, learning rate is 0.000107
Net1: layer conv1:max response is , min response is .
max gradient is 5.393182, min gradient is -8.000000, learning rate is 0.000107
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.892053, learning rate is 0.000400
Net2: layer deconv3:max response is 55.168449, min response is -52.663998.
max gradient is 4.587837, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.221441, min response is -5.139844.
max gradient is 7.468837, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.291356, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 12.083922, min response is -2.508647.
max gradient is 8.000000, min gradient is -6.124467, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.107450, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.12, min inferred z is -4.08, and std is 1.01
 4.36 s (22.9 data/s) [100/100]
training: epoch 107: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.937474, min gradient is -8.000000, learning rate is 0.000107
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.300179, learning rate is 0.000107
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.546534, learning rate is 0.000107
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.787795, learning rate is 0.000400
Net2: layer deconv3:max response is 50.717762, min response is -53.403210.
max gradient is 8.000000, min gradient is -3.183476, learning rate is 0.000200
Net2: layer bn50:max response is 21.918074, min response is -5.292639.
max gradient is 8.000000, min gradient is -6.497193, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.828724, learning rate is 0.000200
Net2: layer bn49:max response is 12.894438, min response is -2.340659.
max gradient is 7.741097, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.749682, learning rate is 0.000200
max inferred z is 4.15, min inferred z is -4.35, and std is 1.01
 4.26 s (23.5 data/s) [100/100]
training: epoch 107: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.169570, min gradient is -8.000000, learning rate is 0.000107
Net1: layer conv2:max response is , min response is .
max gradient is 7.391375, min gradient is -8.000000, learning rate is 0.000107
Net1: layer conv1:max response is , min response is .
max gradient is 7.857197, min gradient is -8.000000, learning rate is 0.000107
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.906447, learning rate is 0.000400
Net2: layer deconv3:max response is 44.803211, min response is -45.674397.
max gradient is 3.003392, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.488876, min response is -4.068855.
max gradient is 7.774492, min gradient is -8.000001, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.748717, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 11.848509, min response is -2.874972.
max gradient is 8.000001, min gradient is -6.892473, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.520703, learning rate is 0.000200
max inferred z is 3.96, min inferred z is -3.80, and std is 1.01
 4.35 s (23.0 data/s) [100/100]
training: epoch 107: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.690767, min gradient is -8.000000, learning rate is 0.000107
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.280757, learning rate is 0.000107
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.760261, learning rate is 0.000107
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.800677, learning rate is 0.000400
Net2: layer deconv3:max response is 42.285465, min response is -47.616932.
max gradient is 8.000000, min gradient is -2.968639, learning rate is 0.000200
Net2: layer bn50:max response is 21.899548, min response is -5.579847.
max gradient is 7.721911, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.124780, learning rate is 0.000200
Net2: layer bn49:max response is 11.466809, min response is -2.307726.
max gradient is 6.997630, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.230450, learning rate is 0.000200
max inferred z is 4.10, min inferred z is -4.29, and std is 1.01
 4.37 s (22.9 data/s) [100/100]
training: epoch 107: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.258253, min gradient is -8.000000, learning rate is 0.000107
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.567872, learning rate is 0.000107
Net1: layer conv1:max response is , min response is .
max gradient is 7.721905, min gradient is -8.000000, learning rate is 0.000107
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.836129, learning rate is 0.000400
Net2: layer deconv3:max response is 46.073715, min response is -44.958786.
max gradient is 2.149883, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.171427, min response is -4.399515.
max gradient is 7.987882, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.025678, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 12.368804, min response is -2.331434.
max gradient is 8.000000, min gradient is -6.079094, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.909834, learning rate is 0.000200
max inferred z is 4.17, min inferred z is -4.07, and std is 1.01
 4.24 s (23.6 data/s) [100/100]
training: epoch 107: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.887273, learning rate is 0.000107
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.160337, learning rate is 0.000107
Net1: layer conv1:max response is , min response is .
max gradient is 6.305042, min gradient is -8.000000, learning rate is 0.000107
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.076333, learning rate is 0.000400
Net2: layer deconv3:max response is 50.844967, min response is -53.444489.
max gradient is 8.000000, min gradient is -3.283257, learning rate is 0.000200
Net2: layer bn50:max response is 23.688019, min response is -4.312259.
max gradient is 6.017380, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.148486, learning rate is 0.000200
Net2: layer bn49:max response is 13.488030, min response is -2.648339.
max gradient is 8.000000, min gradient is -7.874317, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.697775, learning rate is 0.000200
max inferred z is 4.16, min inferred z is -3.89, and std is 1.01
 4.39 s (22.8 data/s) [100/100]
training: epoch 107: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.103739, min gradient is -8.000000, learning rate is 0.000107
Net1: layer conv2:max response is , min response is .
max gradient is 7.573287, min gradient is -8.000000, learning rate is 0.000107
Net1: layer conv1:max response is , min response is .
max gradient is 5.287709, min gradient is -8.000000, learning rate is 0.000107
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.600000, learning rate is 0.000400
Net2: layer deconv3:max response is 50.577751, min response is -49.764027.
max gradient is 3.965505, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.763206, min response is -4.618773.
max gradient is 8.000000, min gradient is -6.108942, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.178813, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 11.836294, min response is -2.701147.
max gradient is 8.000001, min gradient is -7.602479, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.090100, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.10, min inferred z is -3.86, and std is 1.01
 4.48 s (22.3 data/s) [100/100]
training: epoch 107: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.850667, learning rate is 0.000107
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.430840, learning rate is 0.000107
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.146911, learning rate is 0.000107
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.072972, learning rate is 0.000400
Net2: layer deconv3:max response is 75.157555, min response is -79.025383.
max gradient is 8.000000, min gradient is -4.461400, learning rate is 0.000200
Net2: layer bn50:max response is 32.138496, min response is -6.985058.
max gradient is 6.581286, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.479666, learning rate is 0.000200
Net2: layer bn49:max response is 17.649471, min response is -2.966463.
max gradient is 5.129668, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.652276, learning rate is 0.000200
max inferred z is 3.92, min inferred z is -3.87, and std is 1.01
 4.32 s (23.2 data/s) [100/100]
Loss: 1.1703
Iteration 108 / 200
training: epoch 108: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.827247, min gradient is -8.000000, learning rate is 0.000107
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.615391, learning rate is 0.000107
Net1: layer conv1:max response is , min response is .
max gradient is 7.309259, min gradient is -8.000000, learning rate is 0.000107
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.552873, learning rate is 0.000400
Net2: layer deconv3:max response is 47.273731, min response is -47.543575.
max gradient is 4.527912, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.881947, min response is -4.290132.
max gradient is 7.680593, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.795500, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 12.035077, min response is -2.206956.
max gradient is 8.000000, min gradient is -6.533785, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.714567, learning rate is 0.000200
max inferred z is 4.54, min inferred z is -4.12, and std is 0.99
 4.19 s (23.9 data/s) [100/100]
training: epoch 108: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.598697, min gradient is -8.000000, learning rate is 0.000107
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.909303, learning rate is 0.000107
Net1: layer conv1:max response is , min response is .
max gradient is 4.757524, min gradient is -8.000000, learning rate is 0.000107
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.693029, learning rate is 0.000400
Net2: layer deconv3:max response is 57.868141, min response is -60.293346.
max gradient is 8.000000, min gradient is -5.859337, learning rate is 0.000200
Net2: layer bn50:max response is 24.538418, min response is -5.648951.
max gradient is 6.152270, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.917801, learning rate is 0.000200
Net2: layer bn49:max response is 13.838220, min response is -2.337067.
max gradient is 4.956042, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.490125, min gradient is -8.000001, learning rate is 0.000200
max inferred z is 4.11, min inferred z is -4.31, and std is 0.99
 4.31 s (23.2 data/s) [100/100]
training: epoch 108: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.495552, min gradient is -8.000000, learning rate is 0.000107
Net1: layer conv2:max response is , min response is .
max gradient is 7.643725, min gradient is -8.000000, learning rate is 0.000107
Net1: layer conv1:max response is , min response is .
max gradient is 6.794973, min gradient is -8.000000, learning rate is 0.000107
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.484548, learning rate is 0.000400
Net2: layer deconv3:max response is 52.347790, min response is -53.520554.
max gradient is 5.382226, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.547125, min response is -4.724071.
max gradient is 8.000000, min gradient is -6.771650, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.934868, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 11.461360, min response is -2.303199.
max gradient is 8.000000, min gradient is -6.598115, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.058414, learning rate is 0.000200
max inferred z is 3.37, min inferred z is -3.94, and std is 0.99
 4.36 s (22.9 data/s) [100/100]
training: epoch 108: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.646610, min gradient is -8.000000, learning rate is 0.000107
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.378209, learning rate is 0.000107
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.171328, learning rate is 0.000107
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.825413, learning rate is 0.000400
Net2: layer deconv3:max response is 42.352077, min response is -42.038479.
max gradient is 8.000000, min gradient is -6.385457, learning rate is 0.000200
Net2: layer bn50:max response is 19.441742, min response is -3.926310.
max gradient is 6.672753, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.713508, learning rate is 0.000200
Net2: layer bn49:max response is 11.110767, min response is -2.635557.
max gradient is 4.704121, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.544801, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.15, min inferred z is -4.02, and std is 0.99
 4.39 s (22.8 data/s) [100/100]
training: epoch 108: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.141277, min gradient is -8.000000, learning rate is 0.000107
Net1: layer conv2:max response is , min response is .
max gradient is 7.315315, min gradient is -8.000000, learning rate is 0.000107
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.400305, learning rate is 0.000107
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.676068, learning rate is 0.000400
Net2: layer deconv3:max response is 54.588730, min response is -56.327538.
max gradient is 5.105768, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.497032, min response is -5.050851.
max gradient is 8.000000, min gradient is -7.444327, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.478042, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 12.338552, min response is -2.383700.
max gradient is 8.000001, min gradient is -5.266225, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.134562, learning rate is 0.000200
max inferred z is 3.84, min inferred z is -4.47, and std is 0.99
 4.41 s (22.7 data/s) [100/100]
training: epoch 108: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.990504, min gradient is -8.000000, learning rate is 0.000107
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.716414, learning rate is 0.000107
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.834542, learning rate is 0.000107
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.216976, learning rate is 0.000400
Net2: layer deconv3:max response is 41.689857, min response is -39.728397.
max gradient is 7.553166, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.110851, min response is -3.476042.
max gradient is 4.991909, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.139421, learning rate is 0.000200
Net2: layer bn49:max response is 11.246507, min response is -2.345794.
max gradient is 3.865499, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.801296, learning rate is 0.000200
max inferred z is 5.01, min inferred z is -3.92, and std is 0.99
 4.33 s (23.1 data/s) [100/100]
training: epoch 108: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.414946, min gradient is -8.000000, learning rate is 0.000107
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.055042, learning rate is 0.000107
Net1: layer conv1:max response is , min response is .
max gradient is 7.459394, min gradient is -8.000000, learning rate is 0.000107
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.937190, learning rate is 0.000400
Net2: layer deconv3:max response is 49.766380, min response is -50.752922.
max gradient is 8.000000, min gradient is -6.939027, learning rate is 0.000200
Net2: layer bn50:max response is 20.460285, min response is -4.484524.
max gradient is 8.000000, min gradient is -4.878491, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.489660, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 10.888746, min response is -2.210912.
max gradient is 8.000000, min gradient is -5.368180, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.434373, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.01, min inferred z is -3.87, and std is 0.99
 4.32 s (23.1 data/s) [100/100]
training: epoch 108: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.479066, min gradient is -8.000000, learning rate is 0.000107
Net1: layer conv2:max response is , min response is .
max gradient is 6.388828, min gradient is -8.000000, learning rate is 0.000107
Net1: layer conv1:max response is , min response is .
max gradient is 4.916619, min gradient is -8.000000, learning rate is 0.000107
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 0.062231, learning rate is 0.000400
Net2: layer deconv3:max response is 51.322437, min response is -50.152672.
max gradient is 6.850148, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.896458, min response is -4.812458.
max gradient is 5.166135, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.053007, learning rate is 0.000200
Net2: layer bn49:max response is 12.227616, min response is -3.061953.
max gradient is 3.371393, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.069782, learning rate is 0.000200
max inferred z is 4.48, min inferred z is -4.58, and std is 0.99
 4.27 s (23.4 data/s) [100/100]
training: epoch 108: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.008368, min gradient is -8.000000, learning rate is 0.000107
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.668081, learning rate is 0.000107
Net1: layer conv1:max response is , min response is .
max gradient is 6.854118, min gradient is -8.000000, learning rate is 0.000107
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.868596, learning rate is 0.000400
Net2: layer deconv3:max response is 46.207008, min response is -47.324226.
max gradient is 7.187065, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.638487, min response is -4.712814.
max gradient is 8.000000, min gradient is -6.194151, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.959464, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 11.195642, min response is -2.539771.
max gradient is 8.000000, min gradient is -6.645146, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.535476, learning rate is 0.000200
max inferred z is 4.36, min inferred z is -3.65, and std is 0.99
 4.21 s (23.8 data/s) [100/100]
training: epoch 108: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.444024, min gradient is -8.000000, learning rate is 0.000107
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.065322, learning rate is 0.000107
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.874803, learning rate is 0.000107
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.035378, learning rate is 0.000400
Net2: layer deconv3:max response is 47.014343, min response is -47.668335.
max gradient is 7.735236, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.081877, min response is -4.255479.
max gradient is 4.484767, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.045222, learning rate is 0.000200
Net2: layer bn49:max response is 12.174241, min response is -2.336000.
max gradient is 5.055048, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.802324, learning rate is 0.000200
max inferred z is 4.09, min inferred z is -4.49, and std is 0.99
 4.33 s (23.1 data/s) [100/100]
Loss: 1.1667
Iteration 109 / 200
training: epoch 109: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.600781, min gradient is -8.000000, learning rate is 0.000089
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.410891, learning rate is 0.000089
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.988540, learning rate is 0.000089
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.201082, learning rate is 0.000400
Net2: layer deconv3:max response is 46.247322, min response is -48.987793.
max gradient is 8.000000, min gradient is -7.913576, learning rate is 0.000200
Net2: layer bn50:max response is 19.071499, min response is -4.517030.
max gradient is 8.000000, min gradient is -5.017038, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.555603, min gradient is -8.000001, learning rate is 0.000200
Net2: layer bn49:max response is 11.919057, min response is -2.468201.
max gradient is 8.000000, min gradient is -5.711474, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.513169, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.82, min inferred z is -3.73, and std is 1.00
 4.28 s (23.3 data/s) [100/100]
training: epoch 109: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.127685, min gradient is -8.000000, learning rate is 0.000089
Net1: layer conv2:max response is , min response is .
max gradient is 8.000001, min gradient is -7.596919, learning rate is 0.000089
Net1: layer conv1:max response is , min response is .
max gradient is 5.153247, min gradient is -8.000000, learning rate is 0.000089
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.215218, learning rate is 0.000400
Net2: layer deconv3:max response is 48.755657, min response is -51.817562.
max gradient is 8.000000, min gradient is -6.918606, learning rate is 0.000200
Net2: layer bn50:max response is 20.259743, min response is -4.279602.
max gradient is 6.492557, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.493985, learning rate is 0.000200
Net2: layer bn49:max response is 11.749996, min response is -2.362028.
max gradient is 4.251419, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.662944, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.46, min inferred z is -4.12, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 109: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.300612, min gradient is -8.000000, learning rate is 0.000089
Net1: layer conv2:max response is , min response is .
max gradient is 7.390328, min gradient is -8.000000, learning rate is 0.000089
Net1: layer conv1:max response is , min response is .
max gradient is 5.276515, min gradient is -8.000000, learning rate is 0.000089
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.762767, learning rate is 0.000400
Net2: layer deconv3:max response is 48.175644, min response is -48.456070.
max gradient is 6.902217, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.231066, min response is -4.489016.
max gradient is 8.000000, min gradient is -5.787716, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.676201, learning rate is 0.000200
Net2: layer bn49:max response is 10.950982, min response is -2.318168.
max gradient is 8.000000, min gradient is -4.747831, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.778466, learning rate is 0.000200
max inferred z is 3.74, min inferred z is -3.74, and std is 1.00
 4.30 s (23.2 data/s) [100/100]
training: epoch 109: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.514082, min gradient is -8.000000, learning rate is 0.000089
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.286241, learning rate is 0.000089
Net1: layer conv1:max response is , min response is .
max gradient is 5.683061, min gradient is -8.000000, learning rate is 0.000089
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -1.420722, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 45.022709, min response is -44.145496.
max gradient is 7.069198, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.746292, min response is -4.985096.
max gradient is 4.457204, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.666198, learning rate is 0.000200
Net2: layer bn49:max response is 10.778858, min response is -2.380275.
max gradient is 3.766012, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.485250, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.79, min inferred z is -3.93, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 109: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.916641, min gradient is -8.000000, learning rate is 0.000089
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.315240, learning rate is 0.000089
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.164905, learning rate is 0.000089
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.129419, learning rate is 0.000400
Net2: layer deconv3:max response is 51.111195, min response is -53.438118.
max gradient is 8.000000, min gradient is -6.108328, learning rate is 0.000200
Net2: layer bn50:max response is 20.673698, min response is -4.527965.
max gradient is 8.000000, min gradient is -3.554136, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.697587, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 11.262355, min response is -2.414668.
max gradient is 8.000001, min gradient is -4.401763, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.861369, learning rate is 0.000200
max inferred z is 4.40, min inferred z is -4.11, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
training: epoch 109: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.536356, min gradient is -8.000000, learning rate is 0.000089
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.007682, learning rate is 0.000089
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.582538, learning rate is 0.000089
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.803462, learning rate is 0.000400
Net2: layer deconv3:max response is 59.186741, min response is -59.486095.
max gradient is 7.867035, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.976763, min response is -5.085046.
max gradient is 3.955159, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.784650, learning rate is 0.000200
Net2: layer bn49:max response is 12.230239, min response is -2.554816.
max gradient is 5.106186, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.767877, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.84, min inferred z is -3.87, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 109: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.270899, min gradient is -8.000000, learning rate is 0.000089
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.851969, learning rate is 0.000089
Net1: layer conv1:max response is , min response is .
max gradient is 7.466457, min gradient is -8.000000, learning rate is 0.000089
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -3.040692, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 52.668873, min response is -58.543129.
max gradient is 6.587094, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.448965, min response is -5.311964.
max gradient is 8.000000, min gradient is -4.421772, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.287077, learning rate is 0.000200
Net2: layer bn49:max response is 11.861903, min response is -2.643301.
max gradient is 8.000000, min gradient is -4.874105, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.802429, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.98, min inferred z is -3.96, and std is 1.00
 4.22 s (23.7 data/s) [100/100]
training: epoch 109: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.865679, min gradient is -8.000000, learning rate is 0.000089
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.016659, learning rate is 0.000089
Net1: layer conv1:max response is , min response is .
max gradient is 5.565787, min gradient is -8.000000, learning rate is 0.000089
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.201828, learning rate is 0.000400
Net2: layer deconv3:max response is 49.656132, min response is -51.552513.
max gradient is 7.843260, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.197287, min response is -4.495080.
max gradient is 5.861039, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.818585, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 11.142139, min response is -2.367078.
max gradient is 8.000000, min gradient is -7.604205, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.350467, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.51, min inferred z is -3.82, and std is 1.00
 4.38 s (22.9 data/s) [100/100]
training: epoch 109: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.060143, min gradient is -8.000000, learning rate is 0.000089
Net1: layer conv2:max response is , min response is .
max gradient is 7.857171, min gradient is -8.000000, learning rate is 0.000089
Net1: layer conv1:max response is , min response is .
max gradient is 5.523290, min gradient is -8.000000, learning rate is 0.000089
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.486901, learning rate is 0.000400
Net2: layer deconv3:max response is 46.990723, min response is -46.497288.
max gradient is 4.376403, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.844923, min response is -4.832890.
max gradient is 6.309507, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.102592, learning rate is 0.000200
Net2: layer bn49:max response is 12.777120, min response is -2.603296.
max gradient is 8.000000, min gradient is -6.655516, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.592832, learning rate is 0.000200
max inferred z is 4.13, min inferred z is -3.79, and std is 1.00
 4.50 s (22.2 data/s) [100/100]
training: epoch 109: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.994306, learning rate is 0.000089
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.967499, learning rate is 0.000089
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.676804, learning rate is 0.000089
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.376771, learning rate is 0.000400
Net2: layer deconv3:max response is 48.697361, min response is -54.608410.
max gradient is 8.000000, min gradient is -4.512653, learning rate is 0.000200
Net2: layer bn50:max response is 19.864641, min response is -4.343664.
max gradient is 7.014307, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.707969, learning rate is 0.000200
Net2: layer bn49:max response is 12.384768, min response is -2.363262.
max gradient is 6.420600, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 4.952231, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.82, min inferred z is -4.31, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
Loss: 1.2333
Iteration 110 / 200
training: epoch 110: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.891955, min gradient is -8.000000, learning rate is 0.000089
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.907946, learning rate is 0.000089
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.864414, learning rate is 0.000089
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.553101, learning rate is 0.000400
Net2: layer deconv3:max response is 54.868244, min response is -57.002975.
max gradient is 4.799424, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.025053, min response is -5.293895.
max gradient is 8.000000, min gradient is -5.133756, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.785405, min gradient is -8.000001, learning rate is 0.000200
Net2: layer bn49:max response is 12.538890, min response is -3.094600.
max gradient is 7.318625, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.957813, learning rate is 0.000200
max inferred z is 3.82, min inferred z is -3.68, and std is 1.01
 4.20 s (23.8 data/s) [100/100]
training: epoch 110: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.255298, min gradient is -8.000000, learning rate is 0.000089
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.419579, learning rate is 0.000089
Net1: layer conv1:max response is , min response is .
max gradient is 5.743080, min gradient is -8.000000, learning rate is 0.000089
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.717858, learning rate is 0.000400
Net2: layer deconv3:max response is 49.393993, min response is -51.666054.
max gradient is 6.646634, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.096312, min response is -4.160124.
max gradient is 2.502712, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.678814, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 13.936807, min response is -2.227109.
max gradient is 4.702554, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.510554, learning rate is 0.000200
max inferred z is 3.61, min inferred z is -3.82, and std is 1.01
 4.28 s (23.4 data/s) [100/100]
training: epoch 110: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.666142, min gradient is -8.000000, learning rate is 0.000089
Net1: layer conv2:max response is , min response is .
max gradient is 7.571862, min gradient is -8.000000, learning rate is 0.000089
Net1: layer conv1:max response is , min response is .
max gradient is 5.578051, min gradient is -8.000000, learning rate is 0.000089
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.450516, learning rate is 0.000400
Net2: layer deconv3:max response is 58.173866, min response is -63.594170.
max gradient is 7.283897, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 24.015013, min response is -5.509492.
max gradient is 8.000000, min gradient is -2.933753, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.387437, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 13.434440, min response is -2.761459.
max gradient is 8.000000, min gradient is -5.698919, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.849763, learning rate is 0.000200
max inferred z is 4.49, min inferred z is -3.74, and std is 1.01
 4.30 s (23.3 data/s) [100/100]
training: epoch 110: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.951210, min gradient is -8.000000, learning rate is 0.000089
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.726415, learning rate is 0.000089
Net1: layer conv1:max response is , min response is .
max gradient is 5.943164, min gradient is -8.000001, learning rate is 0.000089
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.774871, learning rate is 0.000400
Net2: layer deconv3:max response is 49.142456, min response is -50.098080.
max gradient is 8.000000, min gradient is -6.006555, learning rate is 0.000200
Net2: layer bn50:max response is 20.704062, min response is -4.137984.
max gradient is 5.727473, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.096602, learning rate is 0.000200
Net2: layer bn49:max response is 11.559460, min response is -2.626382.
max gradient is 3.523257, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.334306, learning rate is 0.000200
max inferred z is 3.73, min inferred z is -4.10, and std is 1.01
 4.29 s (23.3 data/s) [100/100]
training: epoch 110: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.599434, min gradient is -8.000000, learning rate is 0.000089
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.496565, learning rate is 0.000089
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.977345, learning rate is 0.000089
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.723691, learning rate is 0.000400
Net2: layer deconv3:max response is 58.867912, min response is -60.199562.
max gradient is 4.443115, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.049723, min response is -5.631502.
max gradient is 6.480841, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.091626, learning rate is 0.000200
Net2: layer bn49:max response is 13.166294, min response is -2.365310.
max gradient is 8.000000, min gradient is -6.621261, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.375111, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.12, min inferred z is -4.26, and std is 1.01
 4.26 s (23.5 data/s) [100/100]
training: epoch 110: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.886750, min gradient is -8.000000, learning rate is 0.000089
Net1: layer conv2:max response is , min response is .
max gradient is 8.000001, min gradient is -5.642148, learning rate is 0.000089
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.932798, learning rate is 0.000089
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.719180, learning rate is 0.000400
Net2: layer deconv3:max response is 47.808365, min response is -51.266029.
max gradient is 8.000000, min gradient is -3.755115, learning rate is 0.000200
Net2: layer bn50:max response is 20.139122, min response is -5.225376.
max gradient is 8.000000, min gradient is -6.297736, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.926985, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 12.809586, min response is -2.657352.
max gradient is 4.974008, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.356945, learning rate is 0.000200
max inferred z is 3.75, min inferred z is -3.97, and std is 1.01
 4.21 s (23.8 data/s) [100/100]
training: epoch 110: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.165611, min gradient is -8.000000, learning rate is 0.000089
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.010191, learning rate is 0.000089
Net1: layer conv1:max response is , min response is .
max gradient is 6.883049, min gradient is -8.000000, learning rate is 0.000089
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.111421, learning rate is 0.000400
Net2: layer deconv3:max response is 60.591488, min response is -60.952347.
max gradient is 3.685513, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.414433, min response is -5.847211.
max gradient is 7.073879, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.855109, learning rate is 0.000200
Net2: layer bn49:max response is 13.821700, min response is -2.802807.
max gradient is 8.000000, min gradient is -4.966670, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.867851, learning rate is 0.000200
max inferred z is 3.57, min inferred z is -3.92, and std is 1.01
 4.27 s (23.4 data/s) [100/100]
training: epoch 110: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.252480, min gradient is -8.000000, learning rate is 0.000089
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.662255, learning rate is 0.000089
Net1: layer conv1:max response is , min response is .
max gradient is 6.260971, min gradient is -8.000000, learning rate is 0.000089
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.198332, learning rate is 0.000400
Net2: layer deconv3:max response is 42.041428, min response is -45.670639.
max gradient is 8.000000, min gradient is -4.406992, learning rate is 0.000200
Net2: layer bn50:max response is 21.502184, min response is -3.966242.
max gradient is 8.000000, min gradient is -7.608826, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.856420, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 13.545613, min response is -2.506333.
max gradient is 6.104324, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.212137, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.79, min inferred z is -3.57, and std is 1.01
 4.30 s (23.2 data/s) [100/100]
training: epoch 110: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.209408, min gradient is -8.000000, learning rate is 0.000089
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.840228, learning rate is 0.000089
Net1: layer conv1:max response is , min response is .
max gradient is 5.338596, min gradient is -8.000000, learning rate is 0.000089
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.143869, learning rate is 0.000400
Net2: layer deconv3:max response is 43.154667, min response is -44.352184.
max gradient is 4.200428, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.350414, min response is -3.674040.
max gradient is 6.478843, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.978948, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 12.016285, min response is -2.322829.
max gradient is 8.000000, min gradient is -7.422558, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.151533, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.26, min inferred z is -3.92, and std is 1.01
 4.23 s (23.7 data/s) [100/100]
training: epoch 110: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.813265, learning rate is 0.000089
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.570502, learning rate is 0.000089
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.552525, learning rate is 0.000089
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.081582, learning rate is 0.000400
Net2: layer deconv3:max response is 44.996883, min response is -51.224934.
max gradient is 8.000000, min gradient is -4.361305, learning rate is 0.000200
Net2: layer bn50:max response is 18.609949, min response is -4.344415.
max gradient is 8.000000, min gradient is -6.118626, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.774809, learning rate is 0.000200
Net2: layer bn49:max response is 12.618275, min response is -2.478637.
max gradient is 6.704593, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.747137, learning rate is 0.000200
max inferred z is 4.61, min inferred z is -3.64, and std is 1.01
 4.38 s (22.9 data/s) [100/100]
Loss: 1.2518
Iteration 111 / 200
training: epoch 111: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.448237, min gradient is -8.000000, learning rate is 0.000074
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.483459, learning rate is 0.000074
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.862378, learning rate is 0.000074
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.008086, learning rate is 0.000400
Net2: layer deconv3:max response is 49.341621, min response is -50.633526.
max gradient is 4.085179, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.627413, min response is -4.379155.
max gradient is 7.466893, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.558191, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 12.750284, min response is -2.474515.
max gradient is 8.000000, min gradient is -6.420380, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.393416, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.97, min inferred z is -3.61, and std is 1.00
 4.16 s (24.0 data/s) [100/100]
training: epoch 111: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.110993, min gradient is -8.000000, learning rate is 0.000074
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.915032, learning rate is 0.000074
Net1: layer conv1:max response is , min response is .
max gradient is 5.995626, min gradient is -8.000000, learning rate is 0.000074
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.952310, learning rate is 0.000400
Net2: layer deconv3:max response is 44.932667, min response is -49.868008.
max gradient is 8.000000, min gradient is -4.358890, learning rate is 0.000200
Net2: layer bn50:max response is 23.434879, min response is -4.135628.
max gradient is 8.000000, min gradient is -6.585392, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.716637, learning rate is 0.000200
Net2: layer bn49:max response is 12.398982, min response is -2.349611.
max gradient is 8.000000, min gradient is -7.297363, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.597236, learning rate is 0.000200
max inferred z is 3.63, min inferred z is -4.34, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 111: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.266709, min gradient is -8.000000, learning rate is 0.000074
Net1: layer conv2:max response is , min response is .
max gradient is 7.533185, min gradient is -8.000000, learning rate is 0.000074
Net1: layer conv1:max response is , min response is .
max gradient is 5.473709, min gradient is -8.000000, learning rate is 0.000074
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.356895, learning rate is 0.000400
Net2: layer deconv3:max response is 54.980156, min response is -59.058117.
max gradient is 5.220833, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.127567, min response is -4.531945.
max gradient is 8.000000, min gradient is -7.379247, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.068218, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 11.683410, min response is -2.333288.
max gradient is 8.000000, min gradient is -7.895606, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.664469, learning rate is 0.000200
max inferred z is 4.36, min inferred z is -4.12, and std is 1.00
 4.34 s (23.1 data/s) [100/100]
training: epoch 111: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.065184, min gradient is -8.000000, learning rate is 0.000074
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.530778, learning rate is 0.000074
Net1: layer conv1:max response is , min response is .
max gradient is 5.675627, min gradient is -8.000001, learning rate is 0.000074
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 6.590273, min gradient is -0.787669, learning rate is 0.000400
Net2: layer deconv3:max response is 49.230892, min response is -54.387356.
max gradient is 8.000001, min gradient is -4.984613, learning rate is 0.000200
Net2: layer bn50:max response is 20.782322, min response is -4.510465.
max gradient is 8.000000, min gradient is -7.319999, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.345105, learning rate is 0.000200
Net2: layer bn49:max response is 12.216215, min response is -2.868968.
max gradient is 7.705842, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.405157, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.09, min inferred z is -3.93, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 111: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.550439, min gradient is -8.000000, learning rate is 0.000074
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.852458, learning rate is 0.000074
Net1: layer conv1:max response is , min response is .
max gradient is 7.789380, min gradient is -8.000000, learning rate is 0.000074
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.793153, learning rate is 0.000400
Net2: layer deconv3:max response is 53.472481, min response is -47.676006.
max gradient is 3.982025, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.661741, min response is -3.852443.
max gradient is 6.649960, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.457005, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 11.534178, min response is -3.108779.
max gradient is 8.000000, min gradient is -6.994108, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.645020, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.71, min inferred z is -4.05, and std is 1.00
 4.34 s (23.1 data/s) [100/100]
training: epoch 111: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.112648, min gradient is -8.000000, learning rate is 0.000074
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.694600, learning rate is 0.000074
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.021707, learning rate is 0.000074
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 5.796295, min gradient is -3.246849, learning rate is 0.000400
Net2: layer deconv3:max response is 49.449146, min response is -55.745968.
max gradient is 8.000000, min gradient is -4.009967, learning rate is 0.000200
Net2: layer bn50:max response is 20.496468, min response is -4.582306.
max gradient is 8.000000, min gradient is -6.300666, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.091975, learning rate is 0.000200
Net2: layer bn49:max response is 12.120355, min response is -2.551574.
max gradient is 6.791809, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.382681, learning rate is 0.000200
max inferred z is 4.23, min inferred z is -3.65, and std is 1.00
 4.30 s (23.3 data/s) [100/100]
training: epoch 111: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.747290, min gradient is -8.000000, learning rate is 0.000074
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.861386, learning rate is 0.000074
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.449320, learning rate is 0.000074
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.631391, learning rate is 0.000400
Net2: layer deconv3:max response is 47.764137, min response is -49.236813.
max gradient is 3.261152, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.132694, min response is -4.781078.
max gradient is 7.752638, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.009352, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 11.775547, min response is -2.831658.
max gradient is 8.000000, min gradient is -6.152286, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.039020, learning rate is 0.000200
max inferred z is 3.69, min inferred z is -3.79, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 111: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.958041, min gradient is -8.000000, learning rate is 0.000074
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.151633, learning rate is 0.000074
Net1: layer conv1:max response is , min response is .
max gradient is 7.647912, min gradient is -8.000000, learning rate is 0.000074
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -3.781075, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 40.840771, min response is -46.844810.
max gradient is 8.000000, min gradient is -3.336138, learning rate is 0.000200
Net2: layer bn50:max response is 20.963503, min response is -4.686806.
max gradient is 8.000000, min gradient is -6.822371, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.586983, learning rate is 0.000200
Net2: layer bn49:max response is 10.061664, min response is -2.483659.
max gradient is 6.570399, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.392498, learning rate is 0.000200
max inferred z is 4.04, min inferred z is -3.59, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 111: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.229043, min gradient is -8.000000, learning rate is 0.000074
Net1: layer conv2:max response is , min response is .
max gradient is 6.742041, min gradient is -8.000000, learning rate is 0.000074
Net1: layer conv1:max response is , min response is .
max gradient is 5.292921, min gradient is -8.000000, learning rate is 0.000074
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.629475, learning rate is 0.000400
Net2: layer deconv3:max response is 46.542542, min response is -47.638451.
max gradient is 3.438504, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.047592, min response is -4.388227.
max gradient is 6.819999, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.346585, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 11.524573, min response is -2.413637.
max gradient is 8.000000, min gradient is -5.555547, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.069315, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.92, min inferred z is -3.87, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
training: epoch 111: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 8.000000, min gradient is -7.764887, learning rate is 0.000074
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.542659, learning rate is 0.000074
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.327440, learning rate is 0.000074
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.063707, learning rate is 0.000400
Net2: layer deconv3:max response is 50.176594, min response is -57.693996.
max gradient is 8.000000, min gradient is -6.526983, learning rate is 0.000200
Net2: layer bn50:max response is 24.163273, min response is -4.303387.
max gradient is 6.317098, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.835539, learning rate is 0.000200
Net2: layer bn49:max response is 13.883065, min response is -3.359339.
max gradient is 6.898043, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.957554, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.80, min inferred z is -3.49, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
Loss: 1.2376
Iteration 112 / 200
training: epoch 112: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.821587, min gradient is -8.000000, learning rate is 0.000074
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.539776, learning rate is 0.000074
Net1: layer conv1:max response is , min response is .
max gradient is 7.749166, min gradient is -8.000000, learning rate is 0.000074
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.801860, learning rate is 0.000400
Net2: layer deconv3:max response is 59.225304, min response is -64.629532.
max gradient is 5.434945, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.841782, min response is -5.162862.
max gradient is 8.000000, min gradient is -6.238782, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.290231, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 12.808661, min response is -2.766193.
max gradient is 8.000000, min gradient is -7.646923, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.282630, learning rate is 0.000200
max inferred z is 4.74, min inferred z is -4.10, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 112: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.457487, min gradient is -8.000000, learning rate is 0.000074
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.955058, learning rate is 0.000074
Net1: layer conv1:max response is , min response is .
max gradient is 5.680236, min gradient is -8.000000, learning rate is 0.000074
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 1.185810, min gradient is 0.158292, learning rate is 0.000400
Net2: layer deconv3:max response is 46.990719, min response is -51.189877.
max gradient is 8.000000, min gradient is -6.758121, learning rate is 0.000200
Net2: layer bn50:max response is 23.592113, min response is -4.607298.
max gradient is 6.057449, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.842924, learning rate is 0.000200
Net2: layer bn49:max response is 12.801881, min response is -2.569960.
max gradient is 4.020792, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.468356, learning rate is 0.000200
max inferred z is 4.49, min inferred z is -5.03, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 112: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.943529, min gradient is -8.000000, learning rate is 0.000074
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.888719, learning rate is 0.000074
Net1: layer conv1:max response is , min response is .
max gradient is 6.012005, min gradient is -8.000000, learning rate is 0.000074
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.746446, learning rate is 0.000400
Net2: layer deconv3:max response is 48.906330, min response is -53.229340.
max gradient is 6.744245, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.223242, min response is -5.042655.
max gradient is 8.000000, min gradient is -7.339103, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.703733, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 11.933721, min response is -2.950924.
max gradient is 8.000000, min gradient is -5.981137, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.110911, learning rate is 0.000200
max inferred z is 4.08, min inferred z is -4.14, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 112: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.426574, min gradient is -8.000000, learning rate is 0.000074
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.729231, learning rate is 0.000074
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.372433, learning rate is 0.000074
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.314462, learning rate is 0.000400
Net2: layer deconv3:max response is 48.108273, min response is -54.116039.
max gradient is 8.000000, min gradient is -6.223216, learning rate is 0.000200
Net2: layer bn50:max response is 20.168343, min response is -4.882025.
max gradient is 6.395324, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.696103, learning rate is 0.000200
Net2: layer bn49:max response is 12.328660, min response is -3.306825.
max gradient is 4.008198, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.808980, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.88, min inferred z is -3.72, and std is 1.00
 4.16 s (24.0 data/s) [100/100]
training: epoch 112: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.493690, min gradient is -8.000000, learning rate is 0.000074
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.237938, learning rate is 0.000074
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.011798, learning rate is 0.000074
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.907678, learning rate is 0.000400
Net2: layer deconv3:max response is 55.553062, min response is -61.895748.
max gradient is 7.684565, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.996141, min response is -4.765798.
max gradient is 8.000000, min gradient is -5.296437, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.730737, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 12.058423, min response is -2.536566.
max gradient is 8.000000, min gradient is -4.950429, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.508070, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.33, min inferred z is -3.63, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 112: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.925225, min gradient is -8.000000, learning rate is 0.000074
Net1: layer conv2:max response is , min response is .
max gradient is 8.000001, min gradient is -6.375211, learning rate is 0.000074
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.911919, learning rate is 0.000074
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.539935, learning rate is 0.000400
Net2: layer deconv3:max response is 45.378193, min response is -50.061199.
max gradient is 8.000000, min gradient is -7.786713, learning rate is 0.000200
Net2: layer bn50:max response is 18.520031, min response is -4.704414.
max gradient is 6.052743, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.898500, learning rate is 0.000200
Net2: layer bn49:max response is 12.271186, min response is -2.367801.
max gradient is 3.121654, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.895134, learning rate is 0.000200
max inferred z is 3.77, min inferred z is -3.94, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 112: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.537270, min gradient is -8.000000, learning rate is 0.000074
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.222977, learning rate is 0.000074
Net1: layer conv1:max response is , min response is .
max gradient is 7.737316, min gradient is -8.000000, learning rate is 0.000074
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.235501, learning rate is 0.000400
Net2: layer deconv3:max response is 46.202324, min response is -47.993217.
max gradient is 5.804726, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.813841, min response is -4.495584.
max gradient is 8.000000, min gradient is -5.545322, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.648963, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 13.715998, min response is -3.461813.
max gradient is 8.000000, min gradient is -3.930418, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.910825, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.93, min inferred z is -3.60, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 112: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.787714, min gradient is -8.000000, learning rate is 0.000074
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.695477, learning rate is 0.000074
Net1: layer conv1:max response is , min response is .
max gradient is 5.350516, min gradient is -8.000000, learning rate is 0.000074
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 0.360246, min gradient is -4.134789, learning rate is 0.000400
Net2: layer deconv3:max response is 43.879547, min response is -49.692722.
max gradient is 7.417741, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.987051, min response is -4.265547.
max gradient is 4.775129, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.867156, learning rate is 0.000200
Net2: layer bn49:max response is 11.505383, min response is -2.457519.
max gradient is 2.899313, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.381823, learning rate is 0.000200
max inferred z is 3.87, min inferred z is -4.72, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 112: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.265262, min gradient is -8.000000, learning rate is 0.000074
Net1: layer conv2:max response is , min response is .
max gradient is 7.927289, min gradient is -8.000000, learning rate is 0.000074
Net1: layer conv1:max response is , min response is .
max gradient is 5.275970, min gradient is -8.000000, learning rate is 0.000074
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.809362, learning rate is 0.000400
Net2: layer deconv3:max response is 54.529640, min response is -61.204811.
max gradient is 8.000000, min gradient is -7.018242, learning rate is 0.000200
Net2: layer bn50:max response is 21.707966, min response is -5.381105.
max gradient is 8.000000, min gradient is -4.485679, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.096285, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 13.512625, min response is -3.013843.
max gradient is 8.000000, min gradient is -4.615617, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.507802, learning rate is 0.000200
max inferred z is 3.74, min inferred z is -3.72, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
training: epoch 112: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 7.527199, min gradient is -8.000000, learning rate is 0.000074
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.873695, learning rate is 0.000074
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.444294, learning rate is 0.000074
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.856399, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 46.575863, min response is -50.101601.
max gradient is 5.707600, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.779718, min response is -4.148064.
max gradient is 3.451489, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.052017, learning rate is 0.000200
Net2: layer bn49:max response is 12.659136, min response is -2.708588.
max gradient is 3.461416, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.998994, learning rate is 0.000200
max inferred z is 4.09, min inferred z is -3.92, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
Loss: 1.2382
Iteration 113 / 200
training: epoch 113: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.619625, min gradient is -8.000000, learning rate is 0.000061
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.338215, learning rate is 0.000061
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.104257, learning rate is 0.000061
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.013866, learning rate is 0.000400
Net2: layer deconv3:max response is 64.557419, min response is -73.581802.
max gradient is 8.000000, min gradient is -7.258716, learning rate is 0.000200
Net2: layer bn50:max response is 26.112513, min response is -5.535469.
max gradient is 4.675354, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.977012, learning rate is 0.000200
Net2: layer bn49:max response is 14.409200, min response is -3.114172.
max gradient is 8.000000, min gradient is -4.002434, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.744990, learning rate is 0.000200
max inferred z is 4.60, min inferred z is -4.74, and std is 0.99
 4.29 s (23.3 data/s) [100/100]
training: epoch 113: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.023296, min gradient is -8.000000, learning rate is 0.000061
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.086761, learning rate is 0.000061
Net1: layer conv1:max response is , min response is .
max gradient is 5.753362, min gradient is -8.000000, learning rate is 0.000061
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.365618, learning rate is 0.000400
Net2: layer deconv3:max response is 51.585140, min response is -56.821323.
max gradient is 7.679283, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.217157, min response is -5.520382.
max gradient is 8.000000, min gradient is -3.169460, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.126660, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 14.230127, min response is -2.707384.
max gradient is 8.000000, min gradient is -5.884928, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.918983, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.13, min inferred z is -3.89, and std is 0.99
 4.40 s (22.7 data/s) [100/100]
training: epoch 113: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.476664, min gradient is -8.000000, learning rate is 0.000061
Net1: layer conv2:max response is , min response is .
max gradient is 6.879936, min gradient is -8.000000, learning rate is 0.000061
Net1: layer conv1:max response is , min response is .
max gradient is 5.971323, min gradient is -8.000000, learning rate is 0.000061
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 7.153053, min gradient is 1.459439, learning rate is 0.000400
Net2: layer deconv3:max response is 48.994095, min response is -55.933125.
max gradient is 8.000000, min gradient is -3.727465, learning rate is 0.000200
Net2: layer bn50:max response is 20.320984, min response is -4.972464.
max gradient is 8.000000, min gradient is -6.475880, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.898852, learning rate is 0.000200
Net2: layer bn49:max response is 12.763096, min response is -2.489811.
max gradient is 8.000000, min gradient is -7.531180, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.342381, learning rate is 0.000200
max inferred z is 4.02, min inferred z is -4.01, and std is 0.99
 4.31 s (23.2 data/s) [100/100]
training: epoch 113: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.616535, min gradient is -8.000000, learning rate is 0.000061
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.846405, learning rate is 0.000061
Net1: layer conv1:max response is , min response is .
max gradient is 6.959743, min gradient is -8.000000, learning rate is 0.000061
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.329935, learning rate is 0.000400
Net2: layer deconv3:max response is 58.948669, min response is -61.285423.
max gradient is 2.469881, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.704378, min response is -5.553283.
max gradient is 7.227745, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.667990, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 13.735159, min response is -2.685076.
max gradient is 8.000000, min gradient is -6.505240, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.818601, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.87, min inferred z is -4.40, and std is 0.99
 4.42 s (22.6 data/s) [100/100]
training: epoch 113: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.194267, min gradient is -8.000000, learning rate is 0.000061
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.871852, learning rate is 0.000061
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.799052, learning rate is 0.000061
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.586684, learning rate is 0.000400
Net2: layer deconv3:max response is 43.757027, min response is -49.821796.
max gradient is 8.000000, min gradient is -4.154294, learning rate is 0.000200
Net2: layer bn50:max response is 18.018459, min response is -4.187155.
max gradient is 8.000000, min gradient is -6.912477, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.779623, learning rate is 0.000200
Net2: layer bn49:max response is 14.820615, min response is -2.567820.
max gradient is 7.727528, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.982691, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.96, min inferred z is -4.40, and std is 0.99
 4.39 s (22.8 data/s) [100/100]
training: epoch 113: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.463742, min gradient is -8.000000, learning rate is 0.000061
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.229004, learning rate is 0.000061
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.088102, learning rate is 0.000061
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.290697, learning rate is 0.000400
Net2: layer deconv3:max response is 43.013821, min response is -47.167389.
max gradient is 5.174054, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.041140, min response is -3.983460.
max gradient is 7.607109, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.842585, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 14.725754, min response is -2.417695.
max gradient is 8.000000, min gradient is -6.452830, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.240306, learning rate is 0.000200
max inferred z is 3.81, min inferred z is -3.79, and std is 0.99
 4.36 s (22.9 data/s) [100/100]
training: epoch 113: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.080076, min gradient is -8.000001, learning rate is 0.000061
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.015890, learning rate is 0.000061
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.248950, learning rate is 0.000061
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 2.011169, min gradient is -3.501611, learning rate is 0.000400
Net2: layer deconv3:max response is 64.473869, min response is -73.583748.
max gradient is 8.000000, min gradient is -4.426859, learning rate is 0.000200
Net2: layer bn50:max response is 26.389849, min response is -6.262371.
max gradient is 8.000000, min gradient is -6.295845, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.722339, learning rate is 0.000200
Net2: layer bn49:max response is 16.185341, min response is -3.085493.
max gradient is 6.081380, min gradient is -8.000001, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.338189, learning rate is 0.000200
max inferred z is 3.56, min inferred z is -4.17, and std is 0.99
 4.44 s (22.5 data/s) [100/100]
training: epoch 113: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.650713, min gradient is -8.000000, learning rate is 0.000061
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.671313, learning rate is 0.000061
Net1: layer conv1:max response is , min response is .
max gradient is 6.065601, min gradient is -8.000000, learning rate is 0.000061
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.013075, learning rate is 0.000400
Net2: layer deconv3:max response is 46.604290, min response is -51.417637.
max gradient is 4.070508, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.414948, min response is -3.993540.
max gradient is 7.020348, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.279598, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 11.828422, min response is -2.751668.
max gradient is 8.000000, min gradient is -5.841969, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.127344, learning rate is 0.000200
max inferred z is 4.20, min inferred z is -4.07, and std is 0.99
 4.39 s (22.8 data/s) [100/100]
training: epoch 113: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.008656, min gradient is -8.000000, learning rate is 0.000061
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.853388, learning rate is 0.000061
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.227941, learning rate is 0.000061
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000001, min gradient is 4.412364, learning rate is 0.000400
Net2: layer deconv3:max response is 46.386795, min response is -53.533249.
max gradient is 8.000000, min gradient is -2.834784, learning rate is 0.000200
Net2: layer bn50:max response is 19.071283, min response is -4.368069.
max gradient is 8.000000, min gradient is -6.940727, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.381138, learning rate is 0.000200
Net2: layer bn49:max response is 12.269573, min response is -3.293731.
max gradient is 6.730703, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.544425, learning rate is 0.000200
max inferred z is 4.02, min inferred z is -4.25, and std is 0.99
 4.39 s (22.8 data/s) [100/100]
training: epoch 113: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.919509, min gradient is -8.000000, learning rate is 0.000061
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.746260, learning rate is 0.000061
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.788424, learning rate is 0.000061
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.326321, learning rate is 0.000400
Net2: layer deconv3:max response is 56.850044, min response is -59.872105.
max gradient is 3.480597, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.689993, min response is -5.512866.
max gradient is 6.920841, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.529574, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 13.739829, min response is -2.905560.
max gradient is 8.000000, min gradient is -6.051654, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.214849, learning rate is 0.000200
max inferred z is 4.09, min inferred z is -3.71, and std is 0.99
 4.32 s (23.2 data/s) [100/100]
Loss: 1.2494
Iteration 114 / 200
training: epoch 114: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.391765, min gradient is -8.000000, learning rate is 0.000061
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.810863, learning rate is 0.000061
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.828941, learning rate is 0.000061
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.365732, learning rate is 0.000400
Net2: layer deconv3:max response is 51.988941, min response is -59.697903.
max gradient is 8.000000, min gradient is -4.925817, learning rate is 0.000200
Net2: layer bn50:max response is 21.169693, min response is -4.786428.
max gradient is 8.000000, min gradient is -6.361481, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.052618, learning rate is 0.000200
Net2: layer bn49:max response is 12.653932, min response is -2.684554.
max gradient is 6.534526, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000001, min gradient is -6.525687, learning rate is 0.000200
max inferred z is 3.87, min inferred z is -3.91, and std is 1.00
 4.21 s (23.7 data/s) [100/100]
training: epoch 114: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.102273, min gradient is -8.000000, learning rate is 0.000061
Net1: layer conv2:max response is , min response is .
max gradient is 7.825365, min gradient is -8.000000, learning rate is 0.000061
Net1: layer conv1:max response is , min response is .
max gradient is 5.768326, min gradient is -8.000000, learning rate is 0.000061
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.202081, learning rate is 0.000400
Net2: layer deconv3:max response is 46.978146, min response is -50.957073.
max gradient is 5.617431, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.736408, min response is -4.080640.
max gradient is 7.431743, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.656971, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 11.991392, min response is -2.426863.
max gradient is 8.000000, min gradient is -7.262114, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.258011, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.21, min inferred z is -4.14, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 114: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.470009, min gradient is -8.000000, learning rate is 0.000061
Net1: layer conv2:max response is , min response is .
max gradient is 6.978583, min gradient is -8.000000, learning rate is 0.000061
Net1: layer conv1:max response is , min response is .
max gradient is 6.772161, min gradient is -8.000000, learning rate is 0.000061
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.550312, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 47.643818, min response is -55.441288.
max gradient is 8.000000, min gradient is -5.309553, learning rate is 0.000200
Net2: layer bn50:max response is 23.289852, min response is -4.966790.
max gradient is 8.000000, min gradient is -6.779124, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.714711, learning rate is 0.000200
Net2: layer bn49:max response is 14.852095, min response is -2.618308.
max gradient is 5.393412, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.853808, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.82, min inferred z is -3.86, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 114: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.410770, min gradient is -8.000000, learning rate is 0.000061
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.873094, learning rate is 0.000061
Net1: layer conv1:max response is , min response is .
max gradient is 7.615009, min gradient is -8.000000, learning rate is 0.000061
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.606494, learning rate is 0.000400
Net2: layer deconv3:max response is 51.371361, min response is -56.843262.
max gradient is 3.573662, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.983805, min response is -5.082930.
max gradient is 6.794601, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.647509, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 13.297390, min response is -2.946757.
max gradient is 8.000000, min gradient is -5.437789, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.329685, learning rate is 0.000200
max inferred z is 4.65, min inferred z is -4.14, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 114: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.574663, min gradient is -8.000000, learning rate is 0.000061
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.179874, learning rate is 0.000061
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.791879, learning rate is 0.000061
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 6.280535, min gradient is -5.891099, learning rate is 0.000400
Net2: layer deconv3:max response is 45.979458, min response is -51.916203.
max gradient is 8.000000, min gradient is -2.203996, learning rate is 0.000200
Net2: layer bn50:max response is 22.049297, min response is -4.491663.
max gradient is 8.000000, min gradient is -7.574745, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.283560, learning rate is 0.000200
Net2: layer bn49:max response is 11.816244, min response is -3.154172.
max gradient is 8.000000, min gradient is -7.151219, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.155553, learning rate is 0.000200
max inferred z is 4.03, min inferred z is -3.75, and std is 1.00
 4.18 s (23.9 data/s) [100/100]
training: epoch 114: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.052810, min gradient is -8.000000, learning rate is 0.000061
Net1: layer conv2:max response is , min response is .
max gradient is 7.810728, min gradient is -8.000000, learning rate is 0.000061
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.231934, learning rate is 0.000061
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.208232, learning rate is 0.000400
Net2: layer deconv3:max response is 54.675877, min response is -60.292377.
max gradient is 2.481261, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.521879, min response is -5.247244.
max gradient is 8.000000, min gradient is -7.905034, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.980839, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 13.461053, min response is -2.731560.
max gradient is 8.000000, min gradient is -6.802593, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.833415, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.34, min inferred z is -4.08, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 114: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.466905, min gradient is -8.000000, learning rate is 0.000061
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.280963, learning rate is 0.000061
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.461935, learning rate is 0.000061
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.311298, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 47.455963, min response is -55.431881.
max gradient is 8.000000, min gradient is -3.089802, learning rate is 0.000200
Net2: layer bn50:max response is 19.418606, min response is -4.712291.
max gradient is 8.000000, min gradient is -7.386902, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.487548, learning rate is 0.000200
Net2: layer bn49:max response is 12.995150, min response is -3.182169.
max gradient is 8.000000, min gradient is -7.477306, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.757752, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.71, min inferred z is -3.89, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 114: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.226740, min gradient is -8.000000, learning rate is 0.000061
Net1: layer conv2:max response is , min response is .
max gradient is 7.665052, min gradient is -8.000000, learning rate is 0.000061
Net1: layer conv1:max response is , min response is .
max gradient is 6.232711, min gradient is -8.000000, learning rate is 0.000061
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.390228, learning rate is 0.000400
Net2: layer deconv3:max response is 59.341179, min response is -65.857613.
max gradient is 5.362129, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.318464, min response is -5.123739.
max gradient is 8.000000, min gradient is -7.969203, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.758300, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 16.050394, min response is -2.440054.
max gradient is 8.000000, min gradient is -5.503656, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.609198, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.85, min inferred z is -4.14, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 114: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.452505, min gradient is -8.000000, learning rate is 0.000061
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.272716, learning rate is 0.000061
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.997599, learning rate is 0.000061
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.905787, learning rate is 0.000400
Net2: layer deconv3:max response is 53.423016, min response is -61.421822.
max gradient is 8.000000, min gradient is -5.487906, learning rate is 0.000200
Net2: layer bn50:max response is 21.421717, min response is -5.017124.
max gradient is 6.250652, min gradient is -8.000001, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.082251, learning rate is 0.000200
Net2: layer bn49:max response is 14.322340, min response is -3.057359.
max gradient is 6.830048, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.164554, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 5.03, min inferred z is -4.20, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
training: epoch 114: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.481152, min gradient is -8.000000, learning rate is 0.000061
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.142934, learning rate is 0.000061
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.689669, learning rate is 0.000061
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.631320, learning rate is 0.000400
Net2: layer deconv3:max response is 46.693306, min response is -51.532730.
max gradient is 8.000000, min gradient is -7.965365, learning rate is 0.000200
Net2: layer bn50:max response is 18.597391, min response is -4.554451.
max gradient is 8.000000, min gradient is -5.006119, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.820107, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 15.783087, min response is -2.622409.
max gradient is 8.000001, min gradient is -6.493304, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 4.728484, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.08, min inferred z is -4.12, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
Loss: 1.3022
Iteration 115 / 200
training: epoch 115: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.606975, min gradient is -8.000000, learning rate is 0.000051
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.167450, learning rate is 0.000051
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.114270, learning rate is 0.000051
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -1.989235, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 48.477528, min response is -54.985889.
max gradient is 6.556765, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.092018, min response is -4.589776.
max gradient is 3.880269, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.457841, learning rate is 0.000200
Net2: layer bn49:max response is 14.468837, min response is -3.055225.
max gradient is 5.085473, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.392132, learning rate is 0.000200
max inferred z is 3.94, min inferred z is -4.01, and std is 1.00
 4.36 s (23.0 data/s) [100/100]
training: epoch 115: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.356196, min gradient is -8.000000, learning rate is 0.000051
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.964988, learning rate is 0.000051
Net1: layer conv1:max response is , min response is .
max gradient is 6.744984, min gradient is -8.000000, learning rate is 0.000051
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.112941, learning rate is 0.000400
Net2: layer deconv3:max response is 51.144737, min response is -51.313061.
max gradient is 7.196247, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 17.991053, min response is -4.206413.
max gradient is 6.080121, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 3.863430, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 12.636250, min response is -3.908824.
max gradient is 8.000000, min gradient is -6.651707, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.103012, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.96, min inferred z is -3.85, and std is 1.00
 4.41 s (22.7 data/s) [100/100]
training: epoch 115: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.099344, min gradient is -8.000000, learning rate is 0.000051
Net1: layer conv2:max response is , min response is .
max gradient is 6.842746, min gradient is -8.000000, learning rate is 0.000051
Net1: layer conv1:max response is , min response is .
max gradient is 6.888636, min gradient is -8.000000, learning rate is 0.000051
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.279169, learning rate is 0.000400
Net2: layer deconv3:max response is 51.056896, min response is -60.319958.
max gradient is 8.000000, min gradient is -4.883814, learning rate is 0.000200
Net2: layer bn50:max response is 19.370127, min response is -4.854274.
max gradient is 8.000000, min gradient is -6.659419, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.154807, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.474874, min response is -2.644105.
max gradient is 4.591867, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.190943, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.75, min inferred z is -4.11, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 115: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.083558, min gradient is -8.000000, learning rate is 0.000051
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.999666, learning rate is 0.000051
Net1: layer conv1:max response is , min response is .
max gradient is 6.014828, min gradient is -8.000000, learning rate is 0.000051
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.057078, learning rate is 0.000400
Net2: layer deconv3:max response is 50.326134, min response is -48.815426.
max gradient is 5.409667, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.543755, min response is -4.378343.
max gradient is 6.271524, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.117800, learning rate is 0.000200
Net2: layer bn49:max response is 13.270758, min response is -2.564739.
max gradient is 8.000000, min gradient is -6.163391, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.531201, learning rate is 0.000200
max inferred z is 3.82, min inferred z is -3.92, and std is 1.00
 4.43 s (22.6 data/s) [100/100]
training: epoch 115: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.215912, min gradient is -8.000000, learning rate is 0.000051
Net1: layer conv2:max response is , min response is .
max gradient is 8.000001, min gradient is -7.562826, learning rate is 0.000051
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.270219, learning rate is 0.000051
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.373503, learning rate is 0.000400
Net2: layer deconv3:max response is 47.968960, min response is -53.479229.
max gradient is 8.000000, min gradient is -5.511927, learning rate is 0.000200
Net2: layer bn50:max response is 21.259296, min response is -5.259404.
max gradient is 6.820244, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.124679, learning rate is 0.000200
Net2: layer bn49:max response is 12.550104, min response is -2.958227.
max gradient is 4.101079, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.751127, learning rate is 0.000200
max inferred z is 4.03, min inferred z is -3.93, and std is 1.00
 4.43 s (22.6 data/s) [100/100]
training: epoch 115: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.885456, min gradient is -8.000000, learning rate is 0.000051
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.209370, learning rate is 0.000051
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.351563, learning rate is 0.000051
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.732979, learning rate is 0.000400
Net2: layer deconv3:max response is 63.002296, min response is -57.368259.
max gradient is 6.061145, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.812778, min response is -4.797028.
max gradient is 8.000000, min gradient is -5.459691, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.991724, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 12.805864, min response is -2.668684.
max gradient is 8.000000, min gradient is -5.474422, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.822032, learning rate is 0.000200
max inferred z is 4.17, min inferred z is -3.76, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
training: epoch 115: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.438065, min gradient is -8.000000, learning rate is 0.000051
Net1: layer conv2:max response is , min response is .
max gradient is 7.779384, min gradient is -8.000000, learning rate is 0.000051
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.508141, learning rate is 0.000051
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 1.811553, min gradient is -1.800573, learning rate is 0.000400
Net2: layer deconv3:max response is 47.401066, min response is -55.201050.
max gradient is 6.894501, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.893457, min response is -5.265552.
max gradient is 6.091290, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.169812, learning rate is 0.000200
Net2: layer bn49:max response is 13.115735, min response is -2.561093.
max gradient is 5.314220, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.614123, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.76, min inferred z is -3.83, and std is 1.00
 4.38 s (22.9 data/s) [100/100]
training: epoch 115: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.086962, min gradient is -8.000000, learning rate is 0.000051
Net1: layer conv2:max response is , min response is .
max gradient is 8.000001, min gradient is -7.845554, learning rate is 0.000051
Net1: layer conv1:max response is , min response is .
max gradient is 6.134940, min gradient is -8.000000, learning rate is 0.000051
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.568986, learning rate is 0.000400
Net2: layer deconv3:max response is 47.368126, min response is -51.440304.
max gradient is 8.000000, min gradient is -7.863088, learning rate is 0.000200
Net2: layer bn50:max response is 20.302170, min response is -4.794309.
max gradient is 8.000000, min gradient is -6.076325, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.069087, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 13.282930, min response is -2.616234.
max gradient is 8.000000, min gradient is -7.093384, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.632239, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.89, min inferred z is -3.91, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 115: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.356190, min gradient is -8.000000, learning rate is 0.000051
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.217024, learning rate is 0.000051
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.869065, learning rate is 0.000051
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -1.006298, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 46.588024, min response is -50.460320.
max gradient is 7.319081, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.700880, min response is -4.425256.
max gradient is 5.517564, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.284299, learning rate is 0.000200
Net2: layer bn49:max response is 14.839142, min response is -2.885355.
max gradient is 4.134322, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.639928, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.52, min inferred z is -4.34, and std is 1.00
 4.43 s (22.6 data/s) [100/100]
training: epoch 115: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 6.019973, min gradient is -8.000000, learning rate is 0.000051
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.784165, learning rate is 0.000051
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.674532, learning rate is 0.000051
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.857958, learning rate is 0.000400
Net2: layer deconv3:max response is 50.722126, min response is -57.742485.
max gradient is 8.000000, min gradient is -7.998077, learning rate is 0.000200
Net2: layer bn50:max response is 22.100679, min response is -5.522305.
max gradient is 8.000000, min gradient is -5.727623, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.346097, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 14.469679, min response is -3.117731.
max gradient is 8.000000, min gradient is -6.543059, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.618052, learning rate is 0.000200
max inferred z is 4.11, min inferred z is -3.95, and std is 1.00
 4.41 s (22.7 data/s) [100/100]
Loss: 1.2565
Iteration 116 / 200
training: epoch 116: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.248578, min gradient is -8.000000, learning rate is 0.000051
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.131824, learning rate is 0.000051
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.192722, learning rate is 0.000051
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -4.688587, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 61.623653, min response is -69.439468.
max gradient is 8.000000, min gradient is -5.701910, learning rate is 0.000200
Net2: layer bn50:max response is 23.801466, min response is -5.583800.
max gradient is 7.507523, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.388775, learning rate is 0.000200
Net2: layer bn49:max response is 16.774164, min response is -3.006927.
max gradient is 4.479326, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.082785, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.90, min inferred z is -4.11, and std is 1.01
 4.17 s (24.0 data/s) [100/100]
training: epoch 116: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.582767, min gradient is -8.000000, learning rate is 0.000051
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.752206, learning rate is 0.000051
Net1: layer conv1:max response is , min response is .
max gradient is 6.551153, min gradient is -8.000000, learning rate is 0.000051
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.363975, learning rate is 0.000400
Net2: layer deconv3:max response is 56.375458, min response is -62.483227.
max gradient is 5.683050, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.133404, min response is -5.690856.
max gradient is 7.431225, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.386131, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 14.497688, min response is -2.927355.
max gradient is 8.000000, min gradient is -6.210235, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.907276, learning rate is 0.000200
max inferred z is 3.79, min inferred z is -3.83, and std is 1.01
 4.27 s (23.4 data/s) [100/100]
training: epoch 116: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.807986, min gradient is -8.000000, learning rate is 0.000051
Net1: layer conv2:max response is , min response is .
max gradient is 6.144930, min gradient is -8.000000, learning rate is 0.000051
Net1: layer conv1:max response is , min response is .
max gradient is 6.306085, min gradient is -8.000000, learning rate is 0.000051
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.069085, learning rate is 0.000400
Net2: layer deconv3:max response is 61.902607, min response is -72.652328.
max gradient is 8.000001, min gradient is -4.684575, learning rate is 0.000200
Net2: layer bn50:max response is 25.712664, min response is -6.265936.
max gradient is 8.000000, min gradient is -6.842104, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.479063, learning rate is 0.000200
Net2: layer bn49:max response is 17.718901, min response is -2.688235.
max gradient is 8.000000, min gradient is -7.606519, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.958220, learning rate is 0.000200
max inferred z is 4.10, min inferred z is -3.76, and std is 1.01
 4.24 s (23.6 data/s) [100/100]
training: epoch 116: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.009068, min gradient is -8.000000, learning rate is 0.000051
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.824323, learning rate is 0.000051
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.604923, learning rate is 0.000051
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.445839, learning rate is 0.000400
Net2: layer deconv3:max response is 49.696476, min response is -54.846539.
max gradient is 3.517151, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.545963, min response is -4.395596.
max gradient is 7.233632, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.396623, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 14.872833, min response is -2.385391.
max gradient is 8.000000, min gradient is -6.524858, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.460641, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.19, min inferred z is -4.68, and std is 1.01
 4.24 s (23.6 data/s) [100/100]
training: epoch 116: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.964074, min gradient is -8.000000, learning rate is 0.000051
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.574605, learning rate is 0.000051
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.230261, learning rate is 0.000051
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.122950, learning rate is 0.000400
Net2: layer deconv3:max response is 50.484692, min response is -60.376957.
max gradient is 8.000000, min gradient is -2.968760, learning rate is 0.000200
Net2: layer bn50:max response is 19.961052, min response is -5.062274.
max gradient is 8.000000, min gradient is -6.679705, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.416417, learning rate is 0.000200
Net2: layer bn49:max response is 14.627883, min response is -3.614756.
max gradient is 7.771076, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.213976, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.85, min inferred z is -4.26, and std is 1.01
 4.25 s (23.5 data/s) [100/100]
training: epoch 116: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.702566, min gradient is -8.000000, learning rate is 0.000051
Net1: layer conv2:max response is , min response is .
max gradient is 7.408881, min gradient is -8.000000, learning rate is 0.000051
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.056699, learning rate is 0.000051
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.925613, learning rate is 0.000400
Net2: layer deconv3:max response is 45.494415, min response is -46.566360.
max gradient is 2.774533, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.361925, min response is -4.194628.
max gradient is 7.007425, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.536265, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 13.302045, min response is -2.684273.
max gradient is 8.000000, min gradient is -6.642471, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.660276, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.00, min inferred z is -3.72, and std is 1.01
 4.41 s (22.7 data/s) [100/100]
training: epoch 116: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.271912, min gradient is -8.000000, learning rate is 0.000051
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.688141, learning rate is 0.000051
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.950870, learning rate is 0.000051
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.002361, learning rate is 0.000400
Net2: layer deconv3:max response is 43.645061, min response is -48.968044.
max gradient is 8.000000, min gradient is -2.820704, learning rate is 0.000200
Net2: layer bn50:max response is 17.526546, min response is -4.325664.
max gradient is 8.000000, min gradient is -6.456261, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.621585, learning rate is 0.000200
Net2: layer bn49:max response is 11.983199, min response is -2.578841.
max gradient is 8.000000, min gradient is -7.835729, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.512909, learning rate is 0.000200
max inferred z is 3.87, min inferred z is -4.44, and std is 1.01
 4.31 s (23.2 data/s) [100/100]
training: epoch 116: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.875208, min gradient is -8.000001, learning rate is 0.000051
Net1: layer conv2:max response is , min response is .
max gradient is 7.576219, min gradient is -8.000000, learning rate is 0.000051
Net1: layer conv1:max response is , min response is .
max gradient is 6.024539, min gradient is -8.000000, learning rate is 0.000051
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.022019, learning rate is 0.000400
Net2: layer deconv3:max response is 49.531731, min response is -52.014454.
max gradient is 4.863969, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.100254, min response is -4.560425.
max gradient is 6.303984, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.624437, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 15.272645, min response is -2.834770.
max gradient is 8.000000, min gradient is -6.251809, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.251003, learning rate is 0.000200
max inferred z is 3.83, min inferred z is -4.00, and std is 1.01
 4.37 s (22.9 data/s) [100/100]
training: epoch 116: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.055969, min gradient is -8.000000, learning rate is 0.000051
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.700470, learning rate is 0.000051
Net1: layer conv1:max response is , min response is .
max gradient is 6.339319, min gradient is -8.000000, learning rate is 0.000051
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.575403, learning rate is 0.000400
Net2: layer deconv3:max response is 55.500313, min response is -62.781700.
max gradient is 8.000000, min gradient is -4.306387, learning rate is 0.000200
Net2: layer bn50:max response is 20.856167, min response is -5.397953.
max gradient is 8.000000, min gradient is -6.040467, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.781653, learning rate is 0.000200
Net2: layer bn49:max response is 16.020964, min response is -2.647293.
max gradient is 5.354446, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.403417, learning rate is 0.000200
max inferred z is 3.82, min inferred z is -3.68, and std is 1.01
 4.33 s (23.1 data/s) [100/100]
training: epoch 116: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.300692, min gradient is -8.000000, learning rate is 0.000051
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.845466, learning rate is 0.000051
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.427246, learning rate is 0.000051
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.318912, learning rate is 0.000400
Net2: layer deconv3:max response is 47.901566, min response is -53.123531.
max gradient is 4.742677, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.049444, min response is -4.566618.
max gradient is 6.230644, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.231914, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 14.369095, min response is -3.143240.
max gradient is 8.000000, min gradient is -4.988032, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.899027, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.11, min inferred z is -3.59, and std is 1.01
 4.32 s (23.1 data/s) [100/100]
Loss: 1.225
Iteration 117 / 200
training: epoch 117: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.257616, min gradient is -8.000000, learning rate is 0.000042
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.181495, learning rate is 0.000042
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.603257, learning rate is 0.000042
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.198357, learning rate is 0.000400
Net2: layer deconv3:max response is 49.575466, min response is -58.431973.
max gradient is 8.000000, min gradient is -3.690595, learning rate is 0.000200
Net2: layer bn50:max response is 21.968838, min response is -5.183399.
max gradient is 8.000000, min gradient is -6.089406, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.963612, learning rate is 0.000200
Net2: layer bn49:max response is 14.349846, min response is -2.878084.
max gradient is 6.768091, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.858431, learning rate is 0.000200
max inferred z is 3.87, min inferred z is -4.01, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 117: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.478838, min gradient is -8.000000, learning rate is 0.000042
Net1: layer conv2:max response is , min response is .
max gradient is 6.921473, min gradient is -8.000000, learning rate is 0.000042
Net1: layer conv1:max response is , min response is .
max gradient is 6.602066, min gradient is -8.000000, learning rate is 0.000042
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.422810, learning rate is 0.000400
Net2: layer deconv3:max response is 49.148033, min response is -47.045662.
max gradient is 3.316491, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 17.589861, min response is -3.915486.
max gradient is 6.818857, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.841980, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 13.442739, min response is -3.221426.
max gradient is 8.000000, min gradient is -6.574073, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.935932, learning rate is 0.000200
max inferred z is 3.80, min inferred z is -3.83, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 117: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.822480, min gradient is -8.000000, learning rate is 0.000042
Net1: layer conv2:max response is , min response is .
max gradient is 6.376657, min gradient is -8.000000, learning rate is 0.000042
Net1: layer conv1:max response is , min response is .
max gradient is 6.941755, min gradient is -8.000000, learning rate is 0.000042
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.802499, learning rate is 0.000400
Net2: layer deconv3:max response is 47.823750, min response is -52.598469.
max gradient is 8.000000, min gradient is -4.777739, learning rate is 0.000200
Net2: layer bn50:max response is 17.916695, min response is -4.549479.
max gradient is 8.000000, min gradient is -6.690227, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.862552, learning rate is 0.000200
Net2: layer bn49:max response is 13.864403, min response is -2.768732.
max gradient is 8.000000, min gradient is -6.763940, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.700132, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.37, min inferred z is -4.03, and std is 1.00
 4.46 s (22.4 data/s) [100/100]
training: epoch 117: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.936129, min gradient is -8.000000, learning rate is 0.000042
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.855933, learning rate is 0.000042
Net1: layer conv1:max response is , min response is .
max gradient is 7.946159, min gradient is -8.000000, learning rate is 0.000042
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.252556, learning rate is 0.000400
Net2: layer deconv3:max response is 68.573738, min response is -50.652710.
max gradient is 4.680668, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.305382, min response is -4.211404.
max gradient is 6.928598, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.771304, min gradient is -8.000001, learning rate is 0.000200
Net2: layer bn49:max response is 14.718625, min response is -2.805867.
max gradient is 8.000000, min gradient is -5.962749, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.964790, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.14, min inferred z is -3.89, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 117: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.692882, min gradient is -8.000000, learning rate is 0.000042
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.269513, learning rate is 0.000042
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.099060, learning rate is 0.000042
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 0.943153, learning rate is 0.000400
Net2: layer deconv3:max response is 45.771626, min response is -51.396378.
max gradient is 8.000000, min gradient is -4.112947, learning rate is 0.000200
Net2: layer bn50:max response is 18.043079, min response is -4.550731.
max gradient is 8.000000, min gradient is -6.259884, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.826158, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 13.653106, min response is -2.787186.
max gradient is 5.772181, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.276650, learning rate is 0.000200
max inferred z is 3.57, min inferred z is -4.10, and std is 1.00
 4.17 s (24.0 data/s) [100/100]
training: epoch 117: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.685752, min gradient is -8.000000, learning rate is 0.000042
Net1: layer conv2:max response is , min response is .
max gradient is 7.372776, min gradient is -8.000000, learning rate is 0.000042
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.868579, learning rate is 0.000042
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.392859, learning rate is 0.000400
Net2: layer deconv3:max response is 57.756817, min response is -52.552361.
max gradient is 4.191727, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.155401, min response is -4.486483.
max gradient is 6.317407, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.996044, learning rate is 0.000200
Net2: layer bn49:max response is 15.366274, min response is -2.786452.
max gradient is 8.000000, min gradient is -6.404645, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.759344, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.71, min inferred z is -4.04, and std is 1.00
 4.30 s (23.3 data/s) [100/100]
training: epoch 117: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.175673, min gradient is -8.000000, learning rate is 0.000042
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.633202, learning rate is 0.000042
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.739683, learning rate is 0.000042
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.129170, learning rate is 0.000400
Net2: layer deconv3:max response is 52.893185, min response is -55.580132.
max gradient is 8.000000, min gradient is -4.595698, learning rate is 0.000200
Net2: layer bn50:max response is 19.659519, min response is -4.874171.
max gradient is 8.000000, min gradient is -5.751974, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.646747, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 15.121761, min response is -2.770199.
max gradient is 6.348847, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.040103, learning rate is 0.000200
max inferred z is 3.42, min inferred z is -3.87, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 117: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.988759, min gradient is -8.000000, learning rate is 0.000042
Net1: layer conv2:max response is , min response is .
max gradient is 7.873674, min gradient is -8.000000, learning rate is 0.000042
Net1: layer conv1:max response is , min response is .
max gradient is 6.039681, min gradient is -8.000000, learning rate is 0.000042
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.519250, learning rate is 0.000400
Net2: layer deconv3:max response is 50.658974, min response is -51.144428.
max gradient is 3.309357, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.211660, min response is -4.161031.
max gradient is 6.978791, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.984063, learning rate is 0.000200
Net2: layer bn49:max response is 13.402294, min response is -3.083220.
max gradient is 8.000000, min gradient is -5.028701, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.928660, learning rate is 0.000200
max inferred z is 3.59, min inferred z is -3.94, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 117: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.967728, min gradient is -8.000000, learning rate is 0.000042
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.339725, learning rate is 0.000042
Net1: layer conv1:max response is , min response is .
max gradient is 7.599605, min gradient is -8.000000, learning rate is 0.000042
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 1.468224, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 53.815262, min response is -51.939941.
max gradient is 8.000000, min gradient is -2.831602, learning rate is 0.000200
Net2: layer bn50:max response is 18.553085, min response is -3.975378.
max gradient is 8.000001, min gradient is -6.991076, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.962870, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 13.761003, min response is -2.771536.
max gradient is 7.614170, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.692563, learning rate is 0.000200
max inferred z is 3.95, min inferred z is -3.69, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 117: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.203004, min gradient is -8.000000, learning rate is 0.000042
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.063172, learning rate is 0.000042
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.129869, learning rate is 0.000042
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.239648, learning rate is 0.000400
Net2: layer deconv3:max response is 64.258652, min response is -73.081924.
max gradient is 3.122631, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 24.000786, min response is -6.006055.
max gradient is 6.215814, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.673465, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.790876, min response is -2.882123.
max gradient is 8.000000, min gradient is -6.457620, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.490973, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.71, min inferred z is -4.05, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
Loss: 1.2236
Iteration 118 / 200
training: epoch 118: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.024751, min gradient is -8.000000, learning rate is 0.000042
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.585199, learning rate is 0.000042
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.700734, learning rate is 0.000042
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.273331, learning rate is 0.000400
Net2: layer deconv3:max response is 53.466473, min response is -43.013954.
max gradient is 8.000000, min gradient is -3.627344, learning rate is 0.000200
Net2: layer bn50:max response is 18.533749, min response is -3.707232.
max gradient is 8.000000, min gradient is -6.120564, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000001, min gradient is -6.983047, learning rate is 0.000200
Net2: layer bn49:max response is 12.354148, min response is -2.908087.
max gradient is 7.275548, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.536980, learning rate is 0.000200
max inferred z is 3.74, min inferred z is -3.81, and std is 0.99
 4.28 s (23.4 data/s) [100/100]
training: epoch 118: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.346270, min gradient is -8.000000, learning rate is 0.000042
Net1: layer conv2:max response is , min response is .
max gradient is 7.238196, min gradient is -8.000000, learning rate is 0.000042
Net1: layer conv1:max response is , min response is .
max gradient is 6.842511, min gradient is -8.000000, learning rate is 0.000042
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.195399, learning rate is 0.000400
Net2: layer deconv3:max response is 54.362202, min response is -43.276199.
max gradient is 2.189253, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 17.990227, min response is -4.041170.
max gradient is 7.209209, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.577932, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 13.105149, min response is -2.899794.
max gradient is 8.000000, min gradient is -5.437782, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.071121, learning rate is 0.000200
max inferred z is 4.14, min inferred z is -3.78, and std is 0.99
 4.23 s (23.6 data/s) [100/100]
training: epoch 118: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.688086, min gradient is -8.000000, learning rate is 0.000042
Net1: layer conv2:max response is , min response is .
max gradient is 6.424558, min gradient is -8.000000, learning rate is 0.000042
Net1: layer conv1:max response is , min response is .
max gradient is 6.363885, min gradient is -8.000000, learning rate is 0.000042
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 3.819997, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 59.055706, min response is -50.930855.
max gradient is 8.000000, min gradient is -2.980707, learning rate is 0.000200
Net2: layer bn50:max response is 18.325253, min response is -4.543869.
max gradient is 8.000000, min gradient is -7.108151, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.926567, learning rate is 0.000200
Net2: layer bn49:max response is 13.713604, min response is -3.481332.
max gradient is 7.022374, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.406863, learning rate is 0.000200
max inferred z is 4.05, min inferred z is -3.95, and std is 0.99
 4.39 s (22.8 data/s) [100/100]
training: epoch 118: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.763417, min gradient is -8.000000, learning rate is 0.000042
Net1: layer conv2:max response is , min response is .
max gradient is 7.438013, min gradient is -8.000000, learning rate is 0.000042
Net1: layer conv1:max response is , min response is .
max gradient is 6.014853, min gradient is -8.000000, learning rate is 0.000042
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.305449, learning rate is 0.000400
Net2: layer deconv3:max response is 63.734566, min response is -59.043488.
max gradient is 3.603902, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.963108, min response is -5.047629.
max gradient is 6.631171, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.911662, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 16.049921, min response is -2.917213.
max gradient is 8.000000, min gradient is -5.606294, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.573278, learning rate is 0.000200
max inferred z is 4.67, min inferred z is -4.31, and std is 0.99
 4.32 s (23.1 data/s) [100/100]
training: epoch 118: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.807518, min gradient is -8.000000, learning rate is 0.000042
Net1: layer conv2:max response is , min response is .
max gradient is 7.844102, min gradient is -8.000000, learning rate is 0.000042
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.325907, learning rate is 0.000042
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.405633, learning rate is 0.000400
Net2: layer deconv3:max response is 53.507526, min response is -46.254089.
max gradient is 8.000000, min gradient is -5.829829, learning rate is 0.000200
Net2: layer bn50:max response is 19.472130, min response is -4.512447.
max gradient is 8.000000, min gradient is -6.794600, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.602424, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 15.354418, min response is -3.213007.
max gradient is 6.223021, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.046989, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.96, min inferred z is -3.58, and std is 0.99
 4.39 s (22.8 data/s) [100/100]
training: epoch 118: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.469806, min gradient is -8.000000, learning rate is 0.000042
Net1: layer conv2:max response is , min response is .
max gradient is 7.467468, min gradient is -8.000000, learning rate is 0.000042
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.311177, learning rate is 0.000042
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.436785, learning rate is 0.000400
Net2: layer deconv3:max response is 61.735310, min response is -65.361885.
max gradient is 4.586372, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.292505, min response is -5.542549.
max gradient is 6.312037, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.804282, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.569538, min response is -2.687781.
max gradient is 8.000000, min gradient is -5.662325, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.162639, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.61, min inferred z is -4.13, and std is 0.99
 4.18 s (23.9 data/s) [100/100]
training: epoch 118: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.927231, min gradient is -8.000000, learning rate is 0.000042
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.077428, learning rate is 0.000042
Net1: layer conv1:max response is , min response is .
max gradient is 7.786720, min gradient is -8.000000, learning rate is 0.000042
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.058616, learning rate is 0.000400
Net2: layer deconv3:max response is 48.201221, min response is -42.741119.
max gradient is 8.000000, min gradient is -4.904750, learning rate is 0.000200
Net2: layer bn50:max response is 17.663040, min response is -3.775220.
max gradient is 8.000000, min gradient is -6.482013, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.705890, learning rate is 0.000200
Net2: layer bn49:max response is 13.756528, min response is -2.810341.
max gradient is 6.037516, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.777320, learning rate is 0.000200
max inferred z is 4.76, min inferred z is -4.12, and std is 0.99
 4.17 s (24.0 data/s) [100/100]
training: epoch 118: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.872386, min gradient is -8.000000, learning rate is 0.000042
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.430830, learning rate is 0.000042
Net1: layer conv1:max response is , min response is .
max gradient is 6.360680, min gradient is -8.000000, learning rate is 0.000042
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.533724, learning rate is 0.000400
Net2: layer deconv3:max response is 52.471622, min response is -51.876965.
max gradient is 5.363755, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.485420, min response is -4.654588.
max gradient is 6.865896, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.359430, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 14.064568, min response is -2.953119.
max gradient is 8.000000, min gradient is -7.312335, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.663335, min gradient is -8.000001, learning rate is 0.000200
max inferred z is 4.39, min inferred z is -3.84, and std is 0.99
 4.41 s (22.7 data/s) [100/100]
training: epoch 118: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.922814, min gradient is -8.000000, learning rate is 0.000042
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.635740, learning rate is 0.000042
Net1: layer conv1:max response is , min response is .
max gradient is 7.387449, min gradient is -8.000000, learning rate is 0.000042
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.140069, learning rate is 0.000400
Net2: layer deconv3:max response is 54.435757, min response is -46.658501.
max gradient is 8.000000, min gradient is -5.599433, learning rate is 0.000200
Net2: layer bn50:max response is 18.959906, min response is -4.467313.
max gradient is 8.000000, min gradient is -7.053902, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.834912, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 14.106662, min response is -3.002299.
max gradient is 6.993985, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.382904, learning rate is 0.000200
max inferred z is 4.72, min inferred z is -4.71, and std is 0.99
 4.46 s (22.4 data/s) [100/100]
training: epoch 118: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.899769, min gradient is -8.000000, learning rate is 0.000042
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.923125, learning rate is 0.000042
Net1: layer conv1:max response is , min response is .
max gradient is 7.923186, min gradient is -8.000000, learning rate is 0.000042
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.248392, learning rate is 0.000400
Net2: layer deconv3:max response is 57.879910, min response is -45.559025.
max gradient is 6.761968, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.794310, min response is -3.717543.
max gradient is 8.000000, min gradient is -6.926673, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.831747, learning rate is 0.000200
Net2: layer bn49:max response is 12.908657, min response is -3.282317.
max gradient is 7.420269, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.693597, learning rate is 0.000200
max inferred z is 3.94, min inferred z is -3.99, and std is 0.99
 4.37 s (22.9 data/s) [100/100]
Loss: 1.1889
Iteration 119 / 200
training: epoch 119: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.907866, min gradient is -8.000000, learning rate is 0.000035
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.403697, learning rate is 0.000035
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.436757, learning rate is 0.000035
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.834740, learning rate is 0.000400
Net2: layer deconv3:max response is 75.795761, min response is -48.460541.
max gradient is 8.000000, min gradient is -5.798054, learning rate is 0.000200
Net2: layer bn50:max response is 23.586622, min response is -4.519827.
max gradient is 8.000000, min gradient is -6.304995, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.906539, learning rate is 0.000200
Net2: layer bn49:max response is 15.684756, min response is -3.459274.
max gradient is 4.333861, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.076978, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.78, min inferred z is -3.99, and std is 1.00
 4.22 s (23.7 data/s) [100/100]
training: epoch 119: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.361502, min gradient is -8.000000, learning rate is 0.000035
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.542536, learning rate is 0.000035
Net1: layer conv1:max response is , min response is .
max gradient is 6.926563, min gradient is -8.000000, learning rate is 0.000035
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.373055, learning rate is 0.000400
Net2: layer deconv3:max response is 54.227444, min response is -53.379601.
max gradient is 4.692051, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.538296, min response is -4.686176.
max gradient is 6.677581, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.587223, learning rate is 0.000200
Net2: layer bn49:max response is 18.573292, min response is -2.812234.
max gradient is 8.000001, min gradient is -7.215392, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.240654, learning rate is 0.000200
max inferred z is 4.31, min inferred z is -5.10, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 119: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.657316, min gradient is -8.000000, learning rate is 0.000035
Net1: layer conv2:max response is , min response is .
max gradient is 6.362374, min gradient is -8.000000, learning rate is 0.000035
Net1: layer conv1:max response is , min response is .
max gradient is 6.746515, min gradient is -8.000000, learning rate is 0.000035
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.568221, learning rate is 0.000400
Net2: layer deconv3:max response is 57.930374, min response is -62.030708.
max gradient is 8.000000, min gradient is -6.022336, learning rate is 0.000200
Net2: layer bn50:max response is 20.322062, min response is -4.833907.
max gradient is 7.848833, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.429637, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.088112, min response is -3.197911.
max gradient is 5.414762, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.034159, learning rate is 0.000200
max inferred z is 3.80, min inferred z is -3.92, and std is 1.00
 4.23 s (23.7 data/s) [100/100]
training: epoch 119: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.589967, min gradient is -8.000000, learning rate is 0.000035
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.011584, learning rate is 0.000035
Net1: layer conv1:max response is , min response is .
max gradient is 6.913050, min gradient is -8.000000, learning rate is 0.000035
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.224592, learning rate is 0.000400
Net2: layer deconv3:max response is 61.983509, min response is -68.230751.
max gradient is 7.501561, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.839558, min response is -5.405906.
max gradient is 8.000000, min gradient is -7.370618, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.341168, learning rate is 0.000200
Net2: layer bn49:max response is 18.182507, min response is -2.906895.
max gradient is 8.000000, min gradient is -6.699364, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.723292, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.58, min inferred z is -4.00, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 119: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.501175, min gradient is -8.000000, learning rate is 0.000035
Net1: layer conv2:max response is , min response is .
max gradient is 6.562578, min gradient is -8.000001, learning rate is 0.000035
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.914409, learning rate is 0.000035
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.163849, learning rate is 0.000400
Net2: layer deconv3:max response is 47.406757, min response is -50.498096.
max gradient is 8.000000, min gradient is -5.480864, learning rate is 0.000200
Net2: layer bn50:max response is 18.399319, min response is -4.335061.
max gradient is 8.000000, min gradient is -6.278371, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000001, min gradient is -7.716571, learning rate is 0.000200
Net2: layer bn49:max response is 14.879416, min response is -3.265810.
max gradient is 6.454324, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.040168, learning rate is 0.000200
max inferred z is 3.96, min inferred z is -4.05, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 119: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.496136, min gradient is -8.000000, learning rate is 0.000035
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.914059, learning rate is 0.000035
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.949245, learning rate is 0.000035
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.511234, learning rate is 0.000400
Net2: layer deconv3:max response is 50.844601, min response is -54.043468.
max gradient is 7.145040, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.967194, min response is -4.448067.
max gradient is 7.913228, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.204615, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 14.811590, min response is -3.350292.
max gradient is 7.385992, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.639539, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.42, min inferred z is -3.77, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 119: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.763260, min gradient is -8.000000, learning rate is 0.000035
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.266210, learning rate is 0.000035
Net1: layer conv1:max response is , min response is .
max gradient is 7.841350, min gradient is -8.000000, learning rate is 0.000035
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -3.763398, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 60.412037, min response is -48.297615.
max gradient is 8.000000, min gradient is -5.985550, learning rate is 0.000200
Net2: layer bn50:max response is 19.165453, min response is -4.361837.
max gradient is 8.000000, min gradient is -6.688365, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.219193, learning rate is 0.000200
Net2: layer bn49:max response is 19.738659, min response is -3.094210.
max gradient is 7.405711, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.772135, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.94, min inferred z is -4.07, and std is 1.00
 4.21 s (23.7 data/s) [100/100]
training: epoch 119: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.729891, min gradient is -8.000000, learning rate is 0.000035
Net1: layer conv2:max response is , min response is .
max gradient is 7.857600, min gradient is -8.000000, learning rate is 0.000035
Net1: layer conv1:max response is , min response is .
max gradient is 6.180909, min gradient is -8.000000, learning rate is 0.000035
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.293179, learning rate is 0.000400
Net2: layer deconv3:max response is 59.148018, min response is -49.135532.
max gradient is 3.166589, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.952026, min response is -4.328259.
max gradient is 7.753070, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.811854, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 15.045041, min response is -3.065143.
max gradient is 8.000000, min gradient is -7.278842, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.456432, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.03, min inferred z is -4.39, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 119: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.578851, min gradient is -8.000000, learning rate is 0.000035
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.026168, learning rate is 0.000035
Net1: layer conv1:max response is , min response is .
max gradient is 7.524670, min gradient is -8.000000, learning rate is 0.000035
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.898189, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 60.128971, min response is -57.945618.
max gradient is 8.000000, min gradient is -2.571669, learning rate is 0.000200
Net2: layer bn50:max response is 20.368164, min response is -4.646730.
max gradient is 6.584922, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.996853, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 15.771212, min response is -3.011902.
max gradient is 8.000000, min gradient is -7.201786, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.661880, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.72, min inferred z is -3.53, and std is 1.00
 4.41 s (22.7 data/s) [100/100]
training: epoch 119: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.800324, min gradient is -8.000000, learning rate is 0.000035
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.810337, learning rate is 0.000035
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -6.822999, learning rate is 0.000035
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.566065, learning rate is 0.000400
Net2: layer deconv3:max response is 59.451103, min response is -50.983688.
max gradient is 3.994220, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.346535, min response is -4.383286.
max gradient is 7.407452, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.715099, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 15.285270, min response is -3.490669.
max gradient is 8.000000, min gradient is -7.024036, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.111100, learning rate is 0.000200
max inferred z is 3.92, min inferred z is -3.88, and std is 1.00
 4.23 s (23.6 data/s) [100/100]
Loss: 1.1748
Iteration 120 / 200
training: epoch 120: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.819000, min gradient is -8.000000, learning rate is 0.000035
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.079688, learning rate is 0.000035
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.969476, learning rate is 0.000035
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.519718, learning rate is 0.000400
Net2: layer deconv3:max response is 56.120518, min response is -61.559956.
max gradient is 8.000000, min gradient is -7.850267, learning rate is 0.000200
Net2: layer bn50:max response is 24.902096, min response is -6.160024.
max gradient is 2.728007, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.211952, learning rate is 0.000200
Net2: layer bn49:max response is 16.902306, min response is -3.022403.
max gradient is 6.437614, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.101039, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.83, min inferred z is -3.88, and std is 1.00
 4.19 s (23.9 data/s) [100/100]
training: epoch 120: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.850097, min gradient is -8.000000, learning rate is 0.000035
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.770369, learning rate is 0.000035
Net1: layer conv1:max response is , min response is .
max gradient is 7.630038, min gradient is -8.000000, learning rate is 0.000035
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.150180, learning rate is 0.000400
Net2: layer deconv3:max response is 61.177048, min response is -52.626698.
max gradient is 7.850726, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.890329, min response is -4.829536.
max gradient is 8.000000, min gradient is -3.125919, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.498664, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 14.683153, min response is -3.245181.
max gradient is 8.000000, min gradient is -5.450269, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.196752, learning rate is 0.000200
max inferred z is 4.21, min inferred z is -4.18, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
training: epoch 120: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.697325, min gradient is -8.000000, learning rate is 0.000035
Net1: layer conv2:max response is , min response is .
max gradient is 5.380991, min gradient is -8.000000, learning rate is 0.000035
Net1: layer conv1:max response is , min response is .
max gradient is 6.733655, min gradient is -8.000000, learning rate is 0.000035
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.726453, learning rate is 0.000400
Net2: layer deconv3:max response is 56.533363, min response is -53.951534.
max gradient is 8.000000, min gradient is -4.614319, learning rate is 0.000200
Net2: layer bn50:max response is 17.751345, min response is -4.530412.
max gradient is 8.000000, min gradient is -7.435230, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.670150, learning rate is 0.000200
Net2: layer bn49:max response is 15.000132, min response is -2.547288.
max gradient is 6.664523, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.867690, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.03, min inferred z is -4.15, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 120: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.544437, min gradient is -8.000000, learning rate is 0.000035
Net1: layer conv2:max response is , min response is .
max gradient is 8.000001, min gradient is -7.535527, learning rate is 0.000035
Net1: layer conv1:max response is , min response is .
max gradient is 7.152159, min gradient is -8.000000, learning rate is 0.000035
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -0.469698, learning rate is 0.000400
Net2: layer deconv3:max response is 60.141243, min response is -57.801167.
max gradient is 2.113810, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.581697, min response is -5.353666.
max gradient is 7.430828, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.762189, learning rate is 0.000200
Net2: layer bn49:max response is 17.087833, min response is -2.998560.
max gradient is 8.000000, min gradient is -6.859795, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.975147, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.38, min inferred z is -4.41, and std is 1.00
 4.23 s (23.7 data/s) [100/100]
training: epoch 120: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.564769, min gradient is -8.000000, learning rate is 0.000035
Net1: layer conv2:max response is , min response is .
max gradient is 6.704869, min gradient is -8.000000, learning rate is 0.000035
Net1: layer conv1:max response is , min response is .
max gradient is 7.311680, min gradient is -8.000000, learning rate is 0.000035
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.711008, learning rate is 0.000400
Net2: layer deconv3:max response is 70.423088, min response is -50.336353.
max gradient is 8.000000, min gradient is -7.980452, learning rate is 0.000200
Net2: layer bn50:max response is 22.362448, min response is -4.297134.
max gradient is 3.835330, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.640101, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 15.249063, min response is -3.418710.
max gradient is 6.378478, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.827533, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.68, min inferred z is -3.49, and std is 1.00
 4.30 s (23.2 data/s) [100/100]
training: epoch 120: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.430309, min gradient is -8.000000, learning rate is 0.000035
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.002935, learning rate is 0.000035
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.873734, learning rate is 0.000035
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.559520, learning rate is 0.000400
Net2: layer deconv3:max response is 54.854031, min response is -53.329712.
max gradient is 8.000000, min gradient is -7.675773, learning rate is 0.000200
Net2: layer bn50:max response is 18.048910, min response is -4.243446.
max gradient is 8.000000, min gradient is -2.727262, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.455536, learning rate is 0.000200
Net2: layer bn49:max response is 16.224417, min response is -2.769094.
max gradient is 8.000000, min gradient is -4.504376, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.509390, learning rate is 0.000200
max inferred z is 4.37, min inferred z is -3.98, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 120: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.950567, min gradient is -8.000000, learning rate is 0.000035
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.287928, learning rate is 0.000035
Net1: layer conv1:max response is , min response is .
max gradient is 7.962650, min gradient is -8.000000, learning rate is 0.000035
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.307056, learning rate is 0.000400
Net2: layer deconv3:max response is 54.045513, min response is -50.697731.
max gradient is 7.031548, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.251499, min response is -4.394483.
max gradient is 6.474930, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.412758, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.068298, min response is -3.324555.
max gradient is 7.768296, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.850378, learning rate is 0.000200
max inferred z is 4.24, min inferred z is -4.09, and std is 1.00
 4.41 s (22.7 data/s) [100/100]
training: epoch 120: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.671154, min gradient is -8.000000, learning rate is 0.000035
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.402276, learning rate is 0.000035
Net1: layer conv1:max response is , min response is .
max gradient is 5.870039, min gradient is -8.000000, learning rate is 0.000035
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.777213, learning rate is 0.000400
Net2: layer deconv3:max response is 59.591484, min response is -46.815998.
max gradient is 6.460107, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 17.669800, min response is -4.063348.
max gradient is 6.893894, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.954443, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 15.240249, min response is -3.289250.
max gradient is 7.054870, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.483550, learning rate is 0.000200
max inferred z is 4.03, min inferred z is -3.70, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 120: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.661503, min gradient is -8.000000, learning rate is 0.000035
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.672205, learning rate is 0.000035
Net1: layer conv1:max response is , min response is .
max gradient is 5.622748, min gradient is -8.000000, learning rate is 0.000035
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.009209, learning rate is 0.000400
Net2: layer deconv3:max response is 49.821655, min response is -42.912113.
max gradient is 8.000000, min gradient is -6.224713, learning rate is 0.000200
Net2: layer bn50:max response is 16.347635, min response is -4.026439.
max gradient is 8.000000, min gradient is -7.347928, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.977289, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 14.868956, min response is -2.740216.
max gradient is 5.205875, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.908888, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.07, min inferred z is -4.68, and std is 1.00
 4.28 s (23.4 data/s) [100/100]
training: epoch 120: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.063113, min gradient is -8.000000, learning rate is 0.000035
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.551780, learning rate is 0.000035
Net1: layer conv1:max response is , min response is .
max gradient is 7.734517, min gradient is -8.000000, learning rate is 0.000035
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.733673, learning rate is 0.000400
Net2: layer deconv3:max response is 53.594360, min response is -51.408676.
max gradient is 5.407903, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.109724, min response is -4.217020.
max gradient is 8.000000, min gradient is -6.900465, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.342591, learning rate is 0.000200
Net2: layer bn49:max response is 14.874140, min response is -2.964655.
max gradient is 8.000000, min gradient is -6.377046, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.208599, learning rate is 0.000200
max inferred z is 3.86, min inferred z is -3.95, and std is 1.00
 4.23 s (23.6 data/s) [100/100]
Loss: 1.2009
Iteration 121 / 200
training: epoch 121: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.824734, min gradient is -8.000000, learning rate is 0.000029
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.082347, learning rate is 0.000029
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.786150, learning rate is 0.000029
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.958136, learning rate is 0.000400
Net2: layer deconv3:max response is 71.876389, min response is -44.605831.
max gradient is 8.000000, min gradient is -6.732906, learning rate is 0.000200
Net2: layer bn50:max response is 21.457674, min response is -3.935834.
max gradient is 8.000000, min gradient is -4.698964, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.901688, learning rate is 0.000200
Net2: layer bn49:max response is 16.418247, min response is -3.604134.
max gradient is 7.664748, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.808980, learning rate is 0.000200
max inferred z is 3.99, min inferred z is -3.89, and std is 1.00
 4.15 s (24.1 data/s) [100/100]
training: epoch 121: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.516535, min gradient is -8.000000, learning rate is 0.000029
Net1: layer conv2:max response is , min response is .
max gradient is 7.966365, min gradient is -8.000000, learning rate is 0.000029
Net1: layer conv1:max response is , min response is .
max gradient is 6.943491, min gradient is -8.000000, learning rate is 0.000029
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.226687, learning rate is 0.000400
Net2: layer deconv3:max response is 56.316475, min response is -51.441013.
max gradient is 6.313906, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.985342, min response is -4.193718.
max gradient is 3.193727, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.876464, learning rate is 0.000200
Net2: layer bn49:max response is 15.375067, min response is -2.921789.
max gradient is 6.494188, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.321486, learning rate is 0.000200
max inferred z is 3.71, min inferred z is -3.78, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 121: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.569676, min gradient is -8.000000, learning rate is 0.000029
Net1: layer conv2:max response is , min response is .
max gradient is 5.720501, min gradient is -8.000000, learning rate is 0.000029
Net1: layer conv1:max response is , min response is .
max gradient is 6.354071, min gradient is -8.000000, learning rate is 0.000029
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.902129, learning rate is 0.000400
Net2: layer deconv3:max response is 57.235035, min response is -52.134209.
max gradient is 6.074837, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.350189, min response is -4.576734.
max gradient is 8.000000, min gradient is -6.955947, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.891432, learning rate is 0.000200
Net2: layer bn49:max response is 15.462452, min response is -2.877994.
max gradient is 8.000000, min gradient is -6.208703, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.054915, learning rate is 0.000200
max inferred z is 3.84, min inferred z is -3.71, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
training: epoch 121: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.600623, min gradient is -8.000000, learning rate is 0.000029
Net1: layer conv2:max response is , min response is .
max gradient is 7.892313, min gradient is -8.000000, learning rate is 0.000029
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.235271, learning rate is 0.000029
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.553983, learning rate is 0.000400
Net2: layer deconv3:max response is 71.609451, min response is -57.166138.
max gradient is 7.093005, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.760662, min response is -5.830651.
max gradient is 6.717750, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.844891, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.085131, min response is -3.752808.
max gradient is 5.930956, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.347151, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.64, min inferred z is -4.08, and std is 1.00
 4.41 s (22.7 data/s) [100/100]
training: epoch 121: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.917041, min gradient is -8.000000, learning rate is 0.000029
Net1: layer conv2:max response is , min response is .
max gradient is 7.323426, min gradient is -8.000000, learning rate is 0.000029
Net1: layer conv1:max response is , min response is .
max gradient is 7.518573, min gradient is -8.000000, learning rate is 0.000029
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.572230, learning rate is 0.000400
Net2: layer deconv3:max response is 60.873913, min response is -58.569733.
max gradient is 8.000000, min gradient is -7.998074, learning rate is 0.000200
Net2: layer bn50:max response is 19.748442, min response is -4.500289.
max gradient is 8.000000, min gradient is -6.639432, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.101698, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 16.692650, min response is -2.921723.
max gradient is 8.000000, min gradient is -5.366322, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.962444, learning rate is 0.000200
max inferred z is 4.07, min inferred z is -3.84, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 121: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.431835, min gradient is -8.000000, learning rate is 0.000029
Net1: layer conv2:max response is , min response is .
max gradient is 6.397650, min gradient is -8.000000, learning rate is 0.000029
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.997935, learning rate is 0.000029
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.237873, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 61.050610, min response is -49.009388.
max gradient is 8.000000, min gradient is -6.624361, learning rate is 0.000200
Net2: layer bn50:max response is 21.243919, min response is -5.001313.
max gradient is 6.915946, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.550714, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 16.251253, min response is -3.513178.
max gradient is 5.509025, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.420250, learning rate is 0.000200
max inferred z is 3.84, min inferred z is -3.66, and std is 1.00
 4.34 s (23.1 data/s) [100/100]
training: epoch 121: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.923612, min gradient is -8.000000, learning rate is 0.000029
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.699064, learning rate is 0.000029
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.684103, learning rate is 0.000029
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.626549, learning rate is 0.000400
Net2: layer deconv3:max response is 61.077198, min response is -57.439144.
max gradient is 2.926479, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.088326, min response is -4.348467.
max gradient is 8.000000, min gradient is -7.648399, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.549431, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 16.413805, min response is -3.131548.
max gradient is 8.000000, min gradient is -4.343197, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.842557, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.76, min inferred z is -3.48, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 121: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.782289, min gradient is -8.000000, learning rate is 0.000029
Net1: layer conv2:max response is , min response is .
max gradient is 8.000001, min gradient is -7.640851, learning rate is 0.000029
Net1: layer conv1:max response is , min response is .
max gradient is 7.953011, min gradient is -8.000000, learning rate is 0.000029
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 5.763568, min gradient is -7.197016, learning rate is 0.000400
Net2: layer deconv3:max response is 56.376202, min response is -54.687683.
max gradient is 8.000000, min gradient is -2.460503, learning rate is 0.000200
Net2: layer bn50:max response is 19.802288, min response is -4.874859.
max gradient is 6.952720, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.385898, learning rate is 0.000200
Net2: layer bn49:max response is 16.794724, min response is -3.396652.
max gradient is 8.000000, min gradient is -6.639571, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.442235, learning rate is 0.000200
max inferred z is 5.15, min inferred z is -4.56, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 121: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.864476, min gradient is -8.000000, learning rate is 0.000029
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.095746, learning rate is 0.000029
Net1: layer conv1:max response is , min response is .
max gradient is 6.629532, min gradient is -8.000000, learning rate is 0.000029
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.776127, learning rate is 0.000400
Net2: layer deconv3:max response is 60.049694, min response is -46.701851.
max gradient is 2.217665, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.147989, min response is -4.032763.
max gradient is 7.471289, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.650302, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 14.364216, min response is -3.068331.
max gradient is 8.000000, min gradient is -6.741317, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.620780, learning rate is 0.000200
max inferred z is 4.34, min inferred z is -3.95, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 121: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.830902, min gradient is -8.000000, learning rate is 0.000029
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.471889, learning rate is 0.000029
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.955793, learning rate is 0.000029
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.958025, learning rate is 0.000400
Net2: layer deconv3:max response is 63.989079, min response is -62.058086.
max gradient is 8.000000, min gradient is -3.318048, learning rate is 0.000200
Net2: layer bn50:max response is 20.684052, min response is -4.550285.
max gradient is 8.000000, min gradient is -7.051776, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.305182, learning rate is 0.000200
Net2: layer bn49:max response is 16.797840, min response is -3.322466.
max gradient is 5.991642, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.674054, learning rate is 0.000200
max inferred z is 3.56, min inferred z is -3.71, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
Loss: 1.2774
Iteration 122 / 200
training: epoch 122: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.963173, min gradient is -8.000000, learning rate is 0.000029
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.132369, learning rate is 0.000029
Net1: layer conv1:max response is , min response is .
max gradient is 7.546092, min gradient is -8.000000, learning rate is 0.000029
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.513584, learning rate is 0.000400
Net2: layer deconv3:max response is 56.106762, min response is -50.782520.
max gradient is 3.500682, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.731411, min response is -5.250882.
max gradient is 6.559911, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.983423, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 16.041092, min response is -2.729214.
max gradient is 8.000000, min gradient is -3.941317, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.293931, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.90, min inferred z is -3.80, and std is 1.01
 4.13 s (24.2 data/s) [100/100]
training: epoch 122: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.407476, min gradient is -8.000000, learning rate is 0.000029
Net1: layer conv2:max response is , min response is .
max gradient is 6.129749, min gradient is -8.000000, learning rate is 0.000029
Net1: layer conv1:max response is , min response is .
max gradient is 7.379574, min gradient is -8.000000, learning rate is 0.000029
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.224252, learning rate is 0.000400
Net2: layer deconv3:max response is 71.237572, min response is -61.970276.
max gradient is 8.000000, min gradient is -4.531869, learning rate is 0.000200
Net2: layer bn50:max response is 25.371077, min response is -4.917140.
max gradient is 8.000000, min gradient is -6.090227, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.470154, learning rate is 0.000200
Net2: layer bn49:max response is 18.502544, min response is -4.235523.
max gradient is 5.921048, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.706240, learning rate is 0.000200
max inferred z is 3.87, min inferred z is -4.13, and std is 1.01
 4.14 s (24.2 data/s) [100/100]
training: epoch 122: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.766934, min gradient is -8.000000, learning rate is 0.000029
Net1: layer conv2:max response is , min response is .
max gradient is 6.823118, min gradient is -8.000000, learning rate is 0.000029
Net1: layer conv1:max response is , min response is .
max gradient is 6.301989, min gradient is -8.000000, learning rate is 0.000029
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.648483, learning rate is 0.000400
Net2: layer deconv3:max response is 65.040558, min response is -50.792671.
max gradient is 4.669264, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.066891, min response is -4.456958.
max gradient is 7.385809, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.998070, learning rate is 0.000200
Net2: layer bn49:max response is 15.689178, min response is -3.313106.
max gradient is 8.000000, min gradient is -5.057004, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.423124, learning rate is 0.000200
max inferred z is 3.92, min inferred z is -4.57, and std is 1.01
 4.13 s (24.2 data/s) [100/100]
training: epoch 122: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.018157, min gradient is -8.000000, learning rate is 0.000029
Net1: layer conv2:max response is , min response is .
max gradient is 7.679856, min gradient is -8.000000, learning rate is 0.000029
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.769116, learning rate is 0.000029
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.385107, learning rate is 0.000400
Net2: layer deconv3:max response is 65.202370, min response is -58.986904.
max gradient is 8.000000, min gradient is -7.916825, learning rate is 0.000200
Net2: layer bn50:max response is 21.591391, min response is -5.386590.
max gradient is 4.877703, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.934438, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.701935, min response is -3.077885.
max gradient is 5.120720, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.447214, learning rate is 0.000200
max inferred z is 3.70, min inferred z is -4.62, and std is 1.01
 4.28 s (23.4 data/s) [100/100]
training: epoch 122: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.226633, min gradient is -8.000000, learning rate is 0.000029
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.984143, learning rate is 0.000029
Net1: layer conv1:max response is , min response is .
max gradient is 7.597589, min gradient is -8.000000, learning rate is 0.000029
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.380009, learning rate is 0.000400
Net2: layer deconv3:max response is 59.176945, min response is -56.634926.
max gradient is 7.894629, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 17.785370, min response is -4.174411.
max gradient is 8.000000, min gradient is -4.324108, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.434910, learning rate is 0.000200
Net2: layer bn49:max response is 16.666428, min response is -2.993864.
max gradient is 8.000000, min gradient is -5.300569, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.204490, learning rate is 0.000200
max inferred z is 4.16, min inferred z is -4.40, and std is 1.01
 4.25 s (23.5 data/s) [100/100]
training: epoch 122: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.815245, min gradient is -8.000000, learning rate is 0.000029
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.252336, learning rate is 0.000029
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.988943, learning rate is 0.000029
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.508005, learning rate is 0.000400
Net2: layer deconv3:max response is 59.151890, min response is -54.155048.
max gradient is 6.441730, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.394352, min response is -5.569492.
max gradient is 4.345538, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.966539, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.865831, min response is -3.135631.
max gradient is 5.752902, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.291535, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.87, min inferred z is -3.97, and std is 1.01
 4.22 s (23.7 data/s) [100/100]
training: epoch 122: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.839792, min gradient is -8.000000, learning rate is 0.000029
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.678341, learning rate is 0.000029
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.853468, learning rate is 0.000029
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.138981, learning rate is 0.000400
Net2: layer deconv3:max response is 59.067596, min response is -56.230526.
max gradient is 8.000000, min gradient is -7.512227, learning rate is 0.000200
Net2: layer bn50:max response is 18.599758, min response is -4.363568.
max gradient is 8.000000, min gradient is -4.037230, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.535404, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 16.864279, min response is -3.112362.
max gradient is 8.000000, min gradient is -5.294642, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.239748, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.24, min inferred z is -4.09, and std is 1.01
 4.24 s (23.6 data/s) [100/100]
training: epoch 122: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.019160, min gradient is -8.000000, learning rate is 0.000029
Net1: layer conv2:max response is , min response is .
max gradient is 7.197202, min gradient is -8.000000, learning rate is 0.000029
Net1: layer conv1:max response is , min response is .
max gradient is 6.232053, min gradient is -8.000000, learning rate is 0.000029
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.014490, learning rate is 0.000400
Net2: layer deconv3:max response is 65.411278, min response is -61.902618.
max gradient is 7.488281, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.488344, min response is -4.484540.
max gradient is 4.578547, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.331844, learning rate is 0.000200
Net2: layer bn49:max response is 16.651699, min response is -3.310117.
max gradient is 8.000000, min gradient is -7.381649, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.224376, learning rate is 0.000200
max inferred z is 4.35, min inferred z is -4.04, and std is 1.01
 4.38 s (22.8 data/s) [100/100]
training: epoch 122: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.128498, min gradient is -8.000000, learning rate is 0.000029
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.250820, learning rate is 0.000029
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.225049, learning rate is 0.000029
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.647497, learning rate is 0.000400
Net2: layer deconv3:max response is 53.385944, min response is -47.832127.
max gradient is 8.000000, min gradient is -5.750369, learning rate is 0.000200
Net2: layer bn50:max response is 19.990566, min response is -4.830587.
max gradient is 7.696318, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.395677, learning rate is 0.000200
Net2: layer bn49:max response is 14.854597, min response is -3.236291.
max gradient is 7.965409, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.831917, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.33, min inferred z is -3.77, and std is 1.01
 4.28 s (23.4 data/s) [100/100]
training: epoch 122: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.579338, min gradient is -8.000000, learning rate is 0.000029
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.553924, learning rate is 0.000029
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.929234, learning rate is 0.000029
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.327949, learning rate is 0.000400
Net2: layer deconv3:max response is 59.744934, min response is -57.222343.
max gradient is 3.787119, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.470238, min response is -4.425900.
max gradient is 6.142921, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.227877, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 15.962372, min response is -3.061098.
max gradient is 8.000000, min gradient is -5.571155, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.715676, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.26, min inferred z is -3.58, and std is 1.01
 4.27 s (23.4 data/s) [100/100]
Loss: 1.1962
Iteration 123 / 200
training: epoch 123: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.315540, min gradient is -8.000000, learning rate is 0.000024
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.012295, learning rate is 0.000024
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.397047, learning rate is 0.000024
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.224719, learning rate is 0.000400
Net2: layer deconv3:max response is 60.623718, min response is -57.531361.
max gradient is 8.000000, min gradient is -4.007072, learning rate is 0.000200
Net2: layer bn50:max response is 20.526594, min response is -4.144907.
max gradient is 7.817009, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.518956, learning rate is 0.000200
Net2: layer bn49:max response is 16.633945, min response is -3.289190.
max gradient is 6.165340, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.172438, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.74, min inferred z is -3.64, and std is 1.01
 4.37 s (22.9 data/s) [100/100]
training: epoch 123: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.851293, min gradient is -8.000000, learning rate is 0.000024
Net1: layer conv2:max response is , min response is .
max gradient is 7.260451, min gradient is -8.000000, learning rate is 0.000024
Net1: layer conv1:max response is , min response is .
max gradient is 5.859067, min gradient is -8.000000, learning rate is 0.000024
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.629866, learning rate is 0.000400
Net2: layer deconv3:max response is 60.204369, min response is -56.122520.
max gradient is 4.373315, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.881367, min response is -4.542753.
max gradient is 8.000000, min gradient is -6.497365, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.331119, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.378185, min response is -3.003280.
max gradient is 8.000000, min gradient is -5.844175, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.573943, learning rate is 0.000200
max inferred z is 3.65, min inferred z is -4.21, and std is 1.01
 4.21 s (23.8 data/s) [100/100]
training: epoch 123: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.936584, min gradient is -8.000000, learning rate is 0.000024
Net1: layer conv2:max response is , min response is .
max gradient is 6.331489, min gradient is -8.000000, learning rate is 0.000024
Net1: layer conv1:max response is , min response is .
max gradient is 6.679334, min gradient is -8.000000, learning rate is 0.000024
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -3.004050, learning rate is 0.000400
Net2: layer deconv3:max response is 57.880249, min response is -49.399227.
max gradient is 8.000000, min gradient is -3.397233, learning rate is 0.000200
Net2: layer bn50:max response is 19.092022, min response is -4.493546.
max gradient is 8.000000, min gradient is -6.866827, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.634426, learning rate is 0.000200
Net2: layer bn49:max response is 15.485025, min response is -3.004132.
max gradient is 5.315920, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.660491, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.95, min inferred z is -3.88, and std is 1.01
 4.44 s (22.5 data/s) [100/100]
training: epoch 123: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.269250, min gradient is -8.000000, learning rate is 0.000024
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.061462, learning rate is 0.000024
Net1: layer conv1:max response is , min response is .
max gradient is 6.829817, min gradient is -8.000000, learning rate is 0.000024
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.665196, learning rate is 0.000400
Net2: layer deconv3:max response is 61.226730, min response is -52.533772.
max gradient is 2.628107, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.164806, min response is -4.553561.
max gradient is 8.000000, min gradient is -7.545472, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.593357, learning rate is 0.000200
Net2: layer bn49:max response is 16.053095, min response is -3.301119.
max gradient is 8.000000, min gradient is -7.381676, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.180805, learning rate is 0.000200
max inferred z is 3.61, min inferred z is -3.84, and std is 1.01
 4.35 s (23.0 data/s) [100/100]
training: epoch 123: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.382032, min gradient is -8.000000, learning rate is 0.000024
Net1: layer conv2:max response is , min response is .
max gradient is 7.849176, min gradient is -8.000000, learning rate is 0.000024
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.493114, learning rate is 0.000024
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.306975, learning rate is 0.000400
Net2: layer deconv3:max response is 57.957535, min response is -47.112709.
max gradient is 8.000000, min gradient is -3.087603, learning rate is 0.000200
Net2: layer bn50:max response is 19.490294, min response is -3.996357.
max gradient is 8.000000, min gradient is -7.323567, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.492425, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 13.890824, min response is -3.482253.
max gradient is 7.083271, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.036732, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.02, min inferred z is -3.92, and std is 1.01
 4.20 s (23.8 data/s) [100/100]
training: epoch 123: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.077572, min gradient is -8.000000, learning rate is 0.000024
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.662629, learning rate is 0.000024
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.704763, learning rate is 0.000024
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.811027, learning rate is 0.000400
Net2: layer deconv3:max response is 75.055023, min response is -70.638550.
max gradient is 3.903734, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 24.282576, min response is -5.371312.
max gradient is 7.805085, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.786863, learning rate is 0.000200
Net2: layer bn49:max response is 18.902779, min response is -4.054588.
max gradient is 8.000000, min gradient is -4.980892, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.925719, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.14, min inferred z is -3.74, and std is 1.01
 4.40 s (22.7 data/s) [100/100]
training: epoch 123: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.974549, min gradient is -8.000000, learning rate is 0.000024
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.036827, learning rate is 0.000024
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.601171, learning rate is 0.000024
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.288989, learning rate is 0.000400
Net2: layer deconv3:max response is 61.162514, min response is -51.065720.
max gradient is 8.000000, min gradient is -5.294485, learning rate is 0.000200
Net2: layer bn50:max response is 18.820194, min response is -4.004402.
max gradient is 8.000000, min gradient is -7.550266, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.703464, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 14.418339, min response is -3.256968.
max gradient is 6.227576, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.214494, learning rate is 0.000200
max inferred z is 3.59, min inferred z is -4.33, and std is 1.01
 4.29 s (23.3 data/s) [100/100]
training: epoch 123: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.159070, min gradient is -8.000000, learning rate is 0.000024
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.718530, learning rate is 0.000024
Net1: layer conv1:max response is , min response is .
max gradient is 5.858754, min gradient is -8.000000, learning rate is 0.000024
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.548246, learning rate is 0.000400
Net2: layer deconv3:max response is 57.848125, min response is -53.436279.
max gradient is 6.554126, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.017923, min response is -4.376071.
max gradient is 8.000000, min gradient is -6.920040, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.686307, learning rate is 0.000200
Net2: layer bn49:max response is 16.273399, min response is -3.011509.
max gradient is 8.000001, min gradient is -7.890634, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.492128, learning rate is 0.000200
max inferred z is 3.89, min inferred z is -4.04, and std is 1.01
 4.22 s (23.7 data/s) [100/100]
training: epoch 123: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.176782, min gradient is -8.000000, learning rate is 0.000024
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.764449, learning rate is 0.000024
Net1: layer conv1:max response is , min response is .
max gradient is 6.183383, min gradient is -8.000000, learning rate is 0.000024
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.894855, learning rate is 0.000400
Net2: layer deconv3:max response is 67.628967, min response is -53.641430.
max gradient is 7.555189, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.077827, min response is -5.427341.
max gradient is 4.305297, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.631739, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.523439, min response is -3.751994.
max gradient is 5.266817, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.363021, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.04, min inferred z is -4.24, and std is 1.01
 4.23 s (23.7 data/s) [100/100]
training: epoch 123: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.738493, min gradient is -8.000000, learning rate is 0.000024
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.743024, learning rate is 0.000024
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.462117, learning rate is 0.000024
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.163719, learning rate is 0.000400
Net2: layer deconv3:max response is 61.155834, min response is -56.378784.
max gradient is 7.505603, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.870857, min response is -4.842752.
max gradient is 8.000000, min gradient is -5.314212, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.596590, learning rate is 0.000200
Net2: layer bn49:max response is 16.561230, min response is -3.267944.
max gradient is 8.000000, min gradient is -5.259201, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.870508, learning rate is 0.000200
max inferred z is 4.13, min inferred z is -4.02, and std is 1.01
 4.40 s (22.7 data/s) [100/100]
Loss: 1.2374
Iteration 124 / 200
training: epoch 124: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.484660, min gradient is -8.000000, learning rate is 0.000024
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.937170, learning rate is 0.000024
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.299389, learning rate is 0.000024
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.556111, learning rate is 0.000400
Net2: layer deconv3:max response is 60.072800, min response is -53.333229.
max gradient is 8.000000, min gradient is -6.836983, learning rate is 0.000200
Net2: layer bn50:max response is 18.986563, min response is -4.552287.
max gradient is 3.494846, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.244904, learning rate is 0.000200
Net2: layer bn49:max response is 15.521538, min response is -3.270387.
max gradient is 4.978858, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.341410, learning rate is 0.000200
max inferred z is 3.78, min inferred z is -4.37, and std is 0.99
 4.26 s (23.5 data/s) [100/100]
training: epoch 124: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.072463, min gradient is -8.000000, learning rate is 0.000024
Net1: layer conv2:max response is , min response is .
max gradient is 7.375486, min gradient is -8.000000, learning rate is 0.000024
Net1: layer conv1:max response is , min response is .
max gradient is 7.695326, min gradient is -8.000000, learning rate is 0.000024
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.949891, learning rate is 0.000400
Net2: layer deconv3:max response is 67.871742, min response is -57.095192.
max gradient is 5.336063, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.648874, min response is -4.746709.
max gradient is 8.000000, min gradient is -4.660050, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.169679, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 16.623272, min response is -3.930199.
max gradient is 8.000000, min gradient is -6.450682, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.004690, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.85, min inferred z is -3.75, and std is 0.99
 4.36 s (23.0 data/s) [100/100]
training: epoch 124: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.342012, min gradient is -8.000000, learning rate is 0.000024
Net1: layer conv2:max response is , min response is .
max gradient is 6.199877, min gradient is -8.000000, learning rate is 0.000024
Net1: layer conv1:max response is , min response is .
max gradient is 7.613070, min gradient is -8.000000, learning rate is 0.000024
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -3.753699, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 68.193207, min response is -56.365421.
max gradient is 6.233775, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.498949, min response is -4.671796.
max gradient is 5.864980, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.805762, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.196362, min response is -3.769950.
max gradient is 7.051594, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.718860, learning rate is 0.000200
max inferred z is 3.88, min inferred z is -4.29, and std is 0.99
 4.39 s (22.8 data/s) [100/100]
training: epoch 124: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.584157, min gradient is -8.000000, learning rate is 0.000024
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.794553, learning rate is 0.000024
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.404963, learning rate is 0.000024
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.053568, learning rate is 0.000400
Net2: layer deconv3:max response is 72.294518, min response is -67.042892.
max gradient is 8.000000, min gradient is -2.982486, learning rate is 0.000200
Net2: layer bn50:max response is 21.249807, min response is -5.012108.
max gradient is 8.000000, min gradient is -7.861726, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.963439, learning rate is 0.000200
Net2: layer bn49:max response is 18.483788, min response is -2.879352.
max gradient is 6.979147, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.398387, learning rate is 0.000200
max inferred z is 3.68, min inferred z is -3.98, and std is 0.99
 4.35 s (23.0 data/s) [100/100]
training: epoch 124: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.431993, min gradient is -8.000000, learning rate is 0.000024
Net1: layer conv2:max response is , min response is .
max gradient is 7.848042, min gradient is -8.000000, learning rate is 0.000024
Net1: layer conv1:max response is , min response is .
max gradient is 6.857012, min gradient is -8.000000, learning rate is 0.000024
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.170226, learning rate is 0.000400
Net2: layer deconv3:max response is 65.611061, min response is -55.793625.
max gradient is 3.231340, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.983738, min response is -4.244531.
max gradient is 7.339756, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.460188, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 14.983037, min response is -3.600567.
max gradient is 8.000000, min gradient is -6.689629, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.189329, learning rate is 0.000200
max inferred z is 3.90, min inferred z is -4.32, and std is 0.99
 4.35 s (23.0 data/s) [100/100]
training: epoch 124: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.208078, min gradient is -8.000000, learning rate is 0.000024
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.910578, learning rate is 0.000024
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.730272, learning rate is 0.000024
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.577774, learning rate is 0.000400
Net2: layer deconv3:max response is 66.950371, min response is -60.496037.
max gradient is 8.000000, min gradient is -6.028092, learning rate is 0.000200
Net2: layer bn50:max response is 21.089773, min response is -4.791690.
max gradient is 6.788656, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.607406, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.203665, min response is -3.677607.
max gradient is 6.365299, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.543760, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.99, min inferred z is -4.09, and std is 0.99
 4.23 s (23.7 data/s) [100/100]
training: epoch 124: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.467557, min gradient is -8.000000, learning rate is 0.000024
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.600667, learning rate is 0.000024
Net1: layer conv1:max response is , min response is .
max gradient is 7.671435, min gradient is -8.000000, learning rate is 0.000024
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.725529, learning rate is 0.000400
Net2: layer deconv3:max response is 69.016350, min response is -64.991615.
max gradient is 6.706499, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.408899, min response is -4.230306.
max gradient is 8.000000, min gradient is -6.221734, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.951406, learning rate is 0.000200
Net2: layer bn49:max response is 17.370914, min response is -3.075465.
max gradient is 8.000000, min gradient is -7.484569, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.595195, learning rate is 0.000200
max inferred z is 4.25, min inferred z is -4.37, and std is 0.99
 4.33 s (23.1 data/s) [100/100]
training: epoch 124: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.376519, min gradient is -8.000000, learning rate is 0.000024
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.619715, learning rate is 0.000024
Net1: layer conv1:max response is , min response is .
max gradient is 5.811498, min gradient is -8.000000, learning rate is 0.000024
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.623788, learning rate is 0.000400
Net2: layer deconv3:max response is 68.897896, min response is -62.947674.
max gradient is 8.000000, min gradient is -4.168139, learning rate is 0.000200
Net2: layer bn50:max response is 19.779112, min response is -4.895586.
max gradient is 8.000000, min gradient is -6.874648, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.939044, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.314182, min response is -3.525841.
max gradient is 5.367891, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.411636, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.17, min inferred z is -3.69, and std is 0.99
 4.34 s (23.1 data/s) [100/100]
training: epoch 124: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.271633, min gradient is -8.000000, learning rate is 0.000024
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.437258, learning rate is 0.000024
Net1: layer conv1:max response is , min response is .
max gradient is 6.382928, min gradient is -8.000000, learning rate is 0.000024
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000001, min gradient is 7.237063, learning rate is 0.000400
Net2: layer deconv3:max response is 58.796066, min response is -53.156559.
max gradient is 3.341236, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 17.523623, min response is -4.385468.
max gradient is 7.210642, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.115684, learning rate is 0.000200
Net2: layer bn49:max response is 16.048281, min response is -2.995388.
max gradient is 8.000000, min gradient is -4.503978, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.808102, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.76, min inferred z is -3.83, and std is 0.99
 4.30 s (23.2 data/s) [100/100]
training: epoch 124: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.901346, min gradient is -8.000000, learning rate is 0.000024
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.181834, learning rate is 0.000024
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.180540, learning rate is 0.000024
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.929568, learning rate is 0.000400
Net2: layer deconv3:max response is 62.810066, min response is -58.138306.
max gradient is 6.946105, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.111055, min response is -4.453031.
max gradient is 3.288589, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.722266, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 16.014660, min response is -3.363096.
max gradient is 6.934313, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.939466, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.16, min inferred z is -4.11, and std is 0.99
 4.28 s (23.3 data/s) [100/100]
Loss: 1.2875
Iteration 125 / 200
training: epoch 125: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.773177, min gradient is -8.000000, learning rate is 0.000020
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.116848, learning rate is 0.000020
Net1: layer conv1:max response is , min response is .
max gradient is 7.396460, min gradient is -8.000000, learning rate is 0.000020
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.247321, learning rate is 0.000400
Net2: layer deconv3:max response is 81.737694, min response is -77.025192.
max gradient is 8.000001, min gradient is -6.221501, learning rate is 0.000200
Net2: layer bn50:max response is 23.605021, min response is -5.437761.
max gradient is 8.000000, min gradient is -3.396711, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.213988, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.942049, min response is -3.519268.
max gradient is 8.000000, min gradient is -4.704228, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.153629, learning rate is 0.000200
max inferred z is 4.19, min inferred z is -3.98, and std is 1.00
 4.28 s (23.4 data/s) [100/100]
training: epoch 125: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.062951, min gradient is -8.000000, learning rate is 0.000020
Net1: layer conv2:max response is , min response is .
max gradient is 6.757418, min gradient is -8.000000, learning rate is 0.000020
Net1: layer conv1:max response is , min response is .
max gradient is 7.062050, min gradient is -8.000000, learning rate is 0.000020
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 7.008982, min gradient is -2.660464, learning rate is 0.000400
Net2: layer deconv3:max response is 66.609207, min response is -60.353851.
max gradient is 8.000000, min gradient is -7.934885, learning rate is 0.000200
Net2: layer bn50:max response is 19.657196, min response is -4.351085.
max gradient is 8.000000, min gradient is -6.296619, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.400466, learning rate is 0.000200
Net2: layer bn49:max response is 16.605370, min response is -3.327985.
max gradient is 4.662561, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.021942, learning rate is 0.000200
max inferred z is 4.12, min inferred z is -3.74, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 125: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.297837, min gradient is -8.000000, learning rate is 0.000020
Net1: layer conv2:max response is , min response is .
max gradient is 6.446695, min gradient is -8.000000, learning rate is 0.000020
Net1: layer conv1:max response is , min response is .
max gradient is 6.355241, min gradient is -8.000000, learning rate is 0.000020
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.493722, learning rate is 0.000400
Net2: layer deconv3:max response is 75.174484, min response is -68.410934.
max gradient is 4.224098, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.232237, min response is -4.827740.
max gradient is 7.485259, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.914047, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.286041, min response is -3.120221.
max gradient is 8.000000, min gradient is -6.013060, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.643187, learning rate is 0.000200
max inferred z is 4.19, min inferred z is -4.15, and std is 1.00
 4.22 s (23.7 data/s) [100/100]
training: epoch 125: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.539182, min gradient is -8.000000, learning rate is 0.000020
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.455514, learning rate is 0.000020
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.645157, learning rate is 0.000020
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.884676, learning rate is 0.000400
Net2: layer deconv3:max response is 57.869762, min response is -51.833176.
max gradient is 8.000000, min gradient is -3.931337, learning rate is 0.000200
Net2: layer bn50:max response is 19.171751, min response is -4.946766.
max gradient is 8.000000, min gradient is -6.206927, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.030528, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 15.851662, min response is -3.882207.
max gradient is 4.941401, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.668563, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 5.14, min inferred z is -3.88, and std is 1.00
 4.23 s (23.6 data/s) [100/100]
training: epoch 125: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.651106, min gradient is -8.000000, learning rate is 0.000020
Net1: layer conv2:max response is , min response is .
max gradient is 7.958962, min gradient is -8.000000, learning rate is 0.000020
Net1: layer conv1:max response is , min response is .
max gradient is 6.675202, min gradient is -8.000000, learning rate is 0.000020
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.395399, learning rate is 0.000400
Net2: layer deconv3:max response is 62.932980, min response is -55.117142.
max gradient is 3.633662, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.545618, min response is -5.453605.
max gradient is 7.089264, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.930454, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.447731, min response is -3.179957.
max gradient is 8.000000, min gradient is -5.159387, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.422106, learning rate is 0.000200
max inferred z is 4.62, min inferred z is -4.47, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 125: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.327092, min gradient is -8.000000, learning rate is 0.000020
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.611383, learning rate is 0.000020
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.765712, learning rate is 0.000020
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.423603, learning rate is 0.000400
Net2: layer deconv3:max response is 66.055832, min response is -58.740067.
max gradient is 8.000000, min gradient is -4.394507, learning rate is 0.000200
Net2: layer bn50:max response is 19.937225, min response is -4.780540.
max gradient is 8.000000, min gradient is -6.926302, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.089211, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.592005, min response is -3.097302.
max gradient is 5.777885, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.530985, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.76, min inferred z is -3.91, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 125: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.294841, min gradient is -8.000000, learning rate is 0.000020
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.920022, learning rate is 0.000020
Net1: layer conv1:max response is , min response is .
max gradient is 7.082190, min gradient is -8.000000, learning rate is 0.000020
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.613944, learning rate is 0.000400
Net2: layer deconv3:max response is 61.741695, min response is -54.221554.
max gradient is 2.530853, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.442680, min response is -4.465830.
max gradient is 7.554793, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.709634, learning rate is 0.000200
Net2: layer bn49:max response is 16.224676, min response is -3.165524.
max gradient is 8.000000, min gradient is -4.994587, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.015321, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.07, min inferred z is -3.71, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
training: epoch 125: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.706507, min gradient is -8.000000, learning rate is 0.000020
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.697222, learning rate is 0.000020
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.706868, learning rate is 0.000020
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.682591, learning rate is 0.000400
Net2: layer deconv3:max response is 64.185326, min response is -61.269794.
max gradient is 8.000000, min gradient is -1.672291, learning rate is 0.000200
Net2: layer bn50:max response is 19.762001, min response is -4.325951.
max gradient is 7.769384, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.402062, learning rate is 0.000200
Net2: layer bn49:max response is 15.083338, min response is -3.286686.
max gradient is 7.346353, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.070793, learning rate is 0.000200
max inferred z is 3.89, min inferred z is -3.65, and std is 1.00
 4.43 s (22.6 data/s) [100/100]
training: epoch 125: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.624329, min gradient is -8.000000, learning rate is 0.000020
Net1: layer conv2:max response is , min response is .
max gradient is 7.185480, min gradient is -8.000000, learning rate is 0.000020
Net1: layer conv1:max response is , min response is .
max gradient is 6.658453, min gradient is -8.000000, learning rate is 0.000020
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.509153, learning rate is 0.000400
Net2: layer deconv3:max response is 68.683487, min response is -54.055252.
max gradient is 1.629205, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.725134, min response is -4.302896.
max gradient is 7.483879, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.402142, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 15.663130, min response is -3.623364.
max gradient is 8.000000, min gradient is -7.600659, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.840550, learning rate is 0.000200
max inferred z is 3.72, min inferred z is -3.53, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
training: epoch 125: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.723924, min gradient is -8.000000, learning rate is 0.000020
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.783420, learning rate is 0.000020
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.054266, learning rate is 0.000020
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.425211, learning rate is 0.000400
Net2: layer deconv3:max response is 62.315281, min response is -53.906132.
max gradient is 8.000000, min gradient is -4.312265, learning rate is 0.000200
Net2: layer bn50:max response is 19.595592, min response is -4.233427.
max gradient is 8.000000, min gradient is -6.146080, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000001, min gradient is -6.470427, learning rate is 0.000200
Net2: layer bn49:max response is 16.198092, min response is -3.577955.
max gradient is 6.212157, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.617290, learning rate is 0.000200
max inferred z is 4.19, min inferred z is -3.79, and std is 1.00
 4.32 s (23.2 data/s) [100/100]
Loss: 1.2196
Iteration 126 / 200
training: epoch 126: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.785943, min gradient is -8.000000, learning rate is 0.000020
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.738488, learning rate is 0.000020
Net1: layer conv1:max response is , min response is .
max gradient is 7.574785, min gradient is -8.000000, learning rate is 0.000020
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.167455, learning rate is 0.000400
Net2: layer deconv3:max response is 67.205795, min response is -59.412399.
max gradient is 3.742156, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.501341, min response is -4.463705.
max gradient is 6.959290, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.679017, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 16.762327, min response is -3.619049.
max gradient is 8.000000, min gradient is -5.590698, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.923730, learning rate is 0.000200
max inferred z is 4.39, min inferred z is -3.55, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
training: epoch 126: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.322848, min gradient is -8.000000, learning rate is 0.000020
Net1: layer conv2:max response is , min response is .
max gradient is 6.464477, min gradient is -8.000000, learning rate is 0.000020
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.586781, learning rate is 0.000020
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.974037, learning rate is 0.000400
Net2: layer deconv3:max response is 74.594833, min response is -68.282867.
max gradient is 8.000000, min gradient is -6.956870, learning rate is 0.000200
Net2: layer bn50:max response is 21.969507, min response is -4.938964.
max gradient is 5.939832, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.779325, learning rate is 0.000200
Net2: layer bn49:max response is 19.071842, min response is -3.959357.
max gradient is 4.922863, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.528481, learning rate is 0.000200
max inferred z is 4.36, min inferred z is -4.17, and std is 1.00
 4.19 s (23.9 data/s) [100/100]
training: epoch 126: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.422741, min gradient is -8.000000, learning rate is 0.000020
Net1: layer conv2:max response is , min response is .
max gradient is 6.402683, min gradient is -8.000000, learning rate is 0.000020
Net1: layer conv1:max response is , min response is .
max gradient is 6.436203, min gradient is -8.000000, learning rate is 0.000020
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.454568, learning rate is 0.000400
Net2: layer deconv3:max response is 86.028015, min response is -78.347450.
max gradient is 6.104706, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.446255, min response is -5.597222.
max gradient is 8.000000, min gradient is -7.097044, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.466599, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.303204, min response is -3.417781.
max gradient is 8.000000, min gradient is -7.019171, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.508159, learning rate is 0.000200
max inferred z is 3.68, min inferred z is -3.78, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
training: epoch 126: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.618127, min gradient is -8.000000, learning rate is 0.000020
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.777554, learning rate is 0.000020
Net1: layer conv1:max response is , min response is .
max gradient is 7.705765, min gradient is -8.000000, learning rate is 0.000020
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.508039, learning rate is 0.000400
Net2: layer deconv3:max response is 64.113136, min response is -56.266949.
max gradient is 8.000000, min gradient is -5.660676, learning rate is 0.000200
Net2: layer bn50:max response is 20.279818, min response is -4.805791.
max gradient is 8.000000, min gradient is -6.827291, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.977171, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.811384, min response is -3.291185.
max gradient is 6.721702, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.661371, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.03, min inferred z is -4.25, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 126: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.891172, min gradient is -8.000000, learning rate is 0.000020
Net1: layer conv2:max response is , min response is .
max gradient is 6.779397, min gradient is -8.000000, learning rate is 0.000020
Net1: layer conv1:max response is , min response is .
max gradient is 6.778525, min gradient is -8.000000, learning rate is 0.000020
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.528584, learning rate is 0.000400
Net2: layer deconv3:max response is 65.178253, min response is -57.990036.
max gradient is 3.476398, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.329391, min response is -4.822145.
max gradient is 8.000000, min gradient is -7.677311, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.907475, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.307283, min response is -3.471135.
max gradient is 8.000000, min gradient is -6.596893, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.345727, learning rate is 0.000200
max inferred z is 4.05, min inferred z is -4.06, and std is 1.00
 4.43 s (22.6 data/s) [100/100]
training: epoch 126: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.563701, min gradient is -8.000000, learning rate is 0.000020
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.300414, learning rate is 0.000020
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.450963, learning rate is 0.000020
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -3.375768, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 70.138184, min response is -67.042007.
max gradient is 8.000000, min gradient is -1.579546, learning rate is 0.000200
Net2: layer bn50:max response is 19.921822, min response is -4.355008.
max gradient is 6.041550, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.063614, learning rate is 0.000200
Net2: layer bn49:max response is 17.329281, min response is -2.799070.
max gradient is 6.809345, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.927779, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.15, min inferred z is -3.98, and std is 1.00
 4.30 s (23.3 data/s) [100/100]
training: epoch 126: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.505292, min gradient is -8.000000, learning rate is 0.000020
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.549624, learning rate is 0.000020
Net1: layer conv1:max response is , min response is .
max gradient is 7.294042, min gradient is -8.000000, learning rate is 0.000020
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.306083, learning rate is 0.000400
Net2: layer deconv3:max response is 84.478920, min response is -76.400635.
max gradient is 2.894511, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.415331, min response is -5.250185.
max gradient is 8.000000, min gradient is -6.708083, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.511665, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.084560, min response is -3.754605.
max gradient is 8.000000, min gradient is -6.579688, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.479168, learning rate is 0.000200
max inferred z is 3.99, min inferred z is -3.85, and std is 1.00
 4.40 s (22.8 data/s) [100/100]
training: epoch 126: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.740403, min gradient is -8.000000, learning rate is 0.000020
Net1: layer conv2:max response is , min response is .
max gradient is 7.824091, min gradient is -8.000000, learning rate is 0.000020
Net1: layer conv1:max response is , min response is .
max gradient is 6.292896, min gradient is -8.000000, learning rate is 0.000020
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.917940, learning rate is 0.000400
Net2: layer deconv3:max response is 67.449745, min response is -56.529312.
max gradient is 8.000000, min gradient is -3.880921, learning rate is 0.000200
Net2: layer bn50:max response is 20.949238, min response is -4.290218.
max gradient is 8.000000, min gradient is -7.109825, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.566165, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 16.582594, min response is -3.537755.
max gradient is 6.146217, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.084759, learning rate is 0.000200
max inferred z is 4.38, min inferred z is -4.09, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
training: epoch 126: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.527494, min gradient is -8.000000, learning rate is 0.000020
Net1: layer conv2:max response is , min response is .
max gradient is 6.886678, min gradient is -8.000000, learning rate is 0.000020
Net1: layer conv1:max response is , min response is .
max gradient is 6.379611, min gradient is -8.000000, learning rate is 0.000020
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.055293, learning rate is 0.000400
Net2: layer deconv3:max response is 72.047737, min response is -65.124969.
max gradient is 3.411647, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.788252, min response is -4.454206.
max gradient is 6.729408, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.141973, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.115057, min response is -3.277740.
max gradient is 8.000000, min gradient is -4.877158, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.191706, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.73, min inferred z is -4.31, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
training: epoch 126: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.131776, min gradient is -8.000000, learning rate is 0.000020
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.545528, learning rate is 0.000020
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.770013, learning rate is 0.000020
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.080601, learning rate is 0.000400
Net2: layer deconv3:max response is 63.310032, min response is -55.890854.
max gradient is 5.344342, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.200953, min response is -4.654649.
max gradient is 3.819442, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.561455, learning rate is 0.000200
Net2: layer bn49:max response is 17.418602, min response is -3.403319.
max gradient is 5.114890, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.730724, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.97, min inferred z is -3.49, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
Loss: 1.3952
Iteration 127 / 200
training: epoch 127: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.929565, min gradient is -8.000000, learning rate is 0.000017
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.964713, learning rate is 0.000017
Net1: layer conv1:max response is , min response is .
max gradient is 7.994804, min gradient is -8.000000, learning rate is 0.000017
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.252908, learning rate is 0.000400
Net2: layer deconv3:max response is 73.756500, min response is -70.459587.
max gradient is 7.874166, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.028790, min response is -4.646080.
max gradient is 8.000000, min gradient is -4.702667, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.324940, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.615837, min response is -3.160655.
max gradient is 8.000000, min gradient is -6.279256, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.080929, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.79, min inferred z is -4.14, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 127: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.449929, min gradient is -8.000000, learning rate is 0.000017
Net1: layer conv2:max response is , min response is .
max gradient is 6.110034, min gradient is -8.000000, learning rate is 0.000017
Net1: layer conv1:max response is , min response is .
max gradient is 7.618102, min gradient is -8.000000, learning rate is 0.000017
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.403452, learning rate is 0.000400
Net2: layer deconv3:max response is 71.653671, min response is -66.755768.
max gradient is 8.000000, min gradient is -3.909644, learning rate is 0.000200
Net2: layer bn50:max response is 19.850874, min response is -4.393064.
max gradient is 8.000000, min gradient is -7.688475, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.186950, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.595150, min response is -3.253909.
max gradient is 8.000000, min gradient is -6.546830, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.479187, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.05, min inferred z is -4.01, and std is 1.00
 4.18 s (23.9 data/s) [100/100]
training: epoch 127: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.587337, min gradient is -8.000000, learning rate is 0.000017
Net1: layer conv2:max response is , min response is .
max gradient is 5.554212, min gradient is -8.000000, learning rate is 0.000017
Net1: layer conv1:max response is , min response is .
max gradient is 6.914726, min gradient is -8.000000, learning rate is 0.000017
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.303556, learning rate is 0.000400
Net2: layer deconv3:max response is 66.534660, min response is -59.808830.
max gradient is 2.376611, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.113304, min response is -4.624593.
max gradient is 8.000000, min gradient is -6.933181, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.528839, learning rate is 0.000200
Net2: layer bn49:max response is 17.201361, min response is -3.369309.
max gradient is 8.000000, min gradient is -4.304149, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.240992, learning rate is 0.000200
max inferred z is 5.09, min inferred z is -4.39, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
training: epoch 127: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.776165, min gradient is -8.000000, learning rate is 0.000017
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.539144, learning rate is 0.000017
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.183355, learning rate is 0.000017
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.875319, learning rate is 0.000400
Net2: layer deconv3:max response is 73.270233, min response is -68.039597.
max gradient is 8.000000, min gradient is -2.544732, learning rate is 0.000200
Net2: layer bn50:max response is 21.057024, min response is -4.598986.
max gradient is 7.334922, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.576966, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.061180, min response is -3.806168.
max gradient is 6.751750, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.797420, learning rate is 0.000200
max inferred z is 3.87, min inferred z is -3.96, and std is 1.00
 4.30 s (23.3 data/s) [100/100]
training: epoch 127: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.784622, min gradient is -8.000000, learning rate is 0.000017
Net1: layer conv2:max response is , min response is .
max gradient is 6.131363, min gradient is -8.000000, learning rate is 0.000017
Net1: layer conv1:max response is , min response is .
max gradient is 7.190476, min gradient is -8.000000, learning rate is 0.000017
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.739142, learning rate is 0.000400
Net2: layer deconv3:max response is 71.309700, min response is -63.616158.
max gradient is 3.090904, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.283594, min response is -4.289494.
max gradient is 7.333172, min gradient is -8.000001, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.209505, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.434774, min response is -3.555169.
max gradient is 8.000000, min gradient is -6.241984, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.729992, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.95, min inferred z is -3.99, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 127: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.571999, min gradient is -8.000000, learning rate is 0.000017
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.914945, learning rate is 0.000017
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.187174, learning rate is 0.000017
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.212403, learning rate is 0.000400
Net2: layer deconv3:max response is 85.815575, min response is -67.164803.
max gradient is 8.000000, min gradient is -2.709554, learning rate is 0.000200
Net2: layer bn50:max response is 27.760054, min response is -4.629717.
max gradient is 8.000000, min gradient is -6.934672, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.914367, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 16.930555, min response is -4.833131.
max gradient is 6.625541, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.285474, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.82, min inferred z is -3.96, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 127: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.619608, min gradient is -8.000000, learning rate is 0.000017
Net1: layer conv2:max response is , min response is .
max gradient is 7.827049, min gradient is -8.000000, learning rate is 0.000017
Net1: layer conv1:max response is , min response is .
max gradient is 7.462157, min gradient is -8.000000, learning rate is 0.000017
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.581453, learning rate is 0.000400
Net2: layer deconv3:max response is 88.330154, min response is -81.066277.
max gradient is 3.190033, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.638556, min response is -4.898878.
max gradient is 7.507574, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.183145, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.359035, min response is -3.613500.
max gradient is 8.000000, min gradient is -5.024872, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.242596, learning rate is 0.000200
max inferred z is 4.20, min inferred z is -4.41, and std is 1.00
 4.43 s (22.6 data/s) [100/100]
training: epoch 127: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.766492, min gradient is -8.000000, learning rate is 0.000017
Net1: layer conv2:max response is , min response is .
max gradient is 7.051342, min gradient is -8.000000, learning rate is 0.000017
Net1: layer conv1:max response is , min response is .
max gradient is 6.553181, min gradient is -8.000000, learning rate is 0.000017
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.588143, learning rate is 0.000400
Net2: layer deconv3:max response is 66.762268, min response is -60.377300.
max gradient is 8.000000, min gradient is -5.709402, learning rate is 0.000200
Net2: layer bn50:max response is 18.464491, min response is -3.960457.
max gradient is 6.417016, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.126386, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 16.504377, min response is -3.103301.
max gradient is 6.289955, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.519981, learning rate is 0.000200
max inferred z is 4.32, min inferred z is -4.35, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 127: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.835316, min gradient is -8.000000, learning rate is 0.000017
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.601776, learning rate is 0.000017
Net1: layer conv1:max response is , min response is .
max gradient is 6.549805, min gradient is -8.000000, learning rate is 0.000017
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.633815, learning rate is 0.000400
Net2: layer deconv3:max response is 65.909180, min response is -58.707047.
max gradient is 5.450933, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.652281, min response is -4.255244.
max gradient is 8.000000, min gradient is -7.968720, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.295611, learning rate is 0.000200
Net2: layer bn49:max response is 17.465759, min response is -3.715890.
max gradient is 7.370089, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.970698, learning rate is 0.000200
max inferred z is 3.91, min inferred z is -4.52, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 127: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.142447, min gradient is -8.000000, learning rate is 0.000017
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.329952, learning rate is 0.000017
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -6.584390, learning rate is 0.000017
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.069200, learning rate is 0.000400
Net2: layer deconv3:max response is 64.721100, min response is -58.503151.
max gradient is 8.000000, min gradient is -2.915474, learning rate is 0.000200
Net2: layer bn50:max response is 20.000725, min response is -4.820377.
max gradient is 8.000000, min gradient is -7.635339, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.128270, learning rate is 0.000200
Net2: layer bn49:max response is 17.165384, min response is -3.293682.
max gradient is 4.359853, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.401078, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.75, min inferred z is -4.04, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
Loss: 1.3437
Iteration 128 / 200
training: epoch 128: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.001849, min gradient is -8.000000, learning rate is 0.000017
Net1: layer conv2:max response is , min response is .
max gradient is 6.201615, min gradient is -8.000000, learning rate is 0.000017
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.931036, learning rate is 0.000017
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.580314, learning rate is 0.000400
Net2: layer deconv3:max response is 85.445267, min response is -75.882492.
max gradient is 1.612784, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.060329, min response is -5.059723.
max gradient is 7.729061, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.625832, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.660854, min response is -3.001365.
max gradient is 8.000000, min gradient is -4.945487, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.318802, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.31, min inferred z is -4.35, and std is 1.00
 4.18 s (23.9 data/s) [100/100]
training: epoch 128: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.514862, min gradient is -8.000000, learning rate is 0.000017
Net1: layer conv2:max response is , min response is .
max gradient is 6.067408, min gradient is -8.000000, learning rate is 0.000017
Net1: layer conv1:max response is , min response is .
max gradient is 7.635531, min gradient is -8.000000, learning rate is 0.000017
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.054215, learning rate is 0.000400
Net2: layer deconv3:max response is 63.942360, min response is -54.392097.
max gradient is 8.000000, min gradient is -7.063690, learning rate is 0.000200
Net2: layer bn50:max response is 21.846247, min response is -3.844759.
max gradient is 6.324115, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.542807, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 15.559286, min response is -3.639413.
max gradient is 6.690642, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.774876, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.25, min inferred z is -4.31, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
training: epoch 128: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.650649, min gradient is -8.000000, learning rate is 0.000017
Net1: layer conv2:max response is , min response is .
max gradient is 6.053404, min gradient is -8.000000, learning rate is 0.000017
Net1: layer conv1:max response is , min response is .
max gradient is 6.298110, min gradient is -8.000000, learning rate is 0.000017
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.213429, learning rate is 0.000400
Net2: layer deconv3:max response is 79.768867, min response is -71.472809.
max gradient is 6.928454, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.142172, min response is -4.615964.
max gradient is 8.000000, min gradient is -5.487759, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.453189, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.356356, min response is -3.559241.
max gradient is 8.000000, min gradient is -6.939435, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.421768, learning rate is 0.000200
max inferred z is 4.26, min inferred z is -4.05, and std is 1.00
 4.23 s (23.7 data/s) [100/100]
training: epoch 128: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.820368, min gradient is -8.000000, learning rate is 0.000017
Net1: layer conv2:max response is , min response is .
max gradient is 5.834502, min gradient is -8.000000, learning rate is 0.000017
Net1: layer conv1:max response is , min response is .
max gradient is 7.486987, min gradient is -8.000000, learning rate is 0.000017
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.012458, learning rate is 0.000400
Net2: layer deconv3:max response is 73.394623, min response is -63.837868.
max gradient is 6.338196, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.427528, min response is -4.757101.
max gradient is 4.659611, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.080325, learning rate is 0.000200
Net2: layer bn49:max response is 18.328753, min response is -3.610015.
max gradient is 6.486671, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.613864, learning rate is 0.000200
max inferred z is 4.42, min inferred z is -4.07, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
training: epoch 128: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.190504, min gradient is -8.000000, learning rate is 0.000017
Net1: layer conv2:max response is , min response is .
max gradient is 6.170259, min gradient is -8.000000, learning rate is 0.000017
Net1: layer conv1:max response is , min response is .
max gradient is 7.061585, min gradient is -8.000000, learning rate is 0.000017
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.088343, learning rate is 0.000400
Net2: layer deconv3:max response is 76.540970, min response is -70.336128.
max gradient is 6.831039, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.005583, min response is -4.724397.
max gradient is 8.000000, min gradient is -6.349703, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.980110, learning rate is 0.000200
Net2: layer bn49:max response is 18.656973, min response is -3.820412.
max gradient is 8.000000, min gradient is -7.014317, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.036659, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.40, min inferred z is -3.89, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 128: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.659804, min gradient is -8.000000, learning rate is 0.000017
Net1: layer conv2:max response is , min response is .
max gradient is 7.002730, min gradient is -8.000000, learning rate is 0.000017
Net1: layer conv1:max response is , min response is .
max gradient is 7.716223, min gradient is -8.000000, learning rate is 0.000017
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.619365, learning rate is 0.000400
Net2: layer deconv3:max response is 78.586243, min response is -69.924294.
max gradient is 8.000000, min gradient is -7.910302, learning rate is 0.000200
Net2: layer bn50:max response is 21.346928, min response is -4.671052.
max gradient is 5.487537, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.888745, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.019192, min response is -3.435778.
max gradient is 5.333694, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.296453, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.60, min inferred z is -3.90, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 128: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.561341, min gradient is -8.000000, learning rate is 0.000017
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.055609, learning rate is 0.000017
Net1: layer conv1:max response is , min response is .
max gradient is 7.147601, min gradient is -8.000000, learning rate is 0.000017
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.350081, learning rate is 0.000400
Net2: layer deconv3:max response is 63.004597, min response is -54.621822.
max gradient is 6.342499, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 17.908075, min response is -4.034190.
max gradient is 8.000000, min gradient is -6.713759, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.321124, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 16.325602, min response is -3.203173.
max gradient is 8.000000, min gradient is -7.113886, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.276739, learning rate is 0.000200
max inferred z is 3.61, min inferred z is -3.81, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 128: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.822083, min gradient is -8.000000, learning rate is 0.000017
Net1: layer conv2:max response is , min response is .
max gradient is 6.209816, min gradient is -8.000000, learning rate is 0.000017
Net1: layer conv1:max response is , min response is .
max gradient is 7.260358, min gradient is -8.000000, learning rate is 0.000017
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.087011, learning rate is 0.000400
Net2: layer deconv3:max response is 80.895103, min response is -70.743340.
max gradient is 6.051600, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 24.435892, min response is -4.786194.
max gradient is 8.000000, min gradient is -6.840295, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.147790, learning rate is 0.000200
Net2: layer bn49:max response is 19.900324, min response is -4.254709.
max gradient is 6.529086, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.770853, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.67, min inferred z is -3.91, and std is 1.00
 4.23 s (23.6 data/s) [100/100]
training: epoch 128: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.894795, min gradient is -8.000000, learning rate is 0.000017
Net1: layer conv2:max response is , min response is .
max gradient is 7.799816, min gradient is -8.000000, learning rate is 0.000017
Net1: layer conv1:max response is , min response is .
max gradient is 7.145133, min gradient is -8.000000, learning rate is 0.000017
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.392599, learning rate is 0.000400
Net2: layer deconv3:max response is 89.575478, min response is -79.273705.
max gradient is 8.000000, min gradient is -4.828663, learning rate is 0.000200
Net2: layer bn50:max response is 24.384615, min response is -5.247429.
max gradient is 8.000000, min gradient is -7.902938, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.038108, learning rate is 0.000200
Net2: layer bn49:max response is 21.726484, min response is -3.693367.
max gradient is 8.000000, min gradient is -6.532965, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.007115, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.20, min inferred z is -3.84, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 128: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.325722, min gradient is -8.000000, learning rate is 0.000017
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.242502, learning rate is 0.000017
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -6.916010, learning rate is 0.000017
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.232865, learning rate is 0.000400
Net2: layer deconv3:max response is 84.111694, min response is -75.769608.
max gradient is 4.299964, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.638233, min response is -4.804607.
max gradient is 8.000000, min gradient is -7.952588, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.933284, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.170362, min response is -3.206855.
max gradient is 8.000000, min gradient is -5.454995, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.286572, learning rate is 0.000200
max inferred z is 3.77, min inferred z is -4.02, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
Loss: 1.2497
Iteration 129 / 200
training: epoch 129: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.964450, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.117976, learning rate is 0.000014
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.803153, learning rate is 0.000014
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -3.230069, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 57.645531, min response is -52.612679.
max gradient is 8.000000, min gradient is -2.118947, learning rate is 0.000200
Net2: layer bn50:max response is 19.079588, min response is -3.991503.
max gradient is 6.874658, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.903911, learning rate is 0.000200
Net2: layer bn49:max response is 14.913382, min response is -3.191541.
max gradient is 5.698312, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.662328, learning rate is 0.000200
max inferred z is 3.59, min inferred z is -4.05, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 129: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.774161, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv2:max response is , min response is .
max gradient is 5.502776, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv1:max response is , min response is .
max gradient is 7.947440, min gradient is -8.000000, learning rate is 0.000014
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.481766, learning rate is 0.000400
Net2: layer deconv3:max response is 80.413528, min response is -68.399033.
max gradient is 1.994108, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.754723, min response is -4.976607.
max gradient is 8.000000, min gradient is -7.900709, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.440676, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.239975, min response is -3.743653.
max gradient is 8.000000, min gradient is -5.799754, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.817386, learning rate is 0.000200
max inferred z is 4.34, min inferred z is -4.26, and std is 1.00
 4.30 s (23.3 data/s) [100/100]
training: epoch 129: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.681009, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv2:max response is , min response is .
max gradient is 5.821435, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv1:max response is , min response is .
max gradient is 6.993219, min gradient is -8.000000, learning rate is 0.000014
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.840159, learning rate is 0.000400
Net2: layer deconv3:max response is 67.626503, min response is -56.703835.
max gradient is 8.000000, min gradient is -3.290608, learning rate is 0.000200
Net2: layer bn50:max response is 17.709007, min response is -3.884183.
max gradient is 8.000000, min gradient is -7.588044, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.506091, learning rate is 0.000200
Net2: layer bn49:max response is 17.369520, min response is -3.667868.
max gradient is 5.509296, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.571431, learning rate is 0.000200
max inferred z is 4.00, min inferred z is -3.78, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 129: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.895945, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv2:max response is , min response is .
max gradient is 6.333228, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv1:max response is , min response is .
max gradient is 6.377454, min gradient is -8.000000, learning rate is 0.000014
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.796280, learning rate is 0.000400
Net2: layer deconv3:max response is 71.881653, min response is -61.816605.
max gradient is 4.673866, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.195017, min response is -5.072713.
max gradient is 8.000000, min gradient is -7.081991, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.277687, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.023851, min response is -3.314342.
max gradient is 5.980058, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.505124, learning rate is 0.000200
max inferred z is 3.72, min inferred z is -3.47, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 129: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.999623, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv2:max response is , min response is .
max gradient is 5.306775, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv1:max response is , min response is .
max gradient is 7.593322, min gradient is -8.000000, learning rate is 0.000014
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 7.751621, min gradient is -3.710292, learning rate is 0.000400
Net2: layer deconv3:max response is 73.365120, min response is -62.612476.
max gradient is 5.980370, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.043591, min response is -4.756340.
max gradient is 4.298077, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 4.560327, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.881407, min response is -3.282828.
max gradient is 5.654940, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.180393, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.98, min inferred z is -3.87, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
training: epoch 129: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.806781, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv2:max response is , min response is .
max gradient is 7.684704, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.605601, learning rate is 0.000014
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.357676, learning rate is 0.000400
Net2: layer deconv3:max response is 103.596222, min response is -93.477470.
max gradient is 8.000000, min gradient is -7.741721, learning rate is 0.000200
Net2: layer bn50:max response is 27.448172, min response is -5.509881.
max gradient is 8.000000, min gradient is -6.863606, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.294996, learning rate is 0.000200
Net2: layer bn49:max response is 23.618465, min response is -3.488206.
max gradient is 7.765168, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.235615, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.22, min inferred z is -3.97, and std is 1.00
 4.30 s (23.3 data/s) [100/100]
training: epoch 129: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.834346, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv2:max response is , min response is .
max gradient is 6.749638, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.630342, learning rate is 0.000014
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.501541, learning rate is 0.000400
Net2: layer deconv3:max response is 78.903534, min response is -67.332642.
max gradient is 7.874965, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.519543, min response is -4.995184.
max gradient is 4.391590, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.414618, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.830687, min response is -3.277822.
max gradient is 7.505391, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.259942, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.63, min inferred z is -4.19, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 129: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.097073, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv2:max response is , min response is .
max gradient is 6.039788, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv1:max response is , min response is .
max gradient is 6.205103, min gradient is -8.000000, learning rate is 0.000014
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.640429, learning rate is 0.000400
Net2: layer deconv3:max response is 63.799633, min response is -56.313259.
max gradient is 7.171981, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.056290, min response is -3.914885.
max gradient is 8.000000, min gradient is -4.360423, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.864740, learning rate is 0.000200
Net2: layer bn49:max response is 15.916081, min response is -3.047426.
max gradient is 8.000000, min gradient is -6.674385, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.894654, learning rate is 0.000200
max inferred z is 4.09, min inferred z is -3.74, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 129: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.889628, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv2:max response is , min response is .
max gradient is 5.215669, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv1:max response is , min response is .
max gradient is 7.337645, min gradient is -8.000000, learning rate is 0.000014
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -4.743621, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 81.132332, min response is -68.871910.
max gradient is 8.000000, min gradient is -6.599296, learning rate is 0.000200
Net2: layer bn50:max response is 22.532892, min response is -4.640396.
max gradient is 3.891273, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.170211, learning rate is 0.000200
Net2: layer bn49:max response is 19.624149, min response is -3.306164.
max gradient is 7.448704, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.827191, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.27, min inferred z is -3.97, and std is 1.00
 4.41 s (22.7 data/s) [100/100]
training: epoch 129: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.325965, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.747671, learning rate is 0.000014
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.508239, learning rate is 0.000014
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000001, min gradient is 7.508733, learning rate is 0.000400
Net2: layer deconv3:max response is 84.947357, min response is -74.568298.
max gradient is 5.774313, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.967978, min response is -4.454198.
max gradient is 2.771232, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.792818, learning rate is 0.000200
Net2: layer bn49:max response is 20.206161, min response is -3.488927.
max gradient is 8.000000, min gradient is -6.570011, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.480971, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.08, min inferred z is -3.57, and std is 1.00
 4.46 s (22.4 data/s) [100/100]
Loss: 1.392
Iteration 130 / 200
training: epoch 130: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.300239, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.613159, learning rate is 0.000014
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.130969, learning rate is 0.000014
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.530158, learning rate is 0.000400
Net2: layer deconv3:max response is 65.511307, min response is -57.120678.
max gradient is 7.646764, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.991776, min response is -4.033243.
max gradient is 8.000000, min gradient is -4.507884, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.113349, learning rate is 0.000200
Net2: layer bn49:max response is 16.443651, min response is -3.688355.
max gradient is 8.000000, min gradient is -7.504727, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.981351, learning rate is 0.000200
max inferred z is 3.59, min inferred z is -3.49, and std is 1.00
 4.16 s (24.0 data/s) [100/100]
training: epoch 130: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.530474, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv2:max response is , min response is .
max gradient is 5.951674, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv1:max response is , min response is .
max gradient is 7.609718, min gradient is -8.000000, learning rate is 0.000014
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.897716, learning rate is 0.000400
Net2: layer deconv3:max response is 68.593643, min response is -57.457130.
max gradient is 8.000000, min gradient is -4.243124, learning rate is 0.000200
Net2: layer bn50:max response is 22.924316, min response is -3.934107.
max gradient is 8.000000, min gradient is -7.795608, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.534829, learning rate is 0.000200
Net2: layer bn49:max response is 16.724537, min response is -3.868035.
max gradient is 3.991805, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.416365, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.19, min inferred z is -3.94, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 130: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.571499, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv2:max response is , min response is .
max gradient is 5.584801, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv1:max response is , min response is .
max gradient is 6.791893, min gradient is -8.000000, learning rate is 0.000014
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.394627, learning rate is 0.000400
Net2: layer deconv3:max response is 84.166771, min response is -71.131493.
max gradient is 3.184546, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.141829, min response is -4.513063.
max gradient is 7.952284, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.672323, learning rate is 0.000200
Net2: layer bn49:max response is 20.030663, min response is -3.633685.
max gradient is 8.000000, min gradient is -4.813316, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.738004, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.19, min inferred z is -3.91, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 130: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.122582, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv2:max response is , min response is .
max gradient is 6.181957, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv1:max response is , min response is .
max gradient is 7.489851, min gradient is -8.000000, learning rate is 0.000014
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.371104, learning rate is 0.000400
Net2: layer deconv3:max response is 81.632927, min response is -70.387962.
max gradient is 4.496202, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.537218, min response is -4.828021.
max gradient is 6.843098, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.552924, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.571138, min response is -3.496392.
max gradient is 7.472592, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.600916, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.09, min inferred z is -4.21, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 130: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.277097, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv2:max response is , min response is .
max gradient is 6.211298, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv1:max response is , min response is .
max gradient is 7.072734, min gradient is -8.000000, learning rate is 0.000014
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -2.449927, learning rate is 0.000400
Net2: layer deconv3:max response is 70.295479, min response is -61.567383.
max gradient is 8.000000, min gradient is -2.636231, learning rate is 0.000200
Net2: layer bn50:max response is 19.423639, min response is -4.024189.
max gradient is 6.326578, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.596019, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.068943, min response is -3.593906.
max gradient is 5.083097, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.845203, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.73, min inferred z is -3.71, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
training: epoch 130: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.940012, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv2:max response is , min response is .
max gradient is 6.168478, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.576213, learning rate is 0.000014
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.151213, learning rate is 0.000400
Net2: layer deconv3:max response is 73.141937, min response is -61.880459.
max gradient is 3.042442, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.922432, min response is -4.421827.
max gradient is 6.998842, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.842128, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.908836, min response is -3.556908.
max gradient is 8.000000, min gradient is -5.394038, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.717483, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.78, min inferred z is -3.93, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 130: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.795683, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv2:max response is , min response is .
max gradient is 6.842320, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv1:max response is , min response is .
max gradient is 7.777289, min gradient is -8.000000, learning rate is 0.000014
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.825073, learning rate is 0.000400
Net2: layer deconv3:max response is 66.691528, min response is -56.071899.
max gradient is 8.000000, min gradient is -4.371268, learning rate is 0.000200
Net2: layer bn50:max response is 20.865194, min response is -4.201198.
max gradient is 8.000000, min gradient is -6.859538, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.909274, learning rate is 0.000200
Net2: layer bn49:max response is 16.973442, min response is -3.652378.
max gradient is 4.788022, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.574827, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.09, min inferred z is -3.53, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 130: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.026190, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv2:max response is , min response is .
max gradient is 5.326766, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv1:max response is , min response is .
max gradient is 6.660532, min gradient is -8.000000, learning rate is 0.000014
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.124580, learning rate is 0.000400
Net2: layer deconv3:max response is 80.995926, min response is -68.660568.
max gradient is 4.331474, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.551945, min response is -4.581228.
max gradient is 7.050807, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.476163, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.032452, min response is -3.869476.
max gradient is 8.000000, min gradient is -5.630270, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.943022, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.62, min inferred z is -4.44, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 130: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.957629, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv2:max response is , min response is .
max gradient is 5.927270, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv1:max response is , min response is .
max gradient is 6.897364, min gradient is -8.000000, learning rate is 0.000014
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.748636, learning rate is 0.000400
Net2: layer deconv3:max response is 78.377464, min response is -66.010315.
max gradient is 7.045619, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 25.407450, min response is -4.394901.
max gradient is 5.396476, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.210762, learning rate is 0.000200
Net2: layer bn49:max response is 19.596834, min response is -4.429541.
max gradient is 7.983628, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.122823, learning rate is 0.000200
max inferred z is 3.81, min inferred z is -3.77, and std is 1.00
 4.48 s (22.3 data/s) [100/100]
training: epoch 130: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.530890, min gradient is -8.000000, learning rate is 0.000014
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.649966, learning rate is 0.000014
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.216550, learning rate is 0.000014
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.958788, learning rate is 0.000400
Net2: layer deconv3:max response is 70.134155, min response is -62.082188.
max gradient is 6.759515, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.933651, min response is -4.072342.
max gradient is 8.000000, min gradient is -3.980673, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.522061, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.058994, min response is -3.744335.
max gradient is 8.000000, min gradient is -6.281404, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.734387, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.18, min inferred z is -4.08, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
Loss: 1.3055
Iteration 131 / 200
training: epoch 131: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.368825, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv2:max response is , min response is .
max gradient is 4.895737, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.767044, learning rate is 0.000011
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.377412, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 67.147911, min response is -57.320976.
max gradient is 5.007772, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.084015, min response is -3.691574.
max gradient is 4.715832, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.498785, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 16.342913, min response is -3.545224.
max gradient is 8.000001, min gradient is -7.826362, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.322814, learning rate is 0.000200
max inferred z is 3.65, min inferred z is -4.30, and std is 1.01
 4.17 s (24.0 data/s) [100/100]
training: epoch 131: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.674686, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv2:max response is , min response is .
max gradient is 5.341658, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv1:max response is , min response is .
max gradient is 7.459591, min gradient is -8.000000, learning rate is 0.000011
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.145588, learning rate is 0.000400
Net2: layer deconv3:max response is 77.129700, min response is -67.692421.
max gradient is 8.000000, min gradient is -4.092413, learning rate is 0.000200
Net2: layer bn50:max response is 21.408484, min response is -3.992733.
max gradient is 8.000000, min gradient is -6.646175, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.702994, learning rate is 0.000200
Net2: layer bn49:max response is 18.687252, min response is -3.736776.
max gradient is 8.000000, min gradient is -6.816756, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.963670, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.66, min inferred z is -4.12, and std is 1.01
 4.42 s (22.6 data/s) [100/100]
training: epoch 131: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.921344, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv2:max response is , min response is .
max gradient is 5.452667, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv1:max response is , min response is .
max gradient is 6.584421, min gradient is -8.000000, learning rate is 0.000011
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.716993, learning rate is 0.000400
Net2: layer deconv3:max response is 77.448265, min response is -67.321938.
max gradient is 6.006582, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.736790, min response is -4.280553.
max gradient is 8.000000, min gradient is -6.726760, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.681232, learning rate is 0.000200
Net2: layer bn49:max response is 18.021797, min response is -3.559390.
max gradient is 6.735596, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.521106, learning rate is 0.000200
max inferred z is 3.68, min inferred z is -4.31, and std is 1.01
 4.42 s (22.6 data/s) [100/100]
training: epoch 131: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.102650, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv2:max response is , min response is .
max gradient is 5.517923, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv1:max response is , min response is .
max gradient is 7.275077, min gradient is -8.000000, learning rate is 0.000011
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.235717, learning rate is 0.000400
Net2: layer deconv3:max response is 71.153358, min response is -61.582394.
max gradient is 8.000000, min gradient is -2.021866, learning rate is 0.000200
Net2: layer bn50:max response is 19.160318, min response is -4.415081.
max gradient is 7.669186, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.737299, learning rate is 0.000200
Net2: layer bn49:max response is 16.828518, min response is -3.487938.
max gradient is 3.777204, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.146118, learning rate is 0.000200
max inferred z is 4.29, min inferred z is -3.49, and std is 1.01
 4.33 s (23.1 data/s) [100/100]
training: epoch 131: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.119668, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv2:max response is , min response is .
max gradient is 4.942666, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv1:max response is , min response is .
max gradient is 6.575759, min gradient is -8.000000, learning rate is 0.000011
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.951243, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 83.846809, min response is -67.677452.
max gradient is 2.192310, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.587339, min response is -4.541754.
max gradient is 7.654066, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.573414, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.187096, min response is -3.781300.
max gradient is 8.000000, min gradient is -5.466294, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.321878, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.93, min inferred z is -4.49, and std is 1.01
 4.39 s (22.8 data/s) [100/100]
training: epoch 131: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.890457, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv2:max response is , min response is .
max gradient is 6.027739, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.949285, learning rate is 0.000011
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.414883, learning rate is 0.000400
Net2: layer deconv3:max response is 78.943527, min response is -64.447586.
max gradient is 6.360378, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.653627, min response is -4.394013.
max gradient is 4.553020, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.392700, learning rate is 0.000200
Net2: layer bn49:max response is 19.173225, min response is -3.937435.
max gradient is 5.711206, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.540703, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.87, min inferred z is -4.25, and std is 1.01
 4.39 s (22.8 data/s) [100/100]
training: epoch 131: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.840504, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.883374, learning rate is 0.000011
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.121276, learning rate is 0.000011
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.480846, learning rate is 0.000400
Net2: layer deconv3:max response is 72.437462, min response is -62.808113.
max gradient is 8.000000, min gradient is -6.573215, learning rate is 0.000200
Net2: layer bn50:max response is 20.558525, min response is -4.414342.
max gradient is 8.000000, min gradient is -3.792714, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.208277, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.336151, min response is -3.702996.
max gradient is 8.000000, min gradient is -6.552969, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.379603, learning rate is 0.000200
max inferred z is 3.74, min inferred z is -4.38, and std is 1.01
 4.35 s (23.0 data/s) [100/100]
training: epoch 131: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.168869, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv2:max response is , min response is .
max gradient is 5.476888, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv1:max response is , min response is .
max gradient is 6.990823, min gradient is -8.000000, learning rate is 0.000011
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.443101, learning rate is 0.000400
Net2: layer deconv3:max response is 86.247681, min response is -71.531265.
max gradient is 8.000000, min gradient is -4.291279, learning rate is 0.000200
Net2: layer bn50:max response is 23.783171, min response is -4.758408.
max gradient is 8.000000, min gradient is -7.921313, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.970482, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.715536, min response is -3.074553.
max gradient is 6.036629, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.271562, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.89, min inferred z is -4.13, and std is 1.01
 4.37 s (22.9 data/s) [100/100]
training: epoch 131: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.823369, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv2:max response is , min response is .
max gradient is 5.178937, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv1:max response is , min response is .
max gradient is 6.685138, min gradient is -8.000000, learning rate is 0.000011
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -1.071858, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 73.692924, min response is -55.735336.
max gradient is 3.571017, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.738060, min response is -4.838466.
max gradient is 8.000000, min gradient is -6.591900, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.580374, learning rate is 0.000200
Net2: layer bn49:max response is 18.778728, min response is -3.429257.
max gradient is 8.000000, min gradient is -5.933754, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.722432, learning rate is 0.000200
max inferred z is 4.12, min inferred z is -4.27, and std is 1.01
 4.40 s (22.7 data/s) [100/100]
training: epoch 131: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.284241, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.973989, learning rate is 0.000011
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.445981, learning rate is 0.000011
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.246412, learning rate is 0.000400
Net2: layer deconv3:max response is 71.879921, min response is -59.100552.
max gradient is 8.000000, min gradient is -4.527426, learning rate is 0.000200
Net2: layer bn50:max response is 22.799931, min response is -4.004928.
max gradient is 8.000000, min gradient is -7.049032, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.730368, learning rate is 0.000200
Net2: layer bn49:max response is 16.278074, min response is -4.026167.
max gradient is 6.909755, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.707345, learning rate is 0.000200
max inferred z is 3.88, min inferred z is -3.82, and std is 1.01
 4.32 s (23.2 data/s) [100/100]
Loss: 1.3145
Iteration 132 / 200
training: epoch 132: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.357163, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv2:max response is , min response is .
max gradient is 5.614599, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv1:max response is , min response is .
max gradient is 7.541657, min gradient is -8.000000, learning rate is 0.000011
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.752781, learning rate is 0.000400
Net2: layer deconv3:max response is 89.711899, min response is -75.208694.
max gradient is 4.841463, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.974373, min response is -4.593676.
max gradient is 7.520224, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.857462, learning rate is 0.000200
Net2: layer bn49:max response is 21.568577, min response is -4.015010.
max gradient is 8.000000, min gradient is -5.520750, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.203138, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.26, min inferred z is -4.00, and std is 1.00
 4.17 s (24.0 data/s) [100/100]
training: epoch 132: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.819313, min gradient is -8.000001, learning rate is 0.000011
Net1: layer conv2:max response is , min response is .
max gradient is 5.257967, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv1:max response is , min response is .
max gradient is 6.672829, min gradient is -8.000000, learning rate is 0.000011
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.091835, learning rate is 0.000400
Net2: layer deconv3:max response is 69.052940, min response is -58.378113.
max gradient is 8.000000, min gradient is -5.927446, learning rate is 0.000200
Net2: layer bn50:max response is 20.141529, min response is -3.628010.
max gradient is 8.000000, min gradient is -6.186191, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.364354, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 16.746359, min response is -3.421232.
max gradient is 8.000000, min gradient is -7.815691, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.592035, learning rate is 0.000200
max inferred z is 4.58, min inferred z is -4.29, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 132: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.827898, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv2:max response is , min response is .
max gradient is 5.150161, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv1:max response is , min response is .
max gradient is 6.401092, min gradient is -8.000000, learning rate is 0.000011
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.680799, learning rate is 0.000400
Net2: layer deconv3:max response is 71.504257, min response is -57.449905.
max gradient is 8.000000, min gradient is -7.181223, learning rate is 0.000200
Net2: layer bn50:max response is 20.115467, min response is -4.085164.
max gradient is 4.695875, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.955860, learning rate is 0.000200
Net2: layer bn49:max response is 17.911905, min response is -3.745090.
max gradient is 8.000000, min gradient is -7.851625, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.653549, learning rate is 0.000200
max inferred z is 4.24, min inferred z is -3.67, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
training: epoch 132: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.140505, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv2:max response is , min response is .
max gradient is 4.911795, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv1:max response is , min response is .
max gradient is 6.978255, min gradient is -8.000000, learning rate is 0.000011
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.326156, learning rate is 0.000400
Net2: layer deconv3:max response is 79.270416, min response is -65.787964.
max gradient is 2.655571, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.463976, min response is -4.966754.
max gradient is 8.000000, min gradient is -5.746105, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.983293, learning rate is 0.000200
Net2: layer bn49:max response is 18.822710, min response is -3.632726.
max gradient is 8.000000, min gradient is -6.003431, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.339039, min gradient is -8.000001, learning rate is 0.000200
max inferred z is 3.79, min inferred z is -3.71, and std is 1.00
 4.32 s (23.2 data/s) [100/100]
training: epoch 132: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.358478, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv2:max response is , min response is .
max gradient is 5.078041, min gradient is -8.000001, learning rate is 0.000011
Net1: layer conv1:max response is , min response is .
max gradient is 6.692198, min gradient is -8.000000, learning rate is 0.000011
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.755796, learning rate is 0.000400
Net2: layer deconv3:max response is 74.729019, min response is -57.609772.
max gradient is 8.000000, min gradient is -1.791528, learning rate is 0.000200
Net2: layer bn50:max response is 22.983728, min response is -3.722556.
max gradient is 6.005373, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.511889, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 16.310127, min response is -4.188152.
max gradient is 8.000000, min gradient is -7.651371, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.669676, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.91, min inferred z is -4.54, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
training: epoch 132: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.814164, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv2:max response is , min response is .
max gradient is 5.725062, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv1:max response is , min response is .
max gradient is 7.279266, min gradient is -8.000000, learning rate is 0.000011
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.722799, learning rate is 0.000400
Net2: layer deconv3:max response is 110.101685, min response is -84.622620.
max gradient is 3.518287, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 34.302250, min response is -4.815309.
max gradient is 7.129962, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.498723, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.731821, min response is -5.971358.
max gradient is 6.603599, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.967299, learning rate is 0.000200
max inferred z is 3.99, min inferred z is -3.86, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 132: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.824400, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv2:max response is , min response is .
max gradient is 6.312747, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv1:max response is , min response is .
max gradient is 7.193326, min gradient is -8.000000, learning rate is 0.000011
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.962262, learning rate is 0.000400
Net2: layer deconv3:max response is 67.471748, min response is -54.649460.
max gradient is 8.000000, min gradient is -6.958331, learning rate is 0.000200
Net2: layer bn50:max response is 21.814316, min response is -4.631555.
max gradient is 8.000000, min gradient is -7.598296, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.870330, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.720310, min response is -3.597458.
max gradient is 6.030630, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.023683, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.03, min inferred z is -3.95, and std is 1.00
 4.41 s (22.7 data/s) [100/100]
training: epoch 132: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.177531, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv2:max response is , min response is .
max gradient is 5.395142, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv1:max response is , min response is .
max gradient is 6.874397, min gradient is -8.000000, learning rate is 0.000011
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.595286, learning rate is 0.000400
Net2: layer deconv3:max response is 67.457764, min response is -54.674908.
max gradient is 4.064477, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.585451, min response is -3.892283.
max gradient is 7.224303, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.830218, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 16.948826, min response is -3.621849.
max gradient is 8.000000, min gradient is -5.071709, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.389142, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.72, min inferred z is -4.14, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 132: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.876256, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv2:max response is , min response is .
max gradient is 5.368802, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv1:max response is , min response is .
max gradient is 6.622677, min gradient is -8.000000, learning rate is 0.000011
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.779250, learning rate is 0.000400
Net2: layer deconv3:max response is 68.838417, min response is -56.021004.
max gradient is 8.000000, min gradient is -3.803847, learning rate is 0.000200
Net2: layer bn50:max response is 19.923653, min response is -4.148676.
max gradient is 7.932156, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.879231, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 16.718496, min response is -3.657315.
max gradient is 6.342586, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.443144, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.86, min inferred z is -3.66, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
training: epoch 132: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.328302, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv2:max response is , min response is .
max gradient is 6.434221, min gradient is -8.000000, learning rate is 0.000011
Net1: layer conv1:max response is , min response is .
max gradient is 7.860109, min gradient is -8.000000, learning rate is 0.000011
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.021842, learning rate is 0.000400
Net2: layer deconv3:max response is 79.295685, min response is -64.724907.
max gradient is 3.735197, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.908293, min response is -4.193311.
max gradient is 8.000000, min gradient is -7.461028, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.147514, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.013809, min response is -3.923960.
max gradient is 8.000000, min gradient is -6.278061, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.964950, learning rate is 0.000200
max inferred z is 4.41, min inferred z is -4.03, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
Loss: 1.1988
Iteration 133 / 200
training: epoch 133: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.236995, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv2:max response is , min response is .
max gradient is 5.650435, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv1:max response is , min response is .
max gradient is 7.307126, min gradient is -8.000000, learning rate is 0.000010
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.235982, learning rate is 0.000400
Net2: layer deconv3:max response is 66.206932, min response is -53.762489.
max gradient is 8.000000, min gradient is -5.479477, learning rate is 0.000200
Net2: layer bn50:max response is 19.998875, min response is -3.789413.
max gradient is 8.000000, min gradient is -6.799325, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.405485, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.045647, min response is -3.685778.
max gradient is 4.631420, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.721001, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.30, min inferred z is -3.83, and std is 1.00
 4.19 s (23.9 data/s) [100/100]
training: epoch 133: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.834453, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv2:max response is , min response is .
max gradient is 5.153778, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv1:max response is , min response is .
max gradient is 6.437786, min gradient is -8.000000, learning rate is 0.000010
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000001, min gradient is 6.833105, learning rate is 0.000400
Net2: layer deconv3:max response is 97.182297, min response is -80.040329.
max gradient is 4.816365, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 25.219421, min response is -4.413713.
max gradient is 6.749787, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.323741, learning rate is 0.000200
Net2: layer bn49:max response is 22.518839, min response is -4.056647.
max gradient is 8.000000, min gradient is -5.296397, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.201194, learning rate is 0.000200
max inferred z is 5.20, min inferred z is -4.33, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 133: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.793867, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv2:max response is , min response is .
max gradient is 5.164090, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv1:max response is , min response is .
max gradient is 6.427767, min gradient is -8.000000, learning rate is 0.000010
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.527520, learning rate is 0.000400
Net2: layer deconv3:max response is 69.731529, min response is -56.838215.
max gradient is 8.000000, min gradient is -6.027230, learning rate is 0.000200
Net2: layer bn50:max response is 20.197027, min response is -3.701358.
max gradient is 6.597787, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.183724, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.297304, min response is -3.575302.
max gradient is 6.487592, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.473636, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.30, min inferred z is -4.01, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 133: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.079411, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv2:max response is , min response is .
max gradient is 4.763694, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv1:max response is , min response is .
max gradient is 6.483323, min gradient is -8.000000, learning rate is 0.000010
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.674925, learning rate is 0.000400
Net2: layer deconv3:max response is 77.136261, min response is -62.185818.
max gradient is 4.566639, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.324192, min response is -4.162460.
max gradient is 8.000000, min gradient is -7.602870, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.156005, min gradient is -8.000001, learning rate is 0.000200
Net2: layer bn49:max response is 18.020824, min response is -3.631595.
max gradient is 8.000000, min gradient is -5.192958, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.757379, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.90, min inferred z is -4.43, and std is 1.00
 4.38 s (22.9 data/s) [100/100]
training: epoch 133: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.246755, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv2:max response is , min response is .
max gradient is 4.827013, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv1:max response is , min response is .
max gradient is 5.958444, min gradient is -8.000000, learning rate is 0.000010
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.284431, learning rate is 0.000400
Net2: layer deconv3:max response is 87.711197, min response is -72.682335.
max gradient is 8.000000, min gradient is -3.502228, learning rate is 0.000200
Net2: layer bn50:max response is 25.211119, min response is -4.481979.
max gradient is 8.000000, min gradient is -7.587158, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.766099, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.925766, min response is -4.063582.
max gradient is 5.634606, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.331938, learning rate is 0.000200
max inferred z is 3.71, min inferred z is -4.09, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 133: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.862522, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv2:max response is , min response is .
max gradient is 5.401158, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv1:max response is , min response is .
max gradient is 7.118504, min gradient is -8.000000, learning rate is 0.000010
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.380232, learning rate is 0.000400
Net2: layer deconv3:max response is 70.358582, min response is -56.254269.
max gradient is 2.870267, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.518000, min response is -3.675219.
max gradient is 8.000000, min gradient is -7.401677, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.453321, learning rate is 0.000200
Net2: layer bn49:max response is 14.845464, min response is -3.810934.
max gradient is 8.000000, min gradient is -4.767943, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.773449, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.08, min inferred z is -3.56, and std is 1.00
 4.28 s (23.4 data/s) [100/100]
training: epoch 133: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.868279, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv2:max response is , min response is .
max gradient is 5.083262, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv1:max response is , min response is .
max gradient is 6.495474, min gradient is -8.000000, learning rate is 0.000010
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.575059, learning rate is 0.000400
Net2: layer deconv3:max response is 72.100899, min response is -60.224533.
max gradient is 8.000000, min gradient is -5.614565, learning rate is 0.000200
Net2: layer bn50:max response is 23.734749, min response is -3.355247.
max gradient is 6.923710, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.712316, learning rate is 0.000200
Net2: layer bn49:max response is 16.786428, min response is -3.756862.
max gradient is 6.241394, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.771908, min gradient is -8.000001, learning rate is 0.000200
max inferred z is 3.80, min inferred z is -3.77, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 133: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.179839, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv2:max response is , min response is .
max gradient is 5.203259, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv1:max response is , min response is .
max gradient is 6.094841, min gradient is -8.000000, learning rate is 0.000010
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.750598, learning rate is 0.000400
Net2: layer deconv3:max response is 75.982040, min response is -63.083664.
max gradient is 4.962143, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.166569, min response is -3.774286.
max gradient is 7.300263, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.437017, learning rate is 0.000200
Net2: layer bn49:max response is 17.882311, min response is -3.297852.
max gradient is 8.000000, min gradient is -6.048698, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.516072, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.41, min inferred z is -4.62, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 133: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.964763, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv2:max response is , min response is .
max gradient is 5.129919, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv1:max response is , min response is .
max gradient is 5.734330, min gradient is -8.000000, learning rate is 0.000010
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 0.946134, learning rate is 0.000400
Net2: layer deconv3:max response is 71.815041, min response is -57.834702.
max gradient is 8.000000, min gradient is -3.694148, learning rate is 0.000200
Net2: layer bn50:max response is 22.919888, min response is -3.917200.
max gradient is 6.952039, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.896836, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 16.821989, min response is -3.759754.
max gradient is 4.819625, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.578304, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.97, min inferred z is -4.12, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 133: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.315614, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv2:max response is , min response is .
max gradient is 4.649429, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv1:max response is , min response is .
max gradient is 7.089167, min gradient is -8.000000, learning rate is 0.000010
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.843510, learning rate is 0.000400
Net2: layer deconv3:max response is 73.267281, min response is -58.244766.
max gradient is 3.081842, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.304611, min response is -4.029728.
max gradient is 8.000000, min gradient is -6.734221, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.919333, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.833183, min response is -3.862385.
max gradient is 8.000000, min gradient is -5.692944, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.102075, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.94, min inferred z is -3.90, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
Loss: 1.2599
Iteration 134 / 200
training: epoch 134: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.143595, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv2:max response is , min response is .
max gradient is 4.825928, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv1:max response is , min response is .
max gradient is 6.213766, min gradient is -8.000000, learning rate is 0.000010
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.888672, learning rate is 0.000400
Net2: layer deconv3:max response is 89.515808, min response is -70.890480.
max gradient is 8.000000, min gradient is -2.668410, learning rate is 0.000200
Net2: layer bn50:max response is 25.008516, min response is -4.799644.
max gradient is 6.375978, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.865044, learning rate is 0.000200
Net2: layer bn49:max response is 21.944675, min response is -4.635614.
max gradient is 4.315413, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.831923, learning rate is 0.000200
max inferred z is 4.10, min inferred z is -3.59, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 134: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.792343, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv2:max response is , min response is .
max gradient is 4.762728, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv1:max response is , min response is .
max gradient is 6.035086, min gradient is -8.000000, learning rate is 0.000010
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.775621, learning rate is 0.000400
Net2: layer deconv3:max response is 79.759361, min response is -63.261662.
max gradient is 1.802378, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.579906, min response is -3.877052.
max gradient is 8.000000, min gradient is -5.944962, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.624395, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.003252, min response is -3.589944.
max gradient is 8.000001, min gradient is -4.665944, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.048554, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.84, min inferred z is -4.10, and std is 1.00
 4.40 s (22.8 data/s) [100/100]
training: epoch 134: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.689082, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv2:max response is , min response is .
max gradient is 4.947523, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv1:max response is , min response is .
max gradient is 5.681772, min gradient is -8.000000, learning rate is 0.000010
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.278142, learning rate is 0.000400
Net2: layer deconv3:max response is 69.936241, min response is -54.657711.
max gradient is 8.000000, min gradient is -2.511033, learning rate is 0.000200
Net2: layer bn50:max response is 19.163900, min response is -3.680132.
max gradient is 6.410705, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.208507, learning rate is 0.000200
Net2: layer bn49:max response is 16.669548, min response is -3.008157.
max gradient is 4.749374, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.477895, learning rate is 0.000200
max inferred z is 3.85, min inferred z is -3.31, and std is 1.00
 4.18 s (23.9 data/s) [100/100]
training: epoch 134: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.878987, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv2:max response is , min response is .
max gradient is 4.634161, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv1:max response is , min response is .
max gradient is 6.366096, min gradient is -8.000000, learning rate is 0.000010
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.577995, learning rate is 0.000400
Net2: layer deconv3:max response is 75.082581, min response is -56.578239.
max gradient is 2.670749, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.650106, min response is -4.116518.
max gradient is 8.000000, min gradient is -7.380582, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.736441, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.819963, min response is -3.118261.
max gradient is 8.000000, min gradient is -3.688119, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.635761, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.07, min inferred z is -3.56, and std is 1.00
 4.22 s (23.7 data/s) [100/100]
training: epoch 134: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.306159, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv2:max response is , min response is .
max gradient is 4.717902, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv1:max response is , min response is .
max gradient is 5.949886, min gradient is -8.000000, learning rate is 0.000010
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.032795, learning rate is 0.000400
Net2: layer deconv3:max response is 101.750664, min response is -80.997505.
max gradient is 8.000000, min gradient is -4.268178, learning rate is 0.000200
Net2: layer bn50:max response is 26.417557, min response is -4.612264.
max gradient is 8.000000, min gradient is -6.983896, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.814999, learning rate is 0.000200
Net2: layer bn49:max response is 23.793230, min response is -3.496407.
max gradient is 4.414416, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.997535, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.06, min inferred z is -3.91, and std is 1.00
 4.30 s (23.2 data/s) [100/100]
training: epoch 134: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.082436, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv2:max response is , min response is .
max gradient is 5.277808, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv1:max response is , min response is .
max gradient is 6.676257, min gradient is -8.000000, learning rate is 0.000010
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.157525, learning rate is 0.000400
Net2: layer deconv3:max response is 78.039444, min response is -60.643150.
max gradient is 4.593479, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.129162, min response is -4.217309.
max gradient is 6.966375, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.922105, learning rate is 0.000200
Net2: layer bn49:max response is 18.654833, min response is -3.567519.
max gradient is 8.000000, min gradient is -7.997532, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.429318, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.88, min inferred z is -3.89, and std is 1.00
 4.23 s (23.7 data/s) [100/100]
training: epoch 134: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.710699, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv2:max response is , min response is .
max gradient is 4.861531, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv1:max response is , min response is .
max gradient is 6.182197, min gradient is -8.000000, learning rate is 0.000010
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.002869, learning rate is 0.000400
Net2: layer deconv3:max response is 75.028458, min response is -59.008366.
max gradient is 8.000000, min gradient is -4.920798, learning rate is 0.000200
Net2: layer bn50:max response is 23.636051, min response is -3.413965.
max gradient is 7.867477, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.666472, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.708855, min response is -4.194482.
max gradient is 8.000000, min gradient is -7.373315, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.441097, learning rate is 0.000200
max inferred z is 3.71, min inferred z is -3.81, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 134: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.182938, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv2:max response is , min response is .
max gradient is 5.036992, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv1:max response is , min response is .
max gradient is 6.258010, min gradient is -8.000000, learning rate is 0.000010
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.120640, learning rate is 0.000400
Net2: layer deconv3:max response is 74.119179, min response is -57.056519.
max gradient is 5.603203, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.672121, min response is -4.407236.
max gradient is 7.396985, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.529138, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.380041, min response is -2.976180.
max gradient is 8.000000, min gradient is -5.957345, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.539162, learning rate is 0.000200
max inferred z is 3.81, min inferred z is -4.08, and std is 1.00
 4.41 s (22.7 data/s) [100/100]
training: epoch 134: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.979704, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv2:max response is , min response is .
max gradient is 4.853596, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv1:max response is , min response is .
max gradient is 5.887899, min gradient is -8.000000, learning rate is 0.000010
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000001, min gradient is 4.349431, learning rate is 0.000400
Net2: layer deconv3:max response is 71.817612, min response is -55.054745.
max gradient is 8.000000, min gradient is -3.552752, learning rate is 0.000200
Net2: layer bn50:max response is 19.301376, min response is -3.522701.
max gradient is 7.107418, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.289610, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 16.951065, min response is -3.273218.
max gradient is 4.213861, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.862591, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.92, min inferred z is -3.90, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 134: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.336052, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv2:max response is , min response is .
max gradient is 4.807503, min gradient is -8.000000, learning rate is 0.000010
Net1: layer conv1:max response is , min response is .
max gradient is 7.088711, min gradient is -8.000000, learning rate is 0.000010
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.364923, learning rate is 0.000400
Net2: layer deconv3:max response is 83.682655, min response is -64.611229.
max gradient is 3.030177, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.339634, min response is -4.202227.
max gradient is 8.000000, min gradient is -7.381021, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.131133, learning rate is 0.000200
Net2: layer bn49:max response is 18.763990, min response is -3.772950.
max gradient is 8.000000, min gradient is -3.723855, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.920700, learning rate is 0.000200
max inferred z is 3.92, min inferred z is -3.61, and std is 1.00
 4.43 s (22.6 data/s) [100/100]
Loss: 1.2045
Iteration 135 / 200
training: epoch 135: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.126932, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv2:max response is , min response is .
max gradient is 4.776469, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv1:max response is , min response is .
max gradient is 6.844599, min gradient is -8.000000, learning rate is 0.000008
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.369578, learning rate is 0.000400
Net2: layer deconv3:max response is 75.955963, min response is -56.252842.
max gradient is 6.941051, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.938807, min response is -4.235928.
max gradient is 4.837843, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.200655, learning rate is 0.000200
Net2: layer bn49:max response is 18.478291, min response is -3.554156.
max gradient is 7.016506, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.879448, learning rate is 0.000200
max inferred z is 3.94, min inferred z is -4.05, and std is 1.00
 4.21 s (23.8 data/s) [100/100]
training: epoch 135: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.754035, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv2:max response is , min response is .
max gradient is 4.802588, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv1:max response is , min response is .
max gradient is 5.629233, min gradient is -8.000000, learning rate is 0.000008
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.362467, learning rate is 0.000400
Net2: layer deconv3:max response is 87.028107, min response is -67.257500.
max gradient is 8.000000, min gradient is -6.870618, learning rate is 0.000200
Net2: layer bn50:max response is 24.044981, min response is -4.622610.
max gradient is 8.000000, min gradient is -3.789979, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.099640, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.216192, min response is -3.618814.
max gradient is 6.099469, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.365068, learning rate is 0.000200
max inferred z is 4.46, min inferred z is -4.22, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
training: epoch 135: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.580347, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv2:max response is , min response is .
max gradient is 4.710543, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv1:max response is , min response is .
max gradient is 6.494662, min gradient is -8.000000, learning rate is 0.000008
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.197359, learning rate is 0.000400
Net2: layer deconv3:max response is 85.967674, min response is -65.361565.
max gradient is 7.312037, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.755945, min response is -4.075210.
max gradient is 6.475868, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.635623, learning rate is 0.000200
Net2: layer bn49:max response is 20.234093, min response is -3.711366.
max gradient is 6.972456, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.890851, learning rate is 0.000200
max inferred z is 4.31, min inferred z is -3.82, and std is 1.00
 4.30 s (23.3 data/s) [100/100]
training: epoch 135: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.956370, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv2:max response is , min response is .
max gradient is 4.647542, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv1:max response is , min response is .
max gradient is 6.363735, min gradient is -8.000000, learning rate is 0.000008
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.277626, learning rate is 0.000400
Net2: layer deconv3:max response is 76.219078, min response is -57.409023.
max gradient is 3.056880, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.471998, min response is -3.991755.
max gradient is 7.824942, min gradient is -8.000001, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.285362, learning rate is 0.000200
Net2: layer bn49:max response is 16.455748, min response is -4.176506.
max gradient is 7.159821, min gradient is -8.000001, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.676781, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.72, min inferred z is -3.37, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
training: epoch 135: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.200583, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv2:max response is , min response is .
max gradient is 4.607853, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv1:max response is , min response is .
max gradient is 5.962984, min gradient is -8.000000, learning rate is 0.000008
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.038953, learning rate is 0.000400
Net2: layer deconv3:max response is 74.712318, min response is -52.804596.
max gradient is 8.000000, min gradient is -3.556597, learning rate is 0.000200
Net2: layer bn50:max response is 17.763191, min response is -3.394662.
max gradient is 8.000001, min gradient is -7.221453, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.158391, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 15.509734, min response is -4.073457.
max gradient is 8.000000, min gradient is -6.424251, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.124382, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.00, min inferred z is -4.15, and std is 1.00
 4.46 s (22.4 data/s) [100/100]
training: epoch 135: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.098996, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv2:max response is , min response is .
max gradient is 4.738259, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv1:max response is , min response is .
max gradient is 7.032579, min gradient is -8.000000, learning rate is 0.000008
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.261889, learning rate is 0.000400
Net2: layer deconv3:max response is 89.281204, min response is -68.957176.
max gradient is 3.745395, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 24.855938, min response is -3.948252.
max gradient is 8.000000, min gradient is -7.302013, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.365121, learning rate is 0.000200
Net2: layer bn49:max response is 18.988052, min response is -4.813266.
max gradient is 8.000000, min gradient is -6.262856, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.504313, learning rate is 0.000200
max inferred z is 4.04, min inferred z is -4.44, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
training: epoch 135: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.762494, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv2:max response is , min response is .
max gradient is 4.551254, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv1:max response is , min response is .
max gradient is 6.023686, min gradient is -8.000000, learning rate is 0.000008
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.742702, learning rate is 0.000400
Net2: layer deconv3:max response is 95.222786, min response is -69.266808.
max gradient is 8.000000, min gradient is -3.168948, learning rate is 0.000200
Net2: layer bn50:max response is 25.549875, min response is -4.850433.
max gradient is 6.759182, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.112115, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 22.362787, min response is -3.904600.
max gradient is 4.112816, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.587544, learning rate is 0.000200
max inferred z is 4.15, min inferred z is -3.43, and std is 1.00
 4.19 s (23.9 data/s) [100/100]
training: epoch 135: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.956065, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv2:max response is , min response is .
max gradient is 4.647161, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv1:max response is , min response is .
max gradient is 6.746554, min gradient is -8.000001, learning rate is 0.000008
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.783528, learning rate is 0.000400
Net2: layer deconv3:max response is 69.502121, min response is -51.317947.
max gradient is 1.619334, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.808004, min response is -3.854690.
max gradient is 8.000000, min gradient is -5.375404, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.288147, learning rate is 0.000200
Net2: layer bn49:max response is 16.630072, min response is -3.201069.
max gradient is 8.000000, min gradient is -5.118257, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.573586, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.89, min inferred z is -4.01, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 135: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.719718, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv2:max response is , min response is .
max gradient is 4.528895, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv1:max response is , min response is .
max gradient is 6.440401, min gradient is -8.000000, learning rate is 0.000008
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.031902, learning rate is 0.000400
Net2: layer deconv3:max response is 70.820824, min response is -53.553936.
max gradient is 8.000000, min gradient is -2.045120, learning rate is 0.000200
Net2: layer bn50:max response is 18.946890, min response is -3.722815.
max gradient is 5.200146, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.094316, learning rate is 0.000200
Net2: layer bn49:max response is 17.001457, min response is -3.696861.
max gradient is 4.635151, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.767906, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.30, min inferred z is -3.78, and std is 1.00
 4.28 s (23.4 data/s) [100/100]
training: epoch 135: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.289858, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv2:max response is , min response is .
max gradient is 4.412741, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv1:max response is , min response is .
max gradient is 6.715392, min gradient is -8.000000, learning rate is 0.000008
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.985279, learning rate is 0.000400
Net2: layer deconv3:max response is 74.163948, min response is -56.202068.
max gradient is 2.578346, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.919901, min response is -3.702583.
max gradient is 8.000000, min gradient is -5.926299, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.383259, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 15.721956, min response is -3.933129.
max gradient is 8.000000, min gradient is -6.176532, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.628151, learning rate is 0.000200
max inferred z is 4.20, min inferred z is -3.97, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
Loss: 1.2909
Iteration 136 / 200
training: epoch 136: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.952562, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv2:max response is , min response is .
max gradient is 4.335132, min gradient is -8.000001, learning rate is 0.000008
Net1: layer conv1:max response is , min response is .
max gradient is 6.877645, min gradient is -8.000000, learning rate is 0.000008
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.619194, learning rate is 0.000400
Net2: layer deconv3:max response is 80.729385, min response is -60.066532.
max gradient is 8.000000, min gradient is -3.780723, learning rate is 0.000200
Net2: layer bn50:max response is 22.463556, min response is -4.213942.
max gradient is 7.082988, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.125962, learning rate is 0.000200
Net2: layer bn49:max response is 19.979973, min response is -4.050610.
max gradient is 8.000000, min gradient is -7.175912, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.958776, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.96, min inferred z is -3.45, and std is 1.00
 4.15 s (24.1 data/s) [100/100]
training: epoch 136: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.690606, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv2:max response is , min response is .
max gradient is 4.495755, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv1:max response is , min response is .
max gradient is 6.609111, min gradient is -8.000000, learning rate is 0.000008
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.669811, learning rate is 0.000400
Net2: layer deconv3:max response is 70.572685, min response is -52.162704.
max gradient is 5.592636, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 17.950176, min response is -3.767361.
max gradient is 8.000000, min gradient is -4.341215, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.201499, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 15.802203, min response is -2.974620.
max gradient is 8.000000, min gradient is -6.318747, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000001, min gradient is -6.618898, learning rate is 0.000200
max inferred z is 4.12, min inferred z is -4.10, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 136: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.606416, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv2:max response is , min response is .
max gradient is 4.503287, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv1:max response is , min response is .
max gradient is 6.887219, min gradient is -8.000000, learning rate is 0.000008
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.514479, learning rate is 0.000400
Net2: layer deconv3:max response is 82.656883, min response is -58.487988.
max gradient is 7.642475, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.364693, min response is -4.294397.
max gradient is 5.161036, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.008561, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.504442, min response is -3.517366.
max gradient is 8.000000, min gradient is -7.693692, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.887289, learning rate is 0.000200
max inferred z is 4.13, min inferred z is -4.03, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 136: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.862970, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv2:max response is , min response is .
max gradient is 4.320421, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv1:max response is , min response is .
max gradient is 6.925401, min gradient is -8.000000, learning rate is 0.000008
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000001, min gradient is 5.939118, learning rate is 0.000400
Net2: layer deconv3:max response is 73.618988, min response is -54.554314.
max gradient is 4.520853, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.510599, min response is -3.627939.
max gradient is 8.000000, min gradient is -5.052147, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.963248, learning rate is 0.000200
Net2: layer bn49:max response is 17.531256, min response is -3.961910.
max gradient is 7.618157, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.994002, learning rate is 0.000200
max inferred z is 4.20, min inferred z is -4.18, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 136: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.181239, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv2:max response is , min response is .
max gradient is 4.352190, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv1:max response is , min response is .
max gradient is 6.130316, min gradient is -8.000000, learning rate is 0.000008
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -1.340755, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 65.333557, min response is -50.174763.
max gradient is 8.000000, min gradient is -1.816475, learning rate is 0.000200
Net2: layer bn50:max response is 20.277742, min response is -3.241237.
max gradient is 4.443879, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.201812, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 15.247582, min response is -3.396563.
max gradient is 5.320826, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.406265, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.13, min inferred z is -3.93, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 136: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.039577, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv2:max response is , min response is .
max gradient is 4.548187, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv1:max response is , min response is .
max gradient is 7.253191, min gradient is -8.000000, learning rate is 0.000008
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.871984, learning rate is 0.000400
Net2: layer deconv3:max response is 79.026894, min response is -57.048988.
max gradient is 4.913830, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.608057, min response is -4.449518.
max gradient is 8.000000, min gradient is -7.378546, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.111362, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.154890, min response is -3.351863.
max gradient is 8.000000, min gradient is -7.321349, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.900649, learning rate is 0.000200
max inferred z is 4.07, min inferred z is -3.89, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 136: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.493388, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv2:max response is , min response is .
max gradient is 4.310199, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv1:max response is , min response is .
max gradient is 6.957624, min gradient is -8.000000, learning rate is 0.000008
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.403069, learning rate is 0.000400
Net2: layer deconv3:max response is 77.543213, min response is -55.449978.
max gradient is 8.000000, min gradient is -6.893273, learning rate is 0.000200
Net2: layer bn50:max response is 20.848192, min response is -3.860924.
max gradient is 3.778240, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.628198, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.677061, min response is -3.784075.
max gradient is 6.969641, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.100443, learning rate is 0.000200
max inferred z is 3.91, min inferred z is -4.46, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 136: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.957956, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv2:max response is , min response is .
max gradient is 4.566360, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv1:max response is , min response is .
max gradient is 6.854437, min gradient is -8.000000, learning rate is 0.000008
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.375212, learning rate is 0.000400
Net2: layer deconv3:max response is 81.243790, min response is -57.774986.
max gradient is 6.484294, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.081530, min response is -3.769450.
max gradient is 8.000000, min gradient is -5.533343, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.609582, learning rate is 0.000200
Net2: layer bn49:max response is 18.476341, min response is -4.098052.
max gradient is 8.000000, min gradient is -5.631487, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.527087, learning rate is 0.000200
max inferred z is 3.93, min inferred z is -3.59, and std is 1.00
 4.21 s (23.8 data/s) [100/100]
training: epoch 136: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.648424, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv2:max response is , min response is .
max gradient is 4.410494, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv1:max response is , min response is .
max gradient is 6.748864, min gradient is -8.000000, learning rate is 0.000008
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.260046, learning rate is 0.000400
Net2: layer deconv3:max response is 76.016586, min response is -52.353100.
max gradient is 6.432178, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.674391, min response is -3.663375.
max gradient is 5.617663, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.599017, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.076347, min response is -3.972682.
max gradient is 7.349535, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.666987, learning rate is 0.000200
max inferred z is 4.02, min inferred z is -4.93, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
training: epoch 136: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.102461, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv2:max response is , min response is .
max gradient is 4.258369, min gradient is -8.000000, learning rate is 0.000008
Net1: layer conv1:max response is , min response is .
max gradient is 6.479356, min gradient is -8.000000, learning rate is 0.000008
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.340235, learning rate is 0.000400
Net2: layer deconv3:max response is 85.367531, min response is -63.404686.
max gradient is 8.000000, min gradient is -7.511075, learning rate is 0.000200
Net2: layer bn50:max response is 22.401978, min response is -3.908178.
max gradient is 8.000000, min gradient is -6.105004, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.217052, learning rate is 0.000200
Net2: layer bn49:max response is 20.418940, min response is -3.576712.
max gradient is 8.000000, min gradient is -7.652785, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.399555, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.86, min inferred z is -3.73, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
Loss: 1.3054
Iteration 137 / 200
training: epoch 137: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.973692, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv2:max response is , min response is .
max gradient is 4.187089, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv1:max response is , min response is .
max gradient is 7.624507, min gradient is -8.000000, learning rate is 0.000007
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.289758, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 91.735771, min response is -63.325985.
max gradient is 4.296975, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 24.881371, min response is -4.608949.
max gradient is 8.000000, min gradient is -7.767952, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.789116, learning rate is 0.000200
Net2: layer bn49:max response is 22.136526, min response is -4.126637.
max gradient is 7.671087, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.952218, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.78, min inferred z is -3.89, and std is 1.00
 4.15 s (24.1 data/s) [100/100]
training: epoch 137: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.429901, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv2:max response is , min response is .
max gradient is 4.412249, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv1:max response is , min response is .
max gradient is 6.937701, min gradient is -8.000000, learning rate is 0.000007
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.827816, learning rate is 0.000400
Net2: layer deconv3:max response is 72.197693, min response is -53.465885.
max gradient is 8.000000, min gradient is -7.954755, learning rate is 0.000200
Net2: layer bn50:max response is 20.929977, min response is -3.883147.
max gradient is 5.208463, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.264369, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 15.194626, min response is -3.954899.
max gradient is 7.963125, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.649330, learning rate is 0.000200
max inferred z is 4.03, min inferred z is -3.73, and std is 1.00
 4.28 s (23.3 data/s) [100/100]
training: epoch 137: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.564162, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv2:max response is , min response is .
max gradient is 4.366475, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv1:max response is , min response is .
max gradient is 6.965605, min gradient is -8.000000, learning rate is 0.000007
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.901207, learning rate is 0.000400
Net2: layer deconv3:max response is 69.779808, min response is -53.620522.
max gradient is 8.000000, min gradient is -7.783727, learning rate is 0.000200
Net2: layer bn50:max response is 21.888622, min response is -3.483792.
max gradient is 8.000000, min gradient is -5.110971, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.289465, learning rate is 0.000200
Net2: layer bn49:max response is 16.262856, min response is -3.553380.
max gradient is 8.000000, min gradient is -7.616020, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.831150, learning rate is 0.000200
max inferred z is 3.72, min inferred z is -3.62, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
training: epoch 137: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.827514, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv2:max response is , min response is .
max gradient is 4.216622, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv1:max response is , min response is .
max gradient is 6.985328, min gradient is -8.000000, learning rate is 0.000007
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.733128, learning rate is 0.000400
Net2: layer deconv3:max response is 80.281624, min response is -59.750366.
max gradient is 7.857532, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.192175, min response is -4.952862.
max gradient is 7.901286, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.457245, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.823587, min response is -3.794090.
max gradient is 7.126921, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.078556, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.71, min inferred z is -4.29, and std is 1.00
 4.19 s (23.9 data/s) [100/100]
training: epoch 137: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.088091, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv2:max response is , min response is .
max gradient is 4.322298, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv1:max response is , min response is .
max gradient is 6.619313, min gradient is -8.000000, learning rate is 0.000007
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.760473, learning rate is 0.000400
Net2: layer deconv3:max response is 85.351295, min response is -62.530022.
max gradient is 8.000000, min gradient is -6.000691, learning rate is 0.000200
Net2: layer bn50:max response is 25.823557, min response is -3.867606.
max gradient is 4.543852, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.663743, min gradient is -8.000001, learning rate is 0.000200
Net2: layer bn49:max response is 19.383598, min response is -4.578557.
max gradient is 6.558764, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.271042, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.17, min inferred z is -4.02, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 137: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.990031, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv2:max response is , min response is .
max gradient is 4.597262, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv1:max response is , min response is .
max gradient is 7.363715, min gradient is -8.000000, learning rate is 0.000007
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.683586, learning rate is 0.000400
Net2: layer deconv3:max response is 74.890785, min response is -53.102600.
max gradient is 3.485754, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.088446, min response is -3.604341.
max gradient is 8.000000, min gradient is -4.700740, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.741651, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.462891, min response is -3.911860.
max gradient is 8.000000, min gradient is -5.359592, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.526135, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.10, min inferred z is -3.56, and std is 1.00
 4.19 s (23.9 data/s) [100/100]
training: epoch 137: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.480496, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv2:max response is , min response is .
max gradient is 4.149579, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv1:max response is , min response is .
max gradient is 6.635114, min gradient is -8.000000, learning rate is 0.000007
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.545737, learning rate is 0.000400
Net2: layer deconv3:max response is 74.613930, min response is -56.111298.
max gradient is 8.000000, min gradient is -4.696201, learning rate is 0.000200
Net2: layer bn50:max response is 20.648680, min response is -3.698222.
max gradient is 4.717297, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.207661, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.565575, min response is -3.525738.
max gradient is 5.218310, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.883204, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.81, min inferred z is -3.65, and std is 1.00
 4.22 s (23.7 data/s) [100/100]
training: epoch 137: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.928968, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv2:max response is , min response is .
max gradient is 4.410596, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv1:max response is , min response is .
max gradient is 7.331089, min gradient is -8.000000, learning rate is 0.000007
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.031315, learning rate is 0.000400
Net2: layer deconv3:max response is 89.430557, min response is -63.775665.
max gradient is 3.209053, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.841951, min response is -4.024786.
max gradient is 8.000000, min gradient is -5.678627, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.635491, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.235111, min response is -3.975508.
max gradient is 7.066921, min gradient is -8.000001, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.807394, learning rate is 0.000200
max inferred z is 3.44, min inferred z is -4.33, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 137: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.633248, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv2:max response is , min response is .
max gradient is 4.371888, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv1:max response is , min response is .
max gradient is 6.884604, min gradient is -8.000000, learning rate is 0.000007
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.912555, learning rate is 0.000400
Net2: layer deconv3:max response is 81.573593, min response is -60.828049.
max gradient is 8.000000, min gradient is -5.112167, learning rate is 0.000200
Net2: layer bn50:max response is 20.864567, min response is -3.522368.
max gradient is 4.630578, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.373563, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.686493, min response is -3.863346.
max gradient is 8.000000, min gradient is -5.991075, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.783668, learning rate is 0.000200
max inferred z is 3.83, min inferred z is -4.13, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 137: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.940668, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv2:max response is , min response is .
max gradient is 4.154849, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv1:max response is , min response is .
max gradient is 7.091057, min gradient is -8.000000, learning rate is 0.000007
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.095883, learning rate is 0.000400
Net2: layer deconv3:max response is 78.642029, min response is -56.777485.
max gradient is 3.710196, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.453911, min response is -3.616244.
max gradient is 8.000000, min gradient is -4.277243, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.047499, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.246906, min response is -3.360910.
max gradient is 7.233222, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.035396, learning rate is 0.000200
max inferred z is 4.28, min inferred z is -3.73, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
Loss: 1.1444
Iteration 138 / 200
training: epoch 138: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.978754, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv2:max response is , min response is .
max gradient is 4.129472, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv1:max response is , min response is .
max gradient is 7.364788, min gradient is -8.000000, learning rate is 0.000007
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.624198, learning rate is 0.000400
Net2: layer deconv3:max response is 104.680214, min response is -77.064949.
max gradient is 8.000000, min gradient is -6.635359, learning rate is 0.000200
Net2: layer bn50:max response is 27.927301, min response is -4.801719.
max gradient is 8.000000, min gradient is -7.994998, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.276773, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 24.931114, min response is -4.023366.
max gradient is 8.000000, min gradient is -5.667288, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.623425, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.92, min inferred z is -3.63, and std is 1.00
 4.21 s (23.8 data/s) [100/100]
training: epoch 138: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.480618, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv2:max response is , min response is .
max gradient is 4.395515, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv1:max response is , min response is .
max gradient is 7.058144, min gradient is -8.000000, learning rate is 0.000007
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.663955, learning rate is 0.000400
Net2: layer deconv3:max response is 81.186905, min response is -59.438904.
max gradient is 4.420307, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.222067, min response is -3.556494.
max gradient is 6.405005, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.034957, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.843981, min response is -3.175877.
max gradient is 8.000000, min gradient is -7.779688, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.881998, learning rate is 0.000200
max inferred z is 4.25, min inferred z is -3.72, and std is 1.00
 4.21 s (23.7 data/s) [100/100]
training: epoch 138: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.391898, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv2:max response is , min response is .
max gradient is 4.451605, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv1:max response is , min response is .
max gradient is 7.120412, min gradient is -8.000000, learning rate is 0.000007
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.970710, learning rate is 0.000400
Net2: layer deconv3:max response is 70.139351, min response is -50.321297.
max gradient is 8.000000, min gradient is -4.193112, learning rate is 0.000200
Net2: layer bn50:max response is 19.865974, min response is -3.529736.
max gradient is 6.885906, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.071532, learning rate is 0.000200
Net2: layer bn49:max response is 15.812238, min response is -3.804241.
max gradient is 8.000000, min gradient is -5.476703, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.454574, learning rate is 0.000200
max inferred z is 4.32, min inferred z is -3.91, and std is 1.00
 4.43 s (22.6 data/s) [100/100]
training: epoch 138: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.749566, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv2:max response is , min response is .
max gradient is 4.164909, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv1:max response is , min response is .
max gradient is 7.266260, min gradient is -8.000000, learning rate is 0.000007
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.053100, learning rate is 0.000400
Net2: layer deconv3:max response is 82.407608, min response is -58.496983.
max gradient is 2.538981, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.666758, min response is -4.157038.
max gradient is 8.000000, min gradient is -6.245550, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.902170, learning rate is 0.000200
Net2: layer bn49:max response is 20.009129, min response is -3.463982.
max gradient is 8.000000, min gradient is -7.139709, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.745859, learning rate is 0.000200
max inferred z is 3.55, min inferred z is -4.11, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 138: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.935078, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv2:max response is , min response is .
max gradient is 4.290810, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv1:max response is , min response is .
max gradient is 6.602062, min gradient is -8.000000, learning rate is 0.000007
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.295682, learning rate is 0.000400
Net2: layer deconv3:max response is 89.460342, min response is -67.935257.
max gradient is 8.000000, min gradient is -2.648405, learning rate is 0.000200
Net2: layer bn50:max response is 23.012831, min response is -3.794556.
max gradient is 4.754300, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.668225, learning rate is 0.000200
Net2: layer bn49:max response is 20.410675, min response is -4.508975.
max gradient is 6.854496, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.723610, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.77, min inferred z is -4.89, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 138: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.095536, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv2:max response is , min response is .
max gradient is 4.427831, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv1:max response is , min response is .
max gradient is 7.728902, min gradient is -8.000000, learning rate is 0.000007
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.362022, learning rate is 0.000400
Net2: layer deconv3:max response is 88.859711, min response is -64.089333.
max gradient is 2.334487, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.809925, min response is -3.815025.
max gradient is 8.000000, min gradient is -5.941351, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.404766, learning rate is 0.000200
Net2: layer bn49:max response is 20.254108, min response is -3.497933.
max gradient is 8.000000, min gradient is -6.320730, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.959932, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.42, min inferred z is -4.28, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 138: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.483040, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv2:max response is , min response is .
max gradient is 4.192083, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv1:max response is , min response is .
max gradient is 7.021459, min gradient is -8.000000, learning rate is 0.000007
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.501420, learning rate is 0.000400
Net2: layer deconv3:max response is 70.761093, min response is -53.552685.
max gradient is 8.000000, min gradient is -3.661639, learning rate is 0.000200
Net2: layer bn50:max response is 18.832386, min response is -3.726056.
max gradient is 8.000000, min gradient is -7.086392, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.568007, learning rate is 0.000200
Net2: layer bn49:max response is 16.650579, min response is -3.380077.
max gradient is 5.947726, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.373325, learning rate is 0.000200
max inferred z is 4.04, min inferred z is -3.74, and std is 1.00
 4.46 s (22.4 data/s) [100/100]
training: epoch 138: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.853758, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv2:max response is , min response is .
max gradient is 4.428260, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv1:max response is , min response is .
max gradient is 7.292135, min gradient is -8.000001, learning rate is 0.000007
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.339911, learning rate is 0.000400
Net2: layer deconv3:max response is 88.322433, min response is -63.491932.
max gradient is 3.625178, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.505785, min response is -3.700961.
max gradient is 6.522867, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.000881, learning rate is 0.000200
Net2: layer bn49:max response is 20.265644, min response is -3.549141.
max gradient is 8.000000, min gradient is -5.347870, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.070058, learning rate is 0.000200
max inferred z is 3.83, min inferred z is -3.88, and std is 1.00
 4.28 s (23.4 data/s) [100/100]
training: epoch 138: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.507370, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv2:max response is , min response is .
max gradient is 4.311987, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv1:max response is , min response is .
max gradient is 7.089034, min gradient is -8.000000, learning rate is 0.000007
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.947902, learning rate is 0.000400
Net2: layer deconv3:max response is 79.450584, min response is -57.984241.
max gradient is 8.000000, min gradient is -6.007506, learning rate is 0.000200
Net2: layer bn50:max response is 21.014605, min response is -3.823446.
max gradient is 6.146530, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.481598, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.742413, min response is -3.831686.
max gradient is 6.882275, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.264327, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.19, min inferred z is -4.16, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 138: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.161054, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv2:max response is , min response is .
max gradient is 4.216105, min gradient is -8.000000, learning rate is 0.000007
Net1: layer conv1:max response is , min response is .
max gradient is 6.980930, min gradient is -8.000000, learning rate is 0.000007
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.024353, learning rate is 0.000400
Net2: layer deconv3:max response is 78.899277, min response is -59.165150.
max gradient is 8.000000, min gradient is -6.067145, learning rate is 0.000200
Net2: layer bn50:max response is 20.081541, min response is -3.215486.
max gradient is 8.000000, min gradient is -4.933154, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.449438, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.053143, min response is -3.667051.
max gradient is 7.097901, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.698242, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.32, min inferred z is -4.14, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
Loss: 1.1105
Iteration 139 / 200
training: epoch 139: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.916761, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.053436, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 7.771209, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.084714, learning rate is 0.000400
Net2: layer deconv3:max response is 75.878593, min response is -55.751633.
max gradient is 4.242049, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.245617, min response is -3.133772.
max gradient is 8.000000, min gradient is -7.816813, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.982757, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.063070, min response is -3.290773.
max gradient is 8.000000, min gradient is -7.637903, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.325407, learning rate is 0.000200
max inferred z is 4.09, min inferred z is -3.78, and std is 1.00
 4.22 s (23.7 data/s) [100/100]
training: epoch 139: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.278844, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.281598, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 6.497306, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -2.202278, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 99.979958, min response is -74.277435.
max gradient is 8.000000, min gradient is -4.341094, learning rate is 0.000200
Net2: layer bn50:max response is 25.693335, min response is -4.168864.
max gradient is 8.000000, min gradient is -7.080469, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.100015, learning rate is 0.000200
Net2: layer bn49:max response is 23.059101, min response is -3.283777.
max gradient is 6.060016, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.559152, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.94, min inferred z is -4.32, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
training: epoch 139: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.404704, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.411032, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 7.010185, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.414436, learning rate is 0.000400
Net2: layer deconv3:max response is 85.818779, min response is -63.567333.
max gradient is 8.000000, min gradient is -5.360227, learning rate is 0.000200
Net2: layer bn50:max response is 22.358879, min response is -3.593171.
max gradient is 5.476099, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.324009, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.884346, min response is -3.866197.
max gradient is 6.261662, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.389359, learning rate is 0.000200
max inferred z is 3.91, min inferred z is -3.92, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 139: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.789976, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.124722, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 7.338255, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.448330, learning rate is 0.000400
Net2: layer deconv3:max response is 70.210106, min response is -51.195301.
max gradient is 4.337383, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 17.755774, min response is -3.733843.
max gradient is 7.388987, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.722210, learning rate is 0.000200
Net2: layer bn49:max response is 15.848948, min response is -3.666291.
max gradient is 8.000001, min gradient is -5.350003, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.833466, learning rate is 0.000200
max inferred z is 3.66, min inferred z is -4.46, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 139: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.922168, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.206806, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 6.694428, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.800284, learning rate is 0.000400
Net2: layer deconv3:max response is 79.037430, min response is -58.106518.
max gradient is 8.000000, min gradient is -3.291010, learning rate is 0.000200
Net2: layer bn50:max response is 21.631643, min response is -3.663270.
max gradient is 7.207332, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.988453, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.254183, min response is -4.286030.
max gradient is 6.760269, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.408353, learning rate is 0.000200
max inferred z is 4.49, min inferred z is -3.91, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 139: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.970534, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.492188, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 7.425466, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.452479, learning rate is 0.000400
Net2: layer deconv3:max response is 81.314018, min response is -60.652302.
max gradient is 4.220253, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.787046, min response is -3.440933.
max gradient is 8.000000, min gradient is -6.340992, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.964852, min gradient is -8.000001, learning rate is 0.000200
Net2: layer bn49:max response is 18.849211, min response is -3.866318.
max gradient is 8.000000, min gradient is -4.453579, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.423844, learning rate is 0.000200
max inferred z is 3.85, min inferred z is -4.20, and std is 1.00
 4.47 s (22.4 data/s) [100/100]
training: epoch 139: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.990858, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.090761, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 7.039701, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.031570, learning rate is 0.000400
Net2: layer deconv3:max response is 76.512115, min response is -52.417904.
max gradient is 6.367406, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.552717, min response is -3.092094.
max gradient is 4.917019, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.175609, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.445614, min response is -4.316643.
max gradient is 8.000000, min gradient is -5.431628, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.488702, learning rate is 0.000200
max inferred z is 4.06, min inferred z is -4.69, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 139: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.716962, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.355604, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 6.673685, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -1.243250, learning rate is 0.000400
Net2: layer deconv3:max response is 92.850998, min response is -69.849266.
max gradient is 8.000000, min gradient is -5.477440, learning rate is 0.000200
Net2: layer bn50:max response is 24.895571, min response is -4.261550.
max gradient is 8.000000, min gradient is -7.010463, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.870646, learning rate is 0.000200
Net2: layer bn49:max response is 22.408411, min response is -3.468364.
max gradient is 7.621508, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.089198, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.14, min inferred z is -4.27, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 139: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.590053, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.312299, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 7.074679, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.085296, learning rate is 0.000400
Net2: layer deconv3:max response is 85.051300, min response is -62.928276.
max gradient is 8.000000, min gradient is -7.988871, learning rate is 0.000200
Net2: layer bn50:max response is 21.253765, min response is -3.525049.
max gradient is 8.000000, min gradient is -6.268963, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.107479, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.119328, min response is -2.905829.
max gradient is 8.000000, min gradient is -6.243324, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.613697, learning rate is 0.000200
max inferred z is 3.90, min inferred z is -4.84, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 139: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.825484, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.163833, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 7.346112, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.197670, learning rate is 0.000400
Net2: layer deconv3:max response is 80.770187, min response is -53.606037.
max gradient is 4.210102, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.499743, min response is -3.295950.
max gradient is 5.849975, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.268275, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 16.912823, min response is -4.365095.
max gradient is 8.000000, min gradient is -6.259178, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.950905, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.03, min inferred z is -4.62, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
Loss: 1.1939
Iteration 140 / 200
training: epoch 140: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.629012, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 3.982589, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 7.169347, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.385509, learning rate is 0.000400
Net2: layer deconv3:max response is 80.190887, min response is -58.118145.
max gradient is 8.000000, min gradient is -4.263663, learning rate is 0.000200
Net2: layer bn50:max response is 20.995230, min response is -3.411208.
max gradient is 6.984493, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.795407, learning rate is 0.000200
Net2: layer bn49:max response is 18.460213, min response is -3.297111.
max gradient is 7.900094, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.239994, min gradient is -8.000001, learning rate is 0.000200
max inferred z is 3.87, min inferred z is -4.11, and std is 1.00
 4.17 s (24.0 data/s) [100/100]
training: epoch 140: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.375546, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.194542, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 7.193515, min gradient is -8.000001, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.967975, learning rate is 0.000400
Net2: layer deconv3:max response is 82.630035, min response is -62.223797.
max gradient is 7.175170, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.660746, min response is -3.729192.
max gradient is 6.187619, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.207150, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.874868, min response is -3.861013.
max gradient is 6.428437, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.110559, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.95, min inferred z is -4.03, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
training: epoch 140: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.279532, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.298183, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 7.276498, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.094074, learning rate is 0.000400
Net2: layer deconv3:max response is 88.332344, min response is -65.476585.
max gradient is 3.432210, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.232632, min response is -3.530072.
max gradient is 6.880970, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.691032, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.969904, min response is -3.314995.
max gradient is 8.000000, min gradient is -6.746261, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.595357, learning rate is 0.000200
max inferred z is 4.07, min inferred z is -3.88, and std is 1.00
 4.22 s (23.7 data/s) [100/100]
training: epoch 140: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.556139, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.090350, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 6.851043, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.653313, learning rate is 0.000400
Net2: layer deconv3:max response is 78.266808, min response is -55.426056.
max gradient is 8.000000, min gradient is -5.284643, learning rate is 0.000200
Net2: layer bn50:max response is 20.320452, min response is -3.332488.
max gradient is 7.235735, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.123330, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.854595, min response is -3.873415.
max gradient is 6.452340, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.530504, learning rate is 0.000200
max inferred z is 3.68, min inferred z is -3.86, and std is 1.00
 4.28 s (23.4 data/s) [100/100]
training: epoch 140: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.759523, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.101927, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 7.088544, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.306379, learning rate is 0.000400
Net2: layer deconv3:max response is 86.880859, min response is -61.366650.
max gradient is 3.173043, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.964397, min response is -3.577806.
max gradient is 8.000000, min gradient is -7.832054, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.800264, learning rate is 0.000200
Net2: layer bn49:max response is 19.809174, min response is -3.946105.
max gradient is 8.000000, min gradient is -4.788161, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.212160, learning rate is 0.000200
max inferred z is 4.23, min inferred z is -3.97, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 140: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.516739, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.142649, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 7.568326, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.892536, learning rate is 0.000400
Net2: layer deconv3:max response is 77.994377, min response is -59.867832.
max gradient is 3.941069, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.027067, min response is -3.467331.
max gradient is 8.000000, min gradient is -5.720481, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.611179, learning rate is 0.000200
Net2: layer bn49:max response is 17.796568, min response is -4.130803.
max gradient is 8.000000, min gradient is -7.317613, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.498736, learning rate is 0.000200
max inferred z is 3.94, min inferred z is -4.21, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 140: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.095758, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.022870, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 6.660008, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.797667, learning rate is 0.000400
Net2: layer deconv3:max response is 74.147194, min response is -55.497852.
max gradient is 8.000000, min gradient is -2.960446, learning rate is 0.000200
Net2: layer bn50:max response is 20.846611, min response is -3.264234.
max gradient is 4.903199, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.926999, learning rate is 0.000200
Net2: layer bn49:max response is 17.234459, min response is -3.980657.
max gradient is 6.839504, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.655763, learning rate is 0.000200
max inferred z is 3.89, min inferred z is -4.15, and std is 1.00
 4.21 s (23.8 data/s) [100/100]
training: epoch 140: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.619163, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.319684, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 7.091644, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.010130, learning rate is 0.000400
Net2: layer deconv3:max response is 84.313293, min response is -56.139908.
max gradient is 8.000000, min gradient is -5.108912, learning rate is 0.000200
Net2: layer bn50:max response is 19.669033, min response is -3.199166.
max gradient is 4.684597, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.425844, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 16.844868, min response is -4.679025.
max gradient is 8.000000, min gradient is -6.940629, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.827019, learning rate is 0.000200
max inferred z is 4.51, min inferred z is -3.76, and std is 1.00
 4.30 s (23.3 data/s) [100/100]
training: epoch 140: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.473446, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.208215, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 7.581188, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 0.817868, learning rate is 0.000400
Net2: layer deconv3:max response is 103.531097, min response is -72.860260.
max gradient is 2.529671, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 25.597408, min response is -4.145120.
max gradient is 7.545310, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.025235, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 22.589834, min response is -3.826967.
max gradient is 6.384314, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.508081, learning rate is 0.000200
max inferred z is 3.93, min inferred z is -3.98, and std is 1.00
 4.18 s (23.9 data/s) [100/100]
training: epoch 140: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.522859, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.071820, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 7.545304, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.832165, learning rate is 0.000400
Net2: layer deconv3:max response is 80.629814, min response is -55.412125.
max gradient is 8.000000, min gradient is -7.968614, learning rate is 0.000200
Net2: layer bn50:max response is 22.372499, min response is -3.298466.
max gradient is 5.251197, min gradient is -8.000001, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.412885, learning rate is 0.000200
Net2: layer bn49:max response is 18.377472, min response is -4.484213.
max gradient is 8.000000, min gradient is -4.349674, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.725536, learning rate is 0.000200
max inferred z is 3.97, min inferred z is -3.87, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
Loss: 1.2938
Iteration 141 / 200
training: epoch 141: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.651405, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 3.928145, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 6.847754, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.885961, learning rate is 0.000400
Net2: layer deconv3:max response is 77.694138, min response is -58.399673.
max gradient is 8.000000, min gradient is -7.555399, learning rate is 0.000200
Net2: layer bn50:max response is 20.211159, min response is -3.311097.
max gradient is 7.187148, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.879699, learning rate is 0.000200
Net2: layer bn49:max response is 17.970976, min response is -3.578592.
max gradient is 8.000000, min gradient is -7.160705, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.916701, learning rate is 0.000200
max inferred z is 3.61, min inferred z is -3.68, and std is 1.00
 4.23 s (23.6 data/s) [100/100]
training: epoch 141: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.180368, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.174093, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 7.541799, min gradient is -8.000001, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.565299, learning rate is 0.000400
Net2: layer deconv3:max response is 79.438316, min response is -55.827175.
max gradient is 2.904626, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.204414, min response is -3.399203.
max gradient is 8.000000, min gradient is -4.867064, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.597346, learning rate is 0.000200
Net2: layer bn49:max response is 18.164200, min response is -4.261815.
max gradient is 8.000000, min gradient is -5.899294, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.165524, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.85, min inferred z is -4.45, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 141: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.182066, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.208319, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 7.247233, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.784069, learning rate is 0.000400
Net2: layer deconv3:max response is 76.322632, min response is -55.324356.
max gradient is 8.000000, min gradient is -4.848522, learning rate is 0.000200
Net2: layer bn50:max response is 19.760643, min response is -3.403559.
max gradient is 6.761171, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.593170, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.503660, min response is -3.402404.
max gradient is 8.000000, min gradient is -5.624253, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.696835, learning rate is 0.000200
max inferred z is 4.21, min inferred z is -3.88, and std is 1.00
 4.30 s (23.3 data/s) [100/100]
training: epoch 141: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.499641, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.056267, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 7.474231, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.856290, learning rate is 0.000400
Net2: layer deconv3:max response is 78.327461, min response is -55.506824.
max gradient is 3.629449, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.493893, min response is -3.233712.
max gradient is 8.000000, min gradient is -6.455804, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.639648, learning rate is 0.000200
Net2: layer bn49:max response is 18.057529, min response is -3.780814.
max gradient is 6.697042, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.932461, learning rate is 0.000200
max inferred z is 4.10, min inferred z is -4.32, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
training: epoch 141: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.691133, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.166559, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 6.985181, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.458388, learning rate is 0.000400
Net2: layer deconv3:max response is 78.508423, min response is -58.716755.
max gradient is 8.000000, min gradient is -3.091094, learning rate is 0.000200
Net2: layer bn50:max response is 19.781952, min response is -3.301339.
max gradient is 4.910701, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.096145, learning rate is 0.000200
Net2: layer bn49:max response is 17.440796, min response is -3.984434.
max gradient is 8.000000, min gradient is -6.144613, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.139172, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.95, min inferred z is -3.62, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 141: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.656402, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.355108, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 7.855746, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.656440, learning rate is 0.000400
Net2: layer deconv3:max response is 84.271477, min response is -58.958920.
max gradient is 2.851780, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.151480, min response is -3.474410.
max gradient is 8.000000, min gradient is -5.604435, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.768306, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.673235, min response is -3.323092.
max gradient is 8.000000, min gradient is -7.192203, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.363173, learning rate is 0.000200
max inferred z is 3.80, min inferred z is -3.96, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 141: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.150048, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.223664, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 7.100473, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.866543, learning rate is 0.000400
Net2: layer deconv3:max response is 95.060448, min response is -67.499229.
max gradient is 8.000000, min gradient is -2.301693, learning rate is 0.000200
Net2: layer bn50:max response is 24.168301, min response is -3.950243.
max gradient is 7.123966, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.448584, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 22.061125, min response is -3.713837.
max gradient is 8.000000, min gradient is -7.405762, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.438538, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.74, min inferred z is -4.41, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 141: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.396363, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.291214, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 7.650190, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.262448, learning rate is 0.000400
Net2: layer deconv3:max response is 93.474892, min response is -64.937752.
max gradient is 3.028100, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.208179, min response is -3.680954.
max gradient is 8.000000, min gradient is -6.893530, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.181955, learning rate is 0.000200
Net2: layer bn49:max response is 20.503126, min response is -4.082016.
max gradient is 8.000001, min gradient is -6.139833, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.279459, learning rate is 0.000200
max inferred z is 4.34, min inferred z is -4.32, and std is 1.00
 4.28 s (23.3 data/s) [100/100]
training: epoch 141: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 5.193821, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.184522, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 7.240222, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.096199, learning rate is 0.000400
Net2: layer deconv3:max response is 82.944824, min response is -60.071869.
max gradient is 8.000000, min gradient is -3.980130, learning rate is 0.000200
Net2: layer bn50:max response is 20.927517, min response is -3.829616.
max gradient is 7.744956, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.432726, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.510059, min response is -3.833393.
max gradient is 5.475498, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.216671, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.29, min inferred z is -4.11, and std is 1.00
 4.25 s (23.6 data/s) [100/100]
training: epoch 141: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.294042, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.189055, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 7.856448, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.977276, learning rate is 0.000400
Net2: layer deconv3:max response is 100.507202, min response is -71.165413.
max gradient is 2.469168, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 26.161942, min response is -4.493203.
max gradient is 8.000000, min gradient is -7.118293, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.594142, learning rate is 0.000200
Net2: layer bn49:max response is 23.011616, min response is -4.179789.
max gradient is 8.000000, min gradient is -3.945658, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000001, min gradient is -4.867404, learning rate is 0.000200
max inferred z is 3.81, min inferred z is -3.66, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
Loss: 1.1211
Iteration 142 / 200
training: epoch 142: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.499010, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 3.887708, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 7.604549, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.266178, learning rate is 0.000400
Net2: layer deconv3:max response is 88.406021, min response is -64.274406.
max gradient is 8.000000, min gradient is -3.031665, learning rate is 0.000200
Net2: layer bn50:max response is 22.873856, min response is -3.815374.
max gradient is 5.080399, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.090844, min gradient is -8.000001, learning rate is 0.000200
Net2: layer bn49:max response is 20.299110, min response is -3.974633.
max gradient is 6.431392, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 3.391646, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.71, min inferred z is -3.98, and std is 0.99
 4.12 s (24.3 data/s) [100/100]
training: epoch 142: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.028155, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.162100, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 7.906736, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.496840, learning rate is 0.000400
Net2: layer deconv3:max response is 71.917801, min response is -48.232155.
max gradient is 2.106939, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 17.387487, min response is -2.921398.
max gradient is 8.000000, min gradient is -4.836101, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.527791, learning rate is 0.000200
Net2: layer bn49:max response is 15.357734, min response is -3.770922.
max gradient is 8.000000, min gradient is -4.696801, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.119260, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.16, min inferred z is -3.96, and std is 0.99
 4.12 s (24.3 data/s) [100/100]
training: epoch 142: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.094071, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.299645, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 7.370652, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.602034, learning rate is 0.000400
Net2: layer deconv3:max response is 78.626198, min response is -57.131298.
max gradient is 8.000000, min gradient is -4.162990, learning rate is 0.000200
Net2: layer bn50:max response is 20.174335, min response is -3.258628.
max gradient is 8.000000, min gradient is -7.982776, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.480104, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.961536, min response is -3.800029.
max gradient is 4.212304, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.305268, learning rate is 0.000200
max inferred z is 3.79, min inferred z is -3.65, and std is 0.99
 4.14 s (24.1 data/s) [100/100]
training: epoch 142: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.058252, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.304888, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 7.855738, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.241725, learning rate is 0.000400
Net2: layer deconv3:max response is 87.386223, min response is -62.570278.
max gradient is 3.457420, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.950415, min response is -3.543272.
max gradient is 6.935118, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.375154, learning rate is 0.000200
Net2: layer bn49:max response is 19.401596, min response is -3.667895.
max gradient is 8.000000, min gradient is -5.871823, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.185944, learning rate is 0.000200
max inferred z is 3.74, min inferred z is -4.39, and std is 0.99
 4.17 s (24.0 data/s) [100/100]
training: epoch 142: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.470740, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.082518, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 7.336808, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.136647, learning rate is 0.000400
Net2: layer deconv3:max response is 78.941216, min response is -58.137642.
max gradient is 8.000000, min gradient is -2.635176, learning rate is 0.000200
Net2: layer bn50:max response is 19.932959, min response is -3.189358.
max gradient is 6.321173, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.139068, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.801481, min response is -3.775202.
max gradient is 7.474385, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.182585, learning rate is 0.000200
max inferred z is 4.36, min inferred z is -3.95, and std is 0.99
 4.28 s (23.3 data/s) [100/100]
training: epoch 142: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.372068, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.273869, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.744567, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.702103, learning rate is 0.000400
Net2: layer deconv3:max response is 97.133354, min response is -69.338867.
max gradient is 1.986351, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 24.765064, min response is -3.944441.
max gradient is 8.000000, min gradient is -5.736831, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.648629, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.874006, min response is -3.950334.
max gradient is 8.000000, min gradient is -6.121588, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.377394, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.26, min inferred z is -3.49, and std is 0.99
 4.27 s (23.4 data/s) [100/100]
training: epoch 142: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.815270, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.071296, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 7.291666, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.170405, learning rate is 0.000400
Net2: layer deconv3:max response is 81.074409, min response is -58.419170.
max gradient is 8.000000, min gradient is -1.899362, learning rate is 0.000200
Net2: layer bn50:max response is 21.169901, min response is -3.301961.
max gradient is 4.129989, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.838869, learning rate is 0.000200
Net2: layer bn49:max response is 18.823473, min response is -3.360970.
max gradient is 6.477729, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.447195, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.11, min inferred z is -4.04, and std is 0.99
 4.39 s (22.8 data/s) [100/100]
training: epoch 142: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.673963, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.445188, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 7.950951, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.542583, learning rate is 0.000400
Net2: layer deconv3:max response is 72.492485, min response is -55.152626.
max gradient is 2.076505, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.661142, min response is -3.168630.
max gradient is 8.000000, min gradient is -6.028723, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.531068, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.226440, min response is -4.087473.
max gradient is 8.000000, min gradient is -6.791300, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.801071, learning rate is 0.000200
max inferred z is 3.91, min inferred z is -4.04, and std is 0.99
 4.24 s (23.6 data/s) [100/100]
training: epoch 142: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.962840, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.266302, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 7.495337, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.436843, learning rate is 0.000400
Net2: layer deconv3:max response is 87.721107, min response is -60.848755.
max gradient is 8.000000, min gradient is -1.884387, learning rate is 0.000200
Net2: layer bn50:max response is 22.394093, min response is -4.080652.
max gradient is 5.130013, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.353892, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.381393, min response is -4.990524.
max gradient is 6.253508, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.314996, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.32, min inferred z is -4.21, and std is 0.99
 4.33 s (23.1 data/s) [100/100]
training: epoch 142: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.966602, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv2:max response is , min response is .
max gradient is 4.280210, min gradient is -8.000000, learning rate is 0.000005
Net1: layer conv1:max response is , min response is .
max gradient is 7.991418, min gradient is -8.000000, learning rate is 0.000005
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.931512, learning rate is 0.000400
Net2: layer deconv3:max response is 86.353218, min response is -61.381493.
max gradient is 2.767446, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.309628, min response is -3.598688.
max gradient is 8.000000, min gradient is -6.758912, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.770966, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.593267, min response is -3.725808.
max gradient is 8.000000, min gradient is -5.152699, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.810163, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.42, min inferred z is -3.99, and std is 0.99
 4.18 s (23.9 data/s) [100/100]
Loss: 1.1604
Iteration 143 / 200
training: epoch 143: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.218273, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv2:max response is , min response is .
max gradient is 4.064082, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv1:max response is , min response is .
max gradient is 7.982390, min gradient is -8.000000, learning rate is 0.000004
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.112933, learning rate is 0.000400
Net2: layer deconv3:max response is 72.035759, min response is -50.897484.
max gradient is 8.000000, min gradient is -3.592746, learning rate is 0.000200
Net2: layer bn50:max response is 18.796095, min response is -3.210543.
max gradient is 7.604906, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.855860, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 16.685492, min response is -3.558931.
max gradient is 8.000000, min gradient is -7.480673, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.951926, learning rate is 0.000200
max inferred z is 3.81, min inferred z is -4.32, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 143: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.839554, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv2:max response is , min response is .
max gradient is 4.149353, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.978014, learning rate is 0.000004
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.972926, learning rate is 0.000400
Net2: layer deconv3:max response is 90.334969, min response is -63.208809.
max gradient is 4.008788, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.072546, min response is -3.597080.
max gradient is 8.000000, min gradient is -7.398347, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.262326, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.297569, min response is -3.427847.
max gradient is 7.832685, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.351742, learning rate is 0.000200
max inferred z is 3.67, min inferred z is -3.72, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
training: epoch 143: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.667222, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv2:max response is , min response is .
max gradient is 4.267183, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv1:max response is , min response is .
max gradient is 7.698863, min gradient is -8.000000, learning rate is 0.000004
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.693597, learning rate is 0.000400
Net2: layer deconv3:max response is 81.886963, min response is -59.022892.
max gradient is 8.000000, min gradient is -2.564615, learning rate is 0.000200
Net2: layer bn50:max response is 20.957979, min response is -3.268993.
max gradient is 8.000000, min gradient is -7.415126, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.404750, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.458622, min response is -4.038412.
max gradient is 8.000000, min gradient is -6.147237, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.089500, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.88, min inferred z is -3.70, and std is 1.00
 4.22 s (23.7 data/s) [100/100]
training: epoch 143: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.061211, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv2:max response is , min response is .
max gradient is 4.078720, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv1:max response is , min response is .
max gradient is 7.854625, min gradient is -8.000000, learning rate is 0.000004
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.915061, learning rate is 0.000400
Net2: layer deconv3:max response is 84.598328, min response is -60.271873.
max gradient is 4.862647, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.869474, min response is -3.210208.
max gradient is 8.000000, min gradient is -6.046088, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.940801, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.794012, min response is -3.820122.
max gradient is 5.836382, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.365174, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.00, min inferred z is -3.83, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 143: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.200022, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv2:max response is , min response is .
max gradient is 3.960740, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv1:max response is , min response is .
max gradient is 7.904657, min gradient is -8.000000, learning rate is 0.000004
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.524663, learning rate is 0.000400
Net2: layer deconv3:max response is 76.906494, min response is -55.081207.
max gradient is 4.842346, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.832573, min response is -3.041118.
max gradient is 8.000000, min gradient is -6.349208, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.928404, learning rate is 0.000200
Net2: layer bn49:max response is 17.415722, min response is -3.551546.
max gradient is 8.000000, min gradient is -5.830838, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.444220, learning rate is 0.000200
max inferred z is 3.78, min inferred z is -3.90, and std is 1.00
 4.44 s (22.5 data/s) [100/100]
training: epoch 143: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.265115, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv2:max response is , min response is .
max gradient is 4.318899, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv1:max response is , min response is .
max gradient is 7.706202, min gradient is -8.000000, learning rate is 0.000004
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.355480, learning rate is 0.000400
Net2: layer deconv3:max response is 103.530830, min response is -76.317291.
max gradient is 8.000000, min gradient is -2.119636, learning rate is 0.000200
Net2: layer bn50:max response is 26.760641, min response is -4.260534.
max gradient is 6.379822, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.105130, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 23.743534, min response is -3.913742.
max gradient is 4.593727, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.835279, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.00, min inferred z is -4.02, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 143: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.527603, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv2:max response is , min response is .
max gradient is 3.988396, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv1:max response is , min response is .
max gradient is 7.870215, min gradient is -8.000000, learning rate is 0.000004
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.030943, learning rate is 0.000400
Net2: layer deconv3:max response is 76.396149, min response is -55.861935.
max gradient is 3.095670, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.301870, min response is -3.192101.
max gradient is 8.000000, min gradient is -7.277633, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.361241, learning rate is 0.000200
Net2: layer bn49:max response is 17.469358, min response is -4.111835.
max gradient is 8.000000, min gradient is -4.977942, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.712558, learning rate is 0.000200
max inferred z is 4.06, min inferred z is -4.75, and std is 1.00
 4.28 s (23.3 data/s) [100/100]
training: epoch 143: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.928965, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv2:max response is , min response is .
max gradient is 4.179093, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv1:max response is , min response is .
max gradient is 7.812606, min gradient is -8.000000, learning rate is 0.000004
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.643899, learning rate is 0.000400
Net2: layer deconv3:max response is 96.281761, min response is -67.147247.
max gradient is 8.000000, min gradient is -3.314254, learning rate is 0.000200
Net2: layer bn50:max response is 29.394590, min response is -4.854603.
max gradient is 5.631071, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.614792, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.228897, min response is -5.300161.
max gradient is 8.000000, min gradient is -6.470067, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.345932, learning rate is 0.000200
max inferred z is 3.83, min inferred z is -3.72, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 143: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.842900, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv2:max response is , min response is .
max gradient is 4.298250, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv1:max response is , min response is .
max gradient is 7.966687, min gradient is -8.000000, learning rate is 0.000004
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.853526, learning rate is 0.000400
Net2: layer deconv3:max response is 87.103867, min response is -64.108902.
max gradient is 6.984304, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.808725, min response is -3.696925.
max gradient is 5.373108, min gradient is -8.000001, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.901977, min gradient is -8.000001, learning rate is 0.000200
Net2: layer bn49:max response is 20.159794, min response is -3.938714.
max gradient is 8.000000, min gradient is -6.590031, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.127788, learning rate is 0.000200
max inferred z is 4.06, min inferred z is -3.77, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 143: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.894947, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv2:max response is , min response is .
max gradient is 4.505139, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv1:max response is , min response is .
max gradient is 7.726292, min gradient is -8.000000, learning rate is 0.000004
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.681159, learning rate is 0.000400
Net2: layer deconv3:max response is 80.031944, min response is -59.343243.
max gradient is 4.543259, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.476921, min response is -3.368550.
max gradient is 8.000000, min gradient is -5.353733, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.760549, learning rate is 0.000200
Net2: layer bn49:max response is 17.886421, min response is -3.965353.
max gradient is 8.000000, min gradient is -6.801928, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.880866, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.28, min inferred z is -4.15, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
Loss: 1.1036
Iteration 144 / 200
training: epoch 144: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.176620, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv2:max response is , min response is .
max gradient is 4.157365, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.875798, learning rate is 0.000004
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.159167, learning rate is 0.000400
Net2: layer deconv3:max response is 89.159721, min response is -63.498760.
max gradient is 8.000000, min gradient is -6.449972, learning rate is 0.000200
Net2: layer bn50:max response is 22.761194, min response is -3.599672.
max gradient is 8.000000, min gradient is -4.860798, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.080689, learning rate is 0.000200
Net2: layer bn49:max response is 20.510958, min response is -3.487346.
max gradient is 8.000000, min gradient is -6.845959, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.336580, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.26, min inferred z is -3.79, and std is 1.00
 4.23 s (23.6 data/s) [100/100]
training: epoch 144: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.817451, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv2:max response is , min response is .
max gradient is 4.179013, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.795887, learning rate is 0.000004
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.703080, learning rate is 0.000400
Net2: layer deconv3:max response is 87.563759, min response is -62.835472.
max gradient is 6.002555, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 24.409309, min response is -3.648942.
max gradient is 6.275606, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.147267, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.195662, min response is -4.154918.
max gradient is 6.313517, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.735860, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.01, min inferred z is -4.00, and std is 1.00
 4.41 s (22.7 data/s) [100/100]
training: epoch 144: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.746572, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv2:max response is , min response is .
max gradient is 4.331460, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.915241, learning rate is 0.000004
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.442764, learning rate is 0.000400
Net2: layer deconv3:max response is 74.274490, min response is -53.235798.
max gradient is 7.090919, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.745239, min response is -3.455153.
max gradient is 8.000000, min gradient is -7.858907, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.652166, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.305920, min response is -3.938679.
max gradient is 8.000000, min gradient is -6.672853, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.444871, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.05, min inferred z is -3.45, and std is 1.00
 4.21 s (23.7 data/s) [100/100]
training: epoch 144: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.085890, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv2:max response is , min response is .
max gradient is 3.936273, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv1:max response is , min response is .
max gradient is 7.402041, min gradient is -8.000000, learning rate is 0.000004
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 1.405839, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 94.729202, min response is -73.062073.
max gradient is 8.000000, min gradient is -5.370640, learning rate is 0.000200
Net2: layer bn50:max response is 24.330006, min response is -3.834271.
max gradient is 6.602359, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.395283, learning rate is 0.000200
Net2: layer bn49:max response is 21.855410, min response is -4.001823.
max gradient is 6.392992, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.773067, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.64, min inferred z is -3.77, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 144: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.948297, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv2:max response is , min response is .
max gradient is 4.137750, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv1:max response is , min response is .
max gradient is 7.756853, min gradient is -8.000000, learning rate is 0.000004
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.425916, learning rate is 0.000400
Net2: layer deconv3:max response is 81.587860, min response is -60.668602.
max gradient is 5.056593, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.661839, min response is -3.577266.
max gradient is 8.000000, min gradient is -6.514208, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.396056, learning rate is 0.000200
Net2: layer bn49:max response is 18.115089, min response is -4.199297.
max gradient is 4.887400, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.173338, learning rate is 0.000200
max inferred z is 3.66, min inferred z is -3.98, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 144: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.184948, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv2:max response is , min response is .
max gradient is 4.274790, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.926855, learning rate is 0.000004
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.542401, learning rate is 0.000400
Net2: layer deconv3:max response is 73.912354, min response is -54.093113.
max gradient is 5.911530, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.184378, min response is -3.179201.
max gradient is 8.000000, min gradient is -7.328300, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.545962, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.271721, min response is -3.914751.
max gradient is 6.358625, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.195583, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.09, min inferred z is -3.90, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 144: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.535720, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv2:max response is , min response is .
max gradient is 4.013565, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv1:max response is , min response is .
max gradient is 7.962341, min gradient is -8.000001, learning rate is 0.000004
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.096619, learning rate is 0.000400
Net2: layer deconv3:max response is 81.401863, min response is -60.066341.
max gradient is 8.000000, min gradient is -2.606871, learning rate is 0.000200
Net2: layer bn50:max response is 21.083727, min response is -3.465050.
max gradient is 5.594703, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.675484, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.919077, min response is -4.193642.
max gradient is 8.000000, min gradient is -7.755484, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.925361, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.90, min inferred z is -3.86, and std is 1.00
 4.34 s (23.1 data/s) [100/100]
training: epoch 144: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.614766, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv2:max response is , min response is .
max gradient is 4.167533, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.734289, learning rate is 0.000004
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 7.317926, min gradient is -5.771464, learning rate is 0.000400
Net2: layer deconv3:max response is 101.017059, min response is -70.453293.
max gradient is 2.039125, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 25.006250, min response is -3.967703.
max gradient is 8.000000, min gradient is -5.995366, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.373226, learning rate is 0.000200
Net2: layer bn49:max response is 22.136015, min response is -4.107996.
max gradient is 7.580877, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.093544, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.10, min inferred z is -4.67, and std is 1.00
 4.21 s (23.8 data/s) [100/100]
training: epoch 144: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.726926, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv2:max response is , min response is .
max gradient is 4.137385, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.985985, learning rate is 0.000004
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.307694, learning rate is 0.000400
Net2: layer deconv3:max response is 88.240311, min response is -62.806122.
max gradient is 5.598272, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.599390, min response is -3.525418.
max gradient is 8.000000, min gradient is -7.307635, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.306776, learning rate is 0.000200
Net2: layer bn49:max response is 19.927555, min response is -3.813183.
max gradient is 7.647366, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.298614, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.92, min inferred z is -3.44, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 144: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.726282, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv2:max response is , min response is .
max gradient is 4.512774, min gradient is -8.000000, learning rate is 0.000004
Net1: layer conv1:max response is , min response is .
max gradient is 7.296323, min gradient is -8.000000, learning rate is 0.000004
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.076890, learning rate is 0.000400
Net2: layer deconv3:max response is 86.291016, min response is -65.609299.
max gradient is 8.000000, min gradient is -2.727599, learning rate is 0.000200
Net2: layer bn50:max response is 23.297073, min response is -3.643242.
max gradient is 5.786129, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.488647, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.874870, min response is -4.226718.
max gradient is 8.000000, min gradient is -6.082922, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.014821, learning rate is 0.000200
max inferred z is 4.04, min inferred z is -5.12, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
Loss: 1.1268
Iteration 145 / 200
training: epoch 145: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.977368, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.080091, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 7.955288, min gradient is -8.000000, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.500244, learning rate is 0.000400
Net2: layer deconv3:max response is 83.589127, min response is -62.352444.
max gradient is 8.000000, min gradient is -6.453897, learning rate is 0.000200
Net2: layer bn50:max response is 22.071785, min response is -3.461305.
max gradient is 4.585503, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.466726, min gradient is -8.000001, learning rate is 0.000200
Net2: layer bn49:max response is 19.633284, min response is -3.949512.
max gradient is 8.000000, min gradient is -6.264350, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.969294, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.86, min inferred z is -4.53, and std is 1.00
 4.18 s (23.9 data/s) [100/100]
training: epoch 145: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.879401, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.173803, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.865942, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.548272, learning rate is 0.000400
Net2: layer deconv3:max response is 86.783432, min response is -62.931576.
max gradient is 4.586602, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.568205, min response is -3.503716.
max gradient is 8.000000, min gradient is -4.776567, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.815820, learning rate is 0.000200
Net2: layer bn49:max response is 20.004381, min response is -3.963370.
max gradient is 4.822442, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.602077, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.80, min inferred z is -4.43, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 145: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.776266, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.245441, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 7.861799, min gradient is -8.000000, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.895880, learning rate is 0.000400
Net2: layer deconv3:max response is 90.620880, min response is -65.430031.
max gradient is 8.000000, min gradient is -3.473927, learning rate is 0.000200
Net2: layer bn50:max response is 23.082670, min response is -3.653491.
max gradient is 7.379733, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.256312, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.795143, min response is -3.389080.
max gradient is 7.138562, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.219130, learning rate is 0.000200
max inferred z is 3.75, min inferred z is -4.35, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 145: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.868268, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.074488, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.752000, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.108972, learning rate is 0.000400
Net2: layer deconv3:max response is 77.391266, min response is -55.755970.
max gradient is 4.109757, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.521864, min response is -3.596444.
max gradient is 8.000000, min gradient is -7.296087, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.576960, learning rate is 0.000200
Net2: layer bn49:max response is 17.772150, min response is -4.317263.
max gradient is 8.000000, min gradient is -5.779839, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.652791, learning rate is 0.000200
max inferred z is 3.79, min inferred z is -4.13, and std is 1.00
 4.22 s (23.7 data/s) [100/100]
training: epoch 145: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.049742, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.047401, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 7.731601, min gradient is -8.000000, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.507218, learning rate is 0.000400
Net2: layer deconv3:max response is 85.391319, min response is -64.268379.
max gradient is 8.000000, min gradient is -5.154282, learning rate is 0.000200
Net2: layer bn50:max response is 22.458258, min response is -3.492362.
max gradient is 8.000000, min gradient is -6.842930, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.580319, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.823294, min response is -3.311415.
max gradient is 6.553051, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.971415, learning rate is 0.000200
max inferred z is 3.73, min inferred z is -4.76, and std is 1.00
 4.32 s (23.2 data/s) [100/100]
training: epoch 145: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.167837, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.225352, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.591317, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.341161, learning rate is 0.000400
Net2: layer deconv3:max response is 91.876907, min response is -66.846092.
max gradient is 7.819705, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.481853, min response is -3.629525.
max gradient is 8.000000, min gradient is -6.089028, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.305403, learning rate is 0.000200
Net2: layer bn49:max response is 20.701986, min response is -3.773966.
max gradient is 8.000000, min gradient is -7.495354, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.882773, learning rate is 0.000200
max inferred z is 4.38, min inferred z is -3.86, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 145: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.403171, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.105595, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.987844, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.546329, learning rate is 0.000400
Net2: layer deconv3:max response is 79.119591, min response is -57.629673.
max gradient is 8.000000, min gradient is -5.403397, learning rate is 0.000200
Net2: layer bn50:max response is 21.765392, min response is -3.525420.
max gradient is 5.786858, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.510709, learning rate is 0.000200
Net2: layer bn49:max response is 18.148268, min response is -4.380029.
max gradient is 7.575591, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.892602, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.66, min inferred z is -4.01, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 145: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.849628, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.344168, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 7.813541, min gradient is -8.000000, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.269580, learning rate is 0.000400
Net2: layer deconv3:max response is 85.156815, min response is -63.513531.
max gradient is 5.019519, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 25.378267, min response is -3.678143.
max gradient is 8.000000, min gradient is -4.841052, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.919055, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.371870, min response is -4.120115.
max gradient is 8.000000, min gradient is -6.716546, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.463353, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.82, min inferred z is -3.90, and std is 1.00
 4.44 s (22.5 data/s) [100/100]
training: epoch 145: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.786912, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.233501, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 7.918033, min gradient is -8.000000, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.471185, learning rate is 0.000400
Net2: layer deconv3:max response is 69.901390, min response is -53.036110.
max gradient is 7.496260, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.094999, min response is -3.119592.
max gradient is 8.000000, min gradient is -6.039488, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.520844, learning rate is 0.000200
Net2: layer bn49:max response is 16.044209, min response is -3.401213.
max gradient is 8.000000, min gradient is -6.311647, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.639182, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.19, min inferred z is -3.87, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
training: epoch 145: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.747029, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.608843, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 7.949108, min gradient is -8.000000, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.896244, learning rate is 0.000400
Net2: layer deconv3:max response is 88.955559, min response is -66.188286.
max gradient is 8.000000, min gradient is -6.924598, learning rate is 0.000200
Net2: layer bn50:max response is 24.977331, min response is -4.178909.
max gradient is 6.088132, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.417403, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.294479, min response is -5.128739.
max gradient is 7.393514, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 4.046835, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.82, min inferred z is -4.39, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
Loss: 1.0795
Iteration 146 / 200
training: epoch 146: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.676774, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.289444, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.960149, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.348013, learning rate is 0.000400
Net2: layer deconv3:max response is 93.100471, min response is -68.976456.
max gradient is 3.308406, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 24.021564, min response is -3.737902.
max gradient is 8.000000, min gradient is -5.613553, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.816267, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.146584, min response is -4.275071.
max gradient is 8.000000, min gradient is -6.859790, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.615415, min gradient is -8.000001, learning rate is 0.000200
max inferred z is 4.39, min inferred z is -3.92, and std is 1.00
 4.23 s (23.6 data/s) [100/100]
training: epoch 146: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.776198, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.342575, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 7.700999, min gradient is -8.000000, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.731689, learning rate is 0.000400
Net2: layer deconv3:max response is 86.347458, min response is -59.395676.
max gradient is 8.000000, min gradient is -3.942771, learning rate is 0.000200
Net2: layer bn50:max response is 22.735029, min response is -3.930877.
max gradient is 5.440851, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.268719, learning rate is 0.000200
Net2: layer bn49:max response is 17.768167, min response is -5.009378.
max gradient is 8.000000, min gradient is -6.556087, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.360831, learning rate is 0.000200
max inferred z is 3.87, min inferred z is -3.79, and std is 1.00
 4.41 s (22.7 data/s) [100/100]
training: epoch 146: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.784952, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.215237, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.901524, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.451688, learning rate is 0.000400
Net2: layer deconv3:max response is 77.679474, min response is -54.437229.
max gradient is 4.424439, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.639618, min response is -3.150991.
max gradient is 8.000000, min gradient is -5.046999, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.892299, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 16.930496, min response is -4.116186.
max gradient is 5.723802, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.818888, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.63, min inferred z is -3.66, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 146: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.812522, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.028007, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.808208, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.529449, learning rate is 0.000400
Net2: layer deconv3:max response is 97.655060, min response is -70.011742.
max gradient is 6.846700, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 25.004223, min response is -3.837456.
max gradient is 7.233700, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.079103, learning rate is 0.000200
Net2: layer bn49:max response is 22.102249, min response is -4.462423.
max gradient is 8.000000, min gradient is -5.504059, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.096184, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.78, min inferred z is -4.17, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 146: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.209991, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.023424, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 7.360197, min gradient is -8.000000, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.530491, learning rate is 0.000400
Net2: layer deconv3:max response is 74.464172, min response is -54.946022.
max gradient is 8.000000, min gradient is -2.001148, learning rate is 0.000200
Net2: layer bn50:max response is 18.736263, min response is -3.324749.
max gradient is 5.158040, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.855745, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 16.768272, min response is -3.820099.
max gradient is 7.290666, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.549803, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.67, min inferred z is -4.17, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 146: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.204297, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.256089, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.569765, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.701608, learning rate is 0.000400
Net2: layer deconv3:max response is 87.787338, min response is -63.624943.
max gradient is 2.389613, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.604057, min response is -3.644257.
max gradient is 8.000000, min gradient is -6.314983, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.425117, learning rate is 0.000200
Net2: layer bn49:max response is 20.154133, min response is -4.144457.
max gradient is 8.000000, min gradient is -7.481068, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.440832, learning rate is 0.000200
max inferred z is 4.01, min inferred z is -4.15, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 146: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.309056, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.256802, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.995465, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.551688, learning rate is 0.000400
Net2: layer deconv3:max response is 70.070099, min response is -51.598396.
max gradient is 8.000000, min gradient is -7.964066, learning rate is 0.000200
Net2: layer bn50:max response is 19.810698, min response is -3.366753.
max gradient is 5.031375, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.236228, learning rate is 0.000200
Net2: layer bn49:max response is 16.485500, min response is -3.875125.
max gradient is 8.000000, min gradient is -7.772943, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.021249, learning rate is 0.000200
max inferred z is 3.67, min inferred z is -3.91, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 146: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.537741, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.637097, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 7.332791, min gradient is -8.000000, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.032069, learning rate is 0.000400
Net2: layer deconv3:max response is 83.537323, min response is -65.229675.
max gradient is 8.000000, min gradient is -6.169859, learning rate is 0.000200
Net2: layer bn50:max response is 21.616909, min response is -3.322220.
max gradient is 8.000000, min gradient is -6.230789, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.652442, learning rate is 0.000200
Net2: layer bn49:max response is 19.436388, min response is -3.276073.
max gradient is 8.000000, min gradient is -7.061316, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.077882, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.18, min inferred z is -3.90, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 146: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.613751, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.103732, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.869298, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.886333, learning rate is 0.000400
Net2: layer deconv3:max response is 78.124084, min response is -58.315273.
max gradient is 6.151131, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.876070, min response is -3.301556.
max gradient is 6.891790, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.373342, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.911676, min response is -4.043783.
max gradient is 8.000000, min gradient is -6.799525, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.770037, learning rate is 0.000200
max inferred z is 3.93, min inferred z is -4.00, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 146: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.823019, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.442914, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 7.947162, min gradient is -8.000000, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.041079, learning rate is 0.000400
Net2: layer deconv3:max response is 89.499428, min response is -57.962734.
max gradient is 5.344746, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.319736, min response is -3.880527.
max gradient is 8.000000, min gradient is -7.062045, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.655416, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.708750, min response is -5.167168.
max gradient is 8.000000, min gradient is -7.796792, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.953717, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.83, min inferred z is -4.03, and std is 1.00
 4.17 s (24.0 data/s) [100/100]
Loss: 1.115
Iteration 147 / 200
training: epoch 147: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.157132, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.110660, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.911672, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.286569, learning rate is 0.000400
Net2: layer deconv3:max response is 85.081093, min response is -64.683510.
max gradient is 8.000000, min gradient is -3.602543, learning rate is 0.000200
Net2: layer bn50:max response is 21.814884, min response is -4.045913.
max gradient is 6.049245, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.807067, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.630760, min response is -3.531617.
max gradient is 7.004661, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.206006, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.31, min inferred z is -4.12, and std is 1.01
 4.20 s (23.8 data/s) [100/100]
training: epoch 147: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.701885, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.233024, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.625443, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.898173, learning rate is 0.000400
Net2: layer deconv3:max response is 80.629547, min response is -59.514629.
max gradient is 1.879575, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.736254, min response is -3.598640.
max gradient is 8.000000, min gradient is -6.155210, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.818619, learning rate is 0.000200
Net2: layer bn49:max response is 18.211157, min response is -3.862399.
max gradient is 8.000000, min gradient is -7.393176, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.577641, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.02, min inferred z is -4.61, and std is 1.01
 4.31 s (23.2 data/s) [100/100]
training: epoch 147: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.707944, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.251383, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.990057, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.179310, learning rate is 0.000400
Net2: layer deconv3:max response is 92.689247, min response is -67.529121.
max gradient is 8.000000, min gradient is -4.798712, learning rate is 0.000200
Net2: layer bn50:max response is 23.697670, min response is -3.776273.
max gradient is 8.000000, min gradient is -7.682680, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.963594, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.439787, min response is -4.028916.
max gradient is 6.717363, min gradient is -8.000001, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.892445, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.54, min inferred z is -3.96, and std is 1.01
 4.32 s (23.1 data/s) [100/100]
training: epoch 147: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.701466, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.101494, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.900476, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.272626, learning rate is 0.000400
Net2: layer deconv3:max response is 79.792419, min response is -60.238438.
max gradient is 3.582752, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.827948, min response is -3.355293.
max gradient is 6.608945, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.586612, learning rate is 0.000200
Net2: layer bn49:max response is 18.675459, min response is -4.126122.
max gradient is 8.000000, min gradient is -6.192657, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.903519, learning rate is 0.000200
max inferred z is 3.72, min inferred z is -4.12, and std is 1.01
 4.25 s (23.5 data/s) [100/100]
training: epoch 147: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.856825, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.119113, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 7.909970, min gradient is -8.000000, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.499952, learning rate is 0.000400
Net2: layer deconv3:max response is 91.253235, min response is -68.577621.
max gradient is 8.000000, min gradient is -6.855841, learning rate is 0.000200
Net2: layer bn50:max response is 23.265585, min response is -3.583688.
max gradient is 5.707839, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.830981, learning rate is 0.000200
Net2: layer bn49:max response is 20.562937, min response is -3.807042.
max gradient is 6.900388, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.391575, learning rate is 0.000200
max inferred z is 3.83, min inferred z is -4.17, and std is 1.01
 4.24 s (23.6 data/s) [100/100]
training: epoch 147: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.772747, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.400337, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.866973, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000001, min gradient is 6.940361, learning rate is 0.000400
Net2: layer deconv3:max response is 93.529968, min response is -69.117874.
max gradient is 4.029928, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.626389, min response is -3.557625.
max gradient is 8.000000, min gradient is -4.729594, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.998787, learning rate is 0.000200
Net2: layer bn49:max response is 20.959621, min response is -4.051369.
max gradient is 8.000000, min gradient is -5.762468, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.338366, learning rate is 0.000200
max inferred z is 3.84, min inferred z is -4.48, and std is 1.01
 4.30 s (23.3 data/s) [100/100]
training: epoch 147: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.278990, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.393066, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 7.710574, min gradient is -8.000000, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.007942, learning rate is 0.000400
Net2: layer deconv3:max response is 84.238937, min response is -66.535248.
max gradient is 8.000000, min gradient is -2.964396, learning rate is 0.000200
Net2: layer bn50:max response is 22.409849, min response is -3.772973.
max gradient is 6.916193, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.303800, learning rate is 0.000200
Net2: layer bn49:max response is 20.020302, min response is -3.842918.
max gradient is 7.933162, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.894910, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.38, min inferred z is -4.21, and std is 1.01
 4.49 s (22.3 data/s) [100/100]
training: epoch 147: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.682333, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.093305, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.763737, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.072951, learning rate is 0.000400
Net2: layer deconv3:max response is 91.542809, min response is -68.101585.
max gradient is 6.433290, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.058359, min response is -3.699539.
max gradient is 8.000000, min gradient is -6.984775, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.849720, min gradient is -8.000001, learning rate is 0.000200
Net2: layer bn49:max response is 20.580679, min response is -4.692629.
max gradient is 6.416449, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.251359, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.94, min inferred z is -4.20, and std is 1.01
 4.38 s (22.8 data/s) [100/100]
training: epoch 147: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.809335, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.226147, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 7.939410, min gradient is -8.000000, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.489951, learning rate is 0.000400
Net2: layer deconv3:max response is 83.481461, min response is -62.349075.
max gradient is 4.464459, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.051281, min response is -3.555578.
max gradient is 8.000000, min gradient is -5.944761, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.026286, learning rate is 0.000200
Net2: layer bn49:max response is 18.600952, min response is -4.207025.
max gradient is 8.000000, min gradient is -7.471185, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.444686, learning rate is 0.000200
max inferred z is 4.03, min inferred z is -4.08, and std is 1.01
 4.35 s (23.0 data/s) [100/100]
training: epoch 147: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.699941, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.531329, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 7.801972, min gradient is -8.000000, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.848194, learning rate is 0.000400
Net2: layer deconv3:max response is 85.948875, min response is -64.011620.
max gradient is 8.000000, min gradient is -7.702880, learning rate is 0.000200
Net2: layer bn50:max response is 22.483295, min response is -3.479145.
max gradient is 3.661258, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.839395, min gradient is -8.000001, learning rate is 0.000200
Net2: layer bn49:max response is 20.014690, min response is -3.810278.
max gradient is 6.993710, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.210608, learning rate is 0.000200
max inferred z is 3.75, min inferred z is -3.97, and std is 1.01
 4.36 s (22.9 data/s) [100/100]
Loss: 1.386
Iteration 148 / 200
training: epoch 148: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.998473, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.499925, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 7.341167, min gradient is -8.000000, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.000210, learning rate is 0.000400
Net2: layer deconv3:max response is 80.790306, min response is -62.317017.
max gradient is 7.496540, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.483082, min response is -3.102732.
max gradient is 8.000000, min gradient is -5.165362, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.587650, learning rate is 0.000200
Net2: layer bn49:max response is 18.624014, min response is -3.497096.
max gradient is 8.000000, min gradient is -6.116445, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.342551, learning rate is 0.000200
max inferred z is 4.14, min inferred z is -3.62, and std is 1.00
 4.17 s (24.0 data/s) [100/100]
training: epoch 148: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.828691, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.170101, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.628831, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.603538, learning rate is 0.000400
Net2: layer deconv3:max response is 81.709244, min response is -60.991619.
max gradient is 8.000000, min gradient is -3.842483, learning rate is 0.000200
Net2: layer bn50:max response is 21.745564, min response is -3.730875.
max gradient is 8.000000, min gradient is -7.899384, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.410222, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.897211, min response is -4.159520.
max gradient is 7.417289, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.323739, learning rate is 0.000200
max inferred z is 3.73, min inferred z is -3.69, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
training: epoch 148: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.695234, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.340415, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.684924, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 4.474655, min gradient is -4.690233, learning rate is 0.000400
Net2: layer deconv3:max response is 85.286011, min response is -61.804085.
max gradient is 4.436036, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.686619, min response is -3.642270.
max gradient is 8.000000, min gradient is -5.799640, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.847940, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.609594, min response is -4.316866.
max gradient is 8.000000, min gradient is -7.461467, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.765640, learning rate is 0.000200
max inferred z is 4.27, min inferred z is -4.30, and std is 1.00
 4.43 s (22.6 data/s) [100/100]
training: epoch 148: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.528656, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.080428, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.617576, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.664159, learning rate is 0.000400
Net2: layer deconv3:max response is 74.310448, min response is -52.603626.
max gradient is 5.512914, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.325569, min response is -3.653738.
max gradient is 6.195829, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.658824, learning rate is 0.000200
Net2: layer bn49:max response is 16.379749, min response is -4.449001.
max gradient is 7.996985, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.766654, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.23, min inferred z is -3.92, and std is 1.00
 4.28 s (23.3 data/s) [100/100]
training: epoch 148: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.880404, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.333635, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 7.732896, min gradient is -8.000000, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.870302, learning rate is 0.000400
Net2: layer deconv3:max response is 83.535713, min response is -67.257660.
max gradient is 8.000000, min gradient is -4.432336, learning rate is 0.000200
Net2: layer bn50:max response is 22.304281, min response is -3.736844.
max gradient is 7.367850, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.673850, learning rate is 0.000200
Net2: layer bn49:max response is 19.831871, min response is -3.797565.
max gradient is 7.213552, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.351086, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.69, min inferred z is -4.00, and std is 1.00
 4.17 s (24.0 data/s) [100/100]
training: epoch 148: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.948186, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.176292, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.641258, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.827696, learning rate is 0.000400
Net2: layer deconv3:max response is 82.555679, min response is -62.922768.
max gradient is 4.742751, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.055117, min response is -3.555519.
max gradient is 8.000000, min gradient is -3.590911, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.838683, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.823116, min response is -3.468096.
max gradient is 6.532445, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.557346, learning rate is 0.000200
max inferred z is 3.82, min inferred z is -3.82, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 148: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.230911, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.111622, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.833447, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.571490, learning rate is 0.000400
Net2: layer deconv3:max response is 81.397713, min response is -57.863571.
max gradient is 1.878738, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.214573, min response is -3.881197.
max gradient is 8.000000, min gradient is -5.533667, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.827273, learning rate is 0.000200
Net2: layer bn49:max response is 18.090630, min response is -4.702522.
max gradient is 8.000000, min gradient is -4.268787, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.688246, learning rate is 0.000200
max inferred z is 4.18, min inferred z is -3.95, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 148: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.571712, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.389988, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 7.800375, min gradient is -8.000000, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.613118, learning rate is 0.000400
Net2: layer deconv3:max response is 75.788048, min response is -56.884502.
max gradient is 8.000000, min gradient is -3.297173, learning rate is 0.000200
Net2: layer bn50:max response is 19.804068, min response is -3.170795.
max gradient is 6.340336, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.895345, learning rate is 0.000200
Net2: layer bn49:max response is 17.894375, min response is -3.755472.
max gradient is 7.505043, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.661708, learning rate is 0.000200
max inferred z is 4.31, min inferred z is -3.55, and std is 1.00
 4.44 s (22.5 data/s) [100/100]
training: epoch 148: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.474091, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.337699, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.579682, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.916480, learning rate is 0.000400
Net2: layer deconv3:max response is 80.545837, min response is -58.871868.
max gradient is 2.100939, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.408796, min response is -3.236347.
max gradient is 8.000000, min gradient is -5.521069, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.453259, learning rate is 0.000200
Net2: layer bn49:max response is 18.472122, min response is -3.823275.
max gradient is 6.859996, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.059515, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.12, min inferred z is -3.98, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
training: epoch 148: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.543320, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv2:max response is , min response is .
max gradient is 4.765022, min gradient is -8.000000, learning rate is 0.000003
Net1: layer conv1:max response is , min response is .
max gradient is 7.611067, min gradient is -8.000000, learning rate is 0.000003
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.857959, learning rate is 0.000400
Net2: layer deconv3:max response is 84.538925, min response is -65.084351.
max gradient is 8.000000, min gradient is -3.571323, learning rate is 0.000200
Net2: layer bn50:max response is 22.258780, min response is -3.385266.
max gradient is 4.886047, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.649735, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.882067, min response is -3.822513.
max gradient is 8.000000, min gradient is -7.236555, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.553234, learning rate is 0.000200
max inferred z is 5.14, min inferred z is -3.91, and std is 1.00
 4.22 s (23.7 data/s) [100/100]
Loss: 1.1745
Iteration 149 / 200
training: epoch 149: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.761065, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.205580, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.703765, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.215646, learning rate is 0.000400
Net2: layer deconv3:max response is 87.024467, min response is -64.204590.
max gradient is 2.382244, min gradient is -8.000001, learning rate is 0.000200
Net2: layer bn50:max response is 21.683607, min response is -3.554545.
max gradient is 8.000000, min gradient is -5.795749, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.891393, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.544397, min response is -4.292688.
max gradient is 8.000000, min gradient is -7.308990, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.753198, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.88, min inferred z is -3.90, and std is 1.01
 4.24 s (23.6 data/s) [100/100]
training: epoch 149: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.829702, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.207018, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.992079, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.966856, learning rate is 0.000400
Net2: layer deconv3:max response is 79.803612, min response is -61.578735.
max gradient is 8.000000, min gradient is -4.639790, learning rate is 0.000200
Net2: layer bn50:max response is 19.917425, min response is -3.021413.
max gradient is 5.829594, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.491259, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.129696, min response is -3.295887.
max gradient is 8.000000, min gradient is -6.071205, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.535483, learning rate is 0.000200
max inferred z is 3.88, min inferred z is -3.57, and std is 1.01
 4.31 s (23.2 data/s) [100/100]
training: epoch 149: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.610716, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.311973, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.659047, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 4.035560, min gradient is -6.710113, learning rate is 0.000400
Net2: layer deconv3:max response is 82.828995, min response is -59.704735.
max gradient is 4.366250, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.945080, min response is -3.621537.
max gradient is 8.000000, min gradient is -6.389551, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.970584, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.074318, min response is -3.514130.
max gradient is 7.411548, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.054424, learning rate is 0.000200
max inferred z is 3.77, min inferred z is -4.69, and std is 1.01
 4.39 s (22.8 data/s) [100/100]
training: epoch 149: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.688181, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.094887, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.822891, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.256994, learning rate is 0.000400
Net2: layer deconv3:max response is 86.361595, min response is -63.239403.
max gradient is 8.000000, min gradient is -2.792354, learning rate is 0.000200
Net2: layer bn50:max response is 22.615282, min response is -3.879548.
max gradient is 6.528130, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000001, min gradient is -7.377433, learning rate is 0.000200
Net2: layer bn49:max response is 19.601866, min response is -4.892561.
max gradient is 7.220080, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.877884, learning rate is 0.000200
max inferred z is 4.28, min inferred z is -4.25, and std is 1.01
 4.21 s (23.8 data/s) [100/100]
training: epoch 149: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.713257, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.078506, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.577267, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.205227, learning rate is 0.000400
Net2: layer deconv3:max response is 91.936783, min response is -63.617821.
max gradient is 1.718448, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.560240, min response is -3.979327.
max gradient is 8.000000, min gradient is -6.227340, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.962929, learning rate is 0.000200
Net2: layer bn49:max response is 19.430904, min response is -5.230576.
max gradient is 8.000000, min gradient is -7.320933, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.685452, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.15, min inferred z is -3.49, and std is 1.01
 4.41 s (22.7 data/s) [100/100]
training: epoch 149: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.937878, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.355345, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 7.996418, min gradient is -8.000000, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.948205, learning rate is 0.000400
Net2: layer deconv3:max response is 77.959694, min response is -59.043831.
max gradient is 8.000000, min gradient is -1.925669, learning rate is 0.000200
Net2: layer bn50:max response is 20.375792, min response is -3.101398.
max gradient is 5.730802, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.032311, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.359463, min response is -3.779459.
max gradient is 6.255299, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.100713, learning rate is 0.000200
max inferred z is 4.15, min inferred z is -3.86, and std is 1.01
 4.44 s (22.5 data/s) [100/100]
training: epoch 149: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.388306, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.042360, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.537369, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.428786, learning rate is 0.000400
Net2: layer deconv3:max response is 98.135361, min response is -72.630669.
max gradient is 1.520706, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 24.144381, min response is -3.638712.
max gradient is 8.000000, min gradient is -4.760534, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.157251, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 22.074961, min response is -3.309294.
max gradient is 8.000000, min gradient is -6.402137, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.308212, learning rate is 0.000200
max inferred z is 3.85, min inferred z is -3.95, and std is 1.01
 4.36 s (23.0 data/s) [100/100]
training: epoch 149: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.922177, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.233943, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 7.731607, min gradient is -8.000000, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -1.564655, learning rate is 0.000400
Net2: layer deconv3:max response is 87.459053, min response is -65.193451.
max gradient is 8.000000, min gradient is -3.096496, learning rate is 0.000200
Net2: layer bn50:max response is 21.708130, min response is -3.890182.
max gradient is 6.565054, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.925859, learning rate is 0.000200
Net2: layer bn49:max response is 20.006008, min response is -3.561146.
max gradient is 8.000000, min gradient is -6.706130, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.749306, learning rate is 0.000200
max inferred z is 4.34, min inferred z is -4.62, and std is 1.01
 4.37 s (22.9 data/s) [100/100]
training: epoch 149: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.490675, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.190868, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.389110, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.016843, learning rate is 0.000400
Net2: layer deconv3:max response is 75.257866, min response is -54.859039.
max gradient is 2.484905, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.762377, min response is -3.421299.
max gradient is 8.000000, min gradient is -7.294775, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.063949, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 16.884089, min response is -3.940351.
max gradient is 6.707188, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.138491, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.25, min inferred z is -4.48, and std is 1.01
 4.26 s (23.5 data/s) [100/100]
training: epoch 149: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.721521, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.285226, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.900872, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.892475, learning rate is 0.000400
Net2: layer deconv3:max response is 78.764206, min response is -58.557487.
max gradient is 8.000000, min gradient is -5.910823, learning rate is 0.000200
Net2: layer bn50:max response is 20.654402, min response is -3.889565.
max gradient is 7.590502, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.760450, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.124969, min response is -4.516383.
max gradient is 4.902195, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.058947, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.99, min inferred z is -3.99, and std is 1.01
 4.37 s (22.9 data/s) [100/100]
Loss: 1.0997
Iteration 150 / 200
training: epoch 150: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.859962, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.333248, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.885129, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.359303, learning rate is 0.000400
Net2: layer deconv3:max response is 105.352959, min response is -76.533913.
max gradient is 4.569328, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 26.050369, min response is -4.069232.
max gradient is 8.000000, min gradient is -7.029054, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.978424, learning rate is 0.000200
Net2: layer bn49:max response is 23.439556, min response is -4.140273.
max gradient is 8.000000, min gradient is -5.181268, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.736992, learning rate is 0.000200
max inferred z is 4.03, min inferred z is -4.24, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 150: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.670057, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.169993, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.498670, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.488000, learning rate is 0.000400
Net2: layer deconv3:max response is 82.649963, min response is -62.163738.
max gradient is 8.000000, min gradient is -4.521256, learning rate is 0.000200
Net2: layer bn50:max response is 21.398678, min response is -3.449819.
max gradient is 8.000000, min gradient is -7.943210, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.466272, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.223955, min response is -3.593417.
max gradient is 8.000000, min gradient is -6.631474, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.803453, learning rate is 0.000200
max inferred z is 3.79, min inferred z is -4.36, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 150: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.717613, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.300074, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.403892, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.645474, learning rate is 0.000400
Net2: layer deconv3:max response is 85.030556, min response is -63.146755.
max gradient is 4.621848, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.024948, min response is -3.353147.
max gradient is 8.000000, min gradient is -6.427336, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.770646, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.124983, min response is -3.867693.
max gradient is 7.145242, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.551122, learning rate is 0.000200
max inferred z is 3.71, min inferred z is -3.63, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 150: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.550115, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.132485, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.611086, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.463905, learning rate is 0.000400
Net2: layer deconv3:max response is 78.309364, min response is -57.876114.
max gradient is 8.000000, min gradient is -6.249013, learning rate is 0.000200
Net2: layer bn50:max response is 19.927252, min response is -3.521378.
max gradient is 8.000000, min gradient is -7.154762, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.947611, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.791475, min response is -3.832849.
max gradient is 8.000000, min gradient is -6.997762, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.603731, learning rate is 0.000200
max inferred z is 4.34, min inferred z is -3.80, and std is 1.00
 4.48 s (22.3 data/s) [100/100]
training: epoch 150: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.829920, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.308476, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.679455, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.765889, learning rate is 0.000400
Net2: layer deconv3:max response is 98.274330, min response is -72.453133.
max gradient is 8.000000, min gradient is -7.396878, learning rate is 0.000200
Net2: layer bn50:max response is 24.589472, min response is -3.961366.
max gradient is 8.000000, min gradient is -7.937298, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.539496, learning rate is 0.000200
Net2: layer bn49:max response is 22.232012, min response is -5.131163.
max gradient is 7.032358, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.947899, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.80, min inferred z is -3.96, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 150: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.989371, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.289596, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.713058, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000001, min gradient is 7.540759, learning rate is 0.000400
Net2: layer deconv3:max response is 89.644218, min response is -66.723526.
max gradient is 8.000000, min gradient is -7.763205, learning rate is 0.000200
Net2: layer bn50:max response is 21.639290, min response is -3.281894.
max gradient is 8.000000, min gradient is -4.231113, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.796875, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.569769, min response is -3.605141.
max gradient is 8.000000, min gradient is -5.970739, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.702770, learning rate is 0.000200
max inferred z is 4.36, min inferred z is -4.05, and std is 1.00
 4.34 s (23.1 data/s) [100/100]
training: epoch 150: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.117049, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.223938, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.569373, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.799216, learning rate is 0.000400
Net2: layer deconv3:max response is 81.777626, min response is -58.455276.
max gradient is 3.501908, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.520439, min response is -3.101627.
max gradient is 7.532578, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.094715, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.748863, min response is -3.741102.
max gradient is 8.000000, min gradient is -6.640948, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.206764, learning rate is 0.000200
max inferred z is 3.85, min inferred z is -3.71, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
training: epoch 150: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.546845, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.424593, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.828703, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.734933, learning rate is 0.000400
Net2: layer deconv3:max response is 96.949814, min response is -71.857994.
max gradient is 8.000000, min gradient is -3.260224, learning rate is 0.000200
Net2: layer bn50:max response is 24.991865, min response is -3.746996.
max gradient is 8.000000, min gradient is -6.918702, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.693679, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 22.443745, min response is -3.567260.
max gradient is 5.859583, min gradient is -8.000001, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.174074, learning rate is 0.000200
max inferred z is 4.41, min inferred z is -4.14, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 150: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.719765, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.389725, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.412891, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.489835, learning rate is 0.000400
Net2: layer deconv3:max response is 91.047226, min response is -66.784752.
max gradient is 5.194805, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.169744, min response is -3.427563.
max gradient is 8.000000, min gradient is -7.216223, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.689207, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.219482, min response is -4.213067.
max gradient is 6.370063, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.508234, learning rate is 0.000200
max inferred z is 3.65, min inferred z is -3.99, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 150: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.810349, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.463933, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.874360, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.565057, learning rate is 0.000400
Net2: layer deconv3:max response is 98.405396, min response is -72.913872.
max gradient is 6.940895, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 24.590481, min response is -3.724953.
max gradient is 4.846530, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.321661, learning rate is 0.000200
Net2: layer bn49:max response is 22.163502, min response is -3.938195.
max gradient is 8.000000, min gradient is -7.190345, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.519921, learning rate is 0.000200
max inferred z is 4.05, min inferred z is -3.47, and std is 1.00
 4.22 s (23.7 data/s) [100/100]
Loss: 1.0476
Iteration 151 / 200
training: epoch 151: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.880291, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.222366, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.686973, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.940770, learning rate is 0.000400
Net2: layer deconv3:max response is 103.277740, min response is -75.273262.
max gradient is 8.000000, min gradient is -5.855186, learning rate is 0.000200
Net2: layer bn50:max response is 25.669903, min response is -3.957673.
max gradient is 4.417756, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.394422, learning rate is 0.000200
Net2: layer bn49:max response is 23.110897, min response is -4.187536.
max gradient is 7.499785, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.265920, learning rate is 0.000200
max inferred z is 3.95, min inferred z is -3.69, and std is 1.00
 4.22 s (23.7 data/s) [100/100]
training: epoch 151: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.794220, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.192994, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.386497, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.133518, learning rate is 0.000400
Net2: layer deconv3:max response is 82.469070, min response is -60.592480.
max gradient is 5.011840, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.202679, min response is -3.311741.
max gradient is 8.000000, min gradient is -6.782687, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.934831, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.380606, min response is -3.668748.
max gradient is 6.808801, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.576508, learning rate is 0.000200
max inferred z is 4.09, min inferred z is -4.36, and std is 1.00
 4.44 s (22.5 data/s) [100/100]
training: epoch 151: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.728119, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.154307, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.213755, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.487203, learning rate is 0.000400
Net2: layer deconv3:max response is 79.924637, min response is -60.629433.
max gradient is 8.000000, min gradient is -4.129233, learning rate is 0.000200
Net2: layer bn50:max response is 21.542995, min response is -3.468228.
max gradient is 5.798241, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.265175, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.385458, min response is -4.185626.
max gradient is 8.000000, min gradient is -7.523472, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.583490, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.26, min inferred z is -4.08, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
training: epoch 151: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.620846, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.056726, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.467175, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.355361, learning rate is 0.000400
Net2: layer deconv3:max response is 105.888100, min response is -76.228569.
max gradient is 1.996647, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 25.251690, min response is -3.907447.
max gradient is 8.000000, min gradient is -6.178280, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.952572, learning rate is 0.000200
Net2: layer bn49:max response is 22.941408, min response is -3.477512.
max gradient is 8.000000, min gradient is -6.420477, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.052903, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.63, min inferred z is -3.89, and std is 1.00
 4.19 s (23.9 data/s) [100/100]
training: epoch 151: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.586131, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.309973, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.725120, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.217351, learning rate is 0.000400
Net2: layer deconv3:max response is 78.192444, min response is -58.846703.
max gradient is 8.000000, min gradient is -3.508318, learning rate is 0.000200
Net2: layer bn50:max response is 20.884668, min response is -3.692501.
max gradient is 7.281350, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.023061, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.759785, min response is -4.352146.
max gradient is 8.000000, min gradient is -7.888727, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.461292, learning rate is 0.000200
max inferred z is 4.21, min inferred z is -4.58, and std is 1.00
 4.22 s (23.7 data/s) [100/100]
training: epoch 151: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.199263, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.277258, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.472847, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.873563, learning rate is 0.000400
Net2: layer deconv3:max response is 88.788460, min response is -66.805397.
max gradient is 8.000000, min gradient is -7.526509, learning rate is 0.000200
Net2: layer bn50:max response is 23.995890, min response is -3.833075.
max gradient is 7.806911, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 4.712819, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.149185, min response is -4.528945.
max gradient is 8.000000, min gradient is -5.544914, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.799121, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.20, min inferred z is -3.81, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 151: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.331701, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.103361, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.405493, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.333076, learning rate is 0.000400
Net2: layer deconv3:max response is 73.063065, min response is -55.850479.
max gradient is 2.797129, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.693003, min response is -3.426907.
max gradient is 8.000000, min gradient is -5.934324, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.615642, learning rate is 0.000200
Net2: layer bn49:max response is 16.477568, min response is -4.204349.
max gradient is 8.000000, min gradient is -5.770772, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.199187, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.66, min inferred z is -3.87, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 151: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.673802, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.386827, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.678591, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.061165, learning rate is 0.000400
Net2: layer deconv3:max response is 101.817619, min response is -76.387581.
max gradient is 8.000000, min gradient is -2.867407, learning rate is 0.000200
Net2: layer bn50:max response is 25.362371, min response is -3.786463.
max gradient is 7.493765, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.716719, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 23.083290, min response is -4.796037.
max gradient is 7.955409, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.674868, learning rate is 0.000200
max inferred z is 4.39, min inferred z is -3.65, and std is 1.00
 4.44 s (22.5 data/s) [100/100]
training: epoch 151: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.716221, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.138977, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.233891, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.949390, learning rate is 0.000400
Net2: layer deconv3:max response is 91.788513, min response is -66.765633.
max gradient is 3.135215, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.136423, min response is -3.435038.
max gradient is 8.000000, min gradient is -7.660808, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.525517, learning rate is 0.000200
Net2: layer bn49:max response is 20.240252, min response is -3.758418.
max gradient is 7.195198, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.511306, learning rate is 0.000200
max inferred z is 4.07, min inferred z is -3.82, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 151: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.626781, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.613081, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 7.912083, min gradient is -8.000000, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.519228, learning rate is 0.000400
Net2: layer deconv3:max response is 76.614037, min response is -56.599052.
max gradient is 8.000000, min gradient is -3.912858, learning rate is 0.000200
Net2: layer bn50:max response is 19.437790, min response is -3.500756.
max gradient is 6.348888, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.322265, learning rate is 0.000200
Net2: layer bn49:max response is 17.186777, min response is -4.243541.
max gradient is 8.000000, min gradient is -5.900312, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.158044, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.07, min inferred z is -3.56, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
Loss: 1.0956
Iteration 152 / 200
training: epoch 152: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.885399, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.183918, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.460401, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.087494, learning rate is 0.000400
Net2: layer deconv3:max response is 113.725800, min response is -81.551430.
max gradient is 6.054770, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 27.702579, min response is -4.230850.
max gradient is 8.000000, min gradient is -5.724560, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.465896, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 25.381084, min response is -3.970709.
max gradient is 6.680260, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.891870, learning rate is 0.000200
max inferred z is 3.59, min inferred z is -3.47, and std is 1.01
 4.15 s (24.1 data/s) [100/100]
training: epoch 152: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.817695, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.249769, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.319586, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.352113, learning rate is 0.000400
Net2: layer deconv3:max response is 97.767868, min response is -72.035088.
max gradient is 6.272366, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 24.195086, min response is -4.061288.
max gradient is 8.000000, min gradient is -7.292004, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.838102, learning rate is 0.000200
Net2: layer bn49:max response is 22.174627, min response is -3.816235.
max gradient is 8.000000, min gradient is -5.633731, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.141954, learning rate is 0.000200
max inferred z is 4.15, min inferred z is -4.04, and std is 1.01
 4.22 s (23.7 data/s) [100/100]
training: epoch 152: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.514786, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.285565, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.306628, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.578824, learning rate is 0.000400
Net2: layer deconv3:max response is 87.691048, min response is -66.000839.
max gradient is 6.604455, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.883430, min response is -3.580702.
max gradient is 8.000000, min gradient is -7.285079, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.600978, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.222900, min response is -4.459329.
max gradient is 7.773781, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.792078, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.84, min inferred z is -3.89, and std is 1.01
 4.20 s (23.8 data/s) [100/100]
training: epoch 152: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.780645, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.084746, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.896249, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 4.927472, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 85.007614, min response is -64.622765.
max gradient is 8.000000, min gradient is -3.490749, learning rate is 0.000200
Net2: layer bn50:max response is 21.065645, min response is -3.186607.
max gradient is 6.033420, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.578490, learning rate is 0.000200
Net2: layer bn49:max response is 19.351257, min response is -3.610262.
max gradient is 7.805006, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.544504, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.08, min inferred z is -4.18, and std is 1.01
 4.20 s (23.8 data/s) [100/100]
training: epoch 152: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.543169, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.367470, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.571576, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.286323, learning rate is 0.000400
Net2: layer deconv3:max response is 81.157898, min response is -61.300369.
max gradient is 2.377440, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.670641, min response is -3.614756.
max gradient is 8.000001, min gradient is -5.628542, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.206631, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.724669, min response is -4.204160.
max gradient is 8.000000, min gradient is -5.500770, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.739289, learning rate is 0.000200
max inferred z is 3.77, min inferred z is -4.08, and std is 1.01
 4.18 s (23.9 data/s) [100/100]
training: epoch 152: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.913091, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.361997, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.582061, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.918856, learning rate is 0.000400
Net2: layer deconv3:max response is 86.592926, min response is -64.151817.
max gradient is 8.000000, min gradient is -4.914663, learning rate is 0.000200
Net2: layer bn50:max response is 21.374401, min response is -3.253819.
max gradient is 6.993189, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.434394, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.879585, min response is -3.697451.
max gradient is 7.543320, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.634543, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.25, min inferred z is -4.21, and std is 1.01
 4.39 s (22.8 data/s) [100/100]
training: epoch 152: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.322234, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.174348, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.377656, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.970875, learning rate is 0.000400
Net2: layer deconv3:max response is 83.389183, min response is -60.837128.
max gradient is 2.389485, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.675232, min response is -3.368235.
max gradient is 8.000000, min gradient is -7.076663, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.981294, learning rate is 0.000200
Net2: layer bn49:max response is 18.408146, min response is -3.882034.
max gradient is 8.000000, min gradient is -6.367194, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.850580, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.05, min inferred z is -3.96, and std is 1.01
 4.28 s (23.4 data/s) [100/100]
training: epoch 152: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.510504, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.511022, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.990938, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.908336, learning rate is 0.000400
Net2: layer deconv3:max response is 99.969864, min response is -74.611687.
max gradient is 8.000000, min gradient is -1.939450, learning rate is 0.000200
Net2: layer bn50:max response is 24.035973, min response is -3.693637.
max gradient is 4.637423, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.707288, learning rate is 0.000200
Net2: layer bn49:max response is 22.414059, min response is -3.748317.
max gradient is 6.532441, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.707211, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.15, min inferred z is -4.01, and std is 1.01
 4.38 s (22.8 data/s) [100/100]
training: epoch 152: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.663682, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.184946, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.261698, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.031072, learning rate is 0.000400
Net2: layer deconv3:max response is 83.288567, min response is -58.585648.
max gradient is 4.119818, min gradient is -8.000001, learning rate is 0.000200
Net2: layer bn50:max response is 20.685247, min response is -3.345982.
max gradient is 8.000000, min gradient is -6.866383, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.144659, learning rate is 0.000200
Net2: layer bn49:max response is 19.060843, min response is -3.995650.
max gradient is 7.226624, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.253190, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.18, min inferred z is -3.97, and std is 1.01
 4.34 s (23.1 data/s) [100/100]
training: epoch 152: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.780543, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv2:max response is , min response is .
max gradient is 4.537263, min gradient is -8.000000, learning rate is 0.000002
Net1: layer conv1:max response is , min response is .
max gradient is 7.972980, min gradient is -8.000000, learning rate is 0.000002
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.691625, learning rate is 0.000400
Net2: layer deconv3:max response is 89.627174, min response is -67.268661.
max gradient is 8.000000, min gradient is -4.617340, learning rate is 0.000200
Net2: layer bn50:max response is 21.303707, min response is -3.206392.
max gradient is 5.298100, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.745554, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.989227, min response is -3.523358.
max gradient is 7.496491, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.074379, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.33, min inferred z is -4.31, and std is 1.01
 4.22 s (23.7 data/s) [100/100]
Loss: 1.1148
Iteration 153 / 200
training: epoch 153: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.832119, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.222830, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.380304, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.928332, learning rate is 0.000400
Net2: layer deconv3:max response is 99.926155, min response is -73.223213.
max gradient is 1.852342, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 24.072809, min response is -4.011687.
max gradient is 8.000000, min gradient is -5.900612, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.534615, learning rate is 0.000200
Net2: layer bn49:max response is 22.322231, min response is -4.105150.
max gradient is 8.000000, min gradient is -6.792936, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.813261, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.21, min inferred z is -3.83, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 153: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.759464, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.410781, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.531293, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.085013, learning rate is 0.000400
Net2: layer deconv3:max response is 93.891136, min response is -70.222046.
max gradient is 8.000000, min gradient is -1.895372, learning rate is 0.000200
Net2: layer bn50:max response is 22.656477, min response is -3.463017.
max gradient is 6.115054, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.626721, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.084311, min response is -3.730467.
max gradient is 5.818714, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.081198, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.08, min inferred z is -4.04, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 153: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.605411, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.212010, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.286682, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.057979, learning rate is 0.000400
Net2: layer deconv3:max response is 86.694481, min response is -64.141029.
max gradient is 1.464630, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.901876, min response is -3.784291.
max gradient is 8.000000, min gradient is -5.845507, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.292065, learning rate is 0.000200
Net2: layer bn49:max response is 19.350874, min response is -3.589090.
max gradient is 8.000000, min gradient is -6.922258, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.229908, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.90, min inferred z is -3.81, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 153: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.856320, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.121778, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.425662, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.938886, learning rate is 0.000400
Net2: layer deconv3:max response is 117.209557, min response is -86.609314.
max gradient is 8.000000, min gradient is -1.766965, learning rate is 0.000200
Net2: layer bn50:max response is 28.622944, min response is -4.318361.
max gradient is 5.825499, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.088126, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 26.555708, min response is -4.070236.
max gradient is 5.992666, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.528525, learning rate is 0.000200
max inferred z is 4.12, min inferred z is -4.41, and std is 1.00
 4.28 s (23.4 data/s) [100/100]
training: epoch 153: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.876925, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.088714, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.322015, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.958535, learning rate is 0.000400
Net2: layer deconv3:max response is 91.016556, min response is -64.009262.
max gradient is 1.754651, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.497610, min response is -4.266323.
max gradient is 8.000000, min gradient is -5.675117, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.738491, learning rate is 0.000200
Net2: layer bn49:max response is 20.309715, min response is -4.927727.
max gradient is 8.000000, min gradient is -7.331329, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.897213, learning rate is 0.000200
max inferred z is 4.09, min inferred z is -3.99, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 153: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.871612, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.597655, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.859465, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.421008, learning rate is 0.000400
Net2: layer deconv3:max response is 72.194168, min response is -53.283371.
max gradient is 8.000000, min gradient is -2.649547, learning rate is 0.000200
Net2: layer bn50:max response is 19.048729, min response is -3.011514.
max gradient is 4.604120, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.296103, learning rate is 0.000200
Net2: layer bn49:max response is 16.227478, min response is -3.436459.
max gradient is 8.000000, min gradient is -7.597136, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.847363, learning rate is 0.000200
max inferred z is 3.86, min inferred z is -4.12, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 153: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.226314, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.167185, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.383224, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.837295, learning rate is 0.000400
Net2: layer deconv3:max response is 99.915741, min response is -73.008698.
max gradient is 2.615774, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 24.564285, min response is -3.683167.
max gradient is 8.000000, min gradient is -6.444759, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.777760, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 22.496176, min response is -3.862965.
max gradient is 8.000000, min gradient is -7.643927, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.618647, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.98, min inferred z is -4.10, and std is 1.00
 4.41 s (22.7 data/s) [100/100]
training: epoch 153: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.525756, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.791287, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 7.983600, min gradient is -8.000000, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.989498, learning rate is 0.000400
Net2: layer deconv3:max response is 85.972870, min response is -64.900482.
max gradient is 8.000001, min gradient is -3.878062, learning rate is 0.000200
Net2: layer bn50:max response is 21.395267, min response is -3.919913.
max gradient is 5.646960, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.601069, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.903463, min response is -4.406544.
max gradient is 8.000000, min gradient is -7.844503, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.450858, learning rate is 0.000200
max inferred z is 3.84, min inferred z is -4.58, and std is 1.00
 4.45 s (22.5 data/s) [100/100]
training: epoch 153: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.834564, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.245549, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.179852, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.410874, learning rate is 0.000400
Net2: layer deconv3:max response is 86.747215, min response is -62.255402.
max gradient is 4.533859, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.980093, min response is -3.280581.
max gradient is 8.000000, min gradient is -5.670367, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.972855, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.441542, min response is -3.753212.
max gradient is 7.473979, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.010325, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.03, min inferred z is -3.86, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 153: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.910730, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.567981, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.692353, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.531906, learning rate is 0.000400
Net2: layer deconv3:max response is 91.053017, min response is -67.312981.
max gradient is 8.000000, min gradient is -4.684517, learning rate is 0.000200
Net2: layer bn50:max response is 21.352255, min response is -3.278545.
max gradient is 5.039701, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.952588, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.133511, min response is -3.682074.
max gradient is 8.000000, min gradient is -6.100079, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.716920, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.51, min inferred z is -4.34, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
Loss: 1.1069
Iteration 154 / 200
training: epoch 154: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.901692, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.140676, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.306990, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.537944, learning rate is 0.000400
Net2: layer deconv3:max response is 123.619560, min response is -88.488113.
max gradient is 3.236071, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 29.368589, min response is -4.352870.
max gradient is 8.000000, min gradient is -7.156813, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.326756, learning rate is 0.000200
Net2: layer bn49:max response is 27.184074, min response is -3.883535.
max gradient is 7.567693, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 4.584858, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.96, min inferred z is -3.68, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 154: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.884554, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.365807, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.359767, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.882370, learning rate is 0.000400
Net2: layer deconv3:max response is 83.620560, min response is -62.206264.
max gradient is 8.000000, min gradient is -1.415253, learning rate is 0.000200
Net2: layer bn50:max response is 20.314497, min response is -3.411376.
max gradient is 5.084264, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.223829, learning rate is 0.000200
Net2: layer bn49:max response is 18.887520, min response is -3.998366.
max gradient is 6.466549, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.383756, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.97, min inferred z is -3.66, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 154: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.695657, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.144643, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.189761, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.647109, learning rate is 0.000400
Net2: layer deconv3:max response is 84.024597, min response is -60.664314.
max gradient is 2.113050, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.786444, min response is -3.549110.
max gradient is 8.000000, min gradient is -5.827365, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.745597, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.632120, min response is -4.114015.
max gradient is 8.000000, min gradient is -7.260700, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.807189, learning rate is 0.000200
max inferred z is 3.85, min inferred z is -3.91, and std is 1.00
 4.14 s (24.1 data/s) [100/100]
training: epoch 154: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.721437, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.295639, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.443402, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.234782, learning rate is 0.000400
Net2: layer deconv3:max response is 85.211128, min response is -64.355927.
max gradient is 8.000000, min gradient is -2.335127, learning rate is 0.000200
Net2: layer bn50:max response is 20.959566, min response is -3.675112.
max gradient is 7.670310, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.754054, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.339565, min response is -4.120759.
max gradient is 8.000000, min gradient is -7.963605, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.509721, learning rate is 0.000200
max inferred z is 3.78, min inferred z is -3.76, and std is 1.00
 4.45 s (22.5 data/s) [100/100]
training: epoch 154: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.005978, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.228165, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.217386, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.469303, learning rate is 0.000400
Net2: layer deconv3:max response is 100.416222, min response is -73.007744.
max gradient is 4.976863, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.954170, min response is -3.648730.
max gradient is 8.000000, min gradient is -5.325561, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.860349, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 22.278801, min response is -3.752622.
max gradient is 8.000000, min gradient is -6.919121, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.348149, learning rate is 0.000200
max inferred z is 3.63, min inferred z is -3.63, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 154: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.934550, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.569188, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.554007, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.362600, learning rate is 0.000400
Net2: layer deconv3:max response is 85.869263, min response is -63.589977.
max gradient is 6.507331, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.642345, min response is -3.455737.
max gradient is 5.559815, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.906313, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.237637, min response is -3.874868.
max gradient is 5.727211, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.779673, learning rate is 0.000200
max inferred z is 3.82, min inferred z is -4.61, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 154: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.226476, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.500183, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.503729, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.247019, learning rate is 0.000400
Net2: layer deconv3:max response is 79.992844, min response is -65.218086.
max gradient is 7.481513, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.734314, min response is -3.828583.
max gradient is 7.872821, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.665361, learning rate is 0.000200
Net2: layer bn49:max response is 18.722521, min response is -4.562664.
max gradient is 8.000001, min gradient is -6.055781, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.616044, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.32, min inferred z is -3.84, and std is 1.00
 4.41 s (22.7 data/s) [100/100]
training: epoch 154: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.625740, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.701908, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.966517, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.335871, learning rate is 0.000400
Net2: layer deconv3:max response is 98.608566, min response is -75.326393.
max gradient is 8.000000, min gradient is -3.860684, learning rate is 0.000200
Net2: layer bn50:max response is 24.091829, min response is -4.012026.
max gradient is 7.026695, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.588844, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 22.730345, min response is -3.935479.
max gradient is 7.269430, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.876845, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.04, min inferred z is -3.88, and std is 1.00
 4.21 s (23.8 data/s) [100/100]
training: epoch 154: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.829843, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.313633, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.099996, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.242661, learning rate is 0.000400
Net2: layer deconv3:max response is 96.622978, min response is -71.252426.
max gradient is 2.589993, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.403612, min response is -3.620291.
max gradient is 8.000000, min gradient is -7.474049, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.019739, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.213947, min response is -3.784858.
max gradient is 6.653660, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.764227, learning rate is 0.000200
max inferred z is 3.62, min inferred z is -4.28, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 154: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.721079, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.643366, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.827788, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.861066, learning rate is 0.000400
Net2: layer deconv3:max response is 95.327682, min response is -69.069908.
max gradient is 8.000000, min gradient is -4.012327, learning rate is 0.000200
Net2: layer bn50:max response is 22.573227, min response is -3.330805.
max gradient is 8.000000, min gradient is -6.784568, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.391791, learning rate is 0.000200
Net2: layer bn49:max response is 21.000780, min response is -4.057352.
max gradient is 8.000000, min gradient is -7.706649, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.696225, learning rate is 0.000200
max inferred z is 3.85, min inferred z is -4.32, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
Loss: 1.1312
Iteration 155 / 200
training: epoch 155: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.898549, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.237022, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.451810, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.102530, learning rate is 0.000400
Net2: layer deconv3:max response is 81.897903, min response is -60.307129.
max gradient is 3.448340, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.075367, min response is -3.622004.
max gradient is 7.776312, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.330904, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.065439, min response is -4.492582.
max gradient is 7.638671, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.882059, learning rate is 0.000200
max inferred z is 3.98, min inferred z is -4.34, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 155: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.807986, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.485929, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.327209, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.674125, learning rate is 0.000400
Net2: layer deconv3:max response is 88.301842, min response is -63.796200.
max gradient is 8.000000, min gradient is -3.336819, learning rate is 0.000200
Net2: layer bn50:max response is 21.274391, min response is -3.706596.
max gradient is 7.272891, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.833185, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.597086, min response is -3.596594.
max gradient is 8.000000, min gradient is -7.522169, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.969218, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.90, min inferred z is -3.80, and std is 1.00
 4.17 s (24.0 data/s) [100/100]
training: epoch 155: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.709388, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.322492, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.946399, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.206973, learning rate is 0.000400
Net2: layer deconv3:max response is 104.161575, min response is -78.454010.
max gradient is 4.431363, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 24.741274, min response is -3.787700.
max gradient is 8.000000, min gradient is -5.611756, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.428638, learning rate is 0.000200
Net2: layer bn49:max response is 23.230587, min response is -3.826872.
max gradient is 7.410455, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.904488, learning rate is 0.000200
max inferred z is 4.04, min inferred z is -4.40, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 155: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.062894, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.193952, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.299186, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.182154, learning rate is 0.000400
Net2: layer deconv3:max response is 83.827438, min response is -62.445599.
max gradient is 8.000000, min gradient is -3.640869, learning rate is 0.000200
Net2: layer bn50:max response is 20.582857, min response is -3.777757.
max gradient is 5.053257, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.301838, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.748873, min response is -4.763741.
max gradient is 8.000000, min gradient is -7.223658, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.975039, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.81, min inferred z is -3.71, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 155: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.825970, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.149979, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.191539, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 3.038056, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 107.464447, min response is -76.772545.
max gradient is 2.558120, min gradient is -8.000001, learning rate is 0.000200
Net2: layer bn50:max response is 25.021923, min response is -3.708918.
max gradient is 8.000000, min gradient is -5.630999, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.279224, learning rate is 0.000200
Net2: layer bn49:max response is 23.386370, min response is -4.161886.
max gradient is 8.000000, min gradient is -7.514203, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.479602, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.94, min inferred z is -3.96, and std is 1.00
 4.22 s (23.7 data/s) [100/100]
training: epoch 155: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.125111, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.377478, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.470197, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.441863, learning rate is 0.000400
Net2: layer deconv3:max response is 85.788834, min response is -62.550564.
max gradient is 8.000001, min gradient is -4.054996, learning rate is 0.000200
Net2: layer bn50:max response is 19.978987, min response is -3.714394.
max gradient is 6.897819, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.353293, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.253025, min response is -3.535237.
max gradient is 7.464930, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.761189, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.56, min inferred z is -3.91, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 155: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.250399, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.342277, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.456005, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.372651, learning rate is 0.000400
Net2: layer deconv3:max response is 126.803841, min response is -93.065331.
max gradient is 3.326293, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 29.485104, min response is -4.740587.
max gradient is 8.000000, min gradient is -7.211918, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.413023, learning rate is 0.000200
Net2: layer bn49:max response is 27.930607, min response is -3.847290.
max gradient is 8.000000, min gradient is -6.880331, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.368531, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.28, min inferred z is -3.77, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 155: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.460957, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.548452, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.754779, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.873328, learning rate is 0.000400
Net2: layer deconv3:max response is 100.866234, min response is -73.191490.
max gradient is 8.000000, min gradient is -5.012774, learning rate is 0.000200
Net2: layer bn50:max response is 24.090307, min response is -3.796648.
max gradient is 7.001092, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.652785, learning rate is 0.000200
Net2: layer bn49:max response is 22.535007, min response is -3.942431.
max gradient is 8.000000, min gradient is -7.878890, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.568770, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.59, min inferred z is -3.78, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 155: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.826148, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.355268, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.189702, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.313110, learning rate is 0.000400
Net2: layer deconv3:max response is 87.967819, min response is -66.305496.
max gradient is 6.792623, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.813940, min response is -3.484316.
max gradient is 7.552782, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 4.894496, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.754196, min response is -3.729987.
max gradient is 8.000000, min gradient is -7.697725, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.342991, learning rate is 0.000200
max inferred z is 3.64, min inferred z is -4.42, and std is 1.00
 4.41 s (22.7 data/s) [100/100]
training: epoch 155: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.723942, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.630868, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.648342, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.128307, learning rate is 0.000400
Net2: layer deconv3:max response is 92.204491, min response is -64.835014.
max gradient is 3.450814, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.955425, min response is -3.711065.
max gradient is 8.000000, min gradient is -5.157744, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.269101, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.819769, min response is -3.644515.
max gradient is 8.000000, min gradient is -5.988869, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.370362, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.47, min inferred z is -4.10, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
Loss: 1.2052
Iteration 156 / 200
training: epoch 156: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.139763, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.312005, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.687301, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.979195, learning rate is 0.000400
Net2: layer deconv3:max response is 100.441956, min response is -75.050377.
max gradient is 8.000000, min gradient is -3.423603, learning rate is 0.000200
Net2: layer bn50:max response is 23.637859, min response is -3.525974.
max gradient is 5.526778, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.848871, learning rate is 0.000200
Net2: layer bn49:max response is 22.337212, min response is -4.102182.
max gradient is 7.855092, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.396657, learning rate is 0.000200
max inferred z is 3.75, min inferred z is -4.11, and std is 0.99
 4.32 s (23.1 data/s) [100/100]
training: epoch 156: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.863003, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.256471, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.094803, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.774931, learning rate is 0.000400
Net2: layer deconv3:max response is 76.498199, min response is -56.044579.
max gradient is 3.837027, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.628483, min response is -3.312679.
max gradient is 8.000000, min gradient is -6.146141, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.270727, learning rate is 0.000200
Net2: layer bn49:max response is 16.826904, min response is -3.808403.
max gradient is 5.850123, min gradient is -8.000001, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.610264, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.02, min inferred z is -3.79, and std is 0.99
 4.35 s (23.0 data/s) [100/100]
training: epoch 156: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.707475, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.472731, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.140702, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.266162, learning rate is 0.000400
Net2: layer deconv3:max response is 94.333443, min response is -69.070068.
max gradient is 8.000000, min gradient is -5.460866, learning rate is 0.000200
Net2: layer bn50:max response is 22.523342, min response is -3.502874.
max gradient is 4.598634, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.184061, learning rate is 0.000200
Net2: layer bn49:max response is 21.413860, min response is -3.961763.
max gradient is 8.000000, min gradient is -5.064454, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.926197, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.95, min inferred z is -3.60, and std is 0.99
 4.20 s (23.8 data/s) [100/100]
training: epoch 156: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.616225, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.131241, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.286084, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.882199, learning rate is 0.000400
Net2: layer deconv3:max response is 95.611465, min response is -70.231262.
max gradient is 4.767612, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.213776, min response is -3.447773.
max gradient is 8.000000, min gradient is -6.963943, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.609363, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.132530, min response is -3.852049.
max gradient is 6.108651, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.132847, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.89, min inferred z is -3.83, and std is 0.99
 4.36 s (23.0 data/s) [100/100]
training: epoch 156: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.286380, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.063894, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.216744, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.321387, learning rate is 0.000400
Net2: layer deconv3:max response is 104.357895, min response is -75.842171.
max gradient is 7.141821, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.850897, min response is -3.727721.
max gradient is 4.840682, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.595001, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 22.838387, min response is -4.507038.
max gradient is 8.000000, min gradient is -6.485148, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.754395, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.81, min inferred z is -4.14, and std is 0.99
 4.21 s (23.7 data/s) [100/100]
training: epoch 156: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.062723, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.323977, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.344239, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -2.808032, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 95.193825, min response is -67.832649.
max gradient is 3.561708, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.171160, min response is -3.877964.
max gradient is 8.000000, min gradient is -5.610380, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.378428, learning rate is 0.000200
Net2: layer bn49:max response is 20.781385, min response is -4.217368.
max gradient is 8.000000, min gradient is -6.871924, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.162443, learning rate is 0.000200
max inferred z is 4.04, min inferred z is -3.89, and std is 0.99
 4.36 s (22.9 data/s) [100/100]
training: epoch 156: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.353604, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.275991, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.306068, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.350810, learning rate is 0.000400
Net2: layer deconv3:max response is 89.567169, min response is -64.477219.
max gradient is 8.000000, min gradient is -6.494142, learning rate is 0.000200
Net2: layer bn50:max response is 21.011673, min response is -3.386601.
max gradient is 4.427949, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.732344, learning rate is 0.000200
Net2: layer bn49:max response is 20.012997, min response is -4.070101.
max gradient is 8.000000, min gradient is -7.746497, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.975380, learning rate is 0.000200
max inferred z is 3.70, min inferred z is -4.17, and std is 0.99
 4.33 s (23.1 data/s) [100/100]
training: epoch 156: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.997912, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.493504, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.480067, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.209618, learning rate is 0.000400
Net2: layer deconv3:max response is 89.215477, min response is -69.969368.
max gradient is 6.529241, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.161972, min response is -4.003076.
max gradient is 8.000000, min gradient is -5.136538, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.498741, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.302732, min response is -4.015300.
max gradient is 8.000000, min gradient is -5.751942, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.158006, learning rate is 0.000200
max inferred z is 3.83, min inferred z is -4.05, and std is 0.99
 4.35 s (23.0 data/s) [100/100]
training: epoch 156: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.803473, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.227901, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.077535, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.287553, learning rate is 0.000400
Net2: layer deconv3:max response is 91.262802, min response is -63.884674.
max gradient is 4.304653, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.423683, min response is -3.447657.
max gradient is 8.000000, min gradient is -5.434006, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.377087, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.348045, min response is -4.029423.
max gradient is 8.000000, min gradient is -7.836298, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.814712, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.43, min inferred z is -3.82, and std is 0.99
 4.26 s (23.4 data/s) [100/100]
training: epoch 156: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.648481, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.684384, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.720322, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.846156, learning rate is 0.000400
Net2: layer deconv3:max response is 102.395721, min response is -75.924210.
max gradient is 8.000000, min gradient is -4.943256, learning rate is 0.000200
Net2: layer bn50:max response is 24.244497, min response is -3.659160.
max gradient is 6.361383, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.745797, learning rate is 0.000200
Net2: layer bn49:max response is 22.943209, min response is -4.309455.
max gradient is 7.030692, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.989940, learning rate is 0.000200
max inferred z is 4.44, min inferred z is -4.05, and std is 0.99
 4.29 s (23.3 data/s) [100/100]
Loss: 1.1198
Iteration 157 / 200
training: epoch 157: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.037579, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.378847, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.374342, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.038631, learning rate is 0.000400
Net2: layer deconv3:max response is 89.793053, min response is -66.259598.
max gradient is 4.665697, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.334784, min response is -3.728863.
max gradient is 8.000000, min gradient is -7.301033, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.330576, learning rate is 0.000200
Net2: layer bn49:max response is 19.931711, min response is -4.412741.
max gradient is 8.000000, min gradient is -5.683290, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.589069, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.68, min inferred z is -4.16, and std is 1.00
 4.16 s (24.1 data/s) [100/100]
training: epoch 157: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.748137, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.423891, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.377831, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.231710, learning rate is 0.000400
Net2: layer deconv3:max response is 108.732841, min response is -79.922981.
max gradient is 8.000000, min gradient is -4.471685, learning rate is 0.000200
Net2: layer bn50:max response is 25.255987, min response is -3.760836.
max gradient is 8.000000, min gradient is -6.612281, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 4.471343, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 24.343111, min response is -3.721647.
max gradient is 6.840891, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.990588, learning rate is 0.000200
max inferred z is 3.82, min inferred z is -4.36, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 157: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.721300, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.377389, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.061475, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.351271, learning rate is 0.000400
Net2: layer deconv3:max response is 132.519821, min response is -100.038193.
max gradient is 5.147173, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 30.650543, min response is -4.616592.
max gradient is 7.600161, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.515620, learning rate is 0.000200
Net2: layer bn49:max response is 29.418348, min response is -4.690710.
max gradient is 8.000000, min gradient is -6.576705, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.055947, learning rate is 0.000200
max inferred z is 4.27, min inferred z is -3.80, and std is 1.00
 4.18 s (23.9 data/s) [100/100]
training: epoch 157: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.016530, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.163456, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.214742, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.374036, learning rate is 0.000400
Net2: layer deconv3:max response is 90.402176, min response is -68.546814.
max gradient is 8.000000, min gradient is -3.881568, learning rate is 0.000200
Net2: layer bn50:max response is 21.020710, min response is -3.292984.
max gradient is 7.543687, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.935917, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.317894, min response is -3.420521.
max gradient is 4.541539, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.982908, learning rate is 0.000200
max inferred z is 3.97, min inferred z is -4.02, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 157: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.122750, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.095827, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.250266, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.297221, learning rate is 0.000400
Net2: layer deconv3:max response is 91.000595, min response is -65.703766.
max gradient is 1.722402, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.421289, min response is -4.443355.
max gradient is 8.000000, min gradient is -6.714668, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.009561, learning rate is 0.000200
Net2: layer bn49:max response is 19.663874, min response is -3.966508.
max gradient is 8.000000, min gradient is -6.929869, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.363007, learning rate is 0.000200
max inferred z is 3.97, min inferred z is -4.21, and std is 1.00
 4.17 s (24.0 data/s) [100/100]
training: epoch 157: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.905038, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.601556, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.553459, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.164309, learning rate is 0.000400
Net2: layer deconv3:max response is 104.825897, min response is -77.499886.
max gradient is 8.000000, min gradient is -2.426354, learning rate is 0.000200
Net2: layer bn50:max response is 24.240114, min response is -3.564663.
max gradient is 7.889085, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.120625, learning rate is 0.000200
Net2: layer bn49:max response is 23.453209, min response is -3.560685.
max gradient is 7.594437, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.477820, learning rate is 0.000200
max inferred z is 4.06, min inferred z is -3.56, and std is 1.00
 4.16 s (24.0 data/s) [100/100]
training: epoch 157: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.481367, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.338008, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.437172, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.733233, learning rate is 0.000400
Net2: layer deconv3:max response is 82.121964, min response is -67.208435.
max gradient is 6.460286, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 24.550655, min response is -4.091482.
max gradient is 5.466136, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.511323, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.152020, min response is -4.885028.
max gradient is 8.000000, min gradient is -7.508179, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.884298, learning rate is 0.000200
max inferred z is 4.38, min inferred z is -4.21, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
training: epoch 157: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.619203, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.450610, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.352839, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.009097, learning rate is 0.000400
Net2: layer deconv3:max response is 115.897163, min response is -83.092941.
max gradient is 2.857764, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 26.566290, min response is -4.030428.
max gradient is 8.000000, min gradient is -5.725035, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.545594, learning rate is 0.000200
Net2: layer bn49:max response is 25.490067, min response is -3.799633.
max gradient is 8.000000, min gradient is -4.996502, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.347506, learning rate is 0.000200
max inferred z is 4.55, min inferred z is -4.35, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 157: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.889308, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.319715, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.630788, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.615651, learning rate is 0.000400
Net2: layer deconv3:max response is 83.449661, min response is -61.206692.
max gradient is 8.000001, min gradient is -1.759600, learning rate is 0.000200
Net2: layer bn50:max response is 19.814009, min response is -3.634860.
max gradient is 5.082873, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.426585, learning rate is 0.000200
Net2: layer bn49:max response is 18.900537, min response is -4.101052.
max gradient is 5.730150, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.884652, learning rate is 0.000200
max inferred z is 3.99, min inferred z is -4.37, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 157: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.727522, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.338349, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.566903, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.753309, learning rate is 0.000400
Net2: layer deconv3:max response is 87.687218, min response is -62.659657.
max gradient is 2.833024, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.308414, min response is -3.149587.
max gradient is 8.000000, min gradient is -6.309089, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.717630, learning rate is 0.000200
Net2: layer bn49:max response is 19.541538, min response is -3.822217.
max gradient is 8.000000, min gradient is -6.555401, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.541463, learning rate is 0.000200
max inferred z is 3.96, min inferred z is -3.90, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
Loss: 1.0444
Iteration 158 / 200
training: epoch 158: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.184712, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.388628, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.382690, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.583329, learning rate is 0.000400
Net2: layer deconv3:max response is 98.529587, min response is -69.846497.
max gradient is 8.000000, min gradient is -4.452519, learning rate is 0.000200
Net2: layer bn50:max response is 23.311945, min response is -4.417286.
max gradient is 8.000000, min gradient is -7.237205, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.604089, learning rate is 0.000200
Net2: layer bn49:max response is 22.196310, min response is -4.066240.
max gradient is 4.165579, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.936316, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.47, min inferred z is -3.96, and std is 1.00
 4.14 s (24.1 data/s) [100/100]
training: epoch 158: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.865247, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.596959, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.363124, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.711648, learning rate is 0.000400
Net2: layer deconv3:max response is 87.809837, min response is -69.136116.
max gradient is 3.814033, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 24.926117, min response is -4.243074.
max gradient is 7.121556, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.131382, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.649069, min response is -4.365118.
max gradient is 6.699862, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 4.190853, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.78, min inferred z is -3.90, and std is 1.00
 4.22 s (23.7 data/s) [100/100]
training: epoch 158: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.811146, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.276360, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.887483, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.795734, learning rate is 0.000400
Net2: layer deconv3:max response is 115.672867, min response is -85.760757.
max gradient is 8.000000, min gradient is -5.102493, learning rate is 0.000200
Net2: layer bn50:max response is 26.409065, min response is -4.014682.
max gradient is 8.000000, min gradient is -6.967557, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.913120, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 25.618153, min response is -3.843386.
max gradient is 8.000000, min gradient is -6.382692, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.892701, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.42, min inferred z is -4.23, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 158: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.922230, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.154203, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.068758, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.721533, learning rate is 0.000400
Net2: layer deconv3:max response is 99.404526, min response is -74.166183.
max gradient is 3.108397, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.701214, min response is -3.384787.
max gradient is 8.000000, min gradient is -5.877420, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.879336, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 22.112944, min response is -4.060547.
max gradient is 8.000000, min gradient is -7.621300, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.491684, learning rate is 0.000200
max inferred z is 3.97, min inferred z is -3.77, and std is 1.00
 4.45 s (22.5 data/s) [100/100]
training: epoch 158: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.881551, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.300518, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.335632, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.367441, learning rate is 0.000400
Net2: layer deconv3:max response is 84.187752, min response is -60.907867.
max gradient is 8.000000, min gradient is -3.249837, learning rate is 0.000200
Net2: layer bn50:max response is 19.430258, min response is -3.565635.
max gradient is 6.220507, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.513837, learning rate is 0.000200
Net2: layer bn49:max response is 18.623463, min response is -4.224561.
max gradient is 8.000000, min gradient is -7.192418, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.058214, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.03, min inferred z is -4.21, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 158: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.253116, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.441608, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.253606, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.301533, learning rate is 0.000400
Net2: layer deconv3:max response is 77.917824, min response is -56.381321.
max gradient is 4.120243, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.347527, min response is -3.717582.
max gradient is 8.000000, min gradient is -6.066563, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.015849, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.246977, min response is -4.346599.
max gradient is 8.000000, min gradient is -4.429483, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.862397, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.17, min inferred z is -3.67, and std is 1.00
 4.36 s (23.0 data/s) [100/100]
training: epoch 158: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.379195, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.348980, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.476150, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.601922, learning rate is 0.000400
Net2: layer deconv3:max response is 90.525101, min response is -67.739250.
max gradient is 8.000000, min gradient is -4.252403, learning rate is 0.000200
Net2: layer bn50:max response is 25.073030, min response is -3.770847.
max gradient is 5.387539, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.234226, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.106571, min response is -4.445713.
max gradient is 5.528534, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.086783, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.25, min inferred z is -3.96, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 158: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.603484, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.419754, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.016740, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.074744, learning rate is 0.000400
Net2: layer deconv3:max response is 88.429298, min response is -62.621422.
max gradient is 2.524222, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.971165, min response is -3.597426.
max gradient is 8.000000, min gradient is -6.504778, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.770376, learning rate is 0.000200
Net2: layer bn49:max response is 19.386745, min response is -3.732109.
max gradient is 8.000000, min gradient is -4.989903, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.001732, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.71, min inferred z is -4.52, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 158: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.743900, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.503518, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.513925, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.338589, learning rate is 0.000400
Net2: layer deconv3:max response is 91.107666, min response is -66.906876.
max gradient is 8.000000, min gradient is -1.697526, learning rate is 0.000200
Net2: layer bn50:max response is 20.997889, min response is -3.121185.
max gradient is 4.729993, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.389321, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.460579, min response is -3.906127.
max gradient is 8.000000, min gradient is -7.981662, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.739471, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.23, min inferred z is -3.85, and std is 1.00
 4.22 s (23.7 data/s) [100/100]
training: epoch 158: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.751564, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.508921, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.477885, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.413753, learning rate is 0.000400
Net2: layer deconv3:max response is 104.586327, min response is -76.655563.
max gradient is 2.360332, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.843508, min response is -3.561111.
max gradient is 8.000000, min gradient is -6.163564, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.892614, learning rate is 0.000200
Net2: layer bn49:max response is 22.896320, min response is -3.998796.
max gradient is 8.000000, min gradient is -7.154126, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.651205, learning rate is 0.000200
max inferred z is 4.55, min inferred z is -3.78, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
Loss: 1.0309
Iteration 159 / 200
training: epoch 159: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.930312, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.381167, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.224187, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.095415, learning rate is 0.000400
Net2: layer deconv3:max response is 89.019951, min response is -67.910149.
max gradient is 8.000000, min gradient is -2.938960, learning rate is 0.000200
Net2: layer bn50:max response is 20.897581, min response is -4.053758.
max gradient is 6.651466, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.847245, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.173548, min response is -4.259959.
max gradient is 8.000000, min gradient is -7.988535, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.670961, learning rate is 0.000200
max inferred z is 4.23, min inferred z is -4.09, and std is 0.99
 4.29 s (23.3 data/s) [100/100]
training: epoch 159: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.909487, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.281085, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.281455, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.876854, learning rate is 0.000400
Net2: layer deconv3:max response is 96.532158, min response is -70.453545.
max gradient is 3.425164, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.701811, min response is -3.293810.
max gradient is 8.000000, min gradient is -5.691704, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.096805, learning rate is 0.000200
Net2: layer bn49:max response is 21.153618, min response is -3.827214.
max gradient is 6.902261, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.405817, learning rate is 0.000200
max inferred z is 4.24, min inferred z is -4.59, and std is 0.99
 4.17 s (24.0 data/s) [100/100]
training: epoch 159: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.565895, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.542095, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.047920, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.507563, learning rate is 0.000400
Net2: layer deconv3:max response is 84.700233, min response is -61.514889.
max gradient is 8.000000, min gradient is -6.552537, learning rate is 0.000200
Net2: layer bn50:max response is 20.106678, min response is -3.745741.
max gradient is 3.024332, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.502725, learning rate is 0.000200
Net2: layer bn49:max response is 19.176111, min response is -3.771483.
max gradient is 6.837206, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.414857, min gradient is -8.000001, learning rate is 0.000200
max inferred z is 3.93, min inferred z is -4.20, and std is 0.99
 4.33 s (23.1 data/s) [100/100]
training: epoch 159: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.773787, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.390900, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.318527, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.138319, learning rate is 0.000400
Net2: layer deconv3:max response is 79.317696, min response is -60.346710.
max gradient is 7.413396, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.809509, min response is -3.327754.
max gradient is 7.739651, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 4.380997, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.065048, min response is -4.054348.
max gradient is 7.339009, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.649456, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.70, min inferred z is -3.84, and std is 0.99
 4.43 s (22.6 data/s) [100/100]
training: epoch 159: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.130497, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.135326, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.237995, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.866283, learning rate is 0.000400
Net2: layer deconv3:max response is 101.797638, min response is -73.523415.
max gradient is 6.281772, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.611576, min response is -4.226078.
max gradient is 8.000000, min gradient is -3.338166, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.573729, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 22.693298, min response is -4.325989.
max gradient is 7.567030, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.807738, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.86, min inferred z is -4.35, and std is 0.99
 4.36 s (22.9 data/s) [100/100]
training: epoch 159: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.960335, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.532136, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.512256, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.846185, learning rate is 0.000400
Net2: layer deconv3:max response is 84.480827, min response is -60.601170.
max gradient is 8.000000, min gradient is -7.729826, learning rate is 0.000200
Net2: layer bn50:max response is 20.740938, min response is -3.438000.
max gradient is 3.896349, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.236760, learning rate is 0.000200
Net2: layer bn49:max response is 18.733046, min response is -4.454062.
max gradient is 6.374931, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.309409, learning rate is 0.000200
max inferred z is 3.98, min inferred z is -3.76, and std is 0.99
 4.37 s (22.9 data/s) [100/100]
training: epoch 159: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.525298, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.287354, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.292471, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.150562, learning rate is 0.000400
Net2: layer deconv3:max response is 93.681816, min response is -70.637329.
max gradient is 8.000000, min gradient is -7.513596, learning rate is 0.000200
Net2: layer bn50:max response is 21.100056, min response is -3.633584.
max gradient is 8.000000, min gradient is -5.660820, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.525860, learning rate is 0.000200
Net2: layer bn49:max response is 20.718170, min response is -3.786699.
max gradient is 8.000000, min gradient is -7.032662, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.658403, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.70, min inferred z is -3.84, and std is 0.99
 4.23 s (23.6 data/s) [100/100]
training: epoch 159: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.657763, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.253137, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.175198, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.006451, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 103.148636, min response is -73.420677.
max gradient is 4.177862, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.356171, min response is -3.823402.
max gradient is 8.000000, min gradient is -6.851607, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.959374, learning rate is 0.000200
Net2: layer bn49:max response is 22.580318, min response is -3.917938.
max gradient is 8.000000, min gradient is -6.595906, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.774275, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.90, min inferred z is -4.31, and std is 0.99
 4.16 s (24.0 data/s) [100/100]
training: epoch 159: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.614732, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.454593, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.284832, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.359784, learning rate is 0.000400
Net2: layer deconv3:max response is 81.893402, min response is -62.882774.
max gradient is 7.012568, min gradient is -8.000001, learning rate is 0.000200
Net2: layer bn50:max response is 21.053413, min response is -3.684414.
max gradient is 4.407186, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.838706, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.391794, min response is -4.826272.
max gradient is 8.000000, min gradient is -7.538772, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.652460, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.12, min inferred z is -3.96, and std is 0.99
 4.27 s (23.4 data/s) [100/100]
training: epoch 159: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.704629, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 5.216153, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 7.885263, min gradient is -8.000000, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000001, min gradient is 6.089462, learning rate is 0.000400
Net2: layer deconv3:max response is 96.283852, min response is -72.549576.
max gradient is 7.601767, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.469791, min response is -4.022039.
max gradient is 8.000001, min gradient is -4.530136, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.474484, learning rate is 0.000200
Net2: layer bn49:max response is 21.989378, min response is -4.818912.
max gradient is 8.000000, min gradient is -5.882328, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.896726, learning rate is 0.000200
max inferred z is 4.24, min inferred z is -4.47, and std is 0.99
 4.31 s (23.2 data/s) [100/100]
Loss: 1.0785
Iteration 160 / 200
training: epoch 160: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.914745, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.412207, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.217194, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.736797, learning rate is 0.000400
Net2: layer deconv3:max response is 108.267540, min response is -78.926628.
max gradient is 6.310117, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 24.848948, min response is -3.811975.
max gradient is 8.000000, min gradient is -7.444827, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.996157, learning rate is 0.000200
Net2: layer bn49:max response is 24.163679, min response is -3.668326.
max gradient is 7.378752, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.546293, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.45, min inferred z is -3.95, and std is 1.00
 4.17 s (24.0 data/s) [100/100]
training: epoch 160: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.823258, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.335021, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.376005, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.605509, learning rate is 0.000400
Net2: layer deconv3:max response is 79.595116, min response is -60.645443.
max gradient is 6.581111, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.627077, min response is -3.612403.
max gradient is 5.937278, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.973606, learning rate is 0.000200
Net2: layer bn49:max response is 18.054272, min response is -4.241460.
max gradient is 7.090075, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.697984, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.49, min inferred z is -4.20, and std is 1.00
 4.18 s (23.9 data/s) [100/100]
training: epoch 160: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.737321, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.259560, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.047101, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.427480, learning rate is 0.000400
Net2: layer deconv3:max response is 128.333527, min response is -95.990883.
max gradient is 8.000000, min gradient is -6.635820, learning rate is 0.000200
Net2: layer bn50:max response is 29.353678, min response is -4.394824.
max gradient is 4.699342, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.049401, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 28.828400, min response is -3.844818.
max gradient is 7.944123, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.921038, learning rate is 0.000200
max inferred z is 4.13, min inferred z is -4.25, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 160: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.957603, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.247712, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.084939, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.237681, learning rate is 0.000400
Net2: layer deconv3:max response is 96.261787, min response is -72.682785.
max gradient is 3.989085, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.433765, min response is -3.748698.
max gradient is 8.000000, min gradient is -4.792724, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.149497, learning rate is 0.000200
Net2: layer bn49:max response is 21.434067, min response is -4.117391.
max gradient is 8.000000, min gradient is -6.395211, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.581401, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.02, min inferred z is -3.66, and std is 1.00
 4.36 s (23.0 data/s) [100/100]
training: epoch 160: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.970676, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.307254, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.215083, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.514925, learning rate is 0.000400
Net2: layer deconv3:max response is 87.431038, min response is -65.703705.
max gradient is 5.216910, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.386454, min response is -3.456894.
max gradient is 8.000001, min gradient is -5.382545, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.406937, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.369923, min response is -4.227871.
max gradient is 6.998658, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.892339, learning rate is 0.000200
max inferred z is 4.17, min inferred z is -3.76, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 160: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.828204, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.495312, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.414037, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000001, min gradient is 6.217132, learning rate is 0.000400
Net2: layer deconv3:max response is 106.163132, min response is -76.847542.
max gradient is 6.262248, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.739496, min response is -3.683122.
max gradient is 4.791189, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.512968, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 23.402020, min response is -3.825267.
max gradient is 8.000000, min gradient is -7.653699, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.514395, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.34, min inferred z is -3.77, and std is 1.00
 4.28 s (23.4 data/s) [100/100]
training: epoch 160: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.288570, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.393945, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.490201, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.651260, learning rate is 0.000400
Net2: layer deconv3:max response is 101.564766, min response is -75.573013.
max gradient is 8.000000, min gradient is -4.944855, learning rate is 0.000200
Net2: layer bn50:max response is 23.042919, min response is -3.402066.
max gradient is 5.093416, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.187696, min gradient is -8.000001, learning rate is 0.000200
Net2: layer bn49:max response is 22.578667, min response is -3.318955.
max gradient is 7.400575, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.448856, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.91, min inferred z is -4.33, and std is 1.00
 4.30 s (23.3 data/s) [100/100]
training: epoch 160: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.816173, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.554001, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.175337, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.267739, learning rate is 0.000400
Net2: layer deconv3:max response is 84.937828, min response is -66.622543.
max gradient is 4.840063, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.039555, min response is -3.947022.
max gradient is 8.000000, min gradient is -5.816700, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.164776, learning rate is 0.000200
Net2: layer bn49:max response is 18.922306, min response is -4.751536.
max gradient is 8.000000, min gradient is -5.047020, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.253284, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.94, min inferred z is -3.93, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
training: epoch 160: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.722592, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.582994, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.321612, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.848844, learning rate is 0.000400
Net2: layer deconv3:max response is 88.161911, min response is -64.293480.
max gradient is 5.348857, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.840544, min response is -4.192381.
max gradient is 8.000000, min gradient is -5.672941, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.679251, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.107365, min response is -3.887032.
max gradient is 8.000000, min gradient is -7.306075, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.838862, learning rate is 0.000200
max inferred z is 4.14, min inferred z is -3.79, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 160: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.732530, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.535736, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.698921, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.150268, learning rate is 0.000400
Net2: layer deconv3:max response is 93.335175, min response is -69.987045.
max gradient is 8.000000, min gradient is -5.918335, learning rate is 0.000200
Net2: layer bn50:max response is 21.005995, min response is -3.846318.
max gradient is 5.674553, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000001, min gradient is -7.734404, learning rate is 0.000200
Net2: layer bn49:max response is 20.850103, min response is -4.391240.
max gradient is 8.000000, min gradient is -7.087988, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.163307, min gradient is -8.000001, learning rate is 0.000200
max inferred z is 3.87, min inferred z is -3.66, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
Loss: 1.0532
Iteration 161 / 200
training: epoch 161: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.934282, min gradient is -8.000001, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.318577, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.184119, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.909616, learning rate is 0.000400
Net2: layer deconv3:max response is 81.548874, min response is -61.936722.
max gradient is 6.338902, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.280544, min response is -3.705441.
max gradient is 6.801984, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.460392, learning rate is 0.000200
Net2: layer bn49:max response is 18.408449, min response is -3.901811.
max gradient is 8.000000, min gradient is -6.954005, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.772305, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.23, min inferred z is -4.16, and std is 1.00
 4.21 s (23.7 data/s) [100/100]
training: epoch 161: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.937023, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.514441, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.420174, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.750499, learning rate is 0.000400
Net2: layer deconv3:max response is 100.395981, min response is -75.494476.
max gradient is 8.000000, min gradient is -5.549517, learning rate is 0.000200
Net2: layer bn50:max response is 22.875799, min response is -3.957954.
max gradient is 8.000000, min gradient is -6.974394, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.486072, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 22.775494, min response is -4.250866.
max gradient is 7.777347, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.160516, learning rate is 0.000200
max inferred z is 4.00, min inferred z is -3.88, and std is 1.00
 4.19 s (23.9 data/s) [100/100]
training: epoch 161: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.733434, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.229710, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.954553, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.408265, learning rate is 0.000400
Net2: layer deconv3:max response is 88.516487, min response is -65.189087.
max gradient is 2.157487, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.738150, min response is -3.383283.
max gradient is 8.000000, min gradient is -5.303417, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.756554, learning rate is 0.000200
Net2: layer bn49:max response is 19.738836, min response is -3.826779.
max gradient is 8.000000, min gradient is -6.051075, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.828668, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.64, min inferred z is -3.94, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 161: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.773791, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.381880, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.407767, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.525604, learning rate is 0.000400
Net2: layer deconv3:max response is 90.141853, min response is -66.736771.
max gradient is 8.000000, min gradient is -2.073501, learning rate is 0.000200
Net2: layer bn50:max response is 20.152191, min response is -3.416600.
max gradient is 5.979731, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.643271, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.928560, min response is -4.157066.
max gradient is 6.912324, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.089654, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.05, min inferred z is -3.51, and std is 1.00
 4.53 s (22.1 data/s) [100/100]
training: epoch 161: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.810242, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.163417, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.278571, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -2.283091, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 91.323349, min response is -66.465546.
max gradient is 2.389572, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.688082, min response is -3.967513.
max gradient is 8.000000, min gradient is -6.369568, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.407060, learning rate is 0.000200
Net2: layer bn49:max response is 20.560156, min response is -4.603275.
max gradient is 8.000000, min gradient is -7.248614, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.793139, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.59, min inferred z is -4.09, and std is 1.00
 4.36 s (23.0 data/s) [100/100]
training: epoch 161: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.168701, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.478224, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.622678, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.309394, learning rate is 0.000400
Net2: layer deconv3:max response is 90.963890, min response is -67.284538.
max gradient is 8.000000, min gradient is -1.824786, learning rate is 0.000200
Net2: layer bn50:max response is 22.449144, min response is -4.073490.
max gradient is 5.050817, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.314148, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.187855, min response is -4.482642.
max gradient is 5.976469, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.443592, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.48, min inferred z is -3.81, and std is 1.00
 4.18 s (23.9 data/s) [100/100]
training: epoch 161: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.390463, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.301545, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.303833, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.412966, learning rate is 0.000400
Net2: layer deconv3:max response is 75.423653, min response is -56.653503.
max gradient is 2.109255, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.565710, min response is -3.816498.
max gradient is 8.000000, min gradient is -5.442978, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.536500, learning rate is 0.000200
Net2: layer bn49:max response is 17.044197, min response is -4.050727.
max gradient is 8.000000, min gradient is -5.387913, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.865695, learning rate is 0.000200
max inferred z is 4.27, min inferred z is -4.07, and std is 1.00
 4.21 s (23.8 data/s) [100/100]
training: epoch 161: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.493783, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.693417, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.649420, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.304161, learning rate is 0.000400
Net2: layer deconv3:max response is 110.974648, min response is -82.766502.
max gradient is 8.000000, min gradient is -1.809432, learning rate is 0.000200
Net2: layer bn50:max response is 25.149588, min response is -4.165720.
max gradient is 5.267994, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.530607, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 24.829918, min response is -4.330316.
max gradient is 5.571923, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.420299, learning rate is 0.000200
max inferred z is 4.02, min inferred z is -3.91, and std is 1.00
 4.36 s (23.0 data/s) [100/100]
training: epoch 161: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.569558, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.335655, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.260350, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.428415, learning rate is 0.000400
Net2: layer deconv3:max response is 113.612099, min response is -82.185654.
max gradient is 1.877231, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 25.918308, min response is -3.843089.
max gradient is 8.000000, min gradient is -6.351258, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.816546, learning rate is 0.000200
Net2: layer bn49:max response is 25.377571, min response is -3.999388.
max gradient is 8.000000, min gradient is -5.252716, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.278816, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.11, min inferred z is -3.68, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 161: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.864619, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.698843, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 7.952980, min gradient is -8.000000, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.398690, learning rate is 0.000400
Net2: layer deconv3:max response is 108.216896, min response is -81.465622.
max gradient is 8.000000, min gradient is -2.551457, learning rate is 0.000200
Net2: layer bn50:max response is 24.223063, min response is -4.167351.
max gradient is 5.887010, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.778239, learning rate is 0.000200
Net2: layer bn49:max response is 24.274000, min response is -4.653758.
max gradient is 6.451756, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.158514, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.25, min inferred z is -3.82, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
Loss: 1.1005
Iteration 162 / 200
training: epoch 162: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.998224, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.437298, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.186518, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.486858, learning rate is 0.000400
Net2: layer deconv3:max response is 115.413681, min response is -83.022820.
max gradient is 1.804824, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 25.734636, min response is -4.349420.
max gradient is 8.000000, min gradient is -5.682570, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.295312, learning rate is 0.000200
Net2: layer bn49:max response is 25.463585, min response is -4.288702.
max gradient is 8.000000, min gradient is -6.827977, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.834861, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.12, min inferred z is -4.31, and std is 0.99
 4.12 s (24.3 data/s) [100/100]
training: epoch 162: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.846228, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.420506, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.525118, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.140022, learning rate is 0.000400
Net2: layer deconv3:max response is 87.464302, min response is -64.881203.
max gradient is 8.000000, min gradient is -3.248887, learning rate is 0.000200
Net2: layer bn50:max response is 20.198282, min response is -3.928187.
max gradient is 5.541146, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000001, min gradient is -7.998309, learning rate is 0.000200
Net2: layer bn49:max response is 19.660166, min response is -4.240022.
max gradient is 7.332438, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.863666, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.28, min inferred z is -3.83, and std is 0.99
 4.15 s (24.1 data/s) [100/100]
training: epoch 162: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.613180, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.364327, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.053406, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 7.860436, min gradient is 0.977630, learning rate is 0.000400
Net2: layer deconv3:max response is 98.630905, min response is -72.862007.
max gradient is 2.646567, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.140528, min response is -3.609866.
max gradient is 8.000000, min gradient is -6.258071, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.493631, learning rate is 0.000200
Net2: layer bn49:max response is 22.078644, min response is -3.951160.
max gradient is 8.000000, min gradient is -7.335852, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.607828, learning rate is 0.000200
max inferred z is 3.68, min inferred z is -4.42, and std is 0.99
 4.14 s (24.2 data/s) [100/100]
training: epoch 162: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.771883, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.294952, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.457438, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.097126, learning rate is 0.000400
Net2: layer deconv3:max response is 95.391136, min response is -71.151062.
max gradient is 8.000000, min gradient is -3.131128, learning rate is 0.000200
Net2: layer bn50:max response is 21.281946, min response is -3.323644.
max gradient is 5.147162, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.884513, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.249041, min response is -3.868850.
max gradient is 6.579367, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.518976, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.07, min inferred z is -3.70, and std is 0.99
 4.22 s (23.7 data/s) [100/100]
training: epoch 162: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.225209, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.153624, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.244758, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.289992, learning rate is 0.000400
Net2: layer deconv3:max response is 79.329056, min response is -59.075317.
max gradient is 2.799901, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.997852, min response is -3.569498.
max gradient is 8.000000, min gradient is -7.235595, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.131657, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.545359, min response is -4.134615.
max gradient is 7.532588, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.416905, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.05, min inferred z is -3.80, and std is 0.99
 4.22 s (23.7 data/s) [100/100]
training: epoch 162: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.137723, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.516910, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.549096, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.810721, learning rate is 0.000400
Net2: layer deconv3:max response is 108.082512, min response is -82.220390.
max gradient is 8.000000, min gradient is -2.108315, learning rate is 0.000200
Net2: layer bn50:max response is 23.943874, min response is -3.624365.
max gradient is 5.692853, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.698843, learning rate is 0.000200
Net2: layer bn49:max response is 23.902742, min response is -3.395902.
max gradient is 7.213873, min gradient is -8.000001, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.844376, learning rate is 0.000200
max inferred z is 4.19, min inferred z is -3.75, and std is 0.99
 4.33 s (23.1 data/s) [100/100]
training: epoch 162: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.211628, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.324036, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.401025, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 1.850312, min gradient is -2.671636, learning rate is 0.000400
Net2: layer deconv3:max response is 82.159904, min response is -58.136395.
max gradient is 3.036479, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.558859, min response is -3.497466.
max gradient is 8.000000, min gradient is -6.452751, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.739782, learning rate is 0.000200
Net2: layer bn49:max response is 18.363083, min response is -4.315633.
max gradient is 8.000000, min gradient is -7.111041, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.934540, min gradient is -8.000001, learning rate is 0.000200
max inferred z is 4.06, min inferred z is -3.96, and std is 0.99
 4.32 s (23.1 data/s) [100/100]
training: epoch 162: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.583307, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.688629, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.716864, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.868744, learning rate is 0.000400
Net2: layer deconv3:max response is 85.311920, min response is -70.697800.
max gradient is 8.000000, min gradient is -3.659336, learning rate is 0.000200
Net2: layer bn50:max response is 24.463100, min response is -4.772859.
max gradient is 5.492575, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.610379, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.735300, min response is -5.150090.
max gradient is 7.880130, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.930528, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.15, min inferred z is -3.63, and std is 0.99
 4.34 s (23.0 data/s) [100/100]
training: epoch 162: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.649103, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.390800, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.313979, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.824162, learning rate is 0.000400
Net2: layer deconv3:max response is 77.929382, min response is -56.866215.
max gradient is 4.169609, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.637030, min response is -3.528642.
max gradient is 8.000000, min gradient is -5.871852, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.495076, learning rate is 0.000200
Net2: layer bn49:max response is 17.706217, min response is -4.093479.
max gradient is 8.000000, min gradient is -7.542791, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.033271, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.78, min inferred z is -4.43, and std is 0.99
 4.32 s (23.1 data/s) [100/100]
training: epoch 162: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.456718, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.886620, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.698944, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.970762, learning rate is 0.000400
Net2: layer deconv3:max response is 92.493454, min response is -70.094757.
max gradient is 8.000000, min gradient is -6.166966, learning rate is 0.000200
Net2: layer bn50:max response is 20.548084, min response is -3.312202.
max gradient is 5.690804, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.241312, learning rate is 0.000200
Net2: layer bn49:max response is 20.488680, min response is -4.193019.
max gradient is 8.000001, min gradient is -7.194112, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.914087, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.64, min inferred z is -3.97, and std is 0.99
 4.19 s (23.9 data/s) [100/100]
Loss: 1.0847
Iteration 163 / 200
training: epoch 163: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.920392, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.338664, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.350159, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.317873, learning rate is 0.000400
Net2: layer deconv3:max response is 94.914597, min response is -68.243271.
max gradient is 8.000000, min gradient is -7.628934, learning rate is 0.000200
Net2: layer bn50:max response is 21.398174, min response is -3.889914.
max gradient is 8.000000, min gradient is -7.180934, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.260919, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.239962, min response is -4.070184.
max gradient is 6.427825, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.547372, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.03, min inferred z is -4.02, and std is 0.99
 4.21 s (23.7 data/s) [100/100]
training: epoch 163: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.920176, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.481002, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.668317, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.379205, learning rate is 0.000400
Net2: layer deconv3:max response is 111.747345, min response is -83.887489.
max gradient is 7.426925, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 24.459393, min response is -3.705838.
max gradient is 7.225554, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.462650, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 24.530472, min response is -4.325047.
max gradient is 8.000000, min gradient is -6.456875, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.817905, learning rate is 0.000200
max inferred z is 3.92, min inferred z is -3.80, and std is 0.99
 4.38 s (22.9 data/s) [100/100]
training: epoch 163: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.768047, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.231933, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.141585, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 3.321357, min gradient is 0.220685, learning rate is 0.000400
Net2: layer deconv3:max response is 89.392578, min response is -65.596436.
max gradient is 6.882267, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.441662, min response is -3.970907.
max gradient is 8.000000, min gradient is -6.656991, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.650724, learning rate is 0.000200
Net2: layer bn49:max response is 19.838108, min response is -4.707952.
max gradient is 7.936861, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.085207, learning rate is 0.000200
max inferred z is 3.95, min inferred z is -3.89, and std is 0.99
 4.23 s (23.6 data/s) [100/100]
training: epoch 163: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.713619, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.306915, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.484770, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.501103, learning rate is 0.000400
Net2: layer deconv3:max response is 90.716194, min response is -76.597473.
max gradient is 8.000000, min gradient is -4.968026, learning rate is 0.000200
Net2: layer bn50:max response is 25.779324, min response is -4.400239.
max gradient is 7.577109, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.316686, learning rate is 0.000200
Net2: layer bn49:max response is 18.671139, min response is -5.409950.
max gradient is 8.000000, min gradient is -6.337384, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.276415, learning rate is 0.000200
max inferred z is 3.87, min inferred z is -3.91, and std is 0.99
 4.38 s (22.9 data/s) [100/100]
training: epoch 163: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.067054, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.249442, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.366439, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.760904, learning rate is 0.000400
Net2: layer deconv3:max response is 91.285324, min response is -68.126350.
max gradient is 5.892928, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.830862, min response is -3.321438.
max gradient is 8.000000, min gradient is -3.730502, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.499049, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.150209, min response is -3.986046.
max gradient is 8.000000, min gradient is -5.630407, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.082511, learning rate is 0.000200
max inferred z is 3.72, min inferred z is -4.09, and std is 0.99
 4.40 s (22.7 data/s) [100/100]
training: epoch 163: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.961225, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.479759, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.469487, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.526184, learning rate is 0.000400
Net2: layer deconv3:max response is 108.140205, min response is -79.438087.
max gradient is 7.359489, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 24.196764, min response is -3.712529.
max gradient is 5.836311, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.667130, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 24.114061, min response is -3.801234.
max gradient is 6.860263, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.853829, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.75, min inferred z is -4.07, and std is 0.99
 4.34 s (23.0 data/s) [100/100]
training: epoch 163: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.388540, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.464755, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.594002, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.984590, learning rate is 0.000400
Net2: layer deconv3:max response is 112.496033, min response is -83.053452.
max gradient is 8.000000, min gradient is -4.559405, learning rate is 0.000200
Net2: layer bn50:max response is 24.430706, min response is -4.124409.
max gradient is 7.218357, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.812964, learning rate is 0.000200
Net2: layer bn49:max response is 24.836287, min response is -3.740211.
max gradient is 7.950494, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.728452, learning rate is 0.000200
max inferred z is 3.99, min inferred z is -4.65, and std is 0.99
 4.32 s (23.1 data/s) [100/100]
training: epoch 163: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.631838, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.605544, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.410715, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.231692, learning rate is 0.000400
Net2: layer deconv3:max response is 106.894127, min response is -79.941162.
max gradient is 2.189150, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.414621, min response is -3.810869.
max gradient is 8.000000, min gradient is -5.357397, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.630795, learning rate is 0.000200
Net2: layer bn49:max response is 23.457935, min response is -3.564336.
max gradient is 8.000000, min gradient is -6.483123, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.787150, learning rate is 0.000200
max inferred z is 4.38, min inferred z is -4.06, and std is 0.99
 4.21 s (23.8 data/s) [100/100]
training: epoch 163: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.636378, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.695835, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.992178, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.166944, learning rate is 0.000400
Net2: layer deconv3:max response is 84.067215, min response is -63.180286.
max gradient is 8.000000, min gradient is -2.170702, learning rate is 0.000200
Net2: layer bn50:max response is 20.741873, min response is -4.063326.
max gradient is 4.896603, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.575627, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.600327, min response is -3.796347.
max gradient is 6.969403, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.896605, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.04, min inferred z is -4.12, and std is 0.99
 4.39 s (22.8 data/s) [100/100]
training: epoch 163: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.818776, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.587988, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.832066, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.978887, learning rate is 0.000400
Net2: layer deconv3:max response is 82.777328, min response is -62.838596.
max gradient is 4.404376, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.456875, min response is -3.806042.
max gradient is 8.000000, min gradient is -6.612951, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.546934, learning rate is 0.000200
Net2: layer bn49:max response is 18.240902, min response is -3.968027.
max gradient is 6.753660, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.672215, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 5.31, min inferred z is -4.54, and std is 0.99
 4.21 s (23.8 data/s) [100/100]
Loss: 1.1236
Iteration 164 / 200
training: epoch 164: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.893493, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.485378, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.540826, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.307204, learning rate is 0.000400
Net2: layer deconv3:max response is 81.522797, min response is -65.103966.
max gradient is 6.392293, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.923504, min response is -3.915998.
max gradient is 8.000000, min gradient is -5.700253, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.660371, learning rate is 0.000200
Net2: layer bn49:max response is 18.676874, min response is -4.680163.
max gradient is 8.000000, min gradient is -6.588049, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.473702, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.93, min inferred z is -3.90, and std is 1.00
 4.22 s (23.7 data/s) [100/100]
training: epoch 164: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.809284, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.436977, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.650638, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.617429, learning rate is 0.000400
Net2: layer deconv3:max response is 86.551605, min response is -63.935547.
max gradient is 8.000000, min gradient is -4.211870, learning rate is 0.000200
Net2: layer bn50:max response is 21.435966, min response is -4.018083.
max gradient is 6.751820, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -3.336120, learning rate is 0.000200
Net2: layer bn49:max response is 19.490936, min response is -4.747646.
max gradient is 5.472755, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.113606, learning rate is 0.000200
max inferred z is 3.99, min inferred z is -3.93, and std is 1.00
 4.43 s (22.6 data/s) [100/100]
training: epoch 164: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.806706, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.319293, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.140162, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.345120, learning rate is 0.000400
Net2: layer deconv3:max response is 74.326431, min response is -56.867390.
max gradient is 3.157465, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 17.099344, min response is -3.175721.
max gradient is 6.998837, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 4.632254, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 16.771729, min response is -3.490651.
max gradient is 8.000000, min gradient is -7.717175, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.927375, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.00, min inferred z is -4.38, and std is 1.00
 4.34 s (23.1 data/s) [100/100]
training: epoch 164: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.747519, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.254574, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.602076, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.338047, learning rate is 0.000400
Net2: layer deconv3:max response is 90.743935, min response is -69.805061.
max gradient is 8.000000, min gradient is -3.727736, learning rate is 0.000200
Net2: layer bn50:max response is 19.688089, min response is -3.409329.
max gradient is 6.749507, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.091755, learning rate is 0.000200
Net2: layer bn49:max response is 19.907248, min response is -3.695625.
max gradient is 7.722367, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.284577, learning rate is 0.000200
max inferred z is 4.42, min inferred z is -3.85, and std is 1.00
 4.50 s (22.2 data/s) [100/100]
training: epoch 164: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.044843, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.240128, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.316333, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.172851, learning rate is 0.000400
Net2: layer deconv3:max response is 99.847130, min response is -72.455833.
max gradient is 2.139704, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.720860, min response is -3.922248.
max gradient is 8.000000, min gradient is -6.975235, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.702496, learning rate is 0.000200
Net2: layer bn49:max response is 22.028610, min response is -4.887031.
max gradient is 8.000000, min gradient is -6.378698, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.529203, learning rate is 0.000200
max inferred z is 3.57, min inferred z is -3.98, and std is 1.00
 4.44 s (22.5 data/s) [100/100]
training: epoch 164: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.062200, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.687307, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.660168, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.257618, learning rate is 0.000400
Net2: layer deconv3:max response is 104.537193, min response is -77.741241.
max gradient is 8.000000, min gradient is -2.585087, learning rate is 0.000200
Net2: layer bn50:max response is 23.603285, min response is -4.526989.
max gradient is 5.483566, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.422038, learning rate is 0.000200
Net2: layer bn49:max response is 23.912333, min response is -4.435689.
max gradient is 7.542613, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.475987, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.28, min inferred z is -3.91, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 164: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.256299, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.315377, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.359603, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 5.914608, min gradient is 3.731712, learning rate is 0.000400
Net2: layer deconv3:max response is 94.472664, min response is -69.179787.
max gradient is 2.909801, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.742006, min response is -3.299894.
max gradient is 8.000000, min gradient is -7.097816, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.884669, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.823879, min response is -4.009016.
max gradient is 8.000000, min gradient is -6.909347, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.492907, learning rate is 0.000200
max inferred z is 3.87, min inferred z is -3.96, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 164: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.602927, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.614386, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.780022, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.098870, learning rate is 0.000400
Net2: layer deconv3:max response is 107.812798, min response is -83.450722.
max gradient is 8.000000, min gradient is -3.182525, learning rate is 0.000200
Net2: layer bn50:max response is 23.824167, min response is -4.491262.
max gradient is 4.760376, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.856331, learning rate is 0.000200
Net2: layer bn49:max response is 24.145388, min response is -5.088665.
max gradient is 6.198181, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.376467, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.78, min inferred z is -3.96, and std is 1.00
 4.23 s (23.6 data/s) [100/100]
training: epoch 164: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.894633, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.358208, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.593453, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.470020, learning rate is 0.000400
Net2: layer deconv3:max response is 110.879410, min response is -80.521347.
max gradient is 3.467828, min gradient is -8.000001, learning rate is 0.000200
Net2: layer bn50:max response is 24.783030, min response is -4.768144.
max gradient is 8.000000, min gradient is -5.440283, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.179905, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 24.832491, min response is -3.753731.
max gradient is 8.000000, min gradient is -7.171164, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.662941, learning rate is 0.000200
max inferred z is 3.76, min inferred z is -4.29, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 164: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.702818, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv2:max response is , min response is .
max gradient is 4.615951, min gradient is -8.000000, learning rate is 0.000001
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.670173, learning rate is 0.000001
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.860902, learning rate is 0.000400
Net2: layer deconv3:max response is 101.930740, min response is -76.423424.
max gradient is 8.000000, min gradient is -7.226570, learning rate is 0.000200
Net2: layer bn50:max response is 22.566996, min response is -4.474064.
max gradient is 6.466164, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.578855, learning rate is 0.000200
Net2: layer bn49:max response is 22.446280, min response is -3.952347.
max gradient is 8.000000, min gradient is -7.500750, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.830404, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.53, min inferred z is -3.82, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
Loss: 1.0613
Iteration 165 / 200
training: epoch 165: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.933670, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.274600, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.392577, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.626789, learning rate is 0.000400
Net2: layer deconv3:max response is 90.892822, min response is -67.564529.
max gradient is 6.934712, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.347059, min response is -3.748443.
max gradient is 8.000000, min gradient is -6.292592, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.895206, learning rate is 0.000200
Net2: layer bn49:max response is 20.229473, min response is -4.503397.
max gradient is 7.849922, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.795301, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.89, min inferred z is -3.84, and std is 0.99
 4.23 s (23.6 data/s) [100/100]
training: epoch 165: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.817180, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.608497, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.435419, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.990139, learning rate is 0.000400
Net2: layer deconv3:max response is 100.676849, min response is -75.442520.
max gradient is 8.000000, min gradient is -6.000983, learning rate is 0.000200
Net2: layer bn50:max response is 22.023914, min response is -4.002248.
max gradient is 6.421242, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.812420, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 22.359524, min response is -4.274870.
max gradient is 8.000000, min gradient is -7.487950, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.631724, learning rate is 0.000200
max inferred z is 3.90, min inferred z is -4.01, and std is 0.99
 4.30 s (23.2 data/s) [100/100]
training: epoch 165: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.730300, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.232687, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.211835, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000001, min gradient is 7.515356, learning rate is 0.000400
Net2: layer deconv3:max response is 72.957939, min response is -57.788246.
max gradient is 6.383648, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.566914, min response is -3.621190.
max gradient is 8.000000, min gradient is -6.328311, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.968132, learning rate is 0.000200
Net2: layer bn49:max response is 15.865088, min response is -4.276513.
max gradient is 8.000000, min gradient is -7.380378, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.574178, learning rate is 0.000200
max inferred z is 3.96, min inferred z is -4.04, and std is 0.99
 4.37 s (22.9 data/s) [100/100]
training: epoch 165: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.725311, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.367363, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.468201, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.734314, learning rate is 0.000400
Net2: layer deconv3:max response is 97.123833, min response is -71.799759.
max gradient is 8.000000, min gradient is -7.303576, learning rate is 0.000200
Net2: layer bn50:max response is 21.637516, min response is -4.093119.
max gradient is 6.570975, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.528372, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 22.034634, min response is -4.196532.
max gradient is 8.000000, min gradient is -6.348414, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.798199, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.70, min inferred z is -4.02, and std is 0.99
 4.41 s (22.7 data/s) [100/100]
training: epoch 165: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.084937, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.125737, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.477293, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.813204, learning rate is 0.000400
Net2: layer deconv3:max response is 87.631165, min response is -64.328400.
max gradient is 8.000000, min gradient is -7.954446, learning rate is 0.000200
Net2: layer bn50:max response is 22.177782, min response is -3.476206.
max gradient is 7.381434, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000001, min gradient is -7.850247, learning rate is 0.000200
Net2: layer bn49:max response is 19.667753, min response is -4.541763.
max gradient is 6.474177, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.609605, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.51, min inferred z is -4.20, and std is 0.99
 4.39 s (22.8 data/s) [100/100]
training: epoch 165: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.956248, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.618147, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.564145, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.110111, learning rate is 0.000400
Net2: layer deconv3:max response is 108.700890, min response is -83.779228.
max gradient is 6.584725, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.735601, min response is -3.989441.
max gradient is 8.000000, min gradient is -6.710914, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.964674, learning rate is 0.000200
Net2: layer bn49:max response is 24.318556, min response is -3.740486.
max gradient is 8.000000, min gradient is -6.215357, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.265370, learning rate is 0.000200
max inferred z is 3.65, min inferred z is -4.38, and std is 0.99
 4.42 s (22.6 data/s) [100/100]
training: epoch 165: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.444702, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.224288, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.637894, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.983447, learning rate is 0.000400
Net2: layer deconv3:max response is 102.423973, min response is -75.695274.
max gradient is 8.000000, min gradient is -4.876249, learning rate is 0.000200
Net2: layer bn50:max response is 21.958078, min response is -3.715123.
max gradient is 8.000000, min gradient is -6.297370, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.923134, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 22.591553, min response is -4.078057.
max gradient is 8.000000, min gradient is -7.898632, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.908463, learning rate is 0.000200
max inferred z is 3.62, min inferred z is -3.92, and std is 0.99
 4.43 s (22.6 data/s) [100/100]
training: epoch 165: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.704084, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.424960, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.356800, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.350126, learning rate is 0.000400
Net2: layer deconv3:max response is 102.987877, min response is -75.060410.
max gradient is 2.284977, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.912510, min response is -3.982333.
max gradient is 8.000000, min gradient is -7.547536, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.891373, learning rate is 0.000200
Net2: layer bn49:max response is 22.462765, min response is -4.499492.
max gradient is 8.000000, min gradient is -7.968048, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.207137, learning rate is 0.000200
max inferred z is 3.81, min inferred z is -4.03, and std is 0.99
 4.22 s (23.7 data/s) [100/100]
training: epoch 165: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.512803, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.561371, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.628041, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.100572, learning rate is 0.000400
Net2: layer deconv3:max response is 82.132118, min response is -61.895432.
max gradient is 3.585402, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.746990, min response is -3.703322.
max gradient is 8.000000, min gradient is -6.882549, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.100754, learning rate is 0.000200
Net2: layer bn49:max response is 18.625694, min response is -4.455533.
max gradient is 7.815843, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.396931, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.18, min inferred z is -4.23, and std is 0.99
 4.33 s (23.1 data/s) [100/100]
training: epoch 165: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.806696, min gradient is -8.000001, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.802181, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.691287, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.611247, learning rate is 0.000400
Net2: layer deconv3:max response is 87.960114, min response is -69.119759.
max gradient is 8.000000, min gradient is -2.736069, learning rate is 0.000200
Net2: layer bn50:max response is 20.569784, min response is -3.516826.
max gradient is 4.786473, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.568261, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.701038, min response is -4.037195.
max gradient is 7.349071, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.148991, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.15, min inferred z is -3.91, and std is 0.99
 4.25 s (23.5 data/s) [100/100]
Loss: 1.1196
Iteration 166 / 200
training: epoch 166: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.917383, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.369873, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.121024, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.315474, learning rate is 0.000400
Net2: layer deconv3:max response is 114.828171, min response is -82.130585.
max gradient is 5.638334, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 25.608477, min response is -5.080854.
max gradient is 8.000000, min gradient is -7.540702, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.671978, learning rate is 0.000200
Net2: layer bn49:max response is 25.584583, min response is -4.329279.
max gradient is 7.372213, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.905090, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.00, min inferred z is -4.22, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 166: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.797477, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.638154, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.535629, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.508805, learning rate is 0.000400
Net2: layer deconv3:max response is 79.812294, min response is -64.384422.
max gradient is 5.668455, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.447802, min response is -3.869793.
max gradient is 5.825782, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.709776, learning rate is 0.000200
Net2: layer bn49:max response is 17.814327, min response is -4.769626.
max gradient is 8.000000, min gradient is -6.229002, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.619415, learning rate is 0.000200
max inferred z is 3.81, min inferred z is -3.88, and std is 1.00
 4.30 s (23.2 data/s) [100/100]
training: epoch 166: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.788190, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.266140, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.186802, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.078666, learning rate is 0.000400
Net2: layer deconv3:max response is 94.317795, min response is -71.782692.
max gradient is 8.000000, min gradient is -4.323055, learning rate is 0.000200
Net2: layer bn50:max response is 20.616720, min response is -3.516877.
max gradient is 8.000000, min gradient is -5.556543, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.547945, learning rate is 0.000200
Net2: layer bn49:max response is 21.449711, min response is -3.557807.
max gradient is 8.000000, min gradient is -6.953237, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.124674, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.48, min inferred z is -4.03, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 166: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.990482, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.207808, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.377059, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.212158, learning rate is 0.000400
Net2: layer deconv3:max response is 102.684059, min response is -73.739494.
max gradient is 5.900504, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.621853, min response is -4.269811.
max gradient is 8.000000, min gradient is -4.611946, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.132785, learning rate is 0.000200
Net2: layer bn49:max response is 22.403057, min response is -4.769573.
max gradient is 8.000000, min gradient is -5.198529, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.576898, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.06, min inferred z is -4.77, and std is 1.00
 4.23 s (23.6 data/s) [100/100]
training: epoch 166: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.908905, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.151243, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.362991, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.359483, learning rate is 0.000400
Net2: layer deconv3:max response is 97.804008, min response is -72.180748.
max gradient is 7.630666, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.899097, min response is -3.315901.
max gradient is 5.126042, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.882348, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.333002, min response is -3.836264.
max gradient is 6.012229, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.773612, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.22, min inferred z is -4.08, and std is 1.00
 4.19 s (23.9 data/s) [100/100]
training: epoch 166: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.033219, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.597474, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.701357, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.787714, learning rate is 0.000400
Net2: layer deconv3:max response is 83.234703, min response is -64.594238.
max gradient is 8.000000, min gradient is -4.991547, learning rate is 0.000200
Net2: layer bn50:max response is 20.977625, min response is -4.262730.
max gradient is 8.000000, min gradient is -7.289112, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.391572, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.584862, min response is -4.343267.
max gradient is 8.000000, min gradient is -6.828272, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.325474, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.09, min inferred z is -3.72, and std is 1.00
 4.21 s (23.8 data/s) [100/100]
training: epoch 166: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.304206, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.329059, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.341281, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 0.451466, min gradient is -1.741089, learning rate is 0.000400
Net2: layer deconv3:max response is 96.495323, min response is -68.156319.
max gradient is 2.562706, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.846195, min response is -3.658582.
max gradient is 8.000000, min gradient is -6.046430, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.484046, learning rate is 0.000200
Net2: layer bn49:max response is 21.359150, min response is -3.592312.
max gradient is 8.000000, min gradient is -6.750972, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.435893, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.17, min inferred z is -3.70, and std is 1.00
 4.36 s (23.0 data/s) [100/100]
training: epoch 166: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.781818, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.475477, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.729115, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.565168, learning rate is 0.000400
Net2: layer deconv3:max response is 96.567978, min response is -73.349365.
max gradient is 8.000000, min gradient is -3.323385, learning rate is 0.000200
Net2: layer bn50:max response is 20.792109, min response is -3.697999.
max gradient is 7.600327, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.220597, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.495020, min response is -3.865657.
max gradient is 5.381391, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.598303, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.20, min inferred z is -4.41, and std is 1.00
 4.43 s (22.6 data/s) [100/100]
training: epoch 166: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.766655, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.454859, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.586764, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.793006, learning rate is 0.000400
Net2: layer deconv3:max response is 88.801559, min response is -65.258865.
max gradient is 2.609020, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.349566, min response is -3.479120.
max gradient is 8.000000, min gradient is -6.297640, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.341315, learning rate is 0.000200
Net2: layer bn49:max response is 19.559721, min response is -3.959676.
max gradient is 8.000000, min gradient is -6.424650, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.071148, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.90, min inferred z is -3.88, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 166: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.630671, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.921017, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.707760, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.017008, learning rate is 0.000400
Net2: layer deconv3:max response is 87.473679, min response is -65.772301.
max gradient is 8.000000, min gradient is -3.150293, learning rate is 0.000200
Net2: layer bn50:max response is 20.074661, min response is -3.880302.
max gradient is 5.820238, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.995388, learning rate is 0.000200
Net2: layer bn49:max response is 19.713943, min response is -4.245002.
max gradient is 8.000000, min gradient is -7.247434, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.928625, learning rate is 0.000200
max inferred z is 3.96, min inferred z is -4.02, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
Loss: 1.1182
Iteration 167 / 200
training: epoch 167: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.986270, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.284319, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.287831, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.698942, learning rate is 0.000400
Net2: layer deconv3:max response is 78.514671, min response is -62.095131.
max gradient is 2.742424, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 24.061014, min response is -3.994051.
max gradient is 8.000000, min gradient is -6.011581, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.871105, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.287876, min response is -4.279229.
max gradient is 8.000000, min gradient is -6.832167, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.550878, learning rate is 0.000200
max inferred z is 3.80, min inferred z is -4.20, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
training: epoch 167: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.935843, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.341709, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.450838, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.514939, learning rate is 0.000400
Net2: layer deconv3:max response is 82.730873, min response is -60.395397.
max gradient is 8.000000, min gradient is -4.717571, learning rate is 0.000200
Net2: layer bn50:max response is 19.497736, min response is -3.926173.
max gradient is 5.734401, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.521406, learning rate is 0.000200
Net2: layer bn49:max response is 18.669064, min response is -4.604023.
max gradient is 8.000000, min gradient is -4.918178, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.461081, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.72, min inferred z is -3.68, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
training: epoch 167: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.836594, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.378845, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.596009, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.637894, learning rate is 0.000400
Net2: layer deconv3:max response is 115.113075, min response is -86.186630.
max gradient is 4.971876, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 24.811363, min response is -4.388569.
max gradient is 8.000000, min gradient is -3.836645, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.683429, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 25.385241, min response is -5.005783.
max gradient is 6.407869, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.346265, learning rate is 0.000200
max inferred z is 4.08, min inferred z is -4.23, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 167: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.592273, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.135054, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.180465, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 1.232395, min gradient is 0.473557, learning rate is 0.000400
Net2: layer deconv3:max response is 91.082626, min response is -66.276871.
max gradient is 6.293150, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.434244, min response is -3.710537.
max gradient is 8.000000, min gradient is -7.216384, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.957835, learning rate is 0.000200
Net2: layer bn49:max response is 20.024473, min response is -3.947977.
max gradient is 8.000000, min gradient is -6.631005, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.224073, learning rate is 0.000200
max inferred z is 3.83, min inferred z is -3.84, and std is 1.00
 4.30 s (23.2 data/s) [100/100]
training: epoch 167: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.087084, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.143655, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.757302, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.211335, learning rate is 0.000400
Net2: layer deconv3:max response is 86.410225, min response is -64.197899.
max gradient is 8.000000, min gradient is -2.235646, learning rate is 0.000200
Net2: layer bn50:max response is 20.575918, min response is -4.197681.
max gradient is 5.418048, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.105161, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.607920, min response is -4.132899.
max gradient is 6.830968, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.978361, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.69, min inferred z is -3.81, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 167: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.149173, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.442552, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.150630, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.287785, learning rate is 0.000400
Net2: layer deconv3:max response is 98.464111, min response is -70.564140.
max gradient is 2.642763, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.944565, min response is -3.646141.
max gradient is 8.000000, min gradient is -7.358168, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.347237, learning rate is 0.000200
Net2: layer bn49:max response is 21.733263, min response is -3.837828.
max gradient is 8.000000, min gradient is -6.825118, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.966293, learning rate is 0.000200
max inferred z is 4.28, min inferred z is -4.11, and std is 1.00
 4.32 s (23.2 data/s) [100/100]
training: epoch 167: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.269388, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.502911, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.675329, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.863614, learning rate is 0.000400
Net2: layer deconv3:max response is 97.214470, min response is -70.407829.
max gradient is 6.519476, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.257782, min response is -4.001977.
max gradient is 6.910365, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.601327, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.836510, min response is -4.437953.
max gradient is 8.000000, min gradient is -7.789634, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.503252, learning rate is 0.000200
max inferred z is 4.92, min inferred z is -3.96, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
training: epoch 167: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.721555, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.541635, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 7.802200, min gradient is -8.000000, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -0.772071, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 89.865578, min response is -72.636787.
max gradient is 8.000000, min gradient is -4.275208, learning rate is 0.000200
Net2: layer bn50:max response is 19.945532, min response is -3.501446.
max gradient is 7.893125, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.556563, learning rate is 0.000200
Net2: layer bn49:max response is 20.438692, min response is -3.919430.
max gradient is 8.000000, min gradient is -7.566614, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.367341, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.25, min inferred z is -3.83, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 167: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.706258, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.384338, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.850919, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.125141, learning rate is 0.000400
Net2: layer deconv3:max response is 82.074005, min response is -66.007393.
max gradient is 8.000000, min gradient is -6.090232, learning rate is 0.000200
Net2: layer bn50:max response is 21.796953, min response is -4.034469.
max gradient is 6.823047, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.904284, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.873585, min response is -4.589024.
max gradient is 8.000001, min gradient is -6.617531, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.276289, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.80, min inferred z is -3.92, and std is 1.00
 4.23 s (23.6 data/s) [100/100]
training: epoch 167: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.710091, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.562467, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.630687, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -2.453854, min gradient is -4.118498, learning rate is 0.000400
Net2: layer deconv3:max response is 89.699883, min response is -62.863800.
max gradient is 2.612491, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.551516, min response is -3.610605.
max gradient is 8.000000, min gradient is -7.038746, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000001, min gradient is -5.832925, learning rate is 0.000200
Net2: layer bn49:max response is 19.991919, min response is -4.126736.
max gradient is 8.000000, min gradient is -5.911808, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.053595, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.79, min inferred z is -3.72, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
Loss: 1.1005
Iteration 168 / 200
training: epoch 168: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.187743, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.224998, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.421050, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.791296, learning rate is 0.000400
Net2: layer deconv3:max response is 83.165451, min response is -64.876816.
max gradient is 8.000000, min gradient is -4.491358, learning rate is 0.000200
Net2: layer bn50:max response is 22.088390, min response is -3.913476.
max gradient is 6.459731, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.820455, learning rate is 0.000200
Net2: layer bn49:max response is 18.699661, min response is -4.784238.
max gradient is 7.550183, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.833268, learning rate is 0.000200
max inferred z is 3.92, min inferred z is -3.56, and std is 1.00
 4.21 s (23.7 data/s) [100/100]
training: epoch 168: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.928258, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.501430, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.327965, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.061929, learning rate is 0.000400
Net2: layer deconv3:max response is 95.266739, min response is -74.843178.
max gradient is 5.101672, min gradient is -8.000001, learning rate is 0.000200
Net2: layer bn50:max response is 24.693188, min response is -3.973473.
max gradient is 8.000000, min gradient is -3.869112, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.295210, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.607004, min response is -4.665003.
max gradient is 7.077314, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.920913, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.97, min inferred z is -3.97, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 168: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.701184, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.340930, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.196702, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.484669, learning rate is 0.000400
Net2: layer deconv3:max response is 98.749680, min response is -73.619881.
max gradient is 5.924757, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 25.056980, min response is -4.184516.
max gradient is 8.000000, min gradient is -7.014470, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.692576, learning rate is 0.000200
Net2: layer bn49:max response is 22.570921, min response is -4.879778.
max gradient is 8.000000, min gradient is -6.787646, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.994303, learning rate is 0.000200
max inferred z is 3.74, min inferred z is -3.80, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
training: epoch 168: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.718693, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.220719, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.831824, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.493190, learning rate is 0.000400
Net2: layer deconv3:max response is 77.330864, min response is -61.976158.
max gradient is 8.000000, min gradient is -3.815990, learning rate is 0.000200
Net2: layer bn50:max response is 17.209007, min response is -3.353059.
max gradient is 6.587410, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.633173, min gradient is -8.000001, learning rate is 0.000200
Net2: layer bn49:max response is 17.672884, min response is -3.591498.
max gradient is 6.955564, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.468700, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.57, min inferred z is -3.96, and std is 1.00
 4.41 s (22.7 data/s) [100/100]
training: epoch 168: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.052776, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.071778, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.634916, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.652092, learning rate is 0.000400
Net2: layer deconv3:max response is 90.063454, min response is -67.573273.
max gradient is 5.089691, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.311989, min response is -3.773842.
max gradient is 8.000000, min gradient is -5.710897, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.098903, learning rate is 0.000200
Net2: layer bn49:max response is 19.990915, min response is -4.508846.
max gradient is 6.591665, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.636447, learning rate is 0.000200
max inferred z is 4.16, min inferred z is -4.15, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 168: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.979615, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.593943, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.534696, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.954774, learning rate is 0.000400
Net2: layer deconv3:max response is 101.120827, min response is -76.259605.
max gradient is 4.803352, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.878580, min response is -3.694002.
max gradient is 8.000000, min gradient is -4.999811, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.364273, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 22.487000, min response is -4.190784.
max gradient is 6.683419, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.404067, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.46, min inferred z is -3.98, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 168: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.396184, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.339430, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.743437, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.364130, learning rate is 0.000400
Net2: layer deconv3:max response is 115.078651, min response is -89.428726.
max gradient is 8.000000, min gradient is -4.311412, learning rate is 0.000200
Net2: layer bn50:max response is 25.171144, min response is -4.225899.
max gradient is 8.000000, min gradient is -6.316952, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.298197, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 26.039305, min response is -4.822931.
max gradient is 7.829834, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.499076, learning rate is 0.000200
max inferred z is 3.95, min inferred z is -3.80, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
training: epoch 168: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.899715, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.484341, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.632432, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.428384, learning rate is 0.000400
Net2: layer deconv3:max response is 94.859138, min response is -70.239479.
max gradient is 2.704750, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.887789, min response is -3.692235.
max gradient is 7.980539, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.553206, learning rate is 0.000200
Net2: layer bn49:max response is 21.065762, min response is -4.538216.
max gradient is 8.000000, min gradient is -6.244473, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.843551, learning rate is 0.000200
max inferred z is 4.12, min inferred z is -3.95, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 168: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.686069, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.447875, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.719709, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.278393, learning rate is 0.000400
Net2: layer deconv3:max response is 95.912506, min response is -73.175758.
max gradient is 8.000000, min gradient is -6.944588, learning rate is 0.000200
Net2: layer bn50:max response is 20.914944, min response is -3.846259.
max gradient is 8.000000, min gradient is -6.317688, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.201723, learning rate is 0.000200
Net2: layer bn49:max response is 21.420506, min response is -4.493224.
max gradient is 7.920722, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.443941, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.68, min inferred z is -4.91, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 168: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.703217, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.499545, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.595678, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.271105, learning rate is 0.000400
Net2: layer deconv3:max response is 100.050888, min response is -75.045876.
max gradient is 8.000000, min gradient is -6.828020, learning rate is 0.000200
Net2: layer bn50:max response is 21.949591, min response is -4.097533.
max gradient is 5.093424, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.279705, min gradient is -8.000001, learning rate is 0.000200
Net2: layer bn49:max response is 22.854780, min response is -4.361760.
max gradient is 7.425350, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.638936, learning rate is 0.000200
max inferred z is 3.94, min inferred z is -3.56, and std is 1.00
 4.43 s (22.6 data/s) [100/100]
Loss: 1.0698
Iteration 169 / 200
training: epoch 169: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.907162, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.483153, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.789588, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.716472, learning rate is 0.000400
Net2: layer deconv3:max response is 103.088943, min response is -79.416779.
max gradient is 8.000000, min gradient is -7.144754, learning rate is 0.000200
Net2: layer bn50:max response is 22.168634, min response is -3.644503.
max gradient is 8.000000, min gradient is -6.207021, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.159056, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 22.922600, min response is -3.624170.
max gradient is 8.000000, min gradient is -4.239908, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.882776, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.70, min inferred z is -4.15, and std is 1.00
 4.19 s (23.9 data/s) [100/100]
training: epoch 169: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.948363, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.292180, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.402496, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -3.603150, min gradient is -7.152341, learning rate is 0.000400
Net2: layer deconv3:max response is 84.315460, min response is -63.206139.
max gradient is 8.000000, min gradient is -7.426264, learning rate is 0.000200
Net2: layer bn50:max response is 18.297674, min response is -3.412011.
max gradient is 7.770407, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.348581, learning rate is 0.000200
Net2: layer bn49:max response is 19.109354, min response is -3.516650.
max gradient is 5.636714, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.713638, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.68, min inferred z is -4.23, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 169: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.744655, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.289627, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.167841, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.173393, learning rate is 0.000400
Net2: layer deconv3:max response is 98.554169, min response is -74.709526.
max gradient is 5.565493, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.548107, min response is -3.679928.
max gradient is 8.000000, min gradient is -7.323531, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.856207, learning rate is 0.000200
Net2: layer bn49:max response is 22.321442, min response is -3.591387.
max gradient is 8.000000, min gradient is -7.208650, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.815971, learning rate is 0.000200
max inferred z is 4.33, min inferred z is -3.50, and std is 1.00
 4.21 s (23.7 data/s) [100/100]
training: epoch 169: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.760257, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.253140, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.745245, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -0.865836, learning rate is 0.000400
Net2: layer deconv3:max response is 85.580246, min response is -67.501457.
max gradient is 8.000000, min gradient is -4.566411, learning rate is 0.000200
Net2: layer bn50:max response is 19.023302, min response is -3.614526.
max gradient is 8.000000, min gradient is -7.324469, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.076896, learning rate is 0.000200
Net2: layer bn49:max response is 19.881813, min response is -3.629088.
max gradient is 7.789181, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.971234, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.40, min inferred z is -4.28, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 169: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.087698, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.077770, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.709148, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.786773, learning rate is 0.000400
Net2: layer deconv3:max response is 92.306259, min response is -71.644775.
max gradient is 8.000000, min gradient is -6.597431, learning rate is 0.000200
Net2: layer bn50:max response is 22.019009, min response is -4.070493.
max gradient is 6.831716, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.606638, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.734524, min response is -4.520356.
max gradient is 6.963907, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.840380, learning rate is 0.000200
max inferred z is 3.61, min inferred z is -4.17, and std is 1.00
 4.46 s (22.4 data/s) [100/100]
training: epoch 169: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.752502, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.486193, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.308188, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.766240, learning rate is 0.000400
Net2: layer deconv3:max response is 85.479156, min response is -66.482651.
max gradient is 2.299409, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.653051, min response is -3.829180.
max gradient is 8.000000, min gradient is -6.623328, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.276909, learning rate is 0.000200
Net2: layer bn49:max response is 19.688560, min response is -4.149476.
max gradient is 8.000000, min gradient is -4.170045, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.504265, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.09, min inferred z is -3.49, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 169: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.344095, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.561015, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.871225, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.203589, learning rate is 0.000400
Net2: layer deconv3:max response is 93.744041, min response is -72.528717.
max gradient is 8.000000, min gradient is -2.529891, learning rate is 0.000200
Net2: layer bn50:max response is 20.661814, min response is -3.904093.
max gradient is 5.337059, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.274008, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.463572, min response is -3.736752.
max gradient is 5.227614, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.828876, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.65, min inferred z is -3.88, and std is 1.00
 4.43 s (22.6 data/s) [100/100]
training: epoch 169: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.641097, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.413799, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.567832, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.290063, learning rate is 0.000400
Net2: layer deconv3:max response is 102.871544, min response is -77.109337.
max gradient is 5.406888, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.660395, min response is -4.158025.
max gradient is 8.000000, min gradient is -4.300766, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.941983, learning rate is 0.000200
Net2: layer bn49:max response is 23.095655, min response is -4.721901.
max gradient is 7.557520, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.191198, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.77, min inferred z is -4.05, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 169: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.667715, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.499274, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.996480, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.683394, learning rate is 0.000400
Net2: layer deconv3:max response is 88.707352, min response is -69.939934.
max gradient is 4.212496, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.199179, min response is -4.190249.
max gradient is 5.535379, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.801577, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.939352, min response is -4.963797.
max gradient is 7.092555, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.990501, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 5.00, min inferred z is -4.24, and std is 1.00
 4.43 s (22.5 data/s) [100/100]
training: epoch 169: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.618850, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.715690, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.444545, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.161465, learning rate is 0.000400
Net2: layer deconv3:max response is 71.992157, min response is -56.648319.
max gradient is 7.455713, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 17.841928, min response is -3.264217.
max gradient is 8.000000, min gradient is -6.356947, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.751956, learning rate is 0.000200
Net2: layer bn49:max response is 16.748964, min response is -3.645773.
max gradient is 4.962079, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.350638, learning rate is 0.000200
max inferred z is 4.50, min inferred z is -4.00, and std is 1.00
 4.28 s (23.4 data/s) [100/100]
Loss: 1.2801
Iteration 170 / 200
training: epoch 170: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.887953, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.523468, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.958168, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.187405, learning rate is 0.000400
Net2: layer deconv3:max response is 89.486801, min response is -70.517250.
max gradient is 7.564445, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.759144, min response is -3.387094.
max gradient is 8.000000, min gradient is -6.856202, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.044723, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.624203, min response is -4.057060.
max gradient is 8.000000, min gradient is -6.116703, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.967631, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.02, min inferred z is -4.38, and std is 0.99
 4.16 s (24.1 data/s) [100/100]
training: epoch 170: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.824740, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.312318, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.446706, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.864201, learning rate is 0.000400
Net2: layer deconv3:max response is 89.946419, min response is -70.091446.
max gradient is 4.823874, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.678511, min response is -3.707328.
max gradient is 5.336828, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.439545, learning rate is 0.000200
Net2: layer bn49:max response is 20.660759, min response is -3.889179.
max gradient is 8.000000, min gradient is -7.936867, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.531270, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.96, min inferred z is -4.19, and std is 0.99
 4.28 s (23.4 data/s) [100/100]
training: epoch 170: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.823144, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.309019, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.660197, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.542251, learning rate is 0.000400
Net2: layer deconv3:max response is 84.064323, min response is -66.528839.
max gradient is 8.000000, min gradient is -5.895329, learning rate is 0.000200
Net2: layer bn50:max response is 21.936098, min response is -4.232676.
max gradient is 8.000000, min gradient is -6.196888, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.545953, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.935829, min response is -4.814877.
max gradient is 8.000000, min gradient is -7.817634, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.828404, learning rate is 0.000200
max inferred z is 3.93, min inferred z is -3.83, and std is 0.99
 4.31 s (23.2 data/s) [100/100]
training: epoch 170: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.729586, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.222823, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.307604, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.336773, learning rate is 0.000400
Net2: layer deconv3:max response is 94.424149, min response is -70.584579.
max gradient is 2.102479, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.879368, min response is -4.327307.
max gradient is 8.000000, min gradient is -6.815375, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000001, min gradient is -5.685352, learning rate is 0.000200
Net2: layer bn49:max response is 21.590416, min response is -4.723646.
max gradient is 8.000000, min gradient is -5.341730, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.626554, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.05, min inferred z is -3.87, and std is 0.99
 4.23 s (23.6 data/s) [100/100]
training: epoch 170: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.022428, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.059529, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.794205, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.714007, learning rate is 0.000400
Net2: layer deconv3:max response is 101.966461, min response is -80.376434.
max gradient is 8.000000, min gradient is -3.272172, learning rate is 0.000200
Net2: layer bn50:max response is 22.187317, min response is -3.820431.
max gradient is 5.940977, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.404480, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 23.301916, min response is -4.570877.
max gradient is 4.688227, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.076988, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.16, min inferred z is -3.79, and std is 0.99
 4.39 s (22.8 data/s) [100/100]
training: epoch 170: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.108861, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.468204, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.337013, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.765197, learning rate is 0.000400
Net2: layer deconv3:max response is 96.079834, min response is -72.327354.
max gradient is 3.476038, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.669125, min response is -4.198277.
max gradient is 8.000000, min gradient is -6.877892, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.160466, learning rate is 0.000200
Net2: layer bn49:max response is 21.100452, min response is -3.865324.
max gradient is 8.000000, min gradient is -7.827083, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.939549, learning rate is 0.000200
max inferred z is 3.81, min inferred z is -4.09, and std is 0.99
 4.40 s (22.7 data/s) [100/100]
training: epoch 170: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.341745, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.448417, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.670742, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.053778, learning rate is 0.000400
Net2: layer deconv3:max response is 94.181160, min response is -69.161217.
max gradient is 8.000000, min gradient is -4.899284, learning rate is 0.000200
Net2: layer bn50:max response is 20.417004, min response is -4.113562.
max gradient is 5.355581, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.105515, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.164581, min response is -4.212100.
max gradient is 7.439014, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.796061, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.35, min inferred z is -4.05, and std is 0.99
 4.44 s (22.5 data/s) [100/100]
training: epoch 170: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.794243, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.587896, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.904573, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.335669, learning rate is 0.000400
Net2: layer deconv3:max response is 98.930786, min response is -78.218513.
max gradient is 6.136282, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.084208, min response is -3.461808.
max gradient is 8.000000, min gradient is -6.515970, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.185184, learning rate is 0.000200
Net2: layer bn49:max response is 21.923708, min response is -3.502707.
max gradient is 6.798164, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.165548, learning rate is 0.000200
max inferred z is 4.24, min inferred z is -4.17, and std is 0.99
 4.42 s (22.6 data/s) [100/100]
training: epoch 170: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.839968, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.235556, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.569286, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.331090, learning rate is 0.000400
Net2: layer deconv3:max response is 90.038414, min response is -69.663277.
max gradient is 4.034496, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.530663, min response is -3.616138.
max gradient is 7.197040, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.636282, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.191177, min response is -4.349903.
max gradient is 8.000000, min gradient is -6.097463, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.911221, learning rate is 0.000200
max inferred z is 3.82, min inferred z is -4.37, and std is 0.99
 4.32 s (23.2 data/s) [100/100]
training: epoch 170: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.859012, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.624892, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.704771, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.355023, learning rate is 0.000400
Net2: layer deconv3:max response is 85.276207, min response is -66.551796.
max gradient is 8.000000, min gradient is -2.237131, learning rate is 0.000200
Net2: layer bn50:max response is 20.290354, min response is -3.599487.
max gradient is 7.407652, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.429170, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.200607, min response is -3.857714.
max gradient is 6.799243, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.084819, learning rate is 0.000200
max inferred z is 4.15, min inferred z is -4.00, and std is 0.99
 4.18 s (23.9 data/s) [100/100]
Loss: 1.1582
Iteration 171 / 200
training: epoch 171: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.963915, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.363828, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.314722, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.975491, learning rate is 0.000400
Net2: layer deconv3:max response is 100.821915, min response is -77.311852.
max gradient is 2.115268, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.870609, min response is -4.047408.
max gradient is 8.000000, min gradient is -7.253454, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.694900, learning rate is 0.000200
Net2: layer bn49:max response is 22.641512, min response is -4.241268.
max gradient is 8.000000, min gradient is -6.844237, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.939110, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.77, min inferred z is -3.97, and std is 0.99
 4.21 s (23.7 data/s) [100/100]
training: epoch 171: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.000497, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.355178, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.500911, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.453294, learning rate is 0.000400
Net2: layer deconv3:max response is 81.206749, min response is -66.813614.
max gradient is 8.000000, min gradient is -5.945769, learning rate is 0.000200
Net2: layer bn50:max response is 21.915180, min response is -4.403591.
max gradient is 6.223961, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.958867, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.291964, min response is -4.573182.
max gradient is 8.000000, min gradient is -5.390349, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.708446, learning rate is 0.000200
max inferred z is 4.20, min inferred z is -3.64, and std is 0.99
 4.23 s (23.6 data/s) [100/100]
training: epoch 171: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.776374, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.257473, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.128257, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.917024, learning rate is 0.000400
Net2: layer deconv3:max response is 81.648331, min response is -63.872276.
max gradient is 5.209967, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.405493, min response is -3.526148.
max gradient is 8.000000, min gradient is -4.969100, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000001, min gradient is -6.862576, learning rate is 0.000200
Net2: layer bn49:max response is 18.703693, min response is -4.127745.
max gradient is 6.471389, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.706242, learning rate is 0.000200
max inferred z is 4.02, min inferred z is -4.00, and std is 0.99
 4.44 s (22.5 data/s) [100/100]
training: epoch 171: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.768911, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.165421, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.523036, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.616729, learning rate is 0.000400
Net2: layer deconv3:max response is 84.473610, min response is -65.061546.
max gradient is 8.000000, min gradient is -2.920975, learning rate is 0.000200
Net2: layer bn50:max response is 19.820042, min response is -3.810904.
max gradient is 7.995267, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.122438, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.924675, min response is -4.350884.
max gradient is 4.820044, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.575927, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.87, min inferred z is -4.02, and std is 0.99
 4.33 s (23.1 data/s) [100/100]
training: epoch 171: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.876511, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.147933, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.260929, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.263565, learning rate is 0.000400
Net2: layer deconv3:max response is 102.497284, min response is -76.169846.
max gradient is 2.549749, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.994400, min response is -4.005742.
max gradient is 8.000000, min gradient is -6.894269, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.243245, learning rate is 0.000200
Net2: layer bn49:max response is 22.901320, min response is -4.307874.
max gradient is 8.000000, min gradient is -6.281375, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.749207, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.08, min inferred z is -3.80, and std is 0.99
 4.38 s (22.8 data/s) [100/100]
training: epoch 171: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.185321, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.517857, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.627688, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.639133, learning rate is 0.000400
Net2: layer deconv3:max response is 89.069687, min response is -68.599625.
max gradient is 8.000000, min gradient is -4.393774, learning rate is 0.000200
Net2: layer bn50:max response is 20.564714, min response is -3.682158.
max gradient is 5.963682, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.535562, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.803097, min response is -4.187765.
max gradient is 6.770538, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.821703, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.77, min inferred z is -4.02, and std is 0.99
 4.26 s (23.5 data/s) [100/100]
training: epoch 171: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.411520, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.273331, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.297814, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 7.523699, min gradient is 1.933759, learning rate is 0.000400
Net2: layer deconv3:max response is 90.391418, min response is -69.026520.
max gradient is 2.705656, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.579973, min response is -3.957074.
max gradient is 8.000000, min gradient is -6.768972, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.321093, learning rate is 0.000200
Net2: layer bn49:max response is 20.300753, min response is -4.090577.
max gradient is 8.000000, min gradient is -6.417331, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.303434, learning rate is 0.000200
max inferred z is 4.33, min inferred z is -3.95, and std is 0.99
 4.40 s (22.7 data/s) [100/100]
training: epoch 171: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.943522, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.447661, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 7.933560, min gradient is -8.000000, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.152623, learning rate is 0.000400
Net2: layer deconv3:max response is 99.360542, min response is -76.740082.
max gradient is 8.000000, min gradient is -1.745689, learning rate is 0.000200
Net2: layer bn50:max response is 20.861803, min response is -3.428854.
max gradient is 5.456823, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.866151, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.791859, min response is -3.584995.
max gradient is 6.010031, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.486557, learning rate is 0.000200
max inferred z is 3.82, min inferred z is -4.29, and std is 0.99
 4.39 s (22.8 data/s) [100/100]
training: epoch 171: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.445312, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.504336, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.273145, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.234978, learning rate is 0.000400
Net2: layer deconv3:max response is 94.267845, min response is -71.400764.
max gradient is 2.188340, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.074604, min response is -3.574677.
max gradient is 8.000000, min gradient is -5.940917, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.766336, learning rate is 0.000200
Net2: layer bn49:max response is 20.681997, min response is -4.183849.
max gradient is 8.000000, min gradient is -5.833076, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.424805, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.06, min inferred z is -4.33, and std is 0.99
 4.29 s (23.3 data/s) [100/100]
training: epoch 171: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.605956, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.908159, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.575819, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.034455, learning rate is 0.000400
Net2: layer deconv3:max response is 89.811188, min response is -68.974190.
max gradient is 8.000000, min gradient is -4.210422, learning rate is 0.000200
Net2: layer bn50:max response is 19.264114, min response is -3.696680.
max gradient is 5.684261, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.336493, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.990011, min response is -3.978959.
max gradient is 6.950398, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.721703, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.86, min inferred z is -3.70, and std is 0.99
 4.28 s (23.4 data/s) [100/100]
Loss: 1.0474
Iteration 172 / 200
training: epoch 172: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.058112, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.118144, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.525013, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.519817, learning rate is 0.000400
Net2: layer deconv3:max response is 91.115570, min response is -69.003410.
max gradient is 4.557201, min gradient is -8.000001, learning rate is 0.000200
Net2: layer bn50:max response is 20.179998, min response is -4.149726.
max gradient is 8.000000, min gradient is -4.729423, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.865271, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.832533, min response is -4.096415.
max gradient is 6.228664, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.778866, learning rate is 0.000200
max inferred z is 4.07, min inferred z is -4.15, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
training: epoch 172: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.901435, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.435280, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.227006, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.073346, learning rate is 0.000400
Net2: layer deconv3:max response is 83.808083, min response is -66.802109.
max gradient is 8.000000, min gradient is -5.433909, learning rate is 0.000200
Net2: layer bn50:max response is 23.212458, min response is -4.496908.
max gradient is 5.100471, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.227313, learning rate is 0.000200
Net2: layer bn49:max response is 18.941887, min response is -4.347693.
max gradient is 8.000000, min gradient is -6.537451, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.879500, learning rate is 0.000200
max inferred z is 3.93, min inferred z is -3.82, and std is 1.00
 4.18 s (23.9 data/s) [100/100]
training: epoch 172: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.890890, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.284849, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.758848, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.867476, learning rate is 0.000400
Net2: layer deconv3:max response is 104.666519, min response is -78.093758.
max gradient is 8.000000, min gradient is -6.271553, learning rate is 0.000200
Net2: layer bn50:max response is 22.326097, min response is -4.304275.
max gradient is 8.000000, min gradient is -7.721664, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.095170, learning rate is 0.000200
Net2: layer bn49:max response is 23.466633, min response is -3.867235.
max gradient is 5.698672, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.953906, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.78, min inferred z is -3.95, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
training: epoch 172: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.649343, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.158664, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.124298, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.844336, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 94.565018, min response is -66.947792.
max gradient is 2.793537, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.761387, min response is -4.130192.
max gradient is 8.000000, min gradient is -7.138783, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.622155, learning rate is 0.000200
Net2: layer bn49:max response is 20.922438, min response is -4.557135.
max gradient is 8.000000, min gradient is -5.369483, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.738208, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.58, min inferred z is -3.98, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 172: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.926432, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.133450, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.362993, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.365466, learning rate is 0.000400
Net2: layer deconv3:max response is 81.717224, min response is -61.410889.
max gradient is 8.000000, min gradient is -4.128173, learning rate is 0.000200
Net2: layer bn50:max response is 19.643040, min response is -3.704115.
max gradient is 6.508091, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.081398, learning rate is 0.000200
Net2: layer bn49:max response is 18.752888, min response is -3.542311.
max gradient is 6.710452, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.602958, learning rate is 0.000200
max inferred z is 4.13, min inferred z is -3.81, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 172: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.071249, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.534988, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.632260, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.931976, learning rate is 0.000400
Net2: layer deconv3:max response is 93.500671, min response is -68.799728.
max gradient is 4.988892, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.938696, min response is -4.136173.
max gradient is 8.000000, min gradient is -3.631607, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.089812, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.081322, min response is -3.802484.
max gradient is 7.392732, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.494347, learning rate is 0.000200
max inferred z is 3.84, min inferred z is -4.19, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 172: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.567734, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.358892, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.635367, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.625523, learning rate is 0.000400
Net2: layer deconv3:max response is 78.891151, min response is -58.687004.
max gradient is 3.895960, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 17.785118, min response is -3.416333.
max gradient is 8.000000, min gradient is -3.878552, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.261176, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.266762, min response is -4.122098.
max gradient is 8.000000, min gradient is -6.642667, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.624953, learning rate is 0.000200
max inferred z is 3.57, min inferred z is -3.97, and std is 1.00
 4.34 s (23.1 data/s) [100/100]
training: epoch 172: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.524611, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.496669, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.642247, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.692065, learning rate is 0.000400
Net2: layer deconv3:max response is 95.124001, min response is -70.281387.
max gradient is 8.000000, min gradient is -6.045833, learning rate is 0.000200
Net2: layer bn50:max response is 20.616199, min response is -3.557824.
max gradient is 3.630816, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.506052, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.278923, min response is -3.854613.
max gradient is 8.000000, min gradient is -6.919852, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.597872, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.11, min inferred z is -4.16, and std is 1.00
 4.21 s (23.7 data/s) [100/100]
training: epoch 172: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.877418, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.240697, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 7.922389, min gradient is -8.000000, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.988622, learning rate is 0.000400
Net2: layer deconv3:max response is 87.041267, min response is -64.791550.
max gradient is 8.000000, min gradient is -4.238299, learning rate is 0.000200
Net2: layer bn50:max response is 18.012524, min response is -3.282969.
max gradient is 8.000000, min gradient is -7.742620, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.373611, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.931232, min response is -3.815649.
max gradient is 4.810885, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.500912, learning rate is 0.000200
max inferred z is 3.90, min inferred z is -3.79, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 172: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.730320, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.534860, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.575261, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.525189, learning rate is 0.000400
Net2: layer deconv3:max response is 93.986458, min response is -70.961983.
max gradient is 2.791529, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.543146, min response is -4.330642.
max gradient is 8.000000, min gradient is -7.487900, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.848259, learning rate is 0.000200
Net2: layer bn49:max response is 20.917345, min response is -5.099439.
max gradient is 8.000000, min gradient is -6.512108, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.991254, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.83, min inferred z is -3.91, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
Loss: 1.0549
Iteration 173 / 200
training: epoch 173: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.838215, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.466217, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.683353, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.616158, learning rate is 0.000400
Net2: layer deconv3:max response is 113.389053, min response is -83.111069.
max gradient is 2.941646, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.796911, min response is -3.989665.
max gradient is 8.000000, min gradient is -6.784127, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.227918, learning rate is 0.000200
Net2: layer bn49:max response is 25.049259, min response is -4.357408.
max gradient is 8.000000, min gradient is -6.766537, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.613530, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.37, min inferred z is -4.14, and std is 1.00
 4.19 s (23.9 data/s) [100/100]
training: epoch 173: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.979312, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.228362, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.551538, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -6.955845, learning rate is 0.000400
Net2: layer deconv3:max response is 82.665123, min response is -61.262699.
max gradient is 8.000000, min gradient is -1.668544, learning rate is 0.000200
Net2: layer bn50:max response is 19.794582, min response is -3.629305.
max gradient is 4.926162, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.785551, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.801802, min response is -4.305028.
max gradient is 5.975058, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.139934, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.13, min inferred z is -4.33, and std is 1.00
 4.19 s (23.9 data/s) [100/100]
training: epoch 173: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.701538, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.266233, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.252022, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.227308, learning rate is 0.000400
Net2: layer deconv3:max response is 95.226685, min response is -73.556709.
max gradient is 8.000000, min gradient is -5.632880, learning rate is 0.000200
Net2: layer bn50:max response is 24.980457, min response is -4.606943.
max gradient is 4.084847, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.198052, learning rate is 0.000200
Net2: layer bn49:max response is 21.277647, min response is -5.314589.
max gradient is 7.994836, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.388755, learning rate is 0.000200
max inferred z is 4.09, min inferred z is -4.22, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 173: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.710439, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.363997, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.730940, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.694574, learning rate is 0.000400
Net2: layer deconv3:max response is 84.906784, min response is -65.748131.
max gradient is 5.696056, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.450554, min response is -3.260900.
max gradient is 8.000000, min gradient is -5.885786, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.902254, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.504787, min response is -4.135798.
max gradient is 8.000000, min gradient is -7.425613, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.484804, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.88, min inferred z is -3.96, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
training: epoch 173: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.101835, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.160427, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.859764, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.173545, learning rate is 0.000400
Net2: layer deconv3:max response is 91.371399, min response is -68.362541.
max gradient is 6.658928, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.401686, min response is -3.993387.
max gradient is 8.000000, min gradient is -5.160817, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.433486, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.318180, min response is -4.599670.
max gradient is 7.023563, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.563919, learning rate is 0.000200
max inferred z is 4.20, min inferred z is -3.74, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 173: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.918186, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.281273, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.255227, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -2.515612, min gradient is -6.411333, learning rate is 0.000400
Net2: layer deconv3:max response is 103.955696, min response is -77.620621.
max gradient is 8.000000, min gradient is -6.794848, learning rate is 0.000200
Net2: layer bn50:max response is 22.054546, min response is -3.985812.
max gradient is 5.125412, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.518610, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 23.170301, min response is -3.986215.
max gradient is 8.000000, min gradient is -7.496407, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.976666, learning rate is 0.000200
max inferred z is 4.24, min inferred z is -4.59, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 173: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.312907, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.444307, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.664660, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.061295, learning rate is 0.000400
Net2: layer deconv3:max response is 98.243652, min response is -72.361290.
max gradient is 8.000000, min gradient is -4.778044, learning rate is 0.000200
Net2: layer bn50:max response is 21.057207, min response is -3.777987.
max gradient is 5.090879, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.875937, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 22.087782, min response is -3.883608.
max gradient is 8.000000, min gradient is -7.565265, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.927146, learning rate is 0.000200
max inferred z is 3.79, min inferred z is -3.76, and std is 1.00
 4.21 s (23.8 data/s) [100/100]
training: epoch 173: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.718387, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.503558, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.901202, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.900857, learning rate is 0.000400
Net2: layer deconv3:max response is 98.128815, min response is -73.817009.
max gradient is 5.652946, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.590952, min response is -4.413243.
max gradient is 8.000001, min gradient is -4.168927, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.107857, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.566370, min response is -3.990033.
max gradient is 7.128801, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.057879, learning rate is 0.000200
max inferred z is 3.77, min inferred z is -3.59, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 173: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.529982, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.534293, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.517380, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.325807, learning rate is 0.000400
Net2: layer deconv3:max response is 97.925514, min response is -76.077095.
max gradient is 2.856361, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 24.970207, min response is -4.209011.
max gradient is 8.000000, min gradient is -6.166585, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.619902, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.892174, min response is -5.218418.
max gradient is 7.500921, min gradient is -8.000001, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.718944, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.85, min inferred z is -4.19, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 173: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.610789, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.802343, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.608078, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.077810, learning rate is 0.000400
Net2: layer deconv3:max response is 79.150696, min response is -62.272568.
max gradient is 8.000000, min gradient is -3.336468, learning rate is 0.000200
Net2: layer bn50:max response is 18.413734, min response is -3.833102.
max gradient is 5.003858, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.303921, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.697109, min response is -3.865566.
max gradient is 7.300889, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.022284, learning rate is 0.000200
max inferred z is 3.67, min inferred z is -4.02, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
Loss: 1.0894
Iteration 174 / 200
training: epoch 174: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.949336, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.233586, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.361845, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.325329, learning rate is 0.000400
Net2: layer deconv3:max response is 86.990303, min response is -63.306332.
max gradient is 5.936095, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.454893, min response is -3.694245.
max gradient is 6.544068, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.681499, learning rate is 0.000200
Net2: layer bn49:max response is 19.650293, min response is -4.007511.
max gradient is 7.921011, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.102434, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.94, min inferred z is -3.86, and std is 1.01
 4.25 s (23.5 data/s) [100/100]
training: epoch 174: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.973302, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.371954, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.394615, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.079381, learning rate is 0.000400
Net2: layer deconv3:max response is 98.771141, min response is -77.576614.
max gradient is 8.000000, min gradient is -4.783819, learning rate is 0.000200
Net2: layer bn50:max response is 23.487017, min response is -3.950126.
max gradient is 7.713723, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.786762, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 22.022554, min response is -4.474612.
max gradient is 7.085593, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.171614, learning rate is 0.000200
max inferred z is 4.11, min inferred z is -3.98, and std is 1.01
 4.34 s (23.0 data/s) [100/100]
training: epoch 174: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.696552, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.292117, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.267302, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.943540, learning rate is 0.000400
Net2: layer deconv3:max response is 104.680367, min response is -79.173225.
max gradient is 3.102910, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.832712, min response is -3.953648.
max gradient is 8.000000, min gradient is -5.420275, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.273741, learning rate is 0.000200
Net2: layer bn49:max response is 22.807550, min response is -4.527234.
max gradient is 7.587072, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.664793, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.79, min inferred z is -3.72, and std is 1.01
 4.17 s (24.0 data/s) [100/100]
training: epoch 174: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.713335, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.100041, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.507072, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.328079, learning rate is 0.000400
Net2: layer deconv3:max response is 91.474236, min response is -65.499390.
max gradient is 8.000000, min gradient is -4.663177, learning rate is 0.000200
Net2: layer bn50:max response is 19.498133, min response is -4.056058.
max gradient is 5.964364, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.269948, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.383310, min response is -4.102720.
max gradient is 8.000000, min gradient is -6.512587, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.146583, learning rate is 0.000200
max inferred z is 4.00, min inferred z is -3.89, and std is 1.01
 4.21 s (23.7 data/s) [100/100]
training: epoch 174: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.985854, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.178806, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.511254, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.359000, learning rate is 0.000400
Net2: layer deconv3:max response is 85.267792, min response is -62.780449.
max gradient is 4.051937, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 17.810715, min response is -3.277557.
max gradient is 8.000000, min gradient is -6.450633, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.103931, learning rate is 0.000200
Net2: layer bn49:max response is 18.532764, min response is -4.296134.
max gradient is 7.254211, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.842522, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.16, min inferred z is -3.94, and std is 1.01
 4.40 s (22.7 data/s) [100/100]
training: epoch 174: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.679992, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.711367, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.352429, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.722234, learning rate is 0.000400
Net2: layer deconv3:max response is 94.760376, min response is -70.176056.
max gradient is 8.000000, min gradient is -6.307436, learning rate is 0.000200
Net2: layer bn50:max response is 20.500713, min response is -3.601161.
max gradient is 6.862383, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.901168, learning rate is 0.000200
Net2: layer bn49:max response is 21.122730, min response is -3.982723.
max gradient is 7.313650, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.867290, learning rate is 0.000200
max inferred z is 3.64, min inferred z is -4.33, and std is 1.01
 4.38 s (22.8 data/s) [100/100]
training: epoch 174: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.403816, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.358916, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.504446, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.500928, learning rate is 0.000400
Net2: layer deconv3:max response is 97.590553, min response is -72.623329.
max gradient is 7.242969, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.957642, min response is -4.013724.
max gradient is 5.160316, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.747936, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 22.108969, min response is -4.124608.
max gradient is 8.000001, min gradient is -6.530825, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.720390, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.81, min inferred z is -4.20, and std is 1.01
 4.39 s (22.8 data/s) [100/100]
training: epoch 174: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.568832, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.509984, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.700335, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.380358, learning rate is 0.000400
Net2: layer deconv3:max response is 92.342690, min response is -76.345230.
max gradient is 4.309193, min gradient is -8.000001, learning rate is 0.000200
Net2: layer bn50:max response is 25.585392, min response is -4.806928.
max gradient is 4.712041, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.658490, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.128811, min response is -5.411682.
max gradient is 8.000000, min gradient is -7.089528, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.980713, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.32, min inferred z is -3.77, and std is 1.01
 4.40 s (22.8 data/s) [100/100]
training: epoch 174: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.716312, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.489948, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 7.808355, min gradient is -8.000000, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.755808, learning rate is 0.000400
Net2: layer deconv3:max response is 87.493240, min response is -66.697334.
max gradient is 8.000000, min gradient is -4.818455, learning rate is 0.000200
Net2: layer bn50:max response is 19.988070, min response is -4.147698.
max gradient is 7.349930, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.868910, learning rate is 0.000200
Net2: layer bn49:max response is 19.607502, min response is -3.928021.
max gradient is 6.945630, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.611772, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.45, min inferred z is -3.58, and std is 1.01
 4.36 s (22.9 data/s) [100/100]
training: epoch 174: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.543328, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.492591, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.414153, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -1.367033, min gradient is -4.338863, learning rate is 0.000400
Net2: layer deconv3:max response is 84.030571, min response is -61.117722.
max gradient is 3.704335, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 17.931465, min response is -3.488373.
max gradient is 8.000000, min gradient is -6.655831, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.205820, learning rate is 0.000200
Net2: layer bn49:max response is 18.416227, min response is -4.084555.
max gradient is 8.000000, min gradient is -7.732294, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.166689, learning rate is 0.000200
max inferred z is 3.98, min inferred z is -4.12, and std is 1.01
 4.43 s (22.6 data/s) [100/100]
Loss: 1.0509
Iteration 175 / 200
training: epoch 175: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.769893, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.377576, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.389860, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.871127, learning rate is 0.000400
Net2: layer deconv3:max response is 96.059013, min response is -80.253525.
max gradient is 8.000001, min gradient is -3.662482, learning rate is 0.000200
Net2: layer bn50:max response is 25.078032, min response is -4.114528.
max gradient is 8.000000, min gradient is -7.842181, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.431213, learning rate is 0.000200
Net2: layer bn49:max response is 18.915508, min response is -5.208464.
max gradient is 6.346660, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.544814, learning rate is 0.000200
max inferred z is 3.78, min inferred z is -3.53, and std is 1.00
 4.21 s (23.8 data/s) [100/100]
training: epoch 175: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.837154, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.573142, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.146101, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.552334, learning rate is 0.000400
Net2: layer deconv3:max response is 101.027931, min response is -78.828171.
max gradient is 7.184123, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.924887, min response is -4.075151.
max gradient is 8.000000, min gradient is -4.465174, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.926781, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 22.326340, min response is -4.201834.
max gradient is 8.000000, min gradient is -5.933051, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.785649, learning rate is 0.000200
max inferred z is 4.00, min inferred z is -3.98, and std is 1.00
 4.17 s (24.0 data/s) [100/100]
training: epoch 175: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.782938, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.297331, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.134330, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.036990, learning rate is 0.000400
Net2: layer deconv3:max response is 85.025192, min response is -62.309677.
max gradient is 5.684557, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.131523, min response is -3.595458.
max gradient is 5.050511, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.735657, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.147957, min response is -4.237068.
max gradient is 7.066480, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.881291, learning rate is 0.000200
max inferred z is 3.81, min inferred z is -4.14, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
training: epoch 175: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.738865, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.302383, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.459907, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.117104, learning rate is 0.000400
Net2: layer deconv3:max response is 98.594864, min response is -83.801414.
max gradient is 8.000000, min gradient is -5.674743, learning rate is 0.000200
Net2: layer bn50:max response is 25.046116, min response is -4.001766.
max gradient is 8.000000, min gradient is -7.282698, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.001401, learning rate is 0.000200
Net2: layer bn49:max response is 20.427761, min response is -5.234704.
max gradient is 7.586026, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.970271, learning rate is 0.000200
max inferred z is 4.27, min inferred z is -4.28, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
training: epoch 175: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.070239, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.253100, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.578410, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.173800, learning rate is 0.000400
Net2: layer deconv3:max response is 117.322639, min response is -87.014275.
max gradient is 7.514631, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 25.931377, min response is -5.425893.
max gradient is 7.388281, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.029840, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 26.600523, min response is -4.107982.
max gradient is 7.525113, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.425536, learning rate is 0.000200
max inferred z is 4.19, min inferred z is -4.09, and std is 1.00
 4.17 s (24.0 data/s) [100/100]
training: epoch 175: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.770251, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.406016, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.232831, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.844685, learning rate is 0.000400
Net2: layer deconv3:max response is 90.424507, min response is -67.393074.
max gradient is 3.757763, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.491251, min response is -3.702431.
max gradient is 8.000000, min gradient is -6.206305, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.370309, learning rate is 0.000200
Net2: layer bn49:max response is 19.883907, min response is -4.267260.
max gradient is 7.029942, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.146117, learning rate is 0.000200
max inferred z is 3.98, min inferred z is -3.71, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 175: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.425453, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.457401, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.560085, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.877873, learning rate is 0.000400
Net2: layer deconv3:max response is 99.732452, min response is -74.687637.
max gradient is 8.000000, min gradient is -3.323813, learning rate is 0.000200
Net2: layer bn50:max response is 21.140636, min response is -3.955969.
max gradient is 8.000000, min gradient is -7.139384, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.308629, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 22.505873, min response is -4.010305.
max gradient is 8.000000, min gradient is -7.153169, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.007785, learning rate is 0.000200
max inferred z is 4.29, min inferred z is -4.02, and std is 1.00
 4.21 s (23.7 data/s) [100/100]
training: epoch 175: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.745912, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.518719, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.742028, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000001, min gradient is 7.684460, learning rate is 0.000400
Net2: layer deconv3:max response is 84.165321, min response is -67.836815.
max gradient is 3.742688, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.250889, min response is -3.834731.
max gradient is 8.000000, min gradient is -7.178617, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.335519, learning rate is 0.000200
Net2: layer bn49:max response is 18.985048, min response is -4.256983.
max gradient is 8.000000, min gradient is -4.574481, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.702036, min gradient is -8.000001, learning rate is 0.000200
max inferred z is 3.80, min inferred z is -4.19, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 175: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.788511, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.399642, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.906963, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.778710, learning rate is 0.000400
Net2: layer deconv3:max response is 88.062714, min response is -65.610748.
max gradient is 6.751498, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.546276, min response is -3.680951.
max gradient is 8.000000, min gradient is -6.115448, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.260815, learning rate is 0.000200
Net2: layer bn49:max response is 19.459602, min response is -4.539484.
max gradient is 6.254392, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.002656, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.28, min inferred z is -4.11, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 175: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.580047, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.939960, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.189614, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.367040, learning rate is 0.000400
Net2: layer deconv3:max response is 98.551704, min response is -72.337265.
max gradient is 8.000001, min gradient is -7.372315, learning rate is 0.000200
Net2: layer bn50:max response is 20.327126, min response is -4.077550.
max gradient is 7.598253, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.921566, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.717806, min response is -4.303861.
max gradient is 8.000000, min gradient is -7.445759, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.067286, learning rate is 0.000200
max inferred z is 4.19, min inferred z is -4.92, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
Loss: 1.0421
Iteration 176 / 200
training: epoch 176: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.969247, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.281208, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.396357, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.578123, learning rate is 0.000400
Net2: layer deconv3:max response is 114.419212, min response is -85.039116.
max gradient is 8.000000, min gradient is -6.488750, learning rate is 0.000200
Net2: layer bn50:max response is 24.103193, min response is -4.425137.
max gradient is 8.000000, min gradient is -7.078618, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.587801, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 25.717642, min response is -3.791803.
max gradient is 8.000000, min gradient is -6.342213, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.198002, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.88, min inferred z is -4.05, and std is 1.01
 4.27 s (23.4 data/s) [100/100]
training: epoch 176: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.943446, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.289316, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.523981, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.551599, learning rate is 0.000400
Net2: layer deconv3:max response is 102.763870, min response is -76.020020.
max gradient is 4.071525, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.577507, min response is -3.966546.
max gradient is 8.000000, min gradient is -5.502109, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.349807, learning rate is 0.000200
Net2: layer bn49:max response is 23.232321, min response is -3.979669.
max gradient is 6.803245, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.576053, learning rate is 0.000200
max inferred z is 4.54, min inferred z is -3.50, and std is 1.01
 4.20 s (23.8 data/s) [100/100]
training: epoch 176: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.653641, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.344247, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.988433, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.655543, learning rate is 0.000400
Net2: layer deconv3:max response is 88.025993, min response is -65.769661.
max gradient is 2.705426, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.672041, min response is -3.894794.
max gradient is 8.000000, min gradient is -6.992593, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.235193, learning rate is 0.000200
Net2: layer bn49:max response is 19.925720, min response is -3.477644.
max gradient is 8.000000, min gradient is -6.256464, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.350508, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.20, min inferred z is -3.52, and std is 1.01
 4.37 s (22.9 data/s) [100/100]
training: epoch 176: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.606997, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.496574, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.539405, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.766880, learning rate is 0.000400
Net2: layer deconv3:max response is 84.583206, min response is -64.747009.
max gradient is 8.000000, min gradient is -3.207660, learning rate is 0.000200
Net2: layer bn50:max response is 20.621548, min response is -4.075679.
max gradient is 5.703228, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.589931, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.068741, min response is -4.272857.
max gradient is 7.193124, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.217434, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.58, min inferred z is -3.70, and std is 1.01
 4.43 s (22.5 data/s) [100/100]
training: epoch 176: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.006052, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.194954, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.593667, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.758039, learning rate is 0.000400
Net2: layer deconv3:max response is 100.660294, min response is -76.972237.
max gradient is 8.000000, min gradient is -3.584084, learning rate is 0.000200
Net2: layer bn50:max response is 23.539684, min response is -4.194071.
max gradient is 6.650971, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000001, min gradient is -6.422428, learning rate is 0.000200
Net2: layer bn49:max response is 21.797283, min response is -5.076156.
max gradient is 5.786777, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.401524, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.91, min inferred z is -4.28, and std is 1.01
 4.35 s (23.0 data/s) [100/100]
training: epoch 176: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.945669, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.418501, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.403580, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -4.886080, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 87.264496, min response is -69.010330.
max gradient is 2.190097, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.716537, min response is -3.592869.
max gradient is 8.000000, min gradient is -6.275853, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.695237, learning rate is 0.000200
Net2: layer bn49:max response is 19.189850, min response is -4.818501.
max gradient is 8.000000, min gradient is -5.279340, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.367960, learning rate is 0.000200
max inferred z is 3.86, min inferred z is -3.49, and std is 1.01
 4.38 s (22.8 data/s) [100/100]
training: epoch 176: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.507486, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.341271, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.547585, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.200406, learning rate is 0.000400
Net2: layer deconv3:max response is 98.559929, min response is -70.311081.
max gradient is 5.229980, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.669556, min response is -4.002959.
max gradient is 8.000000, min gradient is -6.012130, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.953867, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.777731, min response is -4.667881.
max gradient is 8.000000, min gradient is -5.544963, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.482995, learning rate is 0.000200
max inferred z is 3.66, min inferred z is -4.13, and std is 1.01
 4.38 s (22.9 data/s) [100/100]
training: epoch 176: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.616342, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.421068, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.975764, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.607558, learning rate is 0.000400
Net2: layer deconv3:max response is 88.897148, min response is -66.215561.
max gradient is 8.000000, min gradient is -4.079891, learning rate is 0.000200
Net2: layer bn50:max response is 18.870340, min response is -3.547437.
max gradient is 5.839093, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.464256, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.530638, min response is -4.149988.
max gradient is 6.721488, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.916734, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.80, min inferred z is -3.87, and std is 1.01
 4.34 s (23.0 data/s) [100/100]
training: epoch 176: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.720344, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.371204, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.399680, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.782255, learning rate is 0.000400
Net2: layer deconv3:max response is 118.084198, min response is -86.257507.
max gradient is 4.750644, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 24.426153, min response is -4.376667.
max gradient is 7.899564, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.445638, learning rate is 0.000200
Net2: layer bn49:max response is 25.923830, min response is -4.444730.
max gradient is 5.534520, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.520453, learning rate is 0.000200
max inferred z is 3.64, min inferred z is -4.27, and std is 1.01
 4.28 s (23.4 data/s) [100/100]
training: epoch 176: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.725230, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.733411, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.348077, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.965936, learning rate is 0.000400
Net2: layer deconv3:max response is 87.255432, min response is -68.317657.
max gradient is 8.000000, min gradient is -5.383365, learning rate is 0.000200
Net2: layer bn50:max response is 19.176458, min response is -3.637314.
max gradient is 4.870069, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.222916, learning rate is 0.000200
Net2: layer bn49:max response is 19.679207, min response is -4.253635.
max gradient is 8.000000, min gradient is -7.628718, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.557286, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.96, min inferred z is -4.29, and std is 1.01
 4.26 s (23.5 data/s) [100/100]
Loss: 1.1048
Iteration 177 / 200
training: epoch 177: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.848691, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.369686, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.515702, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.831549, learning rate is 0.000400
Net2: layer deconv3:max response is 99.906990, min response is -71.619759.
max gradient is 2.423623, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.677208, min response is -3.993910.
max gradient is 8.000000, min gradient is -6.131398, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.654696, learning rate is 0.000200
Net2: layer bn49:max response is 22.218973, min response is -3.858032.
max gradient is 7.937229, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.982924, learning rate is 0.000200
max inferred z is 3.51, min inferred z is -4.11, and std is 1.00
 4.14 s (24.2 data/s) [100/100]
training: epoch 177: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.991705, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.362076, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.408934, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.035116, learning rate is 0.000400
Net2: layer deconv3:max response is 91.622185, min response is -66.410400.
max gradient is 8.000000, min gradient is -4.769890, learning rate is 0.000200
Net2: layer bn50:max response is 20.271353, min response is -3.696906.
max gradient is 7.234060, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.686801, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.646997, min response is -4.319579.
max gradient is 7.972516, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.342522, learning rate is 0.000200
max inferred z is 4.02, min inferred z is -4.03, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
training: epoch 177: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.829326, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.377951, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.162201, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.853329, learning rate is 0.000400
Net2: layer deconv3:max response is 91.054588, min response is -67.609138.
max gradient is 8.000000, min gradient is -6.963079, learning rate is 0.000200
Net2: layer bn50:max response is 19.163860, min response is -3.426010.
max gradient is 4.940208, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.819471, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.917175, min response is -3.823757.
max gradient is 7.872627, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.452062, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.65, min inferred z is -4.48, and std is 1.00
 4.21 s (23.7 data/s) [100/100]
training: epoch 177: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.876451, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.194027, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.569669, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.943551, learning rate is 0.000400
Net2: layer deconv3:max response is 94.122299, min response is -71.261383.
max gradient is 8.000000, min gradient is -7.466195, learning rate is 0.000200
Net2: layer bn50:max response is 19.546841, min response is -4.097541.
max gradient is 8.000000, min gradient is -5.283158, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.653556, learning rate is 0.000200
Net2: layer bn49:max response is 20.626024, min response is -4.074701.
max gradient is 8.000000, min gradient is -7.241521, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.418754, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.06, min inferred z is -4.13, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
training: epoch 177: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.793072, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.295870, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.991416, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.786810, learning rate is 0.000400
Net2: layer deconv3:max response is 100.355850, min response is -72.739792.
max gradient is 7.315096, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.039900, min response is -4.353078.
max gradient is 7.662435, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.393312, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 22.547846, min response is -3.853785.
max gradient is 7.157062, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.487843, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.46, min inferred z is -3.53, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 177: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.012037, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.509278, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.614542, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 0.705318, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 93.284668, min response is -72.070580.
max gradient is 8.000000, min gradient is -5.046914, learning rate is 0.000200
Net2: layer bn50:max response is 22.845600, min response is -4.494521.
max gradient is 7.928893, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.616259, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.253004, min response is -4.483522.
max gradient is 8.000000, min gradient is -7.013828, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.201874, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.02, min inferred z is -3.86, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 177: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.422296, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.280448, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.600897, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.740168, learning rate is 0.000400
Net2: layer deconv3:max response is 81.610512, min response is -62.663086.
max gradient is 8.000000, min gradient is -4.758764, learning rate is 0.000200
Net2: layer bn50:max response is 21.249744, min response is -3.736171.
max gradient is 6.525482, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.590282, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.903290, min response is -3.914518.
max gradient is 5.666791, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.226798, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.63, min inferred z is -4.72, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 177: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.812236, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.344459, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.311130, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -5.969859, min gradient is -7.139097, learning rate is 0.000400
Net2: layer deconv3:max response is 84.149109, min response is -64.742706.
max gradient is 1.795132, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.169142, min response is -3.224774.
max gradient is 8.000000, min gradient is -6.007083, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.753862, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.863159, min response is -4.299323.
max gradient is 8.000000, min gradient is -5.161900, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.406084, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.66, min inferred z is -3.51, and std is 1.00
 4.43 s (22.6 data/s) [100/100]
training: epoch 177: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.316652, min gradient is -8.000001, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.627558, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.364044, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.305921, learning rate is 0.000400
Net2: layer deconv3:max response is 81.924103, min response is -59.878819.
max gradient is 3.893816, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.731089, min response is -3.502789.
max gradient is 8.000000, min gradient is -6.032131, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.523241, learning rate is 0.000200
Net2: layer bn49:max response is 18.534832, min response is -4.168533.
max gradient is 8.000000, min gradient is -6.191436, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.967210, learning rate is 0.000200
max inferred z is 3.83, min inferred z is -4.32, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 177: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.927160, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.431087, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.958262, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 2.787987, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 135.436554, min response is -105.050316.
max gradient is 8.000000, min gradient is -2.877411, learning rate is 0.000200
Net2: layer bn50:max response is 28.654568, min response is -4.850374.
max gradient is 6.032808, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.635907, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 30.870039, min response is -4.555573.
max gradient is 5.748505, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.854256, learning rate is 0.000200
max inferred z is 3.80, min inferred z is -3.80, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
Loss: 1.1227
Iteration 178 / 200
training: epoch 178: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.959693, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.301209, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.393235, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.414800, learning rate is 0.000400
Net2: layer deconv3:max response is 109.769318, min response is -78.948021.
max gradient is 8.000000, min gradient is -6.705795, learning rate is 0.000200
Net2: layer bn50:max response is 23.097565, min response is -4.730640.
max gradient is 8.000000, min gradient is -6.201589, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.976583, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 24.814011, min response is -3.971577.
max gradient is 7.270276, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.654784, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.85, min inferred z is -4.08, and std is 0.99
 4.23 s (23.7 data/s) [100/100]
training: epoch 178: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.859429, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.258149, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.290831, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.791327, learning rate is 0.000400
Net2: layer deconv3:max response is 97.135452, min response is -66.864639.
max gradient is 2.606073, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.613323, min response is -4.434457.
max gradient is 8.000000, min gradient is -5.984162, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.149405, learning rate is 0.000200
Net2: layer bn49:max response is 21.998672, min response is -4.091138.
max gradient is 8.000000, min gradient is -5.156780, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.180152, learning rate is 0.000200
max inferred z is 4.09, min inferred z is -3.80, and std is 0.99
 4.28 s (23.4 data/s) [100/100]
training: epoch 178: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.800965, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.287690, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.559990, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.064162, learning rate is 0.000400
Net2: layer deconv3:max response is 90.928024, min response is -67.421623.
max gradient is 8.000000, min gradient is -5.244063, learning rate is 0.000200
Net2: layer bn50:max response is 19.153364, min response is -3.627426.
max gradient is 7.149848, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.774622, learning rate is 0.000200
Net2: layer bn49:max response is 20.640621, min response is -4.229141.
max gradient is 6.655971, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.626535, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.80, min inferred z is -3.72, and std is 0.99
 4.26 s (23.5 data/s) [100/100]
training: epoch 178: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.671770, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.169914, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.357041, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -2.920178, min gradient is -5.082161, learning rate is 0.000400
Net2: layer deconv3:max response is 98.756615, min response is -73.890915.
max gradient is 2.954456, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.017149, min response is -3.703521.
max gradient is 8.000000, min gradient is -6.776551, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.715673, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.787127, min response is -5.189085.
max gradient is 7.679430, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.773415, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.88, min inferred z is -4.08, and std is 0.99
 4.45 s (22.5 data/s) [100/100]
training: epoch 178: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.886300, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.177240, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.360680, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.076812, learning rate is 0.000400
Net2: layer deconv3:max response is 107.763000, min response is -78.393646.
max gradient is 8.000000, min gradient is -3.815379, learning rate is 0.000200
Net2: layer bn50:max response is 22.800274, min response is -4.441050.
max gradient is 5.998287, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.431683, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 24.604204, min response is -4.655918.
max gradient is 8.000000, min gradient is -6.336272, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.990921, learning rate is 0.000200
max inferred z is 3.62, min inferred z is -4.14, and std is 0.99
 4.48 s (22.3 data/s) [100/100]
training: epoch 178: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.834958, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.627942, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.196604, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.655396, learning rate is 0.000400
Net2: layer deconv3:max response is 99.844627, min response is -75.373398.
max gradient is 5.004289, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.435516, min response is -3.358329.
max gradient is 8.000000, min gradient is -4.493697, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.359242, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.919451, min response is -3.648452.
max gradient is 7.691821, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.988820, learning rate is 0.000200
max inferred z is 4.26, min inferred z is -3.64, and std is 0.99
 4.36 s (22.9 data/s) [100/100]
training: epoch 178: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.237349, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.484749, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.469893, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.228493, learning rate is 0.000400
Net2: layer deconv3:max response is 87.575897, min response is -71.036354.
max gradient is 4.212095, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.937963, min response is -4.666784.
max gradient is 8.000000, min gradient is -6.162936, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.951254, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.520857, min response is -4.321790.
max gradient is 8.000000, min gradient is -7.285808, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.223170, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.68, min inferred z is -3.73, and std is 0.99
 4.44 s (22.5 data/s) [100/100]
training: epoch 178: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.551116, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.592530, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.544616, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.928833, learning rate is 0.000400
Net2: layer deconv3:max response is 75.962791, min response is -64.022148.
max gradient is 8.000000, min gradient is -2.124487, learning rate is 0.000200
Net2: layer bn50:max response is 20.042929, min response is -3.625770.
max gradient is 4.768176, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.095627, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.389288, min response is -4.416232.
max gradient is 6.234739, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.385771, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.61, min inferred z is -3.81, and std is 0.99
 4.34 s (23.1 data/s) [100/100]
training: epoch 178: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.752564, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.361348, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.485506, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.525394, learning rate is 0.000400
Net2: layer deconv3:max response is 147.959152, min response is -109.319115.
max gradient is 3.884602, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 29.952684, min response is -5.327382.
max gradient is 8.000000, min gradient is -5.782204, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.697342, learning rate is 0.000200
Net2: layer bn49:max response is 32.193466, min response is -4.027466.
max gradient is 8.000000, min gradient is -7.350057, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.157964, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.22, min inferred z is -4.00, and std is 0.99
 4.20 s (23.8 data/s) [100/100]
training: epoch 178: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.715186, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.626452, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.425181, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000001, min gradient is 5.153504, learning rate is 0.000400
Net2: layer deconv3:max response is 90.397171, min response is -68.324196.
max gradient is 8.000000, min gradient is -6.382056, learning rate is 0.000200
Net2: layer bn50:max response is 18.826569, min response is -3.297529.
max gradient is 4.761029, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.159226, learning rate is 0.000200
Net2: layer bn49:max response is 20.075178, min response is -3.826490.
max gradient is 8.000000, min gradient is -7.372556, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.612090, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.71, min inferred z is -3.76, and std is 0.99
 4.39 s (22.8 data/s) [100/100]
Loss: 1.0586
Iteration 179 / 200
training: epoch 179: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.877199, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.440059, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.327648, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.878656, learning rate is 0.000400
Net2: layer deconv3:max response is 102.483040, min response is -75.005356.
max gradient is 8.000000, min gradient is -6.928774, learning rate is 0.000200
Net2: layer bn50:max response is 21.016268, min response is -3.927651.
max gradient is 6.787754, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.216640, learning rate is 0.000200
Net2: layer bn49:max response is 22.694284, min response is -4.219262.
max gradient is 8.000000, min gradient is -7.138320, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.734004, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.79, min inferred z is -4.24, and std is 1.00
 4.19 s (23.8 data/s) [100/100]
training: epoch 179: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.035537, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.413626, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.491967, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.115949, learning rate is 0.000400
Net2: layer deconv3:max response is 80.542381, min response is -69.284721.
max gradient is 8.000000, min gradient is -5.244825, learning rate is 0.000200
Net2: layer bn50:max response is 20.301519, min response is -3.561608.
max gradient is 6.962761, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.439149, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.134336, min response is -4.402473.
max gradient is 6.215443, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.055237, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.33, min inferred z is -3.84, and std is 1.00
 4.19 s (23.9 data/s) [100/100]
training: epoch 179: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.775247, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.322693, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.146289, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.895118, learning rate is 0.000400
Net2: layer deconv3:max response is 91.210815, min response is -66.893707.
max gradient is 1.700039, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.489981, min response is -3.843633.
max gradient is 8.000000, min gradient is -6.289149, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.420613, learning rate is 0.000200
Net2: layer bn49:max response is 19.996866, min response is -4.601415.
max gradient is 8.000000, min gradient is -7.104101, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.972645, learning rate is 0.000200
max inferred z is 3.96, min inferred z is -3.85, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 179: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.704165, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.267055, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.318375, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.653176, learning rate is 0.000400
Net2: layer deconv3:max response is 98.654892, min response is -72.281418.
max gradient is 8.000000, min gradient is -2.337593, learning rate is 0.000200
Net2: layer bn50:max response is 20.843643, min response is -4.351523.
max gradient is 5.938751, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.585924, learning rate is 0.000200
Net2: layer bn49:max response is 22.511009, min response is -4.320129.
max gradient is 7.405987, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.160988, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.62, min inferred z is -3.71, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 179: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.866038, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.198243, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.278828, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.568371, learning rate is 0.000400
Net2: layer deconv3:max response is 95.609566, min response is -69.840393.
max gradient is 3.561562, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.601543, min response is -3.460935.
max gradient is 8.000000, min gradient is -5.765236, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.225991, learning rate is 0.000200
Net2: layer bn49:max response is 21.149630, min response is -4.137163.
max gradient is 4.648767, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.252289, learning rate is 0.000200
max inferred z is 4.01, min inferred z is -4.07, and std is 1.00
 4.45 s (22.5 data/s) [100/100]
training: epoch 179: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.858795, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.653379, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.335892, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.989879, learning rate is 0.000400
Net2: layer deconv3:max response is 84.108994, min response is -63.969837.
max gradient is 8.000000, min gradient is -6.834866, learning rate is 0.000200
Net2: layer bn50:max response is 18.531038, min response is -3.644964.
max gradient is 6.588379, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.009301, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.740978, min response is -4.240390.
max gradient is 8.000000, min gradient is -7.890256, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.856050, learning rate is 0.000200
max inferred z is 4.07, min inferred z is -4.15, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
training: epoch 179: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.584909, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.380736, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.657434, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.950253, learning rate is 0.000400
Net2: layer deconv3:max response is 92.156128, min response is -67.515106.
max gradient is 7.800920, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.905140, min response is -3.780703.
max gradient is 8.000000, min gradient is -6.095521, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.806521, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.367800, min response is -3.425524.
max gradient is 6.228510, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.797425, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.89, min inferred z is -4.19, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 179: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.528635, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.644230, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.562204, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.930250, learning rate is 0.000400
Net2: layer deconv3:max response is 95.625160, min response is -77.303879.
max gradient is 6.045163, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.347919, min response is -3.813302.
max gradient is 6.349679, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.398071, learning rate is 0.000200
Net2: layer bn49:max response is 21.038225, min response is -5.015488.
max gradient is 8.000000, min gradient is -6.449091, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000001, min gradient is -6.360659, learning rate is 0.000200
max inferred z is 3.96, min inferred z is -4.12, and std is 1.00
 4.44 s (22.5 data/s) [100/100]
training: epoch 179: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.734654, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.408602, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.682456, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.183074, learning rate is 0.000400
Net2: layer deconv3:max response is 89.417595, min response is -68.932693.
max gradient is 8.000000, min gradient is -3.634763, learning rate is 0.000200
Net2: layer bn50:max response is 18.308550, min response is -3.365546.
max gradient is 7.313654, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.395279, learning rate is 0.000200
Net2: layer bn49:max response is 19.910286, min response is -4.303307.
max gradient is 6.781530, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.767663, learning rate is 0.000200
max inferred z is 3.99, min inferred z is -4.13, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 179: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.641652, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.615017, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.402154, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.146321, learning rate is 0.000400
Net2: layer deconv3:max response is 95.912025, min response is -68.047096.
max gradient is 2.075774, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.676569, min response is -3.966466.
max gradient is 8.000000, min gradient is -6.289847, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.374467, learning rate is 0.000200
Net2: layer bn49:max response is 21.246819, min response is -4.231561.
max gradient is 8.000000, min gradient is -6.801036, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.514765, learning rate is 0.000200
max inferred z is 4.42, min inferred z is -3.82, and std is 1.00
 4.16 s (24.0 data/s) [100/100]
Loss: 1.0517
Iteration 180 / 200
training: epoch 180: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.967316, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.463845, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.440713, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.471331, learning rate is 0.000400
Net2: layer deconv3:max response is 89.460976, min response is -66.178055.
max gradient is 8.000000, min gradient is -5.530360, learning rate is 0.000200
Net2: layer bn50:max response is 20.040392, min response is -4.268237.
max gradient is 6.918683, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.780552, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.569309, min response is -3.831468.
max gradient is 7.845935, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.728426, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.15, min inferred z is -3.82, and std is 1.00
 4.14 s (24.2 data/s) [100/100]
training: epoch 180: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.047990, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.234820, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.413449, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.315251, learning rate is 0.000400
Net2: layer deconv3:max response is 83.309357, min response is -66.967377.
max gradient is 6.050067, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.623449, min response is -4.046382.
max gradient is 8.000000, min gradient is -5.507871, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.794106, learning rate is 0.000200
Net2: layer bn49:max response is 18.950747, min response is -4.639657.
max gradient is 8.000000, min gradient is -6.089716, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.587719, learning rate is 0.000200
max inferred z is 3.61, min inferred z is -3.94, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 180: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.737890, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.261282, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.212436, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.693319, learning rate is 0.000400
Net2: layer deconv3:max response is 103.891708, min response is -76.361137.
max gradient is 6.155851, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.145969, min response is -3.968855.
max gradient is 4.425261, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.408528, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 22.544817, min response is -4.828022.
max gradient is 8.000000, min gradient is -7.711727, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.613727, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.37, min inferred z is -3.80, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 180: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.561810, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.425299, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.116927, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.543095, learning rate is 0.000400
Net2: layer deconv3:max response is 90.476608, min response is -69.894569.
max gradient is 8.000000, min gradient is -5.249299, learning rate is 0.000200
Net2: layer bn50:max response is 19.095724, min response is -3.704493.
max gradient is 8.000000, min gradient is -6.486517, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.833011, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.268410, min response is -3.893679.
max gradient is 8.000000, min gradient is -7.417521, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.401342, learning rate is 0.000200
max inferred z is 3.85, min inferred z is -3.95, and std is 1.00
 4.28 s (23.4 data/s) [100/100]
training: epoch 180: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.058388, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.120035, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.373930, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.561541, learning rate is 0.000400
Net2: layer deconv3:max response is 122.098373, min response is -89.785973.
max gradient is 3.624535, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 26.247452, min response is -4.910503.
max gradient is 8.000000, min gradient is -6.664756, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.109645, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 26.951326, min response is -5.555364.
max gradient is 7.141572, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.241683, learning rate is 0.000200
max inferred z is 4.76, min inferred z is -3.91, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 180: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.786691, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.454256, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.215574, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.486903, learning rate is 0.000400
Net2: layer deconv3:max response is 88.322083, min response is -66.074707.
max gradient is 3.235619, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.551214, min response is -3.722661.
max gradient is 8.000000, min gradient is -6.212988, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.284062, learning rate is 0.000200
Net2: layer bn49:max response is 19.114485, min response is -4.563850.
max gradient is 8.000000, min gradient is -5.226384, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.892637, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.13, min inferred z is -4.65, and std is 1.00
 4.32 s (23.2 data/s) [100/100]
training: epoch 180: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.281288, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.505262, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.531289, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.659338, learning rate is 0.000400
Net2: layer deconv3:max response is 91.862076, min response is -70.375305.
max gradient is 8.000000, min gradient is -2.785225, learning rate is 0.000200
Net2: layer bn50:max response is 19.360428, min response is -3.696690.
max gradient is 5.765174, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.638246, learning rate is 0.000200
Net2: layer bn49:max response is 20.747459, min response is -3.931492.
max gradient is 7.184825, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.621522, learning rate is 0.000200
max inferred z is 3.79, min inferred z is -4.07, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
training: epoch 180: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.580568, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.385303, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.396276, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.953155, learning rate is 0.000400
Net2: layer deconv3:max response is 91.044243, min response is -67.245354.
max gradient is 1.967167, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.483467, min response is -3.692556.
max gradient is 8.000000, min gradient is -7.576903, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.723192, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.903215, min response is -4.615431.
max gradient is 8.000000, min gradient is -6.750430, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.291920, learning rate is 0.000200
max inferred z is 4.17, min inferred z is -4.01, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 180: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.640427, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.627277, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.658117, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.236365, learning rate is 0.000400
Net2: layer deconv3:max response is 126.104607, min response is -95.108513.
max gradient is 8.000000, min gradient is -2.481540, learning rate is 0.000200
Net2: layer bn50:max response is 25.525648, min response is -4.952200.
max gradient is 4.734995, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.007830, learning rate is 0.000200
Net2: layer bn49:max response is 27.415237, min response is -3.951303.
max gradient is 6.435292, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.167429, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.07, min inferred z is -4.21, and std is 1.00
 4.67 s (21.4 data/s) [100/100]
training: epoch 180: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.739867, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.488935, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.552901, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.198926, learning rate is 0.000400
Net2: layer deconv3:max response is 91.680473, min response is -68.291840.
max gradient is 3.845731, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.014212, min response is -3.915319.
max gradient is 8.000000, min gradient is -5.944752, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.722894, learning rate is 0.000200
Net2: layer bn49:max response is 19.739420, min response is -4.530607.
max gradient is 5.181634, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.802127, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.99, min inferred z is -3.91, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
Loss: 1.038
Iteration 181 / 200
training: epoch 181: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.902569, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.381644, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.527158, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.269618, learning rate is 0.000400
Net2: layer deconv3:max response is 116.758278, min response is -84.015419.
max gradient is 3.204375, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.742750, min response is -4.642558.
max gradient is 8.000000, min gradient is -5.009586, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.576957, learning rate is 0.000200
Net2: layer bn49:max response is 25.491732, min response is -4.493865.
max gradient is 8.000000, min gradient is -6.584740, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.048475, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.90, min inferred z is -3.76, and std is 0.99
 4.30 s (23.3 data/s) [100/100]
training: epoch 181: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.801040, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.508154, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.129646, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.756025, learning rate is 0.000400
Net2: layer deconv3:max response is 86.499168, min response is -66.286430.
max gradient is 8.000000, min gradient is -4.078367, learning rate is 0.000200
Net2: layer bn50:max response is 18.229645, min response is -3.453843.
max gradient is 8.000000, min gradient is -7.743304, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.503526, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.450829, min response is -3.844489.
max gradient is 7.756189, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.340066, learning rate is 0.000200
max inferred z is 3.73, min inferred z is -4.60, and std is 0.99
 4.31 s (23.2 data/s) [100/100]
training: epoch 181: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.800650, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.324783, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.267456, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.516404, learning rate is 0.000400
Net2: layer deconv3:max response is 97.678490, min response is -74.670685.
max gradient is 3.871698, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.889637, min response is -3.685221.
max gradient is 8.000000, min gradient is -7.940282, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.263220, learning rate is 0.000200
Net2: layer bn49:max response is 21.570984, min response is -4.125847.
max gradient is 6.793758, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.870406, learning rate is 0.000200
max inferred z is 3.74, min inferred z is -4.65, and std is 0.99
 4.30 s (23.3 data/s) [100/100]
training: epoch 181: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.622552, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.210221, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.286072, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.603969, learning rate is 0.000400
Net2: layer deconv3:max response is 93.932823, min response is -72.411644.
max gradient is 8.000000, min gradient is -3.017947, learning rate is 0.000200
Net2: layer bn50:max response is 19.667027, min response is -3.852736.
max gradient is 5.028000, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.407810, learning rate is 0.000200
Net2: layer bn49:max response is 20.578468, min response is -4.493496.
max gradient is 6.518075, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.237767, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.02, min inferred z is -3.82, and std is 0.99
 4.42 s (22.6 data/s) [100/100]
training: epoch 181: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.796034, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.221006, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.230773, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.954611, learning rate is 0.000400
Net2: layer deconv3:max response is 98.372597, min response is -72.351845.
max gradient is 2.315068, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.713354, min response is -3.801556.
max gradient is 8.000000, min gradient is -4.768725, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.708655, learning rate is 0.000200
Net2: layer bn49:max response is 21.115593, min response is -4.551096.
max gradient is 8.000000, min gradient is -6.742335, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.572895, learning rate is 0.000200
max inferred z is 3.67, min inferred z is -3.54, and std is 0.99
 4.46 s (22.4 data/s) [100/100]
training: epoch 181: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.022537, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.528410, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.498131, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.667315, learning rate is 0.000400
Net2: layer deconv3:max response is 96.461052, min response is -71.155136.
max gradient is 8.000000, min gradient is -4.698672, learning rate is 0.000200
Net2: layer bn50:max response is 19.694702, min response is -3.848265.
max gradient is 6.464431, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.659457, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.328100, min response is -3.910646.
max gradient is 8.000000, min gradient is -7.924775, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.325456, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.92, min inferred z is -4.14, and std is 0.99
 4.32 s (23.1 data/s) [100/100]
training: epoch 181: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.189921, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.419962, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.310577, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.675963, learning rate is 0.000400
Net2: layer deconv3:max response is 113.763298, min response is -83.686829.
max gradient is 4.182039, min gradient is -8.000001, learning rate is 0.000200
Net2: layer bn50:max response is 22.803947, min response is -3.751462.
max gradient is 8.000000, min gradient is -5.975729, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.303936, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 24.502155, min response is -4.387754.
max gradient is 8.000000, min gradient is -7.946957, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.236435, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.69, min inferred z is -4.08, and std is 0.99
 4.34 s (23.0 data/s) [100/100]
training: epoch 181: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.673193, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.451510, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.798581, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.310144, learning rate is 0.000400
Net2: layer deconv3:max response is 91.828629, min response is -70.712860.
max gradient is 8.000000, min gradient is -4.245246, learning rate is 0.000200
Net2: layer bn50:max response is 18.677982, min response is -4.065795.
max gradient is 6.032482, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.346432, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.922920, min response is -3.544035.
max gradient is 7.929418, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.482616, learning rate is 0.000200
max inferred z is 4.03, min inferred z is -3.93, and std is 0.99
 4.31 s (23.2 data/s) [100/100]
training: epoch 181: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.572641, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.302095, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.542641, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.712025, learning rate is 0.000400
Net2: layer deconv3:max response is 105.326279, min response is -77.967087.
max gradient is 3.376168, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.023520, min response is -3.696225.
max gradient is 8.000000, min gradient is -6.084496, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.082683, learning rate is 0.000200
Net2: layer bn49:max response is 22.413773, min response is -4.365987.
max gradient is 8.000000, min gradient is -7.204190, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.300494, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.82, min inferred z is -4.03, and std is 0.99
 4.44 s (22.5 data/s) [100/100]
training: epoch 181: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.669209, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.522474, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.392068, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.144526, learning rate is 0.000400
Net2: layer deconv3:max response is 132.705292, min response is -102.109756.
max gradient is 8.000000, min gradient is -2.845011, learning rate is 0.000200
Net2: layer bn50:max response is 26.852457, min response is -3.989682.
max gradient is 8.000000, min gradient is -7.190498, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.197025, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 28.755302, min response is -4.910968.
max gradient is 8.000000, min gradient is -6.638842, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.240003, learning rate is 0.000200
max inferred z is 4.35, min inferred z is -4.76, and std is 0.99
 4.34 s (23.0 data/s) [100/100]
Loss: 1.0633
Iteration 182 / 200
training: epoch 182: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.036770, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.256595, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.484366, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.410739, learning rate is 0.000400
Net2: layer deconv3:max response is 102.877487, min response is -74.300552.
max gradient is 4.389019, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.749170, min response is -4.317347.
max gradient is 5.989493, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.662376, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 22.461334, min response is -3.854441.
max gradient is 6.812205, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.391182, learning rate is 0.000200
max inferred z is 3.56, min inferred z is -3.86, and std is 1.00
 4.12 s (24.3 data/s) [100/100]
training: epoch 182: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.854034, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.321402, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.259171, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.259731, learning rate is 0.000400
Net2: layer deconv3:max response is 101.386818, min response is -77.061874.
max gradient is 8.000001, min gradient is -6.899248, learning rate is 0.000200
Net2: layer bn50:max response is 20.461843, min response is -3.867182.
max gradient is 6.420076, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.525926, learning rate is 0.000200
Net2: layer bn49:max response is 22.103106, min response is -3.901775.
max gradient is 8.000000, min gradient is -7.201342, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.809518, learning rate is 0.000200
max inferred z is 3.63, min inferred z is -3.71, and std is 1.00
 4.12 s (24.3 data/s) [100/100]
training: epoch 182: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.825721, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.263403, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.688346, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.468763, learning rate is 0.000400
Net2: layer deconv3:max response is 108.049240, min response is -80.869331.
max gradient is 8.000000, min gradient is -5.514740, learning rate is 0.000200
Net2: layer bn50:max response is 21.799913, min response is -3.856625.
max gradient is 8.000000, min gradient is -7.615945, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.254170, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 23.599041, min response is -3.609277.
max gradient is 7.450076, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.085173, learning rate is 0.000200
max inferred z is 3.86, min inferred z is -3.40, and std is 1.00
 4.16 s (24.0 data/s) [100/100]
training: epoch 182: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.533885, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.214457, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.305101, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 5.551500, min gradient is 2.698406, learning rate is 0.000400
Net2: layer deconv3:max response is 87.704315, min response is -66.247498.
max gradient is 2.699196, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 17.763826, min response is -3.224642.
max gradient is 8.000000, min gradient is -7.104166, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.464778, learning rate is 0.000200
Net2: layer bn49:max response is 19.270704, min response is -3.963889.
max gradient is 8.000001, min gradient is -6.515470, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.138181, learning rate is 0.000200
max inferred z is 3.99, min inferred z is -3.74, and std is 1.00
 4.25 s (23.6 data/s) [100/100]
training: epoch 182: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.756754, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.133274, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.195685, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.352116, learning rate is 0.000400
Net2: layer deconv3:max response is 110.820808, min response is -81.909592.
max gradient is 8.000000, min gradient is -2.753093, learning rate is 0.000200
Net2: layer bn50:max response is 22.674658, min response is -4.166801.
max gradient is 5.041128, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.967310, learning rate is 0.000200
Net2: layer bn49:max response is 24.366175, min response is -4.498688.
max gradient is 5.222162, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.542153, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.46, min inferred z is -3.76, and std is 1.00
 4.32 s (23.2 data/s) [100/100]
training: epoch 182: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.890514, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.562901, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.398553, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.815483, learning rate is 0.000400
Net2: layer deconv3:max response is 76.816010, min response is -64.275398.
max gradient is 3.019743, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.565851, min response is -3.836958.
max gradient is 8.000000, min gradient is -6.005400, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.879963, learning rate is 0.000200
Net2: layer bn49:max response is 17.004845, min response is -4.362651.
max gradient is 6.236444, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.684982, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.07, min inferred z is -3.98, and std is 1.00
 4.28 s (23.4 data/s) [100/100]
training: epoch 182: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.277454, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.378692, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.415097, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.852176, learning rate is 0.000400
Net2: layer deconv3:max response is 96.861130, min response is -71.117729.
max gradient is 8.000000, min gradient is -5.619923, learning rate is 0.000200
Net2: layer bn50:max response is 20.135109, min response is -4.382117.
max gradient is 5.230535, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.213638, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.666279, min response is -4.399830.
max gradient is 8.000000, min gradient is -6.352439, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.027469, learning rate is 0.000200
max inferred z is 4.29, min inferred z is -3.89, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 182: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.745858, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.463910, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.591625, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.573667, learning rate is 0.000400
Net2: layer deconv3:max response is 97.678749, min response is -71.864525.
max gradient is 8.000000, min gradient is -4.046252, learning rate is 0.000200
Net2: layer bn50:max response is 19.870981, min response is -4.379310.
max gradient is 8.000000, min gradient is -7.403420, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.496800, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.137236, min response is -3.889799.
max gradient is 6.511171, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.827243, learning rate is 0.000200
max inferred z is 4.03, min inferred z is -3.81, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 182: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.737711, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.233564, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.743846, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.518590, learning rate is 0.000400
Net2: layer deconv3:max response is 88.982773, min response is -64.296127.
max gradient is 3.635797, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.273094, min response is -3.826949.
max gradient is 8.000000, min gradient is -7.424911, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.602715, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.200937, min response is -4.235922.
max gradient is 7.679013, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.405986, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.59, min inferred z is -3.96, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 182: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.642505, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.684941, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.366882, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.079515, learning rate is 0.000400
Net2: layer deconv3:max response is 107.946083, min response is -82.448547.
max gradient is 7.302809, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.532368, min response is -3.665503.
max gradient is 5.479282, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.578073, learning rate is 0.000200
Net2: layer bn49:max response is 23.436909, min response is -4.155848.
max gradient is 6.907936, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.570659, learning rate is 0.000200
max inferred z is 4.77, min inferred z is -4.11, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
Loss: 1.1785
Iteration 183 / 200
training: epoch 183: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.910276, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.487341, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.451539, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.709014, learning rate is 0.000400
Net2: layer deconv3:max response is 87.646294, min response is -66.148262.
max gradient is 7.593336, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 17.973715, min response is -3.497204.
max gradient is 8.000000, min gradient is -6.564046, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.089671, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.413605, min response is -3.723409.
max gradient is 8.000000, min gradient is -6.452528, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.471223, learning rate is 0.000200
max inferred z is 3.79, min inferred z is -4.05, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 183: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.952754, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.299850, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.595423, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.273788, learning rate is 0.000400
Net2: layer deconv3:max response is 99.981613, min response is -72.610443.
max gradient is 8.000000, min gradient is -6.739643, learning rate is 0.000200
Net2: layer bn50:max response is 19.693913, min response is -3.772176.
max gradient is 8.000000, min gradient is -5.131155, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.688741, learning rate is 0.000200
Net2: layer bn49:max response is 21.429399, min response is -4.516246.
max gradient is 5.157495, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.788695, learning rate is 0.000200
max inferred z is 3.97, min inferred z is -3.97, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
training: epoch 183: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.729518, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.348523, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.452895, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.303337, learning rate is 0.000400
Net2: layer deconv3:max response is 101.355804, min response is -78.229752.
max gradient is 7.076235, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.224129, min response is -3.645542.
max gradient is 4.516447, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.942288, learning rate is 0.000200
Net2: layer bn49:max response is 21.681326, min response is -4.229493.
max gradient is 8.000000, min gradient is -6.116540, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.025303, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.81, min inferred z is -3.82, and std is 1.00
 4.41 s (22.7 data/s) [100/100]
training: epoch 183: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.646790, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.263315, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.365515, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.353896, learning rate is 0.000400
Net2: layer deconv3:max response is 94.198357, min response is -69.795990.
max gradient is 5.504289, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.074800, min response is -3.686636.
max gradient is 7.053644, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.899517, learning rate is 0.000200
Net2: layer bn49:max response is 20.548790, min response is -4.247533.
max gradient is 7.483526, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.943733, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.18, min inferred z is -4.43, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 183: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.945657, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.261570, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.601110, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.028931, learning rate is 0.000400
Net2: layer deconv3:max response is 89.131134, min response is -69.068871.
max gradient is 8.000000, min gradient is -4.090530, learning rate is 0.000200
Net2: layer bn50:max response is 18.141651, min response is -3.428644.
max gradient is 6.229195, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 4.859131, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.776920, min response is -4.169599.
max gradient is 6.388643, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.616013, learning rate is 0.000200
max inferred z is 3.74, min inferred z is -3.75, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
training: epoch 183: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.836447, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.393863, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.436376, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.793938, learning rate is 0.000400
Net2: layer deconv3:max response is 95.295471, min response is -70.949348.
max gradient is 2.155577, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.655693, min response is -3.882722.
max gradient is 8.000001, min gradient is -5.627658, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.264061, learning rate is 0.000200
Net2: layer bn49:max response is 20.121685, min response is -4.402844.
max gradient is 8.000000, min gradient is -7.443942, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.609010, learning rate is 0.000200
max inferred z is 3.67, min inferred z is -4.03, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
training: epoch 183: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.240857, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.335016, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.300008, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.109815, learning rate is 0.000400
Net2: layer deconv3:max response is 98.166985, min response is -75.337929.
max gradient is 8.000000, min gradient is -2.699837, learning rate is 0.000200
Net2: layer bn50:max response is 19.825045, min response is -3.820812.
max gradient is 6.042965, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.445406, learning rate is 0.000200
Net2: layer bn49:max response is 21.561752, min response is -4.596868.
max gradient is 8.000000, min gradient is -7.785768, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.724561, learning rate is 0.000200
max inferred z is 3.88, min inferred z is -3.92, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
training: epoch 183: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.642310, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.423903, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.544648, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.182754, learning rate is 0.000400
Net2: layer deconv3:max response is 105.341209, min response is -77.158508.
max gradient is 5.627852, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.120564, min response is -4.508012.
max gradient is 7.438887, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.322487, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 22.614597, min response is -4.571463.
max gradient is 5.726555, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.807381, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.14, min inferred z is -3.77, and std is 1.00
 4.44 s (22.5 data/s) [100/100]
training: epoch 183: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.772550, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.402414, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.949597, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.992469, learning rate is 0.000400
Net2: layer deconv3:max response is 81.197174, min response is -68.004425.
max gradient is 4.580540, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.158350, min response is -3.831968.
max gradient is 8.000000, min gradient is -5.663255, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.146729, learning rate is 0.000200
Net2: layer bn49:max response is 17.425034, min response is -4.543527.
max gradient is 8.000000, min gradient is -7.426491, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.120707, learning rate is 0.000200
max inferred z is 3.93, min inferred z is -3.92, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 183: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.627356, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.641466, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.322564, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.934840, learning rate is 0.000400
Net2: layer deconv3:max response is 81.411407, min response is -62.620140.
max gradient is 6.410488, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.840193, min response is -3.811837.
max gradient is 8.000000, min gradient is -6.730133, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.663161, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.957150, min response is -4.208416.
max gradient is 8.000000, min gradient is -7.274003, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.573412, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.76, min inferred z is -3.70, and std is 1.00
 4.30 s (23.2 data/s) [100/100]
Loss: 1.2215
Iteration 184 / 200
training: epoch 184: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.980855, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.509334, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.678595, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.586852, learning rate is 0.000400
Net2: layer deconv3:max response is 99.034256, min response is -76.963753.
max gradient is 8.000000, min gradient is -5.837237, learning rate is 0.000200
Net2: layer bn50:max response is 20.113770, min response is -3.622738.
max gradient is 5.890478, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.048738, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.707041, min response is -4.053178.
max gradient is 8.000000, min gradient is -7.758591, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.910807, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.93, min inferred z is -4.12, and std is 1.00
 4.30 s (23.2 data/s) [100/100]
training: epoch 184: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.939105, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.312592, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.670506, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.452194, learning rate is 0.000400
Net2: layer deconv3:max response is 85.137505, min response is -70.715614.
max gradient is 4.390456, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.268568, min response is -3.705497.
max gradient is 8.000000, min gradient is -5.938394, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.522551, learning rate is 0.000200
Net2: layer bn49:max response is 17.328966, min response is -4.603105.
max gradient is 6.652990, min gradient is -8.000001, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.527972, learning rate is 0.000200
max inferred z is 4.72, min inferred z is -4.22, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 184: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.862901, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.311899, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.387879, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.307423, learning rate is 0.000400
Net2: layer deconv3:max response is 110.761253, min response is -79.767357.
max gradient is 8.000000, min gradient is -4.555167, learning rate is 0.000200
Net2: layer bn50:max response is 22.109322, min response is -4.506183.
max gradient is 6.835833, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.321692, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 24.083704, min response is -4.409166.
max gradient is 8.000000, min gradient is -7.711903, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.610180, learning rate is 0.000200
max inferred z is 4.08, min inferred z is -4.35, and std is 1.00
 4.30 s (23.2 data/s) [100/100]
training: epoch 184: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.737376, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.208499, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.442130, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.720578, learning rate is 0.000400
Net2: layer deconv3:max response is 109.875404, min response is -79.998253.
max gradient is 4.904754, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.513277, min response is -3.983820.
max gradient is 8.000000, min gradient is -6.536539, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.994268, learning rate is 0.000200
Net2: layer bn49:max response is 23.149460, min response is -4.529876.
max gradient is 8.000000, min gradient is -7.105598, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.791754, learning rate is 0.000200
max inferred z is 3.73, min inferred z is -3.84, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 184: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.966340, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.228805, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.421558, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.700123, learning rate is 0.000400
Net2: layer deconv3:max response is 107.094559, min response is -81.222069.
max gradient is 8.000000, min gradient is -5.897511, learning rate is 0.000200
Net2: layer bn50:max response is 21.630884, min response is -3.962545.
max gradient is 6.306777, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.904198, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 23.335236, min response is -4.490368.
max gradient is 8.000000, min gradient is -7.215055, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.722413, learning rate is 0.000200
max inferred z is 3.93, min inferred z is -4.42, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 184: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.019575, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.438294, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.580003, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.101626, learning rate is 0.000400
Net2: layer deconv3:max response is 97.602890, min response is -72.951111.
max gradient is 7.596580, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.221451, min response is -3.757916.
max gradient is 8.000000, min gradient is -5.996209, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.029254, learning rate is 0.000200
Net2: layer bn49:max response is 20.696308, min response is -4.348572.
max gradient is 4.994390, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.570531, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.65, min inferred z is -3.95, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 184: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.277174, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.394954, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.445452, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.347052, learning rate is 0.000400
Net2: layer deconv3:max response is 97.893478, min response is -73.094360.
max gradient is 6.886263, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.381578, min response is -3.741709.
max gradient is 6.270511, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.466935, learning rate is 0.000200
Net2: layer bn49:max response is 20.810745, min response is -4.521990.
max gradient is 8.000000, min gradient is -5.018790, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.785532, learning rate is 0.000200
max inferred z is 4.12, min inferred z is -3.95, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 184: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.642561, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.328343, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.315700, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.446015, learning rate is 0.000400
Net2: layer deconv3:max response is 89.251221, min response is -66.809135.
max gradient is 6.647096, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 17.891903, min response is -3.450179.
max gradient is 8.000000, min gradient is -5.676494, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.940684, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.260181, min response is -4.044746.
max gradient is 5.610984, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.478125, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.18, min inferred z is -4.11, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 184: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.801301, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.436491, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.986697, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.624677, learning rate is 0.000400
Net2: layer deconv3:max response is 97.763229, min response is -72.251007.
max gradient is 8.000000, min gradient is -4.012457, learning rate is 0.000200
Net2: layer bn50:max response is 19.793652, min response is -3.889086.
max gradient is 5.241549, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.999442, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.558872, min response is -3.707375.
max gradient is 7.448553, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.069520, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.36, min inferred z is -3.89, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 184: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.714074, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.437284, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.674552, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -1.848862, min gradient is -4.987855, learning rate is 0.000400
Net2: layer deconv3:max response is 107.243935, min response is -75.923935.
max gradient is 1.872991, min gradient is -8.000001, learning rate is 0.000200
Net2: layer bn50:max response is 20.883265, min response is -3.826063.
max gradient is 8.000000, min gradient is -6.003235, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.951717, learning rate is 0.000200
Net2: layer bn49:max response is 22.570011, min response is -4.222304.
max gradient is 8.000000, min gradient is -7.553025, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.285886, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.89, min inferred z is -4.35, and std is 1.00
 4.47 s (22.4 data/s) [100/100]
Loss: 1.0691
Iteration 185 / 200
training: epoch 185: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.846001, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.375938, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.417276, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.902177, learning rate is 0.000400
Net2: layer deconv3:max response is 112.195442, min response is -84.336472.
max gradient is 8.000000, min gradient is -4.459131, learning rate is 0.000200
Net2: layer bn50:max response is 22.386002, min response is -3.897640.
max gradient is 8.000000, min gradient is -7.814500, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.408929, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 23.989687, min response is -4.473047.
max gradient is 7.179615, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.307061, learning rate is 0.000200
max inferred z is 4.13, min inferred z is -3.76, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
training: epoch 185: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.956602, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.303328, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.649633, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.910211, learning rate is 0.000400
Net2: layer deconv3:max response is 113.225945, min response is -84.883171.
max gradient is 7.671640, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.967897, min response is -4.414655.
max gradient is 8.000000, min gradient is -4.065938, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.406802, learning rate is 0.000200
Net2: layer bn49:max response is 25.032396, min response is -4.708648.
max gradient is 8.000000, min gradient is -6.252693, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.919646, learning rate is 0.000200
max inferred z is 3.88, min inferred z is -4.32, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 185: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.763552, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.258534, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.296854, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.202324, learning rate is 0.000400
Net2: layer deconv3:max response is 93.486382, min response is -69.388222.
max gradient is 4.941630, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.346354, min response is -4.224691.
max gradient is 6.053477, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.681945, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.788481, min response is -4.427169.
max gradient is 8.000001, min gradient is -6.055559, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.858025, learning rate is 0.000200
max inferred z is 4.16, min inferred z is -3.78, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 185: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.691713, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.230174, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.403926, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -5.960446, learning rate is 0.000400
Net2: layer deconv3:max response is 83.152512, min response is -68.118645.
max gradient is 8.000000, min gradient is -3.843235, learning rate is 0.000200
Net2: layer bn50:max response is 18.143322, min response is -4.059389.
max gradient is 8.000000, min gradient is -7.648824, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.333061, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.738220, min response is -4.097834.
max gradient is 8.000000, min gradient is -7.690837, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.456292, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.82, min inferred z is -4.24, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 185: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.969947, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.313681, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.264281, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.431057, learning rate is 0.000400
Net2: layer deconv3:max response is 114.256577, min response is -84.934891.
max gradient is 7.969419, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.799185, min response is -4.150463.
max gradient is 4.762189, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.800995, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 24.597578, min response is -3.771349.
max gradient is 8.000000, min gradient is -7.738743, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.957870, learning rate is 0.000200
max inferred z is 3.60, min inferred z is -3.77, and std is 1.00
 4.45 s (22.5 data/s) [100/100]
training: epoch 185: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.062876, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.448012, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.535545, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.759636, learning rate is 0.000400
Net2: layer deconv3:max response is 99.288948, min response is -74.189362.
max gradient is 4.021369, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.950806, min response is -4.187940.
max gradient is 8.000000, min gradient is -5.996137, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.377458, learning rate is 0.000200
Net2: layer bn49:max response is 21.586941, min response is -4.086116.
max gradient is 8.000000, min gradient is -6.111770, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.804776, learning rate is 0.000200
max inferred z is 4.14, min inferred z is -3.88, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 185: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.368295, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.415846, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.532503, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.416721, learning rate is 0.000400
Net2: layer deconv3:max response is 96.615280, min response is -71.275360.
max gradient is 8.000000, min gradient is -7.825040, learning rate is 0.000200
Net2: layer bn50:max response is 19.864439, min response is -3.911899.
max gradient is 7.079715, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 4.001003, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.870319, min response is -3.842693.
max gradient is 8.000000, min gradient is -6.454579, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.594287, learning rate is 0.000200
max inferred z is 3.84, min inferred z is -3.54, and std is 1.00
 4.38 s (22.9 data/s) [100/100]
training: epoch 185: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.397208, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.638114, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.549264, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.499100, learning rate is 0.000400
Net2: layer deconv3:max response is 110.452934, min response is -83.477539.
max gradient is 3.211159, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.435724, min response is -4.185691.
max gradient is 8.000000, min gradient is -7.047239, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.515631, learning rate is 0.000200
Net2: layer bn49:max response is 24.250216, min response is -4.279759.
max gradient is 8.000000, min gradient is -6.628306, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.323279, learning rate is 0.000200
max inferred z is 3.98, min inferred z is -4.80, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 185: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.602893, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.515723, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.795221, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -3.916039, learning rate is 0.000400
Net2: layer deconv3:max response is 88.334595, min response is -73.038528.
max gradient is 8.000000, min gradient is -3.200972, learning rate is 0.000200
Net2: layer bn50:max response is 19.277889, min response is -3.933671.
max gradient is 6.755095, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.073448, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.371000, min response is -4.483063.
max gradient is 7.056870, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.212322, learning rate is 0.000200
max inferred z is 3.88, min inferred z is -3.85, and std is 1.00
 4.17 s (24.0 data/s) [100/100]
training: epoch 185: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.633464, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.546418, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.482792, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.533727, learning rate is 0.000400
Net2: layer deconv3:max response is 115.733131, min response is -84.741364.
max gradient is 5.005911, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.910515, min response is -4.230021.
max gradient is 8.000000, min gradient is -7.777533, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.653710, learning rate is 0.000200
Net2: layer bn49:max response is 24.725550, min response is -4.713103.
max gradient is 7.839570, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.050189, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.47, min inferred z is -3.97, and std is 1.00
 4.25 s (23.6 data/s) [100/100]
Loss: 1.1011
Iteration 186 / 200
training: epoch 186: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.008210, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.262125, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.378746, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.395783, learning rate is 0.000400
Net2: layer deconv3:max response is 95.720238, min response is -79.420868.
max gradient is 7.567343, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.209354, min response is -3.535352.
max gradient is 7.482457, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.824688, learning rate is 0.000200
Net2: layer bn49:max response is 20.325232, min response is -5.040752.
max gradient is 8.000000, min gradient is -6.740677, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 4.741012, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.55, min inferred z is -3.68, and std is 0.99
 4.21 s (23.7 data/s) [100/100]
training: epoch 186: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.831813, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.321035, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.477476, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000001, min gradient is 6.648547, learning rate is 0.000400
Net2: layer deconv3:max response is 122.964661, min response is -91.207466.
max gradient is 5.260891, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 24.394314, min response is -4.449962.
max gradient is 8.000000, min gradient is -7.963110, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.255043, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 26.512962, min response is -4.105795.
max gradient is 7.513728, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.193918, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.28, min inferred z is -4.02, and std is 0.99
 4.31 s (23.2 data/s) [100/100]
training: epoch 186: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.708561, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.389028, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.345461, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.558601, learning rate is 0.000400
Net2: layer deconv3:max response is 100.927780, min response is -74.129181.
max gradient is 8.000000, min gradient is -5.290490, learning rate is 0.000200
Net2: layer bn50:max response is 20.082010, min response is -4.022641.
max gradient is 5.595707, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.497048, learning rate is 0.000200
Net2: layer bn49:max response is 22.161499, min response is -4.555067.
max gradient is 8.000000, min gradient is -6.555679, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.053485, learning rate is 0.000200
max inferred z is 3.75, min inferred z is -3.78, and std is 0.99
 4.23 s (23.7 data/s) [100/100]
training: epoch 186: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.648224, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.154724, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.361753, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.368900, learning rate is 0.000400
Net2: layer deconv3:max response is 104.326126, min response is -81.478531.
max gradient is 6.805479, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.722433, min response is -4.368228.
max gradient is 7.884295, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.831313, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 22.932980, min response is -5.201385.
max gradient is 6.224763, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.327075, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.82, min inferred z is -4.88, and std is 0.99
 4.28 s (23.4 data/s) [100/100]
training: epoch 186: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.858950, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.309355, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.699831, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.852108, learning rate is 0.000400
Net2: layer deconv3:max response is 110.501770, min response is -83.826065.
max gradient is 8.000000, min gradient is -6.914144, learning rate is 0.000200
Net2: layer bn50:max response is 21.497969, min response is -4.434633.
max gradient is 8.000000, min gradient is -7.512371, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.855474, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 23.697388, min response is -4.627735.
max gradient is 8.000000, min gradient is -7.127219, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.237668, learning rate is 0.000200
max inferred z is 4.43, min inferred z is -3.85, and std is 0.99
 4.36 s (22.9 data/s) [100/100]
training: epoch 186: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.907793, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.417116, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.644834, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.346367, learning rate is 0.000400
Net2: layer deconv3:max response is 93.206535, min response is -69.363281.
max gradient is 1.931037, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.188047, min response is -3.820838.
max gradient is 8.000000, min gradient is -6.761468, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.725171, learning rate is 0.000200
Net2: layer bn49:max response is 19.945086, min response is -4.010352.
max gradient is 8.000000, min gradient is -6.333910, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.718291, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.73, min inferred z is -4.83, and std is 0.99
 4.42 s (22.6 data/s) [100/100]
training: epoch 186: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.396780, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.259684, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.671687, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 7.036424, min gradient is -3.873495, learning rate is 0.000400
Net2: layer deconv3:max response is 96.544128, min response is -73.648216.
max gradient is 8.000000, min gradient is -3.066636, learning rate is 0.000200
Net2: layer bn50:max response is 19.276745, min response is -3.626901.
max gradient is 6.208818, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.830047, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.244968, min response is -3.982659.
max gradient is 7.400750, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.098730, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.28, min inferred z is -3.98, and std is 0.99
 4.31 s (23.2 data/s) [100/100]
training: epoch 186: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.546715, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.385550, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.429681, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.920767, learning rate is 0.000400
Net2: layer deconv3:max response is 96.189217, min response is -72.341721.
max gradient is 4.645150, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.683502, min response is -4.009315.
max gradient is 8.000000, min gradient is -6.623801, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.947478, learning rate is 0.000200
Net2: layer bn49:max response is 20.427000, min response is -3.782500.
max gradient is 5.357307, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.145774, learning rate is 0.000200
max inferred z is 4.62, min inferred z is -3.84, and std is 0.99
 4.34 s (23.0 data/s) [100/100]
training: epoch 186: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.585000, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.318356, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.681282, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.823988, learning rate is 0.000400
Net2: layer deconv3:max response is 96.072037, min response is -71.719139.
max gradient is 6.938849, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.909286, min response is -3.708146.
max gradient is 6.648274, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.612574, learning rate is 0.000200
Net2: layer bn49:max response is 20.475163, min response is -4.105208.
max gradient is 7.365723, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.585073, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.30, min inferred z is -3.79, and std is 0.99
 4.23 s (23.6 data/s) [100/100]
training: epoch 186: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.701965, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.432026, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.581989, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.087565, learning rate is 0.000400
Net2: layer deconv3:max response is 106.390602, min response is -88.132568.
max gradient is 8.000000, min gradient is -5.199849, learning rate is 0.000200
Net2: layer bn50:max response is 23.819481, min response is -4.102058.
max gradient is 8.000000, min gradient is -5.339141, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.292759, learning rate is 0.000200
Net2: layer bn49:max response is 23.182131, min response is -5.515676.
max gradient is 8.000000, min gradient is -7.239635, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.496500, learning rate is 0.000200
max inferred z is 4.26, min inferred z is -3.93, and std is 0.99
 4.35 s (23.0 data/s) [100/100]
Loss: 1.075
Iteration 187 / 200
training: epoch 187: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.934791, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.179593, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.358428, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.860677, learning rate is 0.000400
Net2: layer deconv3:max response is 91.686455, min response is -67.269020.
max gradient is 4.529531, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 17.873135, min response is -3.693352.
max gradient is 8.000000, min gradient is -6.993781, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.720136, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.713913, min response is -3.485168.
max gradient is 6.257226, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.307857, learning rate is 0.000200
max inferred z is 3.89, min inferred z is -4.16, and std is 1.00
 4.25 s (23.6 data/s) [100/100]
training: epoch 187: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.870528, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.404760, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.443490, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.023768, learning rate is 0.000400
Net2: layer deconv3:max response is 108.697144, min response is -79.948128.
max gradient is 8.000000, min gradient is -7.195573, learning rate is 0.000200
Net2: layer bn50:max response is 21.553566, min response is -4.175298.
max gradient is 4.938077, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.991255, learning rate is 0.000200
Net2: layer bn49:max response is 23.583656, min response is -3.625048.
max gradient is 6.521162, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.610155, learning rate is 0.000200
max inferred z is 3.51, min inferred z is -4.47, and std is 1.00
 4.23 s (23.6 data/s) [100/100]
training: epoch 187: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.832565, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.264106, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.564714, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.555827, learning rate is 0.000400
Net2: layer deconv3:max response is 88.259537, min response is -64.830528.
max gradient is 6.428800, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 17.365423, min response is -3.373030.
max gradient is 8.000000, min gradient is -5.054308, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.472160, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.997458, min response is -3.893295.
max gradient is 8.000000, min gradient is -6.402824, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.598292, learning rate is 0.000200
max inferred z is 3.78, min inferred z is -3.76, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 187: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.842469, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.204094, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.573519, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.491746, learning rate is 0.000400
Net2: layer deconv3:max response is 104.850945, min response is -90.962845.
max gradient is 8.000000, min gradient is -5.674076, learning rate is 0.000200
Net2: layer bn50:max response is 23.312792, min response is -4.050460.
max gradient is 8.000001, min gradient is -6.988276, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.543474, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 22.167587, min response is -5.217297.
max gradient is 8.000000, min gradient is -7.498619, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.403441, learning rate is 0.000200
max inferred z is 4.04, min inferred z is -3.67, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 187: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.870184, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.251197, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.393291, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.789167, learning rate is 0.000400
Net2: layer deconv3:max response is 83.879021, min response is -65.512688.
max gradient is 3.414960, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.613907, min response is -3.626115.
max gradient is 8.000000, min gradient is -6.908570, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -4.120089, learning rate is 0.000200
Net2: layer bn49:max response is 17.861710, min response is -4.286534.
max gradient is 8.000000, min gradient is -4.258079, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.275099, learning rate is 0.000200
max inferred z is 3.79, min inferred z is -3.83, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 187: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.057975, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.474658, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.590593, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.106514, learning rate is 0.000400
Net2: layer deconv3:max response is 99.289688, min response is -73.939835.
max gradient is 8.000000, min gradient is -2.421299, learning rate is 0.000200
Net2: layer bn50:max response is 19.519424, min response is -3.979949.
max gradient is 5.924811, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.041611, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.483574, min response is -4.281912.
max gradient is 7.771595, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.400250, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.17, min inferred z is -3.94, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 187: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.309244, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.164024, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.652320, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -3.273467, min gradient is -4.809378, learning rate is 0.000400
Net2: layer deconv3:max response is 91.860085, min response is -79.769638.
max gradient is 3.234512, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.138197, min response is -4.078084.
max gradient is 8.000000, min gradient is -5.970521, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.533359, learning rate is 0.000200
Net2: layer bn49:max response is 19.281460, min response is -5.129215.
max gradient is 7.980960, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.327244, learning rate is 0.000200
max inferred z is 4.35, min inferred z is -4.04, and std is 1.00
 4.28 s (23.4 data/s) [100/100]
training: epoch 187: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.538919, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.253376, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.441138, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.337260, learning rate is 0.000400
Net2: layer deconv3:max response is 112.641098, min response is -82.313797.
max gradient is 4.602726, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.805584, min response is -4.755985.
max gradient is 8.000000, min gradient is -7.204805, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.878233, learning rate is 0.000200
Net2: layer bn49:max response is 25.025806, min response is -4.256380.
max gradient is 7.111456, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.630396, learning rate is 0.000200
max inferred z is 3.76, min inferred z is -3.94, and std is 1.00
 4.36 s (23.0 data/s) [100/100]
training: epoch 187: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.808455, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.405160, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 7.890002, min gradient is -8.000000, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -3.128731, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 87.978951, min response is -79.653633.
max gradient is 8.000000, min gradient is -4.061899, learning rate is 0.000200
Net2: layer bn50:max response is 22.138939, min response is -4.639634.
max gradient is 6.817715, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.888631, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.936029, min response is -5.153715.
max gradient is 8.000000, min gradient is -6.493508, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.696413, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.30, min inferred z is -3.86, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 187: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.581681, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.695076, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.435167, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.833735, learning rate is 0.000400
Net2: layer deconv3:max response is 104.218475, min response is -78.930428.
max gradient is 8.000000, min gradient is -4.184214, learning rate is 0.000200
Net2: layer bn50:max response is 20.963480, min response is -3.923584.
max gradient is 7.777089, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.114563, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 22.790674, min response is -4.013580.
max gradient is 6.994043, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.443285, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.60, min inferred z is -4.12, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
Loss: 1.398
Iteration 188 / 200
training: epoch 188: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.033857, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.294538, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.442160, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -4.760791, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 97.987251, min response is -69.028969.
max gradient is 2.896004, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.020458, min response is -3.701241.
max gradient is 8.000000, min gradient is -7.336254, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.239874, learning rate is 0.000200
Net2: layer bn49:max response is 20.777802, min response is -3.450380.
max gradient is 8.000000, min gradient is -7.400856, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.807383, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.90, min inferred z is -3.99, and std is 0.99
 4.21 s (23.8 data/s) [100/100]
training: epoch 188: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.678669, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.333145, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.389946, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -2.021187, min gradient is -5.322375, learning rate is 0.000400
Net2: layer deconv3:max response is 93.349258, min response is -69.039673.
max gradient is 4.309273, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.667109, min response is -4.003530.
max gradient is 8.000000, min gradient is -7.979488, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.902536, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.314268, min response is -4.385476.
max gradient is 8.000000, min gradient is -5.935378, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.307292, learning rate is 0.000200
max inferred z is 4.14, min inferred z is -4.02, and std is 0.99
 4.18 s (23.9 data/s) [100/100]
training: epoch 188: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.827644, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.168272, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.577088, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -2.697455, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 121.279099, min response is -93.619133.
max gradient is 8.000000, min gradient is -2.926741, learning rate is 0.000200
Net2: layer bn50:max response is 24.334339, min response is -4.038935.
max gradient is 6.165256, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.375426, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 26.334684, min response is -4.107271.
max gradient is 7.139792, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.213653, learning rate is 0.000200
max inferred z is 4.00, min inferred z is -4.35, and std is 0.99
 4.18 s (23.9 data/s) [100/100]
training: epoch 188: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.926584, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.162449, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.635433, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -1.364279, learning rate is 0.000400
Net2: layer deconv3:max response is 86.396622, min response is -65.602654.
max gradient is 8.000000, min gradient is -2.756739, learning rate is 0.000200
Net2: layer bn50:max response is 17.419886, min response is -3.680487.
max gradient is 5.993935, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.203034, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.623507, min response is -4.030363.
max gradient is 5.519986, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.402153, learning rate is 0.000200
max inferred z is 3.73, min inferred z is -3.92, and std is 0.99
 4.35 s (23.0 data/s) [100/100]
training: epoch 188: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.934182, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.362497, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.409599, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.523088, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 96.382492, min response is -82.838310.
max gradient is 1.680305, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.925388, min response is -4.393095.
max gradient is 8.000000, min gradient is -7.288950, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.005495, learning rate is 0.000200
Net2: layer bn49:max response is 17.587629, min response is -5.462343.
max gradient is 8.000000, min gradient is -6.057809, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.729505, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.45, min inferred z is -3.77, and std is 0.99
 4.45 s (22.5 data/s) [100/100]
training: epoch 188: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.843091, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.483010, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.560958, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -7.193081, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 108.805573, min response is -75.305130.
max gradient is 3.927683, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.521679, min response is -4.075796.
max gradient is 7.333200, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.880795, learning rate is 0.000200
Net2: layer bn49:max response is 23.648531, min response is -4.938898.
max gradient is 8.000001, min gradient is -6.253620, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.904167, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.89, min inferred z is -3.82, and std is 0.99
 4.33 s (23.1 data/s) [100/100]
training: epoch 188: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.235794, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.218760, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.705409, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 3.621957, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 106.292015, min response is -79.695290.
max gradient is 8.000000, min gradient is -1.662326, learning rate is 0.000200
Net2: layer bn50:max response is 21.295053, min response is -3.653752.
max gradient is 6.145036, min gradient is -8.000001, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.634780, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 23.232038, min response is -3.784813.
max gradient is 6.068016, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.815291, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.98, min inferred z is -4.18, and std is 0.99
 4.33 s (23.1 data/s) [100/100]
training: epoch 188: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.542058, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.383770, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.615407, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.505442, learning rate is 0.000400
Net2: layer deconv3:max response is 98.476074, min response is -73.474976.
max gradient is 8.000000, min gradient is -3.198175, learning rate is 0.000200
Net2: layer bn50:max response is 19.875305, min response is -3.774216.
max gradient is 7.181068, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.232850, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.677908, min response is -3.869328.
max gradient is 5.280497, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.766267, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.72, min inferred z is -4.27, and std is 0.99
 4.19 s (23.9 data/s) [100/100]
training: epoch 188: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.324794, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.057898, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.376433, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -6.686351, min gradient is -8.000001, learning rate is 0.000400
Net2: layer deconv3:max response is 111.138802, min response is -77.889984.
max gradient is 1.203344, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.680012, min response is -3.873318.
max gradient is 8.000000, min gradient is -6.387242, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.272309, learning rate is 0.000200
Net2: layer bn49:max response is 23.488703, min response is -3.643530.
max gradient is 8.000000, min gradient is -4.946715, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.303876, learning rate is 0.000200
max inferred z is 3.67, min inferred z is -3.59, and std is 0.99
 4.20 s (23.8 data/s) [100/100]
training: epoch 188: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.667819, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.470446, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.674498, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is -4.782785, min gradient is -6.159775, learning rate is 0.000400
Net2: layer deconv3:max response is 104.862289, min response is -73.458321.
max gradient is 3.951530, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.697205, min response is -3.738469.
max gradient is 7.472648, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.671009, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 22.587482, min response is -4.231151.
max gradient is 8.000000, min gradient is -6.194051, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.288835, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.19, min inferred z is -3.75, and std is 0.99
 4.30 s (23.2 data/s) [100/100]
Loss: 1.3725
Iteration 189 / 200
training: epoch 189: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.737103, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.367241, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.469809, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 1.239759, learning rate is 0.000400
Net2: layer deconv3:max response is 86.441841, min response is -64.920189.
max gradient is 8.000000, min gradient is -2.378518, learning rate is 0.000200
Net2: layer bn50:max response is 17.641394, min response is -3.312922.
max gradient is 6.309714, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.770284, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.256907, min response is -3.470712.
max gradient is 7.291167, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.868232, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.84, min inferred z is -4.29, and std is 1.00
 4.28 s (23.4 data/s) [100/100]
training: epoch 189: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.847713, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.282664, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.418359, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.804881, learning rate is 0.000400
Net2: layer deconv3:max response is 110.173035, min response is -80.945663.
max gradient is 8.000000, min gradient is -3.860420, learning rate is 0.000200
Net2: layer bn50:max response is 22.127293, min response is -3.852257.
max gradient is 8.000000, min gradient is -7.391661, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.374681, learning rate is 0.000200
Net2: layer bn49:max response is 24.013674, min response is -4.893530.
max gradient is 4.363381, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.045293, learning rate is 0.000200
max inferred z is 3.80, min inferred z is -4.16, and std is 1.00
 4.19 s (23.8 data/s) [100/100]
training: epoch 189: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.871892, min gradient is -8.000001, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.426103, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.328938, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 7.605430, min gradient is 4.213627, learning rate is 0.000400
Net2: layer deconv3:max response is 92.386925, min response is -71.232018.
max gradient is 2.026149, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.362450, min response is -4.039853.
max gradient is 8.000000, min gradient is -7.619616, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.619497, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.833729, min response is -4.725732.
max gradient is 8.000000, min gradient is -4.262450, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.525156, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.95, min inferred z is -4.07, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 189: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.614483, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.256817, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.288580, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.839532, learning rate is 0.000400
Net2: layer deconv3:max response is 88.570824, min response is -69.493057.
max gradient is 4.062268, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.467773, min response is -4.062057.
max gradient is 8.000000, min gradient is -6.868230, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.465726, learning rate is 0.000200
Net2: layer bn49:max response is 19.624350, min response is -4.613818.
max gradient is 8.000000, min gradient is -4.436405, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.876626, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.07, min inferred z is -4.07, and std is 1.00
 4.28 s (23.3 data/s) [100/100]
training: epoch 189: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.801750, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.289769, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.519397, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 0.450358, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 97.300247, min response is -77.952927.
max gradient is 8.000000, min gradient is -4.350046, learning rate is 0.000200
Net2: layer bn50:max response is 20.459064, min response is -4.108663.
max gradient is 7.865928, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.638996, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 22.364229, min response is -4.225026.
max gradient is 7.688437, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.077074, learning rate is 0.000200
max inferred z is 4.12, min inferred z is -4.34, and std is 1.00
 4.20 s (23.8 data/s) [100/100]
training: epoch 189: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.823883, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.313402, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.513648, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.727222, learning rate is 0.000400
Net2: layer deconv3:max response is 85.240746, min response is -73.152283.
max gradient is 8.000000, min gradient is -3.859124, learning rate is 0.000200
Net2: layer bn50:max response is 19.715183, min response is -3.965149.
max gradient is 6.770356, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.599390, learning rate is 0.000200
Net2: layer bn49:max response is 19.181030, min response is -4.888097.
max gradient is 3.884283, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.775235, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.60, min inferred z is -4.04, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
training: epoch 189: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.370795, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.324988, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.604949, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 0.316697, min gradient is -2.336106, learning rate is 0.000400
Net2: layer deconv3:max response is 97.695267, min response is -69.320061.
max gradient is 2.064702, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.417707, min response is -4.081398.
max gradient is 8.000000, min gradient is -6.992837, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.935489, learning rate is 0.000200
Net2: layer bn49:max response is 21.278471, min response is -4.243370.
max gradient is 8.000000, min gradient is -4.761922, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.238760, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.79, min inferred z is -3.72, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 189: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.608245, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.372837, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.503742, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.206023, learning rate is 0.000400
Net2: layer deconv3:max response is 90.062630, min response is -65.761642.
max gradient is 3.760783, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.106365, min response is -3.743955.
max gradient is 8.000000, min gradient is -7.165871, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.050834, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.928080, min response is -3.736766.
max gradient is 8.000000, min gradient is -6.098007, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.220310, learning rate is 0.000200
max inferred z is 4.07, min inferred z is -4.01, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 189: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.650805, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.395075, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.978105, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 7.248824, min gradient is -6.330103, learning rate is 0.000400
Net2: layer deconv3:max response is 95.823547, min response is -74.655502.
max gradient is 8.000000, min gradient is -3.465554, learning rate is 0.000200
Net2: layer bn50:max response is 19.746286, min response is -3.917812.
max gradient is 7.132192, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.324094, learning rate is 0.000200
Net2: layer bn49:max response is 21.777197, min response is -4.693300.
max gradient is 6.652237, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.530031, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.52, min inferred z is -3.99, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 189: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.737710, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.399049, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.826695, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.443271, learning rate is 0.000400
Net2: layer deconv3:max response is 88.683395, min response is -69.611656.
max gradient is 8.000000, min gradient is -4.231048, learning rate is 0.000200
Net2: layer bn50:max response is 18.601351, min response is -4.005102.
max gradient is 8.000000, min gradient is -6.477722, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.640603, learning rate is 0.000200
Net2: layer bn49:max response is 19.322031, min response is -4.429990.
max gradient is 5.894688, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.428373, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.94, min inferred z is -4.02, and std is 1.00
 4.19 s (23.9 data/s) [100/100]
Loss: 1.3165
Iteration 190 / 200
training: epoch 190: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.889894, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.238218, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.332031, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 5.692770, min gradient is 1.765860, learning rate is 0.000400
Net2: layer deconv3:max response is 99.341537, min response is -71.041946.
max gradient is 2.506467, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.616486, min response is -3.323042.
max gradient is 8.000000, min gradient is -7.844928, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.806982, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.247807, min response is -3.466228.
max gradient is 8.000000, min gradient is -4.027103, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.887763, learning rate is 0.000200
max inferred z is 3.83, min inferred z is -4.01, and std is 1.01
 4.18 s (23.9 data/s) [100/100]
training: epoch 190: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.933202, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.313977, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.535848, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.501670, learning rate is 0.000400
Net2: layer deconv3:max response is 93.854340, min response is -67.703087.
max gradient is 4.753915, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.433714, min response is -3.814293.
max gradient is 8.000000, min gradient is -7.834694, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.055437, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.173782, min response is -4.225811.
max gradient is 8.000000, min gradient is -6.410449, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.957193, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.74, min inferred z is -3.84, and std is 1.01
 4.33 s (23.1 data/s) [100/100]
training: epoch 190: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.636913, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.325429, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.316480, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.084512, learning rate is 0.000400
Net2: layer deconv3:max response is 106.822029, min response is -83.312416.
max gradient is 8.000000, min gradient is -3.554024, learning rate is 0.000200
Net2: layer bn50:max response is 22.218489, min response is -3.500774.
max gradient is 8.000000, min gradient is -7.674012, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.402091, learning rate is 0.000200
Net2: layer bn49:max response is 24.341984, min response is -4.222913.
max gradient is 5.498561, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.655237, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.35, min inferred z is -3.60, and std is 1.01
 4.35 s (23.0 data/s) [100/100]
training: epoch 190: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.621599, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.211714, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.569887, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.639609, learning rate is 0.000400
Net2: layer deconv3:max response is 74.843536, min response is -61.407013.
max gradient is 8.000000, min gradient is -3.139661, learning rate is 0.000200
Net2: layer bn50:max response is 16.610277, min response is -3.707943.
max gradient is 7.259388, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.887677, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.345881, min response is -3.867203.
max gradient is 3.928382, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 4.906714, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.51, min inferred z is -4.06, and std is 1.01
 4.24 s (23.6 data/s) [100/100]
training: epoch 190: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.918139, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.392994, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.376055, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 2.516334, min gradient is 1.486323, learning rate is 0.000400
Net2: layer deconv3:max response is 87.822945, min response is -62.888447.
max gradient is 1.637326, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 17.301748, min response is -3.091211.
max gradient is 8.000000, min gradient is -7.619586, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.616855, learning rate is 0.000200
Net2: layer bn49:max response is 19.102957, min response is -3.792731.
max gradient is 8.000000, min gradient is -4.340010, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.371367, learning rate is 0.000200
max inferred z is 4.32, min inferred z is -3.66, and std is 1.01
 4.43 s (22.6 data/s) [100/100]
training: epoch 190: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.801362, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.377969, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.535305, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.791434, learning rate is 0.000400
Net2: layer deconv3:max response is 105.625275, min response is -76.456413.
max gradient is 5.643184, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.796957, min response is -3.830858.
max gradient is 5.591210, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.864319, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 22.711592, min response is -4.216005.
max gradient is 8.000000, min gradient is -6.796640, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.087002, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.06, min inferred z is -4.02, and std is 1.01
 4.40 s (22.7 data/s) [100/100]
training: epoch 190: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.225853, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.408766, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.622935, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.848755, learning rate is 0.000400
Net2: layer deconv3:max response is 83.761650, min response is -77.918709.
max gradient is 8.000000, min gradient is -3.598791, learning rate is 0.000200
Net2: layer bn50:max response is 20.266575, min response is -4.607480.
max gradient is 8.000000, min gradient is -7.301295, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.399620, learning rate is 0.000200
Net2: layer bn49:max response is 18.569946, min response is -4.149179.
max gradient is 5.025051, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.715955, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.94, min inferred z is -3.57, and std is 1.01
 4.31 s (23.2 data/s) [100/100]
training: epoch 190: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.646574, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.294220, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.633798, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.384559, learning rate is 0.000400
Net2: layer deconv3:max response is 80.973846, min response is -66.471649.
max gradient is 8.000000, min gradient is -5.952643, learning rate is 0.000200
Net2: layer bn50:max response is 17.734562, min response is -3.819090.
max gradient is 8.000000, min gradient is -7.152387, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.875421, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.133051, min response is -4.389348.
max gradient is 4.441856, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.824576, learning rate is 0.000200
max inferred z is 4.19, min inferred z is -3.74, and std is 1.01
 4.34 s (23.1 data/s) [100/100]
training: epoch 190: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.630272, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.387145, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.506458, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.507277, learning rate is 0.000400
Net2: layer deconv3:max response is 86.604889, min response is -70.127388.
max gradient is 3.676826, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.429319, min response is -3.850565.
max gradient is 7.125456, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.814272, learning rate is 0.000200
Net2: layer bn49:max response is 18.713692, min response is -4.643021.
max gradient is 8.000000, min gradient is -7.381176, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.588344, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.51, min inferred z is -4.31, and std is 1.01
 4.32 s (23.2 data/s) [100/100]
training: epoch 190: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.543199, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.543071, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.350050, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.187638, learning rate is 0.000400
Net2: layer deconv3:max response is 81.495667, min response is -68.380127.
max gradient is 5.596080, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.230955, min response is -3.413987.
max gradient is 5.444341, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.904782, learning rate is 0.000200
Net2: layer bn49:max response is 17.323587, min response is -4.247287.
max gradient is 6.747604, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.021796, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.86, min inferred z is -4.24, and std is 1.01
 4.34 s (23.0 data/s) [100/100]
Loss: 1.183
Iteration 191 / 200
training: epoch 191: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.720129, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.344814, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.425355, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.354790, learning rate is 0.000400
Net2: layer deconv3:max response is 94.223953, min response is -72.061287.
max gradient is 8.000000, min gradient is -3.563951, learning rate is 0.000200
Net2: layer bn50:max response is 19.390852, min response is -4.253162.
max gradient is 8.000000, min gradient is -6.230649, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.443500, learning rate is 0.000200
Net2: layer bn49:max response is 21.398270, min response is -4.198430.
max gradient is 4.845200, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.093690, learning rate is 0.000200
max inferred z is 4.03, min inferred z is -3.92, and std is 1.00
 4.18 s (23.9 data/s) [100/100]
training: epoch 191: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.771439, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.324581, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.415593, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.015133, learning rate is 0.000400
Net2: layer deconv3:max response is 97.396667, min response is -71.690750.
max gradient is 5.232965, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.673340, min response is -3.848856.
max gradient is 6.141206, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.148339, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.805330, min response is -4.135253.
max gradient is 4.365832, min gradient is -8.000001, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.170391, learning rate is 0.000200
max inferred z is 3.83, min inferred z is -3.61, and std is 1.00
 4.37 s (22.9 data/s) [100/100]
training: epoch 191: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.767318, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.279616, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.281394, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.762947, learning rate is 0.000400
Net2: layer deconv3:max response is 113.069122, min response is -84.547195.
max gradient is 8.000000, min gradient is -6.596404, learning rate is 0.000200
Net2: layer bn50:max response is 22.220612, min response is -3.757541.
max gradient is 8.000000, min gradient is -6.774248, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.842950, learning rate is 0.000200
Net2: layer bn49:max response is 24.407280, min response is -3.673519.
max gradient is 8.000000, min gradient is -5.045251, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.808978, learning rate is 0.000200
max inferred z is 3.79, min inferred z is -3.74, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 191: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.720947, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.220943, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.672059, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.880939, learning rate is 0.000400
Net2: layer deconv3:max response is 90.254272, min response is -66.971855.
max gradient is 3.121719, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 17.505077, min response is -3.426243.
max gradient is 8.000000, min gradient is -6.351131, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.725562, learning rate is 0.000200
Net2: layer bn49:max response is 19.113047, min response is -3.748898.
max gradient is 7.766716, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.557458, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.52, min inferred z is -4.21, and std is 1.00
 4.31 s (23.2 data/s) [100/100]
training: epoch 191: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.801234, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.251468, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.445633, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.655227, learning rate is 0.000400
Net2: layer deconv3:max response is 102.415657, min response is -76.198944.
max gradient is 8.000000, min gradient is -4.000162, learning rate is 0.000200
Net2: layer bn50:max response is 20.678911, min response is -4.211165.
max gradient is 7.943930, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.999488, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 22.703518, min response is -3.953473.
max gradient is 7.736413, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.574645, learning rate is 0.000200
max inferred z is 3.98, min inferred z is -3.83, and std is 1.00
 4.40 s (22.7 data/s) [100/100]
training: epoch 191: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.769428, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.414623, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.513897, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.887151, learning rate is 0.000400
Net2: layer deconv3:max response is 94.802544, min response is -70.696495.
max gradient is 4.558231, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.053619, min response is -3.559419.
max gradient is 8.000000, min gradient is -7.249244, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.447569, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.002314, min response is -4.466935.
max gradient is 8.000000, min gradient is -7.913457, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.616049, learning rate is 0.000200
max inferred z is 4.55, min inferred z is -4.11, and std is 1.00
 4.43 s (22.6 data/s) [100/100]
training: epoch 191: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.406027, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.344227, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.819703, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.903429, learning rate is 0.000400
Net2: layer deconv3:max response is 90.311295, min response is -67.526436.
max gradient is 8.000000, min gradient is -6.094654, learning rate is 0.000200
Net2: layer bn50:max response is 17.687241, min response is -3.309824.
max gradient is 7.656697, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.125656, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.567587, min response is -4.084529.
max gradient is 8.000000, min gradient is -7.819236, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.386786, learning rate is 0.000200
max inferred z is 4.25, min inferred z is -4.49, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 191: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.612960, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.285252, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.680250, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.768065, learning rate is 0.000400
Net2: layer deconv3:max response is 106.192116, min response is -76.200066.
max gradient is 4.236752, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.189669, min response is -4.042158.
max gradient is 8.000000, min gradient is -5.683342, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.580474, learning rate is 0.000200
Net2: layer bn49:max response is 23.309954, min response is -4.209428.
max gradient is 8.000001, min gradient is -7.974695, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.667141, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.12, min inferred z is -4.31, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 191: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.409338, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.628826, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.495745, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.839116, learning rate is 0.000400
Net2: layer deconv3:max response is 85.478386, min response is -73.260231.
max gradient is 8.000001, min gradient is -2.928435, learning rate is 0.000200
Net2: layer bn50:max response is 18.313580, min response is -3.367058.
max gradient is 5.437266, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.829503, learning rate is 0.000200
Net2: layer bn49:max response is 17.778975, min response is -4.593283.
max gradient is 8.000000, min gradient is -7.643758, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.396843, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.83, min inferred z is -4.45, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 191: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.550710, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.466578, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.439973, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.845814, learning rate is 0.000400
Net2: layer deconv3:max response is 116.146294, min response is -85.697441.
max gradient is 3.192410, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.046085, min response is -3.925290.
max gradient is 8.000000, min gradient is -5.889865, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.509108, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 25.448051, min response is -3.520078.
max gradient is 8.000000, min gradient is -7.951650, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.710763, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.64, min inferred z is -4.01, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
Loss: 1.0578
Iteration 192 / 200
training: epoch 192: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.951985, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.303308, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.437552, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.873980, learning rate is 0.000400
Net2: layer deconv3:max response is 89.074005, min response is -74.079468.
max gradient is 8.000000, min gradient is -6.216680, learning rate is 0.000200
Net2: layer bn50:max response is 22.091494, min response is -4.463193.
max gradient is 5.914716, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.979364, learning rate is 0.000200
Net2: layer bn49:max response is 19.836624, min response is -4.754077.
max gradient is 8.000000, min gradient is -6.042876, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.927245, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.42, min inferred z is -4.31, and std is 0.99
 4.14 s (24.2 data/s) [100/100]
training: epoch 192: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.940513, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.301831, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.541199, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.326734, learning rate is 0.000400
Net2: layer deconv3:max response is 95.045944, min response is -71.635643.
max gradient is 6.382535, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.997189, min response is -3.966527.
max gradient is 8.000000, min gradient is -6.661177, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.105921, learning rate is 0.000200
Net2: layer bn49:max response is 21.024382, min response is -4.155939.
max gradient is 5.537891, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.644117, learning rate is 0.000200
max inferred z is 4.08, min inferred z is -3.97, and std is 0.99
 4.24 s (23.6 data/s) [100/100]
training: epoch 192: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.767641, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.293101, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.504232, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.831493, learning rate is 0.000400
Net2: layer deconv3:max response is 93.835091, min response is -69.845070.
max gradient is 5.990446, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.601915, min response is -3.354010.
max gradient is 8.000000, min gradient is -6.615543, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.660233, learning rate is 0.000200
Net2: layer bn49:max response is 20.466419, min response is -3.758560.
max gradient is 8.000000, min gradient is -5.648860, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.125779, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.07, min inferred z is -3.96, and std is 0.99
 4.36 s (22.9 data/s) [100/100]
training: epoch 192: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.610539, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.186600, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.467384, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.224665, learning rate is 0.000400
Net2: layer deconv3:max response is 79.146545, min response is -66.649193.
max gradient is 8.000000, min gradient is -4.808486, learning rate is 0.000200
Net2: layer bn50:max response is 19.360117, min response is -3.765921.
max gradient is 8.000000, min gradient is -6.591855, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.137276, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.061954, min response is -4.234608.
max gradient is 8.000000, min gradient is -7.189923, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.622382, learning rate is 0.000200
max inferred z is 3.72, min inferred z is -4.03, and std is 0.99
 4.31 s (23.2 data/s) [100/100]
training: epoch 192: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.660646, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.197923, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.342254, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000001, min gradient is 7.434096, learning rate is 0.000400
Net2: layer deconv3:max response is 117.005722, min response is -85.495049.
max gradient is 3.187602, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.444008, min response is -4.189499.
max gradient is 7.528245, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.817904, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 26.061132, min response is -4.582458.
max gradient is 8.000000, min gradient is -7.873585, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 4.252149, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.80, min inferred z is -3.69, and std is 0.99
 4.38 s (22.8 data/s) [100/100]
training: epoch 192: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.758787, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.462753, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.186812, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.498054, learning rate is 0.000400
Net2: layer deconv3:max response is 89.183876, min response is -80.982307.
max gradient is 8.000000, min gradient is -3.316097, learning rate is 0.000200
Net2: layer bn50:max response is 20.085621, min response is -4.040468.
max gradient is 6.970281, min gradient is -8.000001, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.656390, learning rate is 0.000200
Net2: layer bn49:max response is 17.764919, min response is -5.165745.
max gradient is 8.000000, min gradient is -7.442327, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.995720, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.88, min inferred z is -4.02, and std is 0.99
 4.22 s (23.7 data/s) [100/100]
training: epoch 192: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.223499, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.184812, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.644400, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.300399, learning rate is 0.000400
Net2: layer deconv3:max response is 106.180679, min response is -78.023209.
max gradient is 2.056768, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.533346, min response is -4.384217.
max gradient is 8.000000, min gradient is -5.812850, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.788901, learning rate is 0.000200
Net2: layer bn49:max response is 24.003250, min response is -4.312234.
max gradient is 8.000000, min gradient is -7.617797, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.194104, learning rate is 0.000200
max inferred z is 3.85, min inferred z is -3.88, and std is 0.99
 4.34 s (23.0 data/s) [100/100]
training: epoch 192: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.494333, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.603930, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.560169, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.537421, learning rate is 0.000400
Net2: layer deconv3:max response is 92.816872, min response is -69.933029.
max gradient is 8.000000, min gradient is -4.972384, learning rate is 0.000200
Net2: layer bn50:max response is 18.551394, min response is -3.780029.
max gradient is 6.367213, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.349285, learning rate is 0.000200
Net2: layer bn49:max response is 20.378620, min response is -3.890769.
max gradient is 7.512775, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.362974, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.79, min inferred z is -4.19, and std is 0.99
 4.24 s (23.6 data/s) [100/100]
training: epoch 192: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.750496, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.268194, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.798360, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.577308, learning rate is 0.000400
Net2: layer deconv3:max response is 107.284523, min response is -79.527107.
max gradient is 8.000000, min gradient is -6.631893, learning rate is 0.000200
Net2: layer bn50:max response is 21.211138, min response is -4.060234.
max gradient is 8.000000, min gradient is -4.779785, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.552201, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 23.503670, min response is -3.639570.
max gradient is 8.000000, min gradient is -7.739927, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.283816, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.29, min inferred z is -3.70, and std is 0.99
 4.32 s (23.2 data/s) [100/100]
training: epoch 192: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.688405, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.450920, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.602086, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.979079, learning rate is 0.000400
Net2: layer deconv3:max response is 100.004715, min response is -76.152405.
max gradient is 3.333488, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.648912, min response is -3.849389.
max gradient is 8.000000, min gradient is -7.649612, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.169692, learning rate is 0.000200
Net2: layer bn49:max response is 21.792877, min response is -4.626264.
max gradient is 8.000000, min gradient is -6.949351, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.473051, learning rate is 0.000200
max inferred z is 3.75, min inferred z is -3.58, and std is 0.99
 4.38 s (22.9 data/s) [100/100]
Loss: 1.0359
Iteration 193 / 200
training: epoch 193: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.974241, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.356830, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.462842, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.697563, learning rate is 0.000400
Net2: layer deconv3:max response is 83.988396, min response is -73.832497.
max gradient is 8.000000, min gradient is -3.479380, learning rate is 0.000200
Net2: layer bn50:max response is 17.220642, min response is -3.391652.
max gradient is 6.058249, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.307467, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.896034, min response is -3.596988.
max gradient is 8.000000, min gradient is -7.990990, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.945493, learning rate is 0.000200
max inferred z is 4.01, min inferred z is -4.43, and std is 0.99
 4.26 s (23.5 data/s) [100/100]
training: epoch 193: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.814858, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.416280, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.494977, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.042883, learning rate is 0.000400
Net2: layer deconv3:max response is 97.525208, min response is -71.837738.
max gradient is 3.543759, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.681421, min response is -3.835103.
max gradient is 8.000000, min gradient is -4.817347, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.197842, learning rate is 0.000200
Net2: layer bn49:max response is 21.634809, min response is -4.361111.
max gradient is 8.000000, min gradient is -6.605690, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.555020, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.84, min inferred z is -3.78, and std is 0.99
 4.17 s (24.0 data/s) [100/100]
training: epoch 193: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.633344, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.266142, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.369619, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.891930, learning rate is 0.000400
Net2: layer deconv3:max response is 89.342224, min response is -77.183372.
max gradient is 8.000000, min gradient is -4.486337, learning rate is 0.000200
Net2: layer bn50:max response is 19.180611, min response is -3.781164.
max gradient is 5.543268, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.586433, learning rate is 0.000200
Net2: layer bn49:max response is 19.679266, min response is -5.006611.
max gradient is 8.000000, min gradient is -6.073611, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.729953, learning rate is 0.000200
max inferred z is 4.04, min inferred z is -4.25, and std is 0.99
 4.17 s (24.0 data/s) [100/100]
training: epoch 193: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.562685, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.266845, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.376129, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.602512, learning rate is 0.000400
Net2: layer deconv3:max response is 115.790726, min response is -91.293541.
max gradient is 6.296397, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.927019, min response is -3.878272.
max gradient is 8.000000, min gradient is -6.659223, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.775811, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 25.843588, min response is -4.159324.
max gradient is 8.000000, min gradient is -7.602269, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.811047, learning rate is 0.000200
max inferred z is 4.34, min inferred z is -4.05, and std is 0.99
 4.24 s (23.6 data/s) [100/100]
training: epoch 193: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.993768, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.247719, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.633951, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.701843, learning rate is 0.000400
Net2: layer deconv3:max response is 91.095535, min response is -70.455223.
max gradient is 8.000000, min gradient is -6.026124, learning rate is 0.000200
Net2: layer bn50:max response is 18.007208, min response is -3.713745.
max gradient is 6.134009, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.090638, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.671238, min response is -4.311358.
max gradient is 6.437837, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.517423, learning rate is 0.000200
max inferred z is 4.23, min inferred z is -4.22, and std is 0.99
 4.30 s (23.2 data/s) [100/100]
training: epoch 193: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.963560, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.474694, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.623631, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.693288, learning rate is 0.000400
Net2: layer deconv3:max response is 96.368904, min response is -68.615547.
max gradient is 2.747056, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.411530, min response is -3.859075.
max gradient is 8.000000, min gradient is -7.581468, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.371122, learning rate is 0.000200
Net2: layer bn49:max response is 20.563585, min response is -3.628594.
max gradient is 8.000000, min gradient is -5.923344, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.893897, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.87, min inferred z is -3.72, and std is 0.99
 4.27 s (23.4 data/s) [100/100]
training: epoch 193: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.298676, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.260821, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.610287, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.379801, learning rate is 0.000400
Net2: layer deconv3:max response is 86.043877, min response is -65.685791.
max gradient is 8.000000, min gradient is -3.735389, learning rate is 0.000200
Net2: layer bn50:max response is 16.954006, min response is -3.882851.
max gradient is 5.409853, min gradient is -8.000001, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.584544, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.895794, min response is -3.605949.
max gradient is 5.746909, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.630762, learning rate is 0.000200
max inferred z is 3.86, min inferred z is -4.17, and std is 0.99
 4.35 s (23.0 data/s) [100/100]
training: epoch 193: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.673945, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.317208, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.494862, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 1.363351, min gradient is 0.685036, learning rate is 0.000400
Net2: layer deconv3:max response is 97.436150, min response is -76.982780.
max gradient is 3.082992, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.591825, min response is -4.300702.
max gradient is 8.000000, min gradient is -6.687316, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.962962, learning rate is 0.000200
Net2: layer bn49:max response is 21.064957, min response is -5.099805.
max gradient is 8.000000, min gradient is -6.218956, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.948674, learning rate is 0.000200
max inferred z is 3.91, min inferred z is -3.93, and std is 0.99
 4.45 s (22.5 data/s) [100/100]
training: epoch 193: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.470027, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.389240, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.604614, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.752865, learning rate is 0.000400
Net2: layer deconv3:max response is 104.813019, min response is -76.376015.
max gradient is 7.329370, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.670210, min response is -4.248558.
max gradient is 3.153548, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.680011, learning rate is 0.000200
Net2: layer bn49:max response is 22.851276, min response is -4.431293.
max gradient is 7.775097, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.135696, learning rate is 0.000200
max inferred z is 4.11, min inferred z is -4.07, and std is 0.99
 4.31 s (23.2 data/s) [100/100]
training: epoch 193: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.823875, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.536304, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.727044, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 7.434782, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv3:max response is 97.656311, min response is -76.035217.
max gradient is 8.000000, min gradient is -7.349199, learning rate is 0.000200
Net2: layer bn50:max response is 19.136444, min response is -4.104892.
max gradient is 8.000000, min gradient is -5.453283, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.824895, min gradient is -8.000001, learning rate is 0.000200
Net2: layer bn49:max response is 21.298744, min response is -3.759877.
max gradient is 8.000000, min gradient is -6.973657, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.571626, learning rate is 0.000200
max inferred z is 3.77, min inferred z is -4.21, and std is 0.99
 4.22 s (23.7 data/s) [100/100]
Loss: 1.0828
Iteration 194 / 200
training: epoch 194: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.832960, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.205898, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.398192, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.406148, learning rate is 0.000400
Net2: layer deconv3:max response is 100.237846, min response is -80.658310.
max gradient is 4.662143, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.446995, min response is -4.159791.
max gradient is 8.000000, min gradient is -6.733052, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.456885, learning rate is 0.000200
Net2: layer bn49:max response is 21.609831, min response is -5.120187.
max gradient is 8.000000, min gradient is -6.968532, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.061817, learning rate is 0.000200
max inferred z is 3.88, min inferred z is -3.80, and std is 1.00
 4.15 s (24.1 data/s) [100/100]
training: epoch 194: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.972991, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.330861, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.482215, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.991551, learning rate is 0.000400
Net2: layer deconv3:max response is 90.674698, min response is -68.383827.
max gradient is 8.000000, min gradient is -5.181268, learning rate is 0.000200
Net2: layer bn50:max response is 18.480412, min response is -4.151548.
max gradient is 5.636731, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.249496, learning rate is 0.000200
Net2: layer bn49:max response is 20.103512, min response is -4.135561.
max gradient is 5.028690, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.674923, min gradient is -8.000001, learning rate is 0.000200
max inferred z is 4.63, min inferred z is -4.10, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 194: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.725863, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.256293, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.447884, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.385621, learning rate is 0.000400
Net2: layer deconv3:max response is 96.194008, min response is -73.115929.
max gradient is 3.929285, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.214567, min response is -4.449335.
max gradient is 7.388334, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.461642, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.959911, min response is -4.218697.
max gradient is 8.000000, min gradient is -7.561197, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 4.241524, min gradient is -8.000001, learning rate is 0.000200
max inferred z is 4.26, min inferred z is -4.20, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 194: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.587706, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.277751, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.462005, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.140857, learning rate is 0.000400
Net2: layer deconv3:max response is 89.513023, min response is -68.231316.
max gradient is 8.000000, min gradient is -6.813743, learning rate is 0.000200
Net2: layer bn50:max response is 18.413713, min response is -3.723935.
max gradient is 8.000000, min gradient is -6.766093, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.870984, learning rate is 0.000200
Net2: layer bn49:max response is 19.172846, min response is -4.236513.
max gradient is 6.313908, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.475687, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.21, min inferred z is -4.22, and std is 1.00
 4.32 s (23.2 data/s) [100/100]
training: epoch 194: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.871593, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.283955, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.475439, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.891082, learning rate is 0.000400
Net2: layer deconv3:max response is 91.812187, min response is -69.263916.
max gradient is 8.000000, min gradient is -7.278155, learning rate is 0.000200
Net2: layer bn50:max response is 19.614338, min response is -3.891544.
max gradient is 3.564307, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.526709, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.031996, min response is -4.326347.
max gradient is 8.000000, min gradient is -6.579827, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.219760, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.98, min inferred z is -3.87, and std is 1.00
 4.43 s (22.6 data/s) [100/100]
training: epoch 194: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.741249, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.405247, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.493002, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.976553, learning rate is 0.000400
Net2: layer deconv3:max response is 122.198097, min response is -91.640091.
max gradient is 3.589135, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 23.980238, min response is -4.622013.
max gradient is 7.953589, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.182044, learning rate is 0.000200
Net2: layer bn49:max response is 26.521578, min response is -3.976082.
max gradient is 7.466707, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.936503, learning rate is 0.000200
max inferred z is 3.99, min inferred z is -4.02, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
training: epoch 194: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.190319, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.169552, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.516792, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.967130, learning rate is 0.000400
Net2: layer deconv3:max response is 105.184875, min response is -81.144463.
max gradient is 8.000000, min gradient is -4.379572, learning rate is 0.000200
Net2: layer bn50:max response is 21.326317, min response is -4.527418.
max gradient is 8.000000, min gradient is -7.669787, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 4.925310, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 23.905380, min response is -4.086590.
max gradient is 7.564189, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.377846, learning rate is 0.000200
max inferred z is 3.88, min inferred z is -4.31, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 194: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.632234, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.311202, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.660738, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.098429, learning rate is 0.000400
Net2: layer deconv3:max response is 115.140862, min response is -88.487518.
max gradient is 3.353541, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.165508, min response is -3.590760.
max gradient is 8.000000, min gradient is -6.092025, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.068286, learning rate is 0.000200
Net2: layer bn49:max response is 24.616863, min response is -4.455240.
max gradient is 8.000000, min gradient is -7.868993, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.977323, learning rate is 0.000200
max inferred z is 4.26, min inferred z is -4.02, and std is 1.00
 4.22 s (23.7 data/s) [100/100]
training: epoch 194: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.518769, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.349016, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.596050, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.988995, learning rate is 0.000400
Net2: layer deconv3:max response is 95.491409, min response is -70.441002.
max gradient is 8.000000, min gradient is -6.883644, learning rate is 0.000200
Net2: layer bn50:max response is 18.211788, min response is -3.637718.
max gradient is 6.631366, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.550292, learning rate is 0.000200
Net2: layer bn49:max response is 20.124567, min response is -4.059211.
max gradient is 8.000000, min gradient is -6.910398, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.812654, learning rate is 0.000200
max inferred z is 3.98, min inferred z is -4.17, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
training: epoch 194: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.681463, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.370829, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.648986, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.070143, learning rate is 0.000400
Net2: layer deconv3:max response is 103.092674, min response is -77.576401.
max gradient is 7.373644, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.279047, min response is -3.636937.
max gradient is 5.199992, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.920268, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 22.522060, min response is -3.873830.
max gradient is 8.000000, min gradient is -7.481839, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.534630, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.25, min inferred z is -3.88, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
Loss: 1.0434
Iteration 195 / 200
training: epoch 195: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.834882, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.348064, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.300053, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.941761, learning rate is 0.000400
Net2: layer deconv3:max response is 88.800598, min response is -68.627983.
max gradient is 4.322342, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 17.706648, min response is -3.988838.
max gradient is 8.000000, min gradient is -3.792129, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.131312, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.863791, min response is -4.253118.
max gradient is 8.000000, min gradient is -7.822771, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.873482, learning rate is 0.000200
max inferred z is 3.56, min inferred z is -3.93, and std is 1.00
 4.15 s (24.1 data/s) [100/100]
training: epoch 195: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.804423, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.349827, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.482894, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.097339, learning rate is 0.000400
Net2: layer deconv3:max response is 84.287766, min response is -68.565857.
max gradient is 8.000000, min gradient is -4.399792, learning rate is 0.000200
Net2: layer bn50:max response is 17.077599, min response is -3.718718.
max gradient is 4.983407, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.435484, learning rate is 0.000200
Net2: layer bn49:max response is 18.371050, min response is -4.143141.
max gradient is 8.000000, min gradient is -7.612390, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.610271, learning rate is 0.000200
max inferred z is 3.77, min inferred z is -3.74, and std is 1.00
 4.33 s (23.1 data/s) [100/100]
training: epoch 195: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.884775, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.309697, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.518564, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.094795, learning rate is 0.000400
Net2: layer deconv3:max response is 99.141464, min response is -75.340096.
max gradient is 8.000000, min gradient is -6.917344, learning rate is 0.000200
Net2: layer bn50:max response is 18.979912, min response is -4.083290.
max gradient is 6.195235, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.003319, learning rate is 0.000200
Net2: layer bn49:max response is 21.134846, min response is -4.489323.
max gradient is 8.000000, min gradient is -7.950495, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.184380, learning rate is 0.000200
max inferred z is 3.82, min inferred z is -4.22, and std is 1.00
 4.18 s (23.9 data/s) [100/100]
training: epoch 195: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.004679, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.276184, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.694388, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.397835, learning rate is 0.000400
Net2: layer deconv3:max response is 96.700996, min response is -69.228065.
max gradient is 2.805518, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.101416, min response is -3.981775.
max gradient is 7.759432, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.840929, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.296770, min response is -3.882823.
max gradient is 8.000000, min gradient is -6.695667, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 4.658445, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.07, min inferred z is -4.63, and std is 1.00
 4.44 s (22.5 data/s) [100/100]
training: epoch 195: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.653668, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.214255, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.186093, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.316587, learning rate is 0.000400
Net2: layer deconv3:max response is 99.721634, min response is -73.394699.
max gradient is 6.292287, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.054230, min response is -3.890974.
max gradient is 6.430334, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.714604, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.185448, min response is -4.522668.
max gradient is 4.564935, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.454070, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.73, min inferred z is -3.89, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
training: epoch 195: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.575912, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.703445, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.237324, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.291909, learning rate is 0.000400
Net2: layer deconv3:max response is 93.950729, min response is -72.166740.
max gradient is 8.000001, min gradient is -4.465276, learning rate is 0.000200
Net2: layer bn50:max response is 18.880604, min response is -3.732117.
max gradient is 6.849328, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.737998, learning rate is 0.000200
Net2: layer bn49:max response is 20.576283, min response is -4.062224.
max gradient is 7.036058, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.651535, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.04, min inferred z is -4.28, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 195: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.327795, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.240760, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.826617, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.408262, learning rate is 0.000400
Net2: layer deconv3:max response is 82.544472, min response is -73.585945.
max gradient is 7.925049, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.396149, min response is -4.360846.
max gradient is 7.033893, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.188410, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.080740, min response is -4.742973.
max gradient is 8.000000, min gradient is -6.237782, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.297203, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.65, min inferred z is -4.23, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
training: epoch 195: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.626212, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.265862, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.626241, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.205142, learning rate is 0.000400
Net2: layer deconv3:max response is 100.551727, min response is -86.263596.
max gradient is 3.444372, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.641741, min response is -3.755155.
max gradient is 8.000000, min gradient is -7.101152, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.817410, learning rate is 0.000200
Net2: layer bn49:max response is 20.610676, min response is -5.016473.
max gradient is 8.000000, min gradient is -6.689130, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.507625, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.85, min inferred z is -3.96, and std is 1.00
 4.16 s (24.0 data/s) [100/100]
training: epoch 195: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.469036, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.318429, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.836297, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.266362, learning rate is 0.000400
Net2: layer deconv3:max response is 118.353645, min response is -87.781364.
max gradient is 8.000000, min gradient is -2.817458, learning rate is 0.000200
Net2: layer bn50:max response is 22.842913, min response is -3.720330.
max gradient is 4.812082, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.793820, learning rate is 0.000200
Net2: layer bn49:max response is 25.174314, min response is -3.769072.
max gradient is 7.410624, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.554850, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.05, min inferred z is -3.69, and std is 1.00
 4.29 s (23.3 data/s) [100/100]
training: epoch 195: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.721997, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.328117, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.878171, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.709842, learning rate is 0.000400
Net2: layer deconv3:max response is 85.619118, min response is -63.978794.
max gradient is 3.305502, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 16.820612, min response is -3.624240.
max gradient is 8.000000, min gradient is -6.256402, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.445765, learning rate is 0.000200
Net2: layer bn49:max response is 18.401585, min response is -3.846252.
max gradient is 7.554995, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.139790, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.84, min inferred z is -3.60, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
Loss: 1.0772
Iteration 196 / 200
training: epoch 196: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.808050, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.176699, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.435122, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.569178, learning rate is 0.000400
Net2: layer deconv3:max response is 103.757835, min response is -79.187691.
max gradient is 8.000000, min gradient is -3.708463, learning rate is 0.000200
Net2: layer bn50:max response is 20.131220, min response is -3.621077.
max gradient is 5.703435, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.527370, min gradient is -8.000001, learning rate is 0.000200
Net2: layer bn49:max response is 22.601418, min response is -3.783041.
max gradient is 8.000000, min gradient is -7.075600, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.391213, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.29, min inferred z is -3.78, and std is 1.00
 4.17 s (24.0 data/s) [100/100]
training: epoch 196: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.007308, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.328255, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.756297, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.484946, learning rate is 0.000400
Net2: layer deconv3:max response is 97.327606, min response is -76.998146.
max gradient is 5.338156, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.128838, min response is -4.860133.
max gradient is 8.000000, min gradient is -7.310262, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.213759, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.029631, min response is -3.870120.
max gradient is 6.292509, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.490702, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.24, min inferred z is -3.86, and std is 1.00
 4.27 s (23.4 data/s) [100/100]
training: epoch 196: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.701125, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.244225, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.351346, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.920398, learning rate is 0.000400
Net2: layer deconv3:max response is 114.606476, min response is -86.032227.
max gradient is 5.884699, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 22.369497, min response is -4.034541.
max gradient is 8.000000, min gradient is -7.926692, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.330087, learning rate is 0.000200
Net2: layer bn49:max response is 24.818020, min response is -4.239166.
max gradient is 7.887039, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.258912, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.95, min inferred z is -4.14, and std is 1.00
 4.34 s (23.1 data/s) [100/100]
training: epoch 196: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.704691, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.281264, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.450052, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.144997, learning rate is 0.000400
Net2: layer deconv3:max response is 95.489334, min response is -73.221283.
max gradient is 8.000000, min gradient is -4.339151, learning rate is 0.000200
Net2: layer bn50:max response is 18.870518, min response is -3.817722.
max gradient is 7.815606, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.918723, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.817093, min response is -3.892586.
max gradient is 8.000000, min gradient is -6.302731, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.589003, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.22, min inferred z is -4.79, and std is 1.00
 4.36 s (23.0 data/s) [100/100]
training: epoch 196: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.670593, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.323702, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.429487, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.469615, learning rate is 0.000400
Net2: layer deconv3:max response is 85.271980, min response is -65.556580.
max gradient is 3.997650, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 17.196663, min response is -3.921312.
max gradient is 8.000000, min gradient is -6.243848, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.499015, learning rate is 0.000200
Net2: layer bn49:max response is 18.614368, min response is -3.720740.
max gradient is 8.000000, min gradient is -4.943079, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.609369, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.83, min inferred z is -4.41, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 196: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.736614, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.418461, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.424472, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.191296, learning rate is 0.000400
Net2: layer deconv3:max response is 91.562164, min response is -79.674423.
max gradient is 8.000000, min gradient is -2.133612, learning rate is 0.000200
Net2: layer bn50:max response is 19.777573, min response is -4.747108.
max gradient is 5.564986, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.971529, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.858135, min response is -3.609480.
max gradient is 6.503245, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.425432, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.74, min inferred z is -4.22, and std is 1.00
 4.44 s (22.5 data/s) [100/100]
training: epoch 196: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.259231, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.240994, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.786180, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.013828, learning rate is 0.000400
Net2: layer deconv3:max response is 100.944565, min response is -79.485413.
max gradient is 3.534764, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.802528, min response is -3.707979.
max gradient is 8.000000, min gradient is -5.702982, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.900757, learning rate is 0.000200
Net2: layer bn49:max response is 19.960197, min response is -4.537982.
max gradient is 8.000000, min gradient is -6.926294, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.464696, learning rate is 0.000200
max inferred z is 4.14, min inferred z is -4.10, and std is 1.00
 4.34 s (23.0 data/s) [100/100]
training: epoch 196: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.630841, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.332536, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.648551, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.017213, learning rate is 0.000400
Net2: layer deconv3:max response is 115.040665, min response is -87.822685.
max gradient is 8.000000, min gradient is -4.256137, learning rate is 0.000200
Net2: layer bn50:max response is 22.680273, min response is -4.040105.
max gradient is 7.708872, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.111899, learning rate is 0.000200
Net2: layer bn49:max response is 25.061310, min response is -3.916195.
max gradient is 4.119952, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.488374, learning rate is 0.000200
max inferred z is 4.31, min inferred z is -4.04, and std is 1.00
 4.28 s (23.3 data/s) [100/100]
training: epoch 196: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.660444, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.473631, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.509378, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.100478, learning rate is 0.000400
Net2: layer deconv3:max response is 105.958115, min response is -81.810715.
max gradient is 6.518691, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.765255, min response is -3.546015.
max gradient is 8.000000, min gradient is -4.726288, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.948627, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 23.199158, min response is -4.134149.
max gradient is 8.000000, min gradient is -7.407978, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.592946, learning rate is 0.000200
max inferred z is 4.23, min inferred z is -3.97, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 196: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.569607, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.538496, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.620224, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.391813, learning rate is 0.000400
Net2: layer deconv3:max response is 110.991898, min response is -86.250504.
max gradient is 4.906455, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 21.726635, min response is -3.428420.
max gradient is 8.000000, min gradient is -5.685331, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.563552, learning rate is 0.000200
Net2: layer bn49:max response is 24.255371, min response is -3.950868.
max gradient is 6.127452, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.378673, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.94, min inferred z is -3.94, and std is 1.00
 4.34 s (23.1 data/s) [100/100]
Loss: 1.0584
Iteration 197 / 200
training: epoch 197: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.066610, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.217844, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.622082, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.616726, learning rate is 0.000400
Net2: layer deconv3:max response is 94.663895, min response is -83.614044.
max gradient is 8.000000, min gradient is -3.748275, learning rate is 0.000200
Net2: layer bn50:max response is 17.921703, min response is -3.881714.
max gradient is 8.000000, min gradient is -7.552752, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.397295, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 16.902536, min response is -4.622913.
max gradient is 6.200354, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.425717, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.26, min inferred z is -3.81, and std is 1.00
 4.15 s (24.1 data/s) [100/100]
training: epoch 197: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.970531, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.436015, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.671391, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.058399, learning rate is 0.000400
Net2: layer deconv3:max response is 96.834770, min response is -74.143410.
max gradient is 5.315780, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.400961, min response is -3.929317.
max gradient is 8.000000, min gradient is -7.427540, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.223756, learning rate is 0.000200
Net2: layer bn49:max response is 20.641533, min response is -4.163730.
max gradient is 8.000000, min gradient is -6.081858, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.916466, learning rate is 0.000200
max inferred z is 3.61, min inferred z is -3.79, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
training: epoch 197: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.762110, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.358582, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.535968, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.602871, learning rate is 0.000400
Net2: layer deconv3:max response is 106.244965, min response is -69.585663.
max gradient is 8.000000, min gradient is -3.363746, learning rate is 0.000200
Net2: layer bn50:max response is 18.338434, min response is -4.231654.
max gradient is 8.000000, min gradient is -6.121037, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.458263, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.548487, min response is -3.987676.
max gradient is 7.829877, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.676366, learning rate is 0.000200
max inferred z is 4.20, min inferred z is -3.84, and std is 1.00
 4.36 s (23.0 data/s) [100/100]
training: epoch 197: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.527120, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.253027, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.546180, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.908605, learning rate is 0.000400
Net2: layer deconv3:max response is 96.168144, min response is -67.136971.
max gradient is 4.083285, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 16.562033, min response is -3.884054.
max gradient is 8.000000, min gradient is -6.819912, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.477457, learning rate is 0.000200
Net2: layer bn49:max response is 18.240086, min response is -3.829449.
max gradient is 8.000001, min gradient is -5.946432, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.017284, learning rate is 0.000200
max inferred z is 4.05, min inferred z is -3.89, and std is 1.00
 4.43 s (22.6 data/s) [100/100]
training: epoch 197: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.832824, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.141840, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.438737, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.698687, learning rate is 0.000400
Net2: layer deconv3:max response is 85.126617, min response is -64.862167.
max gradient is 8.000000, min gradient is -3.722012, learning rate is 0.000200
Net2: layer bn50:max response is 16.921467, min response is -3.546665.
max gradient is 7.515231, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.701163, learning rate is 0.000200
Net2: layer bn49:max response is 19.157604, min response is -3.617882.
max gradient is 7.291250, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.931947, learning rate is 0.000200
max inferred z is 3.83, min inferred z is -4.50, and std is 1.00
 4.26 s (23.5 data/s) [100/100]
training: epoch 197: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.681141, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.632826, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.727651, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.211983, learning rate is 0.000400
Net2: layer deconv3:max response is 95.382263, min response is -77.056221.
max gradient is 3.145772, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.454140, min response is -4.709112.
max gradient is 8.000000, min gradient is -6.820014, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.447303, learning rate is 0.000200
Net2: layer bn49:max response is 20.397795, min response is -4.763396.
max gradient is 8.000000, min gradient is -7.542100, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.893826, learning rate is 0.000200
max inferred z is 4.34, min inferred z is -3.86, and std is 1.00
 4.39 s (22.8 data/s) [100/100]
training: epoch 197: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.247946, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.233762, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.660746, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.265220, learning rate is 0.000400
Net2: layer deconv3:max response is 94.949501, min response is -74.607117.
max gradient is 8.000000, min gradient is -6.137741, learning rate is 0.000200
Net2: layer bn50:max response is 18.815262, min response is -4.262774.
max gradient is 6.225977, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.953993, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.517950, min response is -3.793254.
max gradient is 7.146252, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.107118, learning rate is 0.000200
max inferred z is 4.53, min inferred z is -4.40, and std is 1.00
 4.45 s (22.5 data/s) [100/100]
training: epoch 197: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.482843, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.330552, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.469020, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.077708, learning rate is 0.000400
Net2: layer deconv3:max response is 91.586189, min response is -68.612885.
max gradient is 4.967643, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 17.890400, min response is -3.894587.
max gradient is 8.000000, min gradient is -6.204321, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.815191, min gradient is -8.000001, learning rate is 0.000200
Net2: layer bn49:max response is 20.056795, min response is -4.196023.
max gradient is 8.000000, min gradient is -7.987323, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.765938, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.73, min inferred z is -4.35, and std is 1.00
 4.34 s (23.1 data/s) [100/100]
training: epoch 197: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.590578, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.335366, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.773852, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.782982, learning rate is 0.000400
Net2: layer deconv3:max response is 90.078690, min response is -68.598389.
max gradient is 8.000000, min gradient is -4.304473, learning rate is 0.000200
Net2: layer bn50:max response is 17.600784, min response is -3.620262.
max gradient is 6.324549, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.784652, learning rate is 0.000200
Net2: layer bn49:max response is 19.685232, min response is -4.079556.
max gradient is 8.000000, min gradient is -6.472134, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.091836, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.91, min inferred z is -4.61, and std is 1.00
 4.19 s (23.9 data/s) [100/100]
training: epoch 197: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.470690, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.458562, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.498779, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.432564, learning rate is 0.000400
Net2: layer deconv3:max response is 90.727806, min response is -67.436195.
max gradient is 5.144960, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 17.839741, min response is -3.866180.
max gradient is 7.740066, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.364440, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.161270, min response is -3.829844.
max gradient is 8.000000, min gradient is -6.582152, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.266990, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.55, min inferred z is -4.38, and std is 1.00
 4.32 s (23.2 data/s) [100/100]
Loss: 1.3158
Iteration 198 / 200
training: epoch 198: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.753916, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.505610, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.317633, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is -1.616047, learning rate is 0.000400
Net2: layer deconv3:max response is 86.286560, min response is -72.354546.
max gradient is 8.000000, min gradient is -5.922243, learning rate is 0.000200
Net2: layer bn50:max response is 17.265804, min response is -4.076618.
max gradient is 7.920954, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.574372, learning rate is 0.000200
Net2: layer bn49:max response is 19.610176, min response is -3.802296.
max gradient is 8.000000, min gradient is -7.651112, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.745416, learning rate is 0.000200
max inferred z is 5.21, min inferred z is -3.56, and std is 1.00
 4.23 s (23.6 data/s) [100/100]
training: epoch 198: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.929515, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.435386, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.672978, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.510798, learning rate is 0.000400
Net2: layer deconv3:max response is 107.871994, min response is -67.291397.
max gradient is 6.952119, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 16.910778, min response is -3.906457.
max gradient is 3.151764, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.882021, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.117031, min response is -3.951870.
max gradient is 8.000000, min gradient is -6.920053, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.969815, learning rate is 0.000200
max inferred z is 4.05, min inferred z is -3.99, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 198: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.761409, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.310221, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.524564, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.290067, learning rate is 0.000400
Net2: layer deconv3:max response is 126.722252, min response is -94.079788.
max gradient is 4.344661, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 24.124653, min response is -4.643449.
max gradient is 8.000000, min gradient is -5.647022, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.895205, learning rate is 0.000200
Net2: layer bn49:max response is 27.103657, min response is -3.873109.
max gradient is 7.172166, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.753956, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.97, min inferred z is -4.25, and std is 1.00
 4.23 s (23.7 data/s) [100/100]
training: epoch 198: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.631655, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.199312, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.417678, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.975017, learning rate is 0.000400
Net2: layer deconv3:max response is 88.322548, min response is -78.223869.
max gradient is 8.000000, min gradient is -4.219848, learning rate is 0.000200
Net2: layer bn50:max response is 19.171928, min response is -4.451955.
max gradient is 6.838323, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.875189, learning rate is 0.000200
Net2: layer bn49:max response is 19.431110, min response is -4.648718.
max gradient is 8.000000, min gradient is -7.074853, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.835226, learning rate is 0.000200
max inferred z is 4.03, min inferred z is -4.22, and std is 1.00
 4.42 s (22.6 data/s) [100/100]
training: epoch 198: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.885520, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.307808, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.518227, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.298681, learning rate is 0.000400
Net2: layer deconv3:max response is 93.232109, min response is -73.332787.
max gradient is 6.588221, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 17.289515, min response is -3.780886.
max gradient is 7.179501, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.124114, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.412428, min response is -4.303778.
max gradient is 6.029459, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000001, min gradient is -7.266780, learning rate is 0.000200
max inferred z is 4.18, min inferred z is -3.85, and std is 1.00
 4.41 s (22.7 data/s) [100/100]
training: epoch 198: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.676270, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.459379, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.359128, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.066601, learning rate is 0.000400
Net2: layer deconv3:max response is 99.635353, min response is -79.241211.
max gradient is 3.267655, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.770222, min response is -4.820976.
max gradient is 6.320769, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.717877, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 22.329679, min response is -3.818015.
max gradient is 8.000000, min gradient is -5.427394, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.966208, learning rate is 0.000200
max inferred z is 4.36, min inferred z is -3.89, and std is 1.00
 4.35 s (23.0 data/s) [100/100]
training: epoch 198: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.096506, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.300993, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.379894, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.883632, learning rate is 0.000400
Net2: layer deconv3:max response is 100.079216, min response is -77.856049.
max gradient is 8.000000, min gradient is -4.945591, learning rate is 0.000200
Net2: layer bn50:max response is 19.505453, min response is -4.272821.
max gradient is 6.892168, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.817492, learning rate is 0.000200
Net2: layer bn49:max response is 21.716232, min response is -3.998107.
max gradient is 6.629880, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.039665, learning rate is 0.000200
max inferred z is 3.63, min inferred z is -4.02, and std is 1.00
 4.28 s (23.4 data/s) [100/100]
training: epoch 198: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.513860, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.294001, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.510556, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.235415, learning rate is 0.000400
Net2: layer deconv3:max response is 93.022736, min response is -72.610123.
max gradient is 5.228233, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 17.899319, min response is -3.892105.
max gradient is 8.000000, min gradient is -4.488621, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.420215, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 19.919361, min response is -4.242077.
max gradient is 8.000000, min gradient is -6.578683, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.329247, learning rate is 0.000200
max inferred z is 4.17, min inferred z is -3.73, and std is 1.00
 4.25 s (23.5 data/s) [100/100]
training: epoch 198: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.607527, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.220269, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.880997, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 3.960686, learning rate is 0.000400
Net2: layer deconv3:max response is 102.398239, min response is -77.801346.
max gradient is 8.000000, min gradient is -3.579452, learning rate is 0.000200
Net2: layer bn50:max response is 19.657663, min response is -4.153046.
max gradient is 4.522296, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.680288, learning rate is 0.000200
Net2: layer bn49:max response is 22.107521, min response is -4.121644.
max gradient is 6.018139, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.175329, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.48, min inferred z is -4.57, and std is 1.00
 4.32 s (23.1 data/s) [100/100]
training: epoch 198: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.629412, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.350927, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.669963, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.904944, learning rate is 0.000400
Net2: layer deconv3:max response is 100.425728, min response is -73.274506.
max gradient is 2.413912, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.001736, min response is -4.003757.
max gradient is 8.000000, min gradient is -5.278934, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.568457, learning rate is 0.000200
Net2: layer bn49:max response is 21.101809, min response is -4.236904.
max gradient is 8.000000, min gradient is -5.222931, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.935129, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.29, min inferred z is -4.09, and std is 1.00
 4.23 s (23.7 data/s) [100/100]
Loss: 1.0534
Iteration 199 / 200
training: epoch 199: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.773619, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.362159, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.222217, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.752254, learning rate is 0.000400
Net2: layer deconv3:max response is 91.803123, min response is -71.696960.
max gradient is 8.000000, min gradient is -4.971815, learning rate is 0.000200
Net2: layer bn50:max response is 17.851269, min response is -4.025889.
max gradient is 4.023839, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.217793, learning rate is 0.000200
Net2: layer bn49:max response is 20.421497, min response is -3.888152.
max gradient is 6.436685, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.688235, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.87, min inferred z is -4.27, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
training: epoch 199: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.889851, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.450955, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.509857, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 4.821294, learning rate is 0.000400
Net2: layer deconv3:max response is 89.254417, min response is -82.919907.
max gradient is 4.592819, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.812752, min response is -4.239208.
max gradient is 8.000000, min gradient is -4.595356, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.999454, learning rate is 0.000200
Net2: layer bn49:max response is 17.888702, min response is -4.960353.
max gradient is 8.000000, min gradient is -7.508357, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.722015, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.80, min inferred z is -4.14, and std is 1.00
 4.36 s (22.9 data/s) [100/100]
training: epoch 199: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.762794, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.389043, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.422501, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.502105, learning rate is 0.000400
Net2: layer deconv3:max response is 86.629158, min response is -73.978882.
max gradient is 4.915732, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 16.632761, min response is -3.360034.
max gradient is 7.851281, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.489874, learning rate is 0.000200
Net2: layer bn49:max response is 18.564697, min response is -4.363204.
max gradient is 6.337153, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.964168, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.07, min inferred z is -3.88, and std is 1.00
 4.38 s (22.8 data/s) [100/100]
training: epoch 199: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.659029, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.429782, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.576906, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.785154, learning rate is 0.000400
Net2: layer deconv3:max response is 111.805794, min response is -83.661491.
max gradient is 8.000000, min gradient is -4.029351, learning rate is 0.000200
Net2: layer bn50:max response is 21.514135, min response is -3.986266.
max gradient is 7.340872, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.309464, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 24.326468, min response is -3.814297.
max gradient is 4.515771, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -5.493868, learning rate is 0.000200
max inferred z is 3.81, min inferred z is -4.08, and std is 1.00
 4.18 s (23.9 data/s) [100/100]
training: epoch 199: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.762510, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.375678, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.541349, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.829516, learning rate is 0.000400
Net2: layer deconv3:max response is 95.840538, min response is -72.473450.
max gradient is 2.657088, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.577143, min response is -4.116329.
max gradient is 8.000000, min gradient is -6.310496, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -5.636986, learning rate is 0.000200
Net2: layer bn49:max response is 21.342289, min response is -4.092663.
max gradient is 8.000000, min gradient is -5.303503, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.750279, learning rate is 0.000200
max inferred z is 3.90, min inferred z is -4.13, and std is 1.00
 4.24 s (23.6 data/s) [100/100]
training: epoch 199: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.743536, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.471605, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.401096, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.816438, learning rate is 0.000400
Net2: layer deconv3:max response is 87.874374, min response is -65.585098.
max gradient is 8.000000, min gradient is -3.566109, learning rate is 0.000200
Net2: layer bn50:max response is 15.736996, min response is -3.890012.
max gradient is 6.513839, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 5.764996, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 17.199020, min response is -3.898669.
max gradient is 8.000000, min gradient is -5.999845, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 5.297525, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.73, min inferred z is -4.07, and std is 1.00
 4.34 s (23.1 data/s) [100/100]
training: epoch 199: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.194458, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.323966, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.651277, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.794620, learning rate is 0.000400
Net2: layer deconv3:max response is 92.487251, min response is -73.112190.
max gradient is 4.193760, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.089460, min response is -4.006373.
max gradient is 8.000000, min gradient is -5.854225, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.224799, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.337208, min response is -4.302743.
max gradient is 8.000000, min gradient is -7.238568, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.592267, learning rate is 0.000200
max inferred z is 3.87, min inferred z is -3.77, and std is 1.00
 4.43 s (22.6 data/s) [100/100]
training: epoch 199: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.434004, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.476228, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.418303, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.494973, learning rate is 0.000400
Net2: layer deconv3:max response is 88.103035, min response is -84.872169.
max gradient is 8.000000, min gradient is -4.358780, learning rate is 0.000200
Net2: layer bn50:max response is 18.219967, min response is -4.316667.
max gradient is 6.861623, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.747534, learning rate is 0.000200
Net2: layer bn49:max response is 19.706818, min response is -3.461868.
max gradient is 6.916920, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.594004, learning rate is 0.000200
max inferred z is 4.27, min inferred z is -4.05, and std is 1.00
 4.30 s (23.2 data/s) [100/100]
training: epoch 199: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.497327, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.148736, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.541439, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.163864, learning rate is 0.000400
Net2: layer deconv3:max response is 95.104134, min response is -73.397400.
max gradient is 7.586958, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.419828, min response is -3.845253.
max gradient is 6.675292, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.956138, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.758825, min response is -4.342177.
max gradient is 6.575869, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.955843, learning rate is 0.000200
max inferred z is 4.50, min inferred z is -3.96, and std is 1.00
 4.32 s (23.2 data/s) [100/100]
training: epoch 199: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.570221, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.489929, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.586336, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.284179, learning rate is 0.000400
Net2: layer deconv3:max response is 102.257629, min response is -79.780418.
max gradient is 6.001605, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 18.933964, min response is -4.078760.
max gradient is 8.000000, min gradient is -4.768260, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.396316, learning rate is 0.000200
Net2: layer bn49:max response is 21.496620, min response is -4.517057.
max gradient is 8.000000, min gradient is -5.477458, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.167428, learning rate is 0.000200
max inferred z is 3.78, min inferred z is -3.63, and std is 1.00
 4.30 s (23.3 data/s) [100/100]
Loss: 1.047
Iteration 200 / 200
training: epoch 200: batch   1/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.765199, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.287164, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.464751, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.713796, learning rate is 0.000400
Net2: layer deconv3:max response is 101.106606, min response is -87.783180.
max gradient is 5.640878, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 20.138227, min response is -3.865623.
max gradient is 7.327146, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.847470, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.954306, min response is -4.800682.
max gradient is 5.290828, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.028001, learning rate is 0.000200
max inferred z is 3.89, min inferred z is -4.21, and std is 0.99
 4.17 s (24.0 data/s) [100/100]
training: epoch 200: batch   2/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.827265, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.324898, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.331194, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 2.331371, learning rate is 0.000400
Net2: layer deconv3:max response is 85.805038, min response is -76.077797.
max gradient is 8.000000, min gradient is -4.211070, learning rate is 0.000200
Net2: layer bn50:max response is 16.532598, min response is -3.853233.
max gradient is 7.213615, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.940859, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 18.707554, min response is -4.589185.
max gradient is 8.000000, min gradient is -6.722966, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.278080, learning rate is 0.000200
max inferred z is 3.93, min inferred z is -3.65, and std is 0.99
 4.22 s (23.7 data/s) [100/100]
training: epoch 200: batch   3/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.726716, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.381793, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.341580, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 6.853294, learning rate is 0.000400
Net2: layer deconv3:max response is 85.378014, min response is -67.974083.
max gradient is 3.794512, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 16.859325, min response is -3.862938.
max gradient is 8.000000, min gradient is -7.299829, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -6.797083, learning rate is 0.000200
Net2: layer bn49:max response is 19.065033, min response is -3.642480.
max gradient is 8.000000, min gradient is -7.044205, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -4.887694, learning rate is 0.000200
max inferred z is 3.82, min inferred z is -3.93, and std is 0.99
 4.29 s (23.3 data/s) [100/100]
training: epoch 200: batch   4/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.599000, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.341532, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.534101, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.185244, learning rate is 0.000400
Net2: layer deconv3:max response is 95.924500, min response is -85.332565.
max gradient is 8.000000, min gradient is -3.464509, learning rate is 0.000200
Net2: layer bn50:max response is 19.612352, min response is -4.289403.
max gradient is 5.860070, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.983691, min gradient is -8.000001, learning rate is 0.000200
Net2: layer bn49:max response is 20.145308, min response is -5.063066.
max gradient is 7.575486, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.751331, learning rate is 0.000200
max inferred z is 4.10, min inferred z is -4.78, and std is 0.99
 4.32 s (23.2 data/s) [100/100]
training: epoch 200: batch   5/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.658577, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.363002, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.396187, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 7.685824, min gradient is 6.194295, learning rate is 0.000400
Net2: layer deconv3:max response is 105.668167, min response is -76.563881.
max gradient is 1.941325, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 19.417755, min response is -4.488250.
max gradient is 8.000000, min gradient is -5.748395, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.759807, learning rate is 0.000200
Net2: layer bn49:max response is 21.897190, min response is -3.658935.
max gradient is 8.000000, min gradient is -7.040760, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 8.000000, min gradient is -6.366653, learning rate is 0.000200
max inferred z is 4.05, min inferred z is -3.74, and std is 0.99
 4.39 s (22.8 data/s) [100/100]
training: epoch 200: batch   6/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.787392, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.509503, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.526697, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.397371, learning rate is 0.000400
Net2: layer deconv3:max response is 129.003616, min response is -84.833237.
max gradient is 8.000000, min gradient is -2.825857, learning rate is 0.000200
Net2: layer bn50:max response is 21.579823, min response is -4.377363.
max gradient is 8.000000, min gradient is -7.663868, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.662616, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.365047, min response is -4.891321.
max gradient is 6.453350, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 6.510909, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.28, min inferred z is -4.39, and std is 0.99
 4.40 s (22.7 data/s) [100/100]
training: epoch 200: batch   7/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.036117, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.241414, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.521619, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.750529, learning rate is 0.000400
Net2: layer deconv3:max response is 87.705666, min response is -70.206779.
max gradient is 3.706384, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 15.844544, min response is -3.589991.
max gradient is 8.000000, min gradient is -6.120520, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.649187, learning rate is 0.000200
Net2: layer bn49:max response is 17.967501, min response is -3.941412.
max gradient is 8.000000, min gradient is -6.604176, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.591183, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.96, min inferred z is -3.65, and std is 0.99
 4.27 s (23.4 data/s) [100/100]
training: epoch 200: batch   8/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.425088, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.442968, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.453441, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.831120, learning rate is 0.000400
Net2: layer deconv3:max response is 96.822975, min response is -77.850319.
max gradient is 8.000000, min gradient is -2.842557, learning rate is 0.000200
Net2: layer bn50:max response is 18.838140, min response is -4.534913.
max gradient is 6.366620, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 6.950819, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 21.281588, min response is -4.574911.
max gradient is 7.637201, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 4.931489, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.97, min inferred z is -3.65, and std is 0.99
 4.43 s (22.5 data/s) [100/100]
training: epoch 200: batch   9/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 4.585588, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.181903, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.582992, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 5.950812, learning rate is 0.000400
Net2: layer deconv3:max response is 87.680756, min response is -69.098625.
max gradient is 5.536818, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 17.593538, min response is -4.139910.
max gradient is 8.000000, min gradient is -6.215764, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 8.000000, min gradient is -7.267436, learning rate is 0.000200
Net2: layer bn49:max response is 18.004765, min response is -3.998054.
max gradient is 7.406180, min gradient is -8.000000, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.951800, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 4.46, min inferred z is -3.74, and std is 0.99
 4.51 s (22.2 data/s) [100/100]
training: epoch 200: batch  10/ 10: 
Net1: layer conv3:max response is , min response is .
max gradient is 3.464312, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv2:max response is , min response is .
max gradient is 4.520154, min gradient is -8.000000, learning rate is 0.000000
Net1: layer conv1:max response is , min response is .
max gradient is 8.000000, min gradient is -7.496581, learning rate is 0.000000
Net2: layer bn51:max response is 1.000000, min response is -1.000000.
max gradient is 8.000000, min gradient is 7.305086, learning rate is 0.000400
Net2: layer deconv3:max response is 92.369125, min response is -76.359215.
max gradient is 7.469016, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn50:max response is 17.697403, min response is -3.743276.
max gradient is 8.000000, min gradient is -4.767375, learning rate is 0.000400
Net2: layer deconv2:max response is , min response is .
max gradient is 7.818898, min gradient is -8.000000, learning rate is 0.000200
Net2: layer bn49:max response is 20.097631, min response is -4.420092.
max gradient is 8.000000, min gradient is -6.343056, learning rate is 0.000400
Net2: layer deconv1:max response is , min response is .
max gradient is 7.838040, min gradient is -8.000000, learning rate is 0.000200
max inferred z is 3.64, min inferred z is -3.93, and std is 0.99
 4.37 s (22.9 data/s) [100/100]
Loss: 1.1459
total learning time is 2 hours / 53 minutes / 27.84 seconds.
experiment_learn_escher_34
